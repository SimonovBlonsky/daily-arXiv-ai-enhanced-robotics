<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation](https://arxiv.org/abs/2602.15060)
*Tengjie Zhu,Guanyu Cai,Yang Zhaohui,Guanzhu Ren,Haohui Xie,ZiRui Wang,Junsong Wu,Jingbo Wang,Xiaokang Yang,Yao Mu,Yichao Yan,Yichao Yan*

Main category: cs.RO

TL;DR: CLOT是一个实时全身人形机器人遥操作系统，通过高频定位反馈实现闭环全局运动跟踪，解决了长时间遥操作中的全局姿态漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型跟踪方法通常在机器人局部坐标系中运行，忽略了全局姿态反馈，导致长时间执行时出现漂移和不稳定性。长时程全身人形机器人遥操作面临全局姿态漂移累积的挑战。

Method: 提出CLOT系统，通过数据驱动的随机化策略将观察轨迹与奖励评估解耦，实现平滑稳定的全局校正；使用对抗运动先验正则化策略抑制不自然行为；收集20小时人类运动数据训练基于Transformer的策略。

Result: 在31自由度全尺寸人形机器人上部署，仿真和真实世界实验验证了高动态运动、高精度跟踪以及强大的sim-to-real鲁棒性。训练超过1300GPU小时。

Conclusion: CLOT实现了无漂移的人对人形机器人模仿，解决了长时程遥操作中的全局姿态漂移问题，为实时全身人形机器人遥操作提供了有效的闭环全局跟踪解决方案。

Abstract: Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.

</details>


### [2] [Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories](https://arxiv.org/abs/2602.15061)
*Zihan Zhang,Haohui Que,Junhan Chang,Xin Zhang,Hao Wei,Tong Zhu*

Main category: cs.RO

TL;DR: Safe-SDL框架为自主科学实验室提供安全保障，通过形式化操作设计域、控制屏障函数和事务安全协议解决AI生成指令与物理安全之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 自主驾驶实验室（SDLs）将AI与机器人自动化结合，能极大加速科学发现，但部署时面临独特的安全挑战，特别是"语法到安全鸿沟"——AI生成的语法正确指令与物理安全影响之间的脱节。

Method: 提出Safe-SDL框架，包含三个协同组件：1) 形式化定义的操作设计域（ODDs），将系统行为限制在数学验证的边界内；2) 控制屏障函数（CBFs），通过连续状态空间监控提供实时安全保证；3) 新颖的事务安全协议（CRUTD），确保数字规划与物理执行之间的原子一致性。

Result: 通过对UniLabOS和Osprey架构等现有实现的分析，验证了安全原则的实例化。在LabSafety Bench上的评估显示，当前基础模型存在显著的安全失败，证明架构安全机制是必需而非可选的。

Conclusion: Safe-SDL框架为自主科学系统的安全部署提供了理论基础和实践指导，为负责任地加速AI驱动的科学发现奠定了基础。

Abstract: The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.

</details>


### [3] [Augmenting Human Balance with Generic Supernumerary Robotic Limbs](https://arxiv.org/abs/2602.15092)
*Xuanyun Qiu,Dorian Verdel,Hector Cervantes-Culebro,Alexis Devillard,Etienne Burdet*

Main category: cs.RO

TL;DR: 提出了一种通用框架，通过三层分层架构（预测、规划、控制层）来保持人机系统平衡，实验证明能有效减少站立不稳定性


<details>
  <summary>Details</summary>
Motivation: 超限机器人肢体（SLs）在广泛应用中具有潜力，但其可用性受到安全和多功能控制等关键技术挑战的限制。特别是保持人机系统平衡是安全舒适增强任务的前提条件，而现有方法多针对特定稳定性支持设计SLs，缺乏通用解决方案。

Method: 提出通用三层分层架构：1）预测层：估计人体躯干和质心动力学；2）规划层：生成最优质心轨迹以抵消躯干运动，并计算相应的SL控制输入；3）控制层：在SL硬件上执行这些控制输入。

Result: 在10名参与者进行前后和侧向弯曲任务的实验中，结果显示站立不稳定性明显减少，证明了该框架在增强平衡方面的有效性。

Conclusion: 这项工作为实现安全、多功能的人机交互铺平了道路，为解决超限机器人肢体系统的平衡问题提供了通用框架。

Abstract: Supernumerary robotic limbs (SLs) have the potential to transform a wide range of human activities, yet their usability remains limited by key technical challenges, particularly in ensuring safety and achieving versatile control. Here, we address the critical problem of maintaining balance in the human-SLs system, a prerequisite for safe and comfortable augmentation tasks. Unlike previous approaches that developed SLs specifically for stability support, we propose a general framework for preserving balance with SLs designed for generic use. Our hierarchical three-layer architecture consists of: (i) a prediction layer that estimates human trunk and center of mass (CoM) dynamics, (ii) a planning layer that generates optimal CoM trajectories to counteract trunk movements and computes the corresponding SL control inputs, and (iii) a control layer that executes these inputs on the SL hardware. We evaluated the framework with ten participants performing forward and lateral bending tasks. The results show a clear reduction in stance instability, demonstrating the framework's effectiveness in enhancing balance. This work paves the path towards safe and versatile human-SLs interactions. [This paper has been submitted for publication to IEEE.]

</details>


### [4] [A ROS2 Benchmarking Framework for Hierarchical Control Strategies in Mobile Robots for Mediterranean Greenhouses](https://arxiv.org/abs/2602.15162)
*Fernando Cañadas-Aránega,Francisco J. Mañas-Álvarez,José L- Guzmán,José C. Moreno,José L. Blanco-Claraco*

Main category: cs.RO

TL;DR: 提出用于温室环境下移动机器人控制器的综合基准测试框架，包含三维环境模型、物理仿真器和分层控制架构，定义三类基准测试和三种干扰场景，引入标准化性能指标确保客观可重复评估。


<details>
  <summary>Details</summary>
Motivation: 农业环境中移动机器人面临不平坦地形、可变摩擦、负载变化和坡度等挑战条件，影响控制性能和稳定性。目前缺乏标准化、可重复的基准测试，阻碍了在真实操作条件下控制策略的公平比较和系统评估。

Method: 集成精确的三维环境模型、基于物理的仿真器和分层控制架构（低、中、高层控制层）。定义三类基准测试（从执行器级控制到完全自主导航），明确建模三种干扰场景（负载变化、地形类型和坡度）。引入标准化性能指标（SAE、SCI和综合性能指数），采用基于重复试验的统计分析减少传感器噪声和环境变异性的影响，并提供插件式架构便于用户自定义控制器和规划器的集成。

Result: 该框架提供了一个稳健且可扩展的工具，用于在真实条件下对经典、预测和基于规划的控制策略进行定量比较，弥合了基于仿真的分析与真实农业工业应用之间的差距。

Conclusion: 提出的基准测试框架为温室环境下移动机器人控制器的评估提供了客观、可重复的标准化方法，有助于推动农业机器人控制策略的公平比较和系统改进。

Abstract: Mobile robots operating in agroindustrial environments, such as Mediterranean greenhouses, are subject to challenging conditions, including uneven terrain, variable friction, payload changes, and terrain slopes, all of which significantly affect control performance and stability. Despite the increasing adoption of robotic platforms in agriculture, the lack of standardized, reproducible benchmarks impedes fair comparisons and systematic evaluations of control strategies under realistic operating conditions. This paper presents a comprehensive benchmarking framework for evaluating mobile robot controllers in greenhouse environments. The proposed framework integrates an accurate three dimensional model of the environment, a physics based simulator, and a hierarchical control architecture comprising low, mid, and high level control layers. Three benchmark categories are defined to enable modular assessment, ranging from actuator level control to full autonomous navigation. Additionally, three disturbance scenarios payload variation, terrain type, and slope are explicitly modeled to replicate real world agricultural conditions. To ensure objective and reproducible evaluation, standardized performance metrics are introduced, including the Squared Absolute Error (SAE), the Squared Control Input (SCI), and composite performance indices. Statistical analysis based on repeated trials is employed to mitigate the influence of sensor noise and environmental variability. The framework is further enhanced by a plugin based architecture that facilitates seamless integration of user defined controllers and planners. The proposed benchmark provides a robust and extensible tool for the quantitative comparison of classical, predictive, and planning based control strategies in realistic conditions, bridging the gap between simulation based analysis and real world agroindustrial applications.

</details>


### [5] [DexEvolve: Evolutionary Optimization for Robust and Diverse Dexterous Grasp Synthesis](https://arxiv.org/abs/2602.15201)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 提出一个可扩展的生成-精炼流程，用于合成大规模、多样化且物理可行的抓取，通过进化算法在仿真中优化分析生成的抓取，并将结果蒸馏到扩散模型中


<details>
  <summary>Details</summary>
Motivation: 数据驱动的抓取预测依赖昂贵的数据集且通常局限于特定夹爪形态，而分析方法因简化假设常产生物理不可行的抓取，需要高保真仿真过滤，这减少了抓取数量和多样性

Method: 提出可扩展的生成-精炼流程：1) 用分析方法生成种子抓取集；2) 在Isaac Sim高保真仿真中使用异步无梯度进化算法优化抓取质量；3) 将精炼后的抓取分布蒸馏到扩散模型中用于实际部署

Result: 在Handles数据集和DexGraspNet子集上，每个物体获得超过120个不同的稳定抓取（比未精炼分析方法提升1.7-6倍），在独特抓取覆盖率上比基于扩散的方法提升46-60%

Conclusion: 该方法通过将高保真仿真作为优化阶段而非仅用于验证，显著提高了抓取数量、多样性和物理可行性，同时强调了多样性在训练和部署中的重要性

Abstract: Dexterous grasping is fundamental to robotics, yet data-driven grasp prediction heavily relies on large, diverse datasets that are costly to generate and typically limited to a narrow set of gripper morphologies. Analytical grasp synthesis can be used to scale data collection, but necessary simplifying assumptions often yield physically infeasible grasps that need to be filtered in high-fidelity simulators, significantly reducing the total number of grasps and their diversity.
  We propose a scalable generate-and-refine pipeline for synthesizing large-scale, diverse, and physically feasible grasps. Instead of using high-fidelity simulators solely for verification and filtering, we leverage them as an optimization stage that continuously improves grasp quality without discarding precomputed candidates. More specifically, we initialize an evolutionary search with a seed set of analytically generated, potentially suboptimal grasps. We then refine these proposals directly in a high-fidelity simulator (Isaac Sim) using an asynchronous, gradient-free evolutionary algorithm, improving stability while maintaining diversity. In addition, this refinement stage can be guided toward human preferences and/or domain-specific quality metrics without requiring a differentiable objective. We further distill the refined grasp distribution into a diffusion model for robust real-world deployment, and highlight the role of diversity for both effective training and during deployment. Experiments on a newly introduced Handles dataset and a DexGraspNet subset demonstrate that our approach achieves over 120 distinct stable grasps per object (a 1.7-6x improvement over unrefined analytical methods) while outperforming diffusion-based alternatives by 46-60\% in unique grasp coverage.

</details>


### [6] [OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy](https://arxiv.org/abs/2602.15309)
*Mostafa A. Atalla,Anand S. Sekar,Remi van Starkenburg,David J. Jager,Aimée Sakes,Michaël Wiertlewski,Paul Breedveld*

Main category: cs.RO

TL;DR: OSCAR是一种受寄生蜂产卵器启发的自推进胶囊机器人，通过相位编码的摩擦各向异性在结肠中产生可控推力，实现无轴结肠镜检查。


<details>
  <summary>Details</summary>
Motivation: 传统结肠镜检查存在轴管打结问题，导致患者不适。在结肠的湿滑、粘弹性环境中可靠移动是一个重大挑战。需要开发一种能够在低法向载荷下产生可控推力的自推进胶囊机器人。

Method: OSCAR采用受寄生蜂产卵器启发的运动模式，通过弹簧加载的凸轮系统驱动12个周向滑块进行协调、相位偏移的序列运动。通过调整运动轮廓以最大化回缩阶段相对于前进阶段的持续时间，在界面处创建受控的摩擦各向异性，从而产生净向前推力。开发了包含Kelvin-Voigt公式的解析模型来捕捉滑块与组织之间的粘弹性粘滑相互作用。

Result: 在离体猪结肠中的综合力表征实验显示平均稳态牵引力为0.85N，与模型预测相符。推力生成与速度无关，并随相位不对称性线性缩放。在运动验证实验中，OSCAR实现了平均速度3.08mm/s，足以匹配传统结肠镜的盲肠插管时间。

Conclusion: 通过将相位编码的摩擦各向异性与预测模型相结合，OSCAR能够在低法向载荷下实现可控的推力生成，为机器人胶囊结肠镜检查提供更安全、更稳健的自推进运动。

Abstract: Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.

</details>


### [7] [Feasibility-aware Imitation Learning from Observation with Multimodal Feedback](https://arxiv.org/abs/2602.15351)
*Kei Takahashi,Hikaru Sasaki,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: FABCO框架通过可行性估计和多模态反馈，解决模仿学习中演示者与机器人物理特性差异导致的数据缺失和动作不可行问题，提升模仿学习性能3.2倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统基于手部演示接口的模仿学习面临两个主要问题：1）演示数据不包含机器人动作；2）演示动作可能对机器人不可行。这些限制使得策略学习变得困难。

Method: 提出可行性感知行为克隆观察（FABCO）框架，整合行为克隆观察（使用机器人动力学模型补充机器人动作）和可行性估计。可行性估计通过从机器人执行数据学习的动力学模型评估演示动作的可重现性。使用多模态反馈（视觉和触觉）促进可行演示动作，并通过可行性感知策略学习减少不可行演示动作的影响。

Result: 在15名参与者的两个任务实验中，FABCO相比无可行性反馈的情况，将模仿学习性能提升了3.2倍以上。

Conclusion: FABCO通过整合可行性估计和多模态反馈，有效解决了演示者与机器人物理特性差异带来的问题，显著提升了模仿学习的性能和稳定性。

Abstract: Imitation learning frameworks that learn robot control policies from demonstrators' motions via hand-mounted demonstration interfaces have attracted increasing attention. However, due to differences in physical characteristics between demonstrators and robots, this approach faces two limitations: i) the demonstration data do not include robot actions, and ii) the demonstrated motions may be infeasible for robots. These limitations make policy learning difficult. To address them, we propose Feasibility-Aware Behavior Cloning from Observation (FABCO). FABCO integrates behavior cloning from observation, which complements robot actions using robot dynamics models, with feasibility estimation. In feasibility estimation, the demonstrated motions are evaluated using a robot-dynamics model, learned from the robot's execution data, to assess reproducibility under the robot's dynamics. The estimated feasibility is used for multimodal feedback and feasibility-aware policy learning to improve the demonstrator's motions and learn robust policies. Multimodal feedback provides feasibility through the demonstrator's visual and haptic senses to promote feasible demonstrated motions. Feasibility-aware policy learning reduces the influence of demonstrated motions that are infeasible for robots, enabling the learning of policies that robots can execute stably. We conducted experiments with 15 participants on two tasks and confirmed that FABCO improves imitation learning performance by more than 3.2 times compared to the case without feasibility feedback.

</details>


### [8] [A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking](https://arxiv.org/abs/2602.15354)
*Jose Luis Peralta-Cabezas,Miguel Torres-Torriti,Marcelo Guarini-Hermann*

Main category: cs.RO

TL;DR: 本文比较了多种估计和预测技术在跟踪多个机器人问题上的性能，主要评估标准包括误差大小、计算量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究不同估计和预测技术在多机器人跟踪问题中的性能表现，为实际应用提供技术选择依据。

Method: 比较了卡尔曼滤波器及其变体（扩展卡尔曼滤波、无迹卡尔曼滤波）与基于序列蒙特卡洛采样的方法（粒子滤波、高斯混合西格玛点粒子滤波）。

Result: 对各种方法在估计误差、计算复杂度和非高斯噪声鲁棒性方面进行了系统比较。

Conclusion: 为多机器人跟踪问题提供了不同估计和预测技术的性能评估，帮助用户根据具体需求选择合适的方法。

Abstract: This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.

</details>


### [9] [Fluoroscopy-Constrained Magnetic Robot Control via Zernike-Based Field Modeling and Nonlinear MPC](https://arxiv.org/abs/2602.15357)
*Xinhao Chen,Hongkun Yao,Anuruddha Bhattacharjee,Suraj Raval,Lamar O. Mair,Yancy Diaz-Mercado,Axel Krieger*

Main category: cs.RO

TL;DR: 该论文提出了一种用于磁驱动手术机器人的控制框架，能够在低帧率、噪声大的荧光成像条件下保持精确稳定控制，通过NMPC、可微磁场模型和卡尔曼滤波器的组合实现。


<details>
  <summary>Details</summary>
Motivation: 磁驱动手术机器人能够导航复杂的解剖路径，减少组织创伤并提高手术精度，但其临床部署受到荧光成像条件下控制的限制，因为荧光成像提供低帧率和噪声大的姿态反馈。

Method: 提出了一种控制框架，结合了直接输出线圈电流的非线性模型预测控制(NMPC)、基于Zernike多项式的解析可微磁场模型，以及用于估计机器人状态的卡尔曼滤波器。

Result: 实验验证表明，当反馈降采样至3Hz并添加高斯噪声(σ=2mm)以模拟临床荧光成像时，该方法仍保持高精度。在脊柱模型实验中，成功执行了药物输送轨迹，均方根位置误差为1.18mm，同时保持与关键解剖边界的安全距离。

Conclusion: 该控制框架能够在临床荧光成像的挑战性条件下实现磁驱动手术机器人的精确稳定控制，为磁驱动手术机器人的临床部署提供了可行的解决方案。

Abstract: Magnetic actuation enables surgical robots to navigate complex anatomical pathways while reducing tissue trauma and improving surgical precision. However, clinical deployment is limited by the challenges of controlling such systems under fluoroscopic imaging, which provides low frame rate and noisy pose feedback. This paper presents a control framework that remains accurate and stable under such conditions by combining a nonlinear model predictive control (NMPC) framework that directly outputs coil currents, an analytically differentiable magnetic field model based on Zernike polynomials, and a Kalman filter to estimate the robot state. Experimental validation is conducted with two magnetic robots in a 3D-printed fluid workspace and a spine phantom replicating drug delivery in the epidural space. Results show the proposed control method remains highly accurate when feedback is downsampled to 3 Hz with added Gaussian noise (sigma = 2 mm), mimicking clinical fluoroscopy. In the spine phantom experiments, the proposed method successfully executed a drug delivery trajectory with a root mean square (RMS) position error of 1.18 mm while maintaining safe clearance from critical anatomical boundaries.

</details>


### [10] [ActionCodec: What Makes for Good Action Tokenizers](https://arxiv.org/abs/2602.15397)
*Zibin Dong,Yicheng Liu,Shiduo Zhang,Baijun Ye,Yifu Yuan,Fei Ni,Jingjing Gong,Xipeng Qiu,Hang Zhao,Yinchuan Li,Jianye Hao*

Main category: cs.RO

TL;DR: 本文针对VLA模型中的动作分词器设计问题，从优化角度提出了信息论指导的设计原则，并开发了ActionCodec分词器，显著提升了训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型中的动作分词器设计主要关注重建保真度，忽视了其对VLA优化的直接影响，缺乏系统性的设计原则来回答"什么构成好的动作分词器"这一根本问题。

Method: 基于信息论洞察建立动作分词器的设计原则，包括最大化时间token重叠、最小化词汇冗余、增强多模态互信息和token独立性，并据此开发了ActionCodec分词器。

Result: ActionCodec显著提升了训练效率和VLA性能，在LIBERO基准上，SmolVLM2-2.2B使用ActionCodec微调达到95.5%成功率；结合架构增强后达到97.4%，创下了无机器人预训练的VLA模型新SOTA。

Conclusion: 本文提出的设计原则和ActionCodec为社区开发更有效的动作分词器提供了清晰路线图，解决了动作分词器设计中的关键优化问题。

Abstract: Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.

</details>


### [11] [Hybrid F' and ROS2 Architecture for Vision-Based Autonomous Flight: Design and Experimental Validation](https://arxiv.org/abs/2602.15398)
*Abdelrahman Metwally,Monijesu James,Aleksey Fedoseev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Andrey Somov*

Main category: cs.RO

TL;DR: 本文提出了一种结合NASA F'飞行软件框架与ROS2中间件的混合架构，通过室内四旋翼飞行测试验证了该架构在实时性能、数据连续性和系统资源利用方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 自主航空航天系统需要平衡确定性实时控制与先进感知能力的架构。传统认证级飞行软件缺乏灵活性，而现代自主系统需要结合确定性控制与灵活的感知处理能力。

Method: 采用NASA的F'飞行软件框架与ROS2中间件通过Protocol Buffers桥接的集成系统。通过32.25分钟的室内四旋翼飞行测试，使用基于视觉的导航进行评估。

Result: 视觉系统达到87.19 Hz位置估计频率，99.90%数据连续性，11.47 ms平均延迟。所有15个地面命令执行成功（100%成功率）。系统资源利用率低（15.19% CPU，1244 MB RAM），无陈旧遥测消息。

Conclusion: 结果验证了混合飞行软件架构的可行性，能够结合认证级确定性与灵活自主性，适用于自主飞行器系统。

Abstract: Autonomous aerospace systems require architectures that balance deterministic real-time control with advanced perception capabilities. This paper presents an integrated system combining NASA's F' flight software framework with ROS2 middleware via Protocol Buffers bridging. We evaluate the architecture through a 32.25-minute indoor quadrotor flight test using vision-based navigation. The vision system achieved 87.19 Hz position estimation with 99.90\% data continuity and 11.47 ms mean latency, validating real-time performance requirements. All 15 ground commands executed successfully with 100 % success rate, demonstrating robust F'--PX4 integration. System resource utilization remained low (15.19 % CPU, 1,244 MB RAM) with zero stale telemetry messages, confirming efficient operation on embedded platforms. Results validate the feasibility of hybrid flight-software architectures combining certification-grade determinism with flexible autonomy for autonomous aerial vehicles.

</details>


### [12] [One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](https://arxiv.org/abs/2602.15400)
*Zerui Li,Hongpei Zheng,Fangguo Zhao,Aidan Chan,Jian Zhou,Sihao Lin,Shijie Li,Qi Wu*

Main category: cs.RO

TL;DR: 提出解耦导航框架，将空间状态估计与语义规划分离，引入交互式度量世界表示，实现零样本SOTA性能并验证跨平台迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于MLLM的导航系统采用紧耦合设计，限制了系统性能。需要分离低层空间状态估计与高层语义规划，同时需要超越简化文本地图的丰富空间表示。

Method: 提出解耦设计：1) 分离空间状态估计与语义规划；2) 引入交互式度量世界表示，保持丰富一致的空间信息；3) 引入反事实推理激发MLLM能力；4) 度量表示确保动作的物理有效性。

Result: 在R2R-CE和RxR-CE基准测试中分别达到48.8%和42.2%的成功率，实现零样本SOTA。在真实世界验证了跨平台迁移能力，包括轮式机器人和无人机。

Conclusion: 解耦框架结合交互式度量世界表示，为具身视觉语言导航提供了鲁棒、领域不变的接口，显著提升了导航性能并支持跨平台部署。

Abstract: A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\% Success Rate (SR) in R2R-CE and 42.2\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.

</details>


### [13] [Lyapunov-Based $\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot](https://arxiv.org/abs/2602.15424)
*Branimir Ćaran,Vladimir Milić,Bojan Jerbić*

Main category: cs.RO

TL;DR: 提出基于Lyapunov的PI类控制器设计方法，用于四轮独立驱动转向移动机器人的L₂稳定运动控制


<details>
  <summary>Details</summary>
Motivation: 为四轮独立驱动转向移动机器人开发具有严格稳定性保证的运动控制器，解决配置依赖效应问题，适合实时嵌入式实现

Method: 基于显式结构验证模型，构造Lyapunov函数，推导显式边界和L₂稳定性结果，设计保持PI形式的控制律

Result: 控制器在真实四轮移动机器人平台上实验验证了有效性和鲁棒性，同时保持标准嵌入式实现的适用性

Conclusion: 提出的Lyapunov-based PI类控制器成功实现了四轮移动机器人的L₂稳定运动控制，兼具理论严格性和工程实用性

Abstract: In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.

</details>


### [14] [Selective Perception for Robot: Task-Aware Attention in Multimodal VLA](https://arxiv.org/abs/2602.15543)
*Young-Chae Son,Jung-Woo Lee,Yoon-Ji Choi,Dae-Kwan Ko,Soo-Chul Lim*

Main category: cs.RO

TL;DR: 提出动态信息融合框架，通过轻量级自适应路由架构实时分析任务相关性，条件性衰减低信息效用视图的计算，实现计算效率与任务相关性成正比


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型采用静态融合处理所有视觉输入，导致不必要的计算开销和任务无关背景信息作为噪声，需要提高效率和鲁棒性

Method: 1) 轻量级自适应路由架构实时分析文本提示和腕部摄像头观察，预测多摄像头视图的任务相关性；2) 条件性衰减低信息效用视图的计算；3) 利用VLM建立自动标注管道降低数据收集和标注成本

Result: 在真实机器人操作场景中，相比现有VLA模型，在推理效率和控制性能方面均有显著提升

Conclusion: 动态信息融合在资源受限的实时机器人控制环境中具有有效性和实用性

Abstract: In robotics, Vision-Language-Action (VLA) models that integrate diverse multimodal signals from multi-view inputs have emerged as an effective approach. However, most prior work adopts static fusion that processes all visual inputs uniformly, which incurs unnecessary computational overhead and allows task-irrelevant background information to act as noise. Inspired by the principles of human active perception, we propose a dynamic information fusion framework designed to maximize the efficiency and robustness of VLA models. Our approach introduces a lightweight adaptive routing architecture that analyzes the current text prompt and observations from a wrist-mounted camera in real-time to predict the task-relevance of multiple camera views. By conditionally attenuating computations for views with low informational utility and selectively providing only essential visual features to the policy network, Our framework achieves computation efficiency proportional to task relevance. Furthermore, to efficiently secure large-scale annotation data for router training, we established an automated labeling pipeline utilizing Vision-Language Models (VLMs) to minimize data collection and annotation costs. Experimental results in real-world robotic manipulation scenarios demonstrate that the proposed approach achieves significant improvements in both inference efficiency and control performance compared to existing VLA models, validating the effectiveness and practicality of dynamic information fusion in resource-constrained, real-time robot control environments.

</details>


### [15] [VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing](https://arxiv.org/abs/2602.15549)
*Guoqin Tang,Qingxuan Jia,Gang Chen,Tong Li,Zeyuan Huang,Zihang Lv,Ning Ji*

Main category: cs.RO

TL;DR: VLM-DEWM提出了一种认知架构，通过持久化的动态外部世界模型将视觉语言模型推理与世界状态管理解耦，解决了智能制造中VLM的状态漂移和不透明推理问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在智能制造高层规划中表现出潜力，但在动态工作单元部署面临两个关键挑战：1) 无状态操作，无法持续跟踪视野外状态，导致世界状态漂移；2) 不透明推理，故障难以诊断，导致昂贵的盲目重试。

Method: 提出VLM-DEWM认知架构，通过持久化、可查询的动态外部世界模型(DEWM)将VLM推理与世界状态管理解耦。每个VLM决策被结构化为外部化推理轨迹(ERT)，包含行动提议、世界信念和因果假设，在执行前与DEWM进行验证。故障发生时，通过预测状态与观测状态之间的差异分析实现针对性恢复而非全局重规划。

Result: 在多站装配、大规模设施探索和真实机器人故障恢复实验中，相比基线记忆增强VLM系统，VLM-DEWM将状态跟踪准确率从56%提升到93%，恢复成功率从低于5%提升到95%，并通过结构化内存显著降低计算开销。

Conclusion: VLM-DEWM为动态制造环境中的长时程机器人操作提供了一个可验证且具有弹性的解决方案，通过解耦推理与世界状态管理，显著提升了系统的可靠性和效率。

Abstract: Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.

</details>


### [16] [Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions](https://arxiv.org/abs/2602.15567)
*Jieting Long,Dechuan Liu,Weidong Cai,Ian Manchester,Weiming Zhi*

Main category: cs.RO

TL;DR: CASF框架通过约束相关度量增强流式流策略，在运行时重塑学习的速度场，实现实时轨迹调整以满足安全约束，同时保持多模态和反应性。


<details>
  <summary>Details</summary>
Motivation: 现有流式流策略缺乏训练后调整轨迹以强制执行安全和任务特定约束的机制，需要一种能够实时适应约束的框架。

Method: 将每个约束建模为可微距离函数，转换为局部度量并拉回到机器人控制空间，在远离限制区域时度量简化为单位矩阵，在约束边界附近平滑衰减或重定向运动。

Result: 在模拟和真实世界操作任务中，CASF生成满足约束的轨迹，保持平滑、可行和动态一致性，优于标准后处理投影基线方法。

Conclusion: CASF成功增强了流式流策略的约束感知能力，实现了实时轨迹适应，同时保持了原始策略的多模态和反应特性。

Abstract: Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajectories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot's workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot's control space. Far from restricted regions, the resulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines.

</details>


### [17] [Grip as Needed, Glide on Demand: Ultrasonic Lubrication for Robotic Locomotion](https://arxiv.org/abs/2602.15608)
*Mostafa A. Atalla,Daan van Bemmel,Jack Cummings,Paul Breedveld,Michaël Wiertlewski,Aimée Sakes*

Main category: cs.RO

TL;DR: 该论文提出了一种利用超声波润滑主动控制摩擦力的机器人运动方法，通过激发共振结构在超声频率下动态切换接触界面的"抓握"和"滑动"状态，实现了高效的双向运动。


<details>
  <summary>Details</summary>
Motivation: 摩擦力是陆地运动的关键中介，但在机器人系统中通常被视为由表面材料和条件决定的被动属性。研究者希望开发一种能够主动控制摩擦力的方法，以提高机器人运动系统的效率和简化设计。

Method: 采用超声波润滑技术，通过激发共振结构在超声频率下动态控制接触界面状态。开发了两种摩擦控制模块：圆柱形设计用于管腔环境，平板设计用于外部表面。将这些模块集成到仿生系统中，模拟尺蠖和黄蜂产卵器的运动机制。

Result: 两种系统都实现了双向运动，运动效率超过90%，接近完美。摩擦特性实验表明，该方法能在各种表面（刚性、柔软、颗粒状、生物组织）、干湿条件以及不同粗糙度表面上显著降低摩擦力，证实了超声波润滑在运动任务中的广泛适用性。

Conclusion: 超声波润滑被确立为一种可行的机器人运动主动摩擦控制机制，具有降低设计复杂性和提高机器人运动系统效率的潜力。

Abstract: Friction is the essential mediator of terrestrial locomotion, yet in robotic systems it is almost always treated as a passive property fixed by surface materials and conditions. Here, we introduce ultrasonic lubrication as a method to actively control friction in robotic locomotion. By exciting resonant structures at ultrasonic frequencies, contact interfaces can dynamically switch between "grip" and "slip" states, enabling locomotion. We developed two friction control modules, a cylindrical design for lumen-like environments and a flat-plate design for external surfaces, and integrated them into bio-inspired systems modeled after inchworm and wasp ovipositor locomotion. Both systems achieved bidirectional locomotion with nearly perfect locomotion efficiencies that exceeded 90%. Friction characterization experiments further demonstrated substantial friction reduction across various surfaces, including rigid, soft, granular, and biological tissue interfaces, under dry and wet conditions, and on surfaces with different levels of roughness, confirming the broad applicability of ultrasonic lubrication to locomotion tasks. These findings establish ultrasonic lubrication as a viable active friction control mechanism for robotic locomotion, with the potential to reduce design complexity and improve efficiency of robotic locomotion systems.

</details>


### [18] [SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms](https://arxiv.org/abs/2602.15633)
*Haichao Liu,Yufeng Hu,Shuang Wang,Kangjun Guo,Jun Ma,Jinni Zhou*

Main category: cs.RO

TL;DR: 提出SpecFuse框架，通过频谱-时间融合预测控制解决无人机在振荡海洋平台上的自主着陆问题，显著提升预测精度和着陆成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法将平台运动视为一般随机过程或缺乏对波浪频谱特性的显式建模，导致在动态海况下性能不佳，无法有效处理波浪引起的多频振荡、风扰和预测相位滞后问题。

Method: 提出频谱-时间融合预测控制框架：1) 频域波浪分解与时间域递归状态估计结合进行6自由度运动预测；2) 分层控制架构，包括基于采样的HPO-RRT*算法进行动态轨迹规划；3) 学习增强预测控制器，融合数据驱动的扰动补偿与优化执行。

Result: 在2000次仿真+8次湖上实验中，实现3.2厘米预测误差、4.46厘米着陆偏差、98.7%/87.5%成功率（仿真/现实）、82毫秒嵌入式硬件延迟，比现有方法精度提升44%-48%。

Conclusion: SpecFuse框架通过显式建模波浪频谱特性，有效解决了海洋平台自主着陆中的预测相位滞后问题，在波浪-风耦合扰动下表现出强鲁棒性，支持搜救和环境监测等关键海事任务。

Abstract: Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.

</details>


### [19] [Spatially-Aware Adaptive Trajectory Optimization with Controller-Guided Feedback for Autonomous Racing](https://arxiv.org/abs/2602.15642)
*Alexander Wachter,Alexander Willert,Marc-Philip Ecker,Christian Hartl-Nesic*

Main category: cs.RO

TL;DR: 提出一个结合NURBS轨迹表示、CMA-ES全局优化和控制器引导空间反馈的闭环自动驾驶赛车线优化框架，利用跟踪误差作为局部赛道特征信号，实现适应不同摩擦条件的鲁棒性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统方法将跟踪误差视为瞬态干扰，而本文认为这些误差包含有价值的局部赛道特征信息。需要开发一个能够适应空间变化赛道条件和车辆行为的自适应优化框架，特别是在真实世界中摩擦条件变化的情况下。

Method: 1. 使用NURBS（非均匀有理B样条）表示轨迹；2. 采用CMA-ES（协方差矩阵自适应进化策略）进行全局轨迹优化；3. 引入控制器引导的空间反馈机制，通过卡尔曼滤波器启发的空间更新将跟踪误差转化为局部赛道特征信号；4. 构建自适应加速度约束图，根据空间变化的赛道和车辆行为迭代优化轨迹。

Result: 仿真中相比使用最大静态加速度参数化的控制器，圈速提升17.38%。在真实硬件测试中，使用从高到低不同摩擦系数的轮胎，无需显式参数化摩擦系数即可获得7.60%的圈速提升，展示了在真实场景中适应变化抓地力条件的鲁棒性。

Conclusion: 该闭环框架成功将跟踪误差转化为有价值的赛道特征信息，实现了在空间变化条件下的自适应轨迹优化。方法对真实世界摩擦条件变化具有鲁棒性，无需显式参数化摩擦系数即可显著提升性能，为自动驾驶赛车线优化提供了有效解决方案。

Abstract: We present a closed-loop framework for autonomous raceline optimization that combines NURBS-based trajectory representation, CMA-ES global trajectory optimization, and controller-guided spatial feedback. Instead of treating tracking errors as transient disturbances, our method exploits them as informative signals of local track characteristics via a Kalman-inspired spatial update. This enables the construction of an adaptive, acceleration-based constraint map that iteratively refines trajectories toward near-optimal performance under spatially varying track and vehicle behavior. In simulation, our approach achieves a 17.38% lap time reduction compared to a controller parametrized with maximum static acceleration. On real hardware, tested with different tire compounds ranging from high to low friction, we obtain a 7.60% lap time improvement without explicitly parametrizing friction. This demonstrates robustness to changing grip conditions in real-world scenarios.

</details>


### [20] [MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction](https://arxiv.org/abs/2602.15733)
*Qiang Zhang,Jiahao Ma,Peiran Liu,Shuai Shi,Zeran Su,Zifan Wang,Jingkai Sun,Wei Cui,Jialin Yu,Gang Han,Wen Zhao,Pihai Sun,Kangning Yin,Jiaxu Wang,Jiahang Cao,Lingfeng Zhang,Hao Cheng,Xiaoshuai Hao,Yiding Ji,Junwei Liang,Jian Tang,Renjing Xu,Yijie Guo*

Main category: cs.RO

TL;DR: MeshMimic框架通过3D视觉模型从视频中重建场景几何和人体轨迹，利用优化算法提取高质量运动数据，并通过接触不变重定向方法将人-环境交互特征转移到人形机器人上，实现低成本、可扩展的运动学习。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人运动控制主要依赖昂贵的动作捕捉数据，这些数据缺乏周围物理环境的几何上下文，导致运动与场景解耦，在复杂地形任务中出现物理不一致问题（如接触滑动、网格穿透）。需要一种低成本、能学习耦合"运动-地形"交互的方法。

Method: 1. 利用先进的3D视觉模型从视频中精确分割和重建人体轨迹及地形/物体的3D几何结构；2. 基于运动学一致性的优化算法从噪声视觉重建中提取高质量运动数据；3. 接触不变重定向方法将人-环境交互特征转移到人形智能体；4. 仅使用消费级单目传感器构建低成本训练管道。

Result: MeshMimic在多样化和具有挑战性的地形上实现了稳健、高度动态的性能。实验证明，仅使用消费级单目传感器的低成本管道能够训练复杂的物理交互，为人形机器人在非结构化环境中的自主进化提供了可扩展的路径。

Conclusion: 该工作成功地将3D场景重建与具身智能相结合，使机器人能够直接从视频中学习耦合的"运动-地形"交互，解决了传统方法中运动与场景解耦的问题，为低成本、可扩展的人形机器人运动学习提供了创新解决方案。

Abstract: Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled "motion-terrain" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.

</details>


### [21] [Robot-Assisted Social Dining as a White Glove Service](https://arxiv.org/abs/2602.15767)
*Atharva S Kashyap,Ugne Aleksandra Morkute,Patricia Alves-Oliveira*

Main category: cs.RO

TL;DR: 机器人辅助喂食系统在社交用餐环境中的设计研究，通过参与式设计探索餐厅等公共场所的应用场景


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助喂食系统主要在实验室或家庭环境中测试，缺乏对餐厅等社交用餐场景的探索，这些环境具有动态、无监督的特点，需要特殊设计考虑

Method: 采用推测性参与式设计方法，结合半结构化访谈和基于AI的视觉故事板工具，与残障人士共同探索理想的社交用餐场景

Result: 发现社交用餐场景中的机器人系统应体现"白手套服务"原则：支持多模态输入和非侵入性输出；具有情境敏感的社交行为并优先考虑用户；扩展喂食以外的角色；适应餐桌上的其他关系

Conclusion: 研究为机器人辅助喂食系统在社交用餐环境和群体场景中的应用提供了设计指导，强调了情境敏感性和社交适应性的重要性

Abstract: Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.

</details>


### [22] [FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy](https://arxiv.org/abs/2602.15813)
*Haochen Zhang,Nirav Savaliya,Faizan Siddiqui,Enna Sachdeva*

Main category: cs.RO

TL;DR: FAST-EQA是一个用于具身问答的框架，通过识别视觉目标、评分感兴趣区域来引导导航，并使用思维链推理视觉记忆来回答问题，同时保持有界场景记忆以实现快速推理。


<details>
  <summary>Details</summary>
Motivation: 具身问答需要在部分可观测环境下结合视觉场景理解、目标导向探索和时空推理。主要挑战是将物理搜索限制在问题相关子空间，同时保持紧凑、可操作的观察记忆，并且实际部署需要快速推理时间。

Method: FAST-EQA框架包含三个核心组件：(1)识别可能的视觉目标；(2)对全局感兴趣区域评分以引导导航；(3)使用思维链推理在视觉记忆上进行推理。框架维护有界场景记忆，存储固定容量的区域-目标假设并在线更新，同时采用全局探索策略将狭窄开口和门视为高价值边界。

Result: 在HMEQA和EXPRESS-Bench上达到最先进性能，在OpenEQA和MT-HM3D上表现有竞争力。相比先前方法，运行速度显著更快，同时提高了场景覆盖率和答案可靠性。

Conclusion: FAST-EQA通过有界记忆管理、目标导向探索和思维链推理，有效解决了具身问答中的搜索空间限制和推理速度问题，实现了高性能和快速推理的平衡。

Abstract: Embodied Question Answering (EQA) combines visual scene understanding, goal-directed exploration, spatial and temporal reasoning under partial observability. A central challenge is to confine physical search to question-relevant subspaces while maintaining a compact, actionable memory of observations. Furthermore, for real-world deployment, fast inference time during exploration is crucial. We introduce FAST-EQA, a question-conditioned framework that (i) identifies likely visual targets, (ii) scores global regions of interest to guide navigation, and (iii) employs Chain-of-Thought (CoT) reasoning over visual memory to answer confidently. FAST-EQA maintains a bounded scene memory that stores a fixed-capacity set of region-target hypotheses and updates them online, enabling robust handling of both single and multi-target questions without unbounded growth. To expand coverage efficiently, a global exploration policy treats narrow openings and doors as high-value frontiers, complementing local target seeking with minimal computation. Together, these components focus the agent's attention, improve scene coverage, and improve answer reliability while running substantially faster than prior approaches. On HMEQA and EXPRESS-Bench, FAST-EQA achieves state-of-the-art performance, while performing competitively on OpenEQA and MT-HM3D.

</details>


### [23] [Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching](https://arxiv.org/abs/2602.15827)
*Zhen Wu,Xiaoyu Huang,Lujie Yang,Yuanhang Zhang,Koushil Sreenath,Xi Chen,Pieter Abbeel,Rocky Duan,Angjoo Kanazawa,Carmelo Sferrazza,Guanya Shi,C. Karen Liu*

Main category: cs.RO

TL;DR: 提出Perceptive Humanoid Parkour (PHP)框架，使人形机器人能够基于视觉自主执行长时程跑酷，通过运动匹配组合人类技能，结合强化学习训练感知策略，实现动态障碍穿越。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人运动控制虽然能在不同地形稳定行走，但难以实现人类动态运动的敏捷性和适应性。复杂环境中的跑酷需要低层鲁棒性、人类运动表现力、长时程技能组合和感知驱动决策。

Method: 1. 使用运动匹配（最近邻搜索）将重定向的人类原子技能组合成长时程运动轨迹；2. 训练运动跟踪强化学习专家策略，通过DAgger和RL蒸馏成单一深度感知多技能学生策略；3. 仅使用机载深度感知和2D速度指令，自主选择跨越、攀爬、翻越或滚下不同几何形状和高度的障碍物。

Result: 在Unitree G1人形机器人上进行大量真实世界实验验证：1. 攀爬高达1.25米（机器人身高的96%）的障碍物；2. 长时程多障碍物穿越，能够闭环适应实时障碍物扰动。

Conclusion: PHP框架成功实现了人形机器人的感知驱动跑酷，展示了动态技能组合、自主决策和复杂环境适应能力，为人形机器人的敏捷运动控制提供了新方法。

Abstract: While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.

</details>


### [24] [Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828)
*Yuxuan Kuang,Sungjae Park,Katerina Fragkiadaki,Shubham Tulsiani*

Main category: cs.RO

TL;DR: Dex4D是一个学习任务无关灵巧操作技能的框架，通过模拟训练3D点轨迹条件策略，实现零样本迁移到真实世界任务


<details>
  <summary>Details</summary>
Motivation: 学习能够完成多种日常任务的通用策略在灵巧操作中仍然是一个开放挑战。真实世界遥操作收集大规模数据昂贵且难以扩展，而模拟学习需要设计多个任务特定环境和奖励同样具有挑战性

Method: 提出Dex4D框架，在模拟中学习领域无关的3D点轨迹条件策略，能够操纵任何物体到任何期望姿态。在数千个具有不同姿态配置的物体上进行训练，覆盖广泛的机器人-物体交互空间。部署时通过从生成视频中提取的物体中心点轨迹提示策略，使用在线点跟踪进行闭环感知和控制

Result: 实验表明该方法支持零样本部署到多样灵巧操作任务，相比先前基线有持续改进。展示了对新物体、场景布局、背景和轨迹的强泛化能力

Conclusion: Dex4D框架通过模拟学习任务无关灵巧技能，能够灵活重组执行多样真实世界操作任务，展示了所提框架的鲁棒性和可扩展性

Abstract: Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.

</details>
