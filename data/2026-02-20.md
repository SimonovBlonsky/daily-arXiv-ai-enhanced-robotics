<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ICP-Based Pallet Tracking for Unloading on Inclined Surfaces by Autonomous Forklifts](https://arxiv.org/abs/2602.16744)
*Takuro Kato,Mitsuharu Morisawa*

Main category: cs.RO

TL;DR: 提出一种自主叉车在倾斜表面上卸货的控制方法，使用ICP算法实时跟踪托盘与货叉的相对位置和姿态角度，使货叉与目标表面平行对齐后沿倾斜方向撤回，避免托盘被拖动。


<details>
  <summary>Details</summary>
Motivation: 解决自主叉车在倾斜表面（如卡车倾斜床板）上卸货时，货叉撤回过程中可能拖动托盘的问题，提高卸货操作的效率和安全性。

Method: 使用迭代最近点（ICP）算法处理从托盘上部区域测量的点云数据，实时跟踪托盘与货叉之间的相对位置和姿态角度差异。根据跟踪结果调整货叉姿态，使其与目标倾斜表面平行对齐，然后沿倾斜方向撤回货叉完成卸货。

Result: 通过动态仿真和真实叉车实验验证了该方法的有效性，成功实现了在卡车倾斜床板上卸货时货叉的平稳撤回，避免了托盘被拖动的情况。

Conclusion: 提出的基于ICP算法的控制方法能够有效解决自主叉车在倾斜表面上卸货时托盘被拖动的问题，通过实时姿态调整确保货叉与倾斜表面平行对齐，实现平稳卸货操作。

Abstract: This paper proposes a control method for autonomous forklifts to unload pallets on inclined surfaces, enabling the fork to be withdrawn without dragging the pallets. The proposed method applies the Iterative Closest Point (ICP) algorithm to point clouds measured from the upper region of the pallet and thereby tracks the relative position and attitude angle difference between the pallet and the fork during the unloading operation in real-time. According to the tracking result, the fork is aligned parallel to the target surface. After the fork is aligned, it is possible to complete the unloading process by withdrawing the fork along the tilt, preventing any dragging of the pallet. The effectiveness of the proposed method is verified through dynamic simulations and experiments using a real forklift that replicate unloading operations onto the inclined bed of a truck.

</details>


### [2] [Smooth trajectory generation and hybrid B-splines-Quaternions based tool path interpolation for a 3T1R parallel kinematic milling robot](https://arxiv.org/abs/2602.16758)
*Sina Akhbari,Mehran Mahboubkhah*

Main category: cs.RO

TL;DR: 提出一种用于四自由度并联铣削机器人的平滑轨迹生成方法，结合B样条和四元数插值技术，通过分段贝塞尔曲线同步位置和姿态数据，实现高精度、低速度波动的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹生成方法在处理并联机器人位置和姿态解耦数据时存在精度不足、速度波动大、计算效率低等问题，需要一种能够同时满足空间约束和时间优化的平滑轨迹生成方法。

Method: 采用B样条和四元数插值技术处理解耦的位置和姿态数据点，通过分段贝塞尔曲线拟合实现姿态与弧长参数化位置的同步，利用贝塞尔曲线的凸包特性保证空间和时间分离约束，使用四元数避免万向节锁，分两阶段优化时间轨迹（任务空间→关节空间）。

Result: 实验结果表明，与传统插值方法相比，该方法在精度、速度波动控制和计算效率方面均有显著提升，能够在低成本微控制器上实现。

Conclusion: 所提出的轨迹生成方法有效解决了四自由度并联铣削机器人的平滑运动控制问题，为多智能体轨迹生成提供了空间和时间分离约束的保障，具有实际应用价值。

Abstract: This paper presents a smooth trajectory generation method for a four-degree-of-freedom parallel kinematic milling robot. The proposed approach integrates B-spline and Quaternion interpolation techniques to manage decoupled position and orientation data points. The synchronization of orientation and arc-length-parameterized position data is achieved through the fitting of smooth piece-wise Bezier curves, which describe the non-linear relationship between path length and tool orientation, solved via sequential quadratic programming. By leveraging the convex hull properties of Bezier curves, the method ensures spatial and temporal separation constraints for multi-agent trajectory generation. Unit quaternions are employed for orientation interpolation, providing a robust and efficient representation that avoids gimbal lock and facilitates smooth, continuous rotation. Modifier polynomials are used for position interpolation. Temporal trajectories are optimized using minimum jerk, time-optimal piece-wise Bezier curves in two stages: task space followed by joint space, implemented on a low-cost microcontroller. Experimental results demonstrate that the proposed method offers enhanced accuracy, reduced velocity fluctuations, and computational efficiency compared to conventional interpolation methods.

</details>


### [3] [RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness](https://arxiv.org/abs/2602.16825)
*Ahmad Ahmad,Shuo Liu,Roberto Tron,Calin Belta*

Main category: cs.RO

TL;DR: RRT^η：一种结合算术几何平均鲁棒性度量的采样运动规划框架，用于满足信号时序逻辑规范，在复杂时空约束下优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统基于采样运动规划结合信号时序逻辑的方法依赖最小-最大鲁棒性度量，只关注关键时间点和子公式，导致非平滑优化景观和尖锐决策边界，阻碍高效的树探索

Method: 提出RRT^η框架，集成算术几何平均鲁棒性度量评估所有时间点和子公式的满足程度；包括AGM鲁棒性区间语义、高效增量监控算法、基于满足优先级逻辑的增强满意度增加方向向量

Result: 框架能够合成满足STL规范的高鲁棒性动态可行控制序列，保持RRT*的概率完备性和渐近最优性；在双积分点机器人、单轮移动机器人和7自由度机械臂上验证，在有限引导信号的多约束场景中优于传统STL鲁棒性规划器

Conclusion: RRT^η通过AGM鲁棒性度量和FPL引导，有效解决了传统STL规划中的非平滑优化问题，在复杂机器人任务中表现出优越性能

Abstract: Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-dimensional configuration spaces. When combined with Signal Temporal Logic (STL), a temporal logic widely used for formalizing interpretable robotic tasks, these methods can address complex spatiotemporal constraints. However, traditional approaches rely on min-max robustness measures that focus only on critical time points and subformulae, creating non-smooth optimization landscapes with sharp decision boundaries that hinder efficient tree exploration.
  We propose RRT$^η$, a sampling-based planning framework that integrates the Arithmetic-Geometric Mean (AGM) robustness measure to evaluate satisfaction across all time points and subformulae. Our key contributions include: (1) AGM robustness interval semantics for reasoning about partial trajectories during tree construction, (2) an efficient incremental monitoring algorithm computing these intervals, and (3) enhanced Direction of Increasing Satisfaction vectors leveraging Fulfillment Priority Logic (FPL) for principled objective composition. Our framework synthesizes dynamically feasible control sequences satisfying STL specifications with high robustness while maintaining the probabilistic completeness and asymptotic optimality of RRT$^\ast$. We validate our approach on three robotic systems. A double integrator point robot, a unicycle mobile robot, and a 7-DOF robot arm, demonstrating superior performance over traditional STL robustness-based planners in multi-constraint scenarios with limited guidance signals.

</details>


### [4] [Sound of Touch: Active Acoustic Tactile Sensing via String Vibrations](https://arxiv.org/abs/2602.16846)
*Xili Yi,Ying Xing,Zachary Manchester,Nima Fazeli*

Main category: cs.RO

TL;DR: Sound of Touch：一种基于振动弦的主动声学触觉传感方法，通过少量拾音器检测接触引起的频谱变化，实现接触位置、法向力和滑动的实时检测。


<details>
  <summary>Details</summary>
Motivation: 分布式触觉传感难以在大面积上扩展：密集传感器阵列增加布线、成本和脆弱性，而许多替代方案覆盖有限或无法捕捉快速交互动态。

Method: 使用振动张紧弦作为传感元件，通过电磁连续激励弦，少量接触式麦克风观察接触引起的频谱变化。开发基于物理的弦振动模拟器预测接触位置和力如何影响振动模式，并建立实时推理管道将振动测量映射到接触状态。

Result: 实验证明毫米级定位精度、可靠的力量估计和实时滑动检测。系统能够从短时音频信号中估计接触位置和法向力，并检测滑动。

Conclusion: 提出了一种轻量级、可扩展的基于弦的触觉传感硬件概念，适用于机器人表面；开发了基于物理的模拟和分析工具；实现了实时推理管道，为大规模触觉传感提供了新方法。

Abstract: Distributed tactile sensing remains difficult to scale over large areas: dense sensor arrays increase wiring, cost, and fragility, while many alternatives provide limited coverage or miss fast interaction dynamics. We present Sound of Touch, an active acoustic tactile-sensing methodology that uses vibrating tensioned strings as sensing elements. The string is continuously excited electromagnetically, and a small number of pickups (contact microphones) observe spectral changes induced by contact. From short-duration audio signals, our system estimates contact location and normal force, and detects slip. To guide design and interpret the sensing mechanism, we derive a physics-based string-vibration simulator that predicts how contact position and force shift vibration modes. Experiments demonstrate millimeter-scale localization, reliable force estimation, and real-time slip detection. Our contributions are: (i) a lightweight, scalable string-based tactile sensing hardware concept for instrumenting extended robot surfaces; (ii) a physics-grounded simulation and analysis tool for contact-induced spectral shifts; and (iii) a real-time inference pipeline that maps vibration measurements to contact state.

</details>


### [5] ["Hello, I'm Delivering. Let Me Pass By": Navigating Public Pathways with Walk-along with Robots in Crowded City Streets](https://arxiv.org/abs/2602.16861)
*EunJeong Cheon,Do Yeon Shin*

Main category: cs.RO

TL;DR: 提出"Walk-Along with Robots"方法，用于研究公共场所自主移动机器人的行为与交互


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人在公共场所日益普及，现有HRI研究方法（如受控实验、结构化观察）难以研究实际运营中的机器人，需要新的研究方法

Method: 借鉴城市研究、地理学和社会学中的公共领域民族志，提出"Walk-Along with Robots"方法，包括方法特点、实施步骤、独特见解和评估方式

Result: 提出了一种系统化的研究方法论，能够研究不受研究者控制的自主机器人在动态环境中的行为

Conclusion: WawR方法为研究公共场所自主机器人提供了新途径，希望激发关于该领域研究方法的进一步讨论

Abstract: As the presence of autonomous robots in public spaces increases-whether navigating campus walkways or neighborhood sidewalks-understanding how to carefully study these robots becomes critical. While HRI research has conducted field studies in public spaces, these are often limited to controlled experiments with prototype robots or structured observational methods, such as the Wizard of Oz technique. However, the autonomous mobile robots we encounter today, particularly delivery robots, operate beyond the control of researchers, navigating dynamic routes and unpredictable environments. To address this challenge, a more deliberate approach is required. Drawing inspiration from public realm ethnography in urban studies, geography, and sociology, this paper proposes the Walk-Along with Robots (WawR) methodology. We outline the key features of this method, the steps we applied in our study, the unique insights it offers, and the ways it can be evaluated. We hope this paper stimulates further discussion on research methodologies for studying autonomous robots in public spaces.

</details>


### [6] [SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation](https://arxiv.org/abs/2602.16863)
*Kushal Kedia,Tyler Ga Wei Lum,Jeannette Bohg,C. Karen Liu*

Main category: cs.RO

TL;DR: SimToolReal：通过程序生成大量工具状物体并训练单一RL策略，实现零样本通用工具操作，无需特定对象或任务训练


<details>
  <summary>Details</summary>
Motivation: 工具操作对机器人能力扩展至关重要，但传统方法需要为每个任务单独建模和调优，工程成本高且难以泛化

Method: 在仿真中程序化生成大量工具状物体基元，训练单一强化学习策略以随机目标姿态操作各种物体，实现通用工具操作能力

Result: SimToolReal比先前方法提升37%性能，与针对特定对象训练的专家策略相当，在真实世界120次测试中表现出强大的零样本泛化能力

Conclusion: 通过程序化生成多样训练数据和通用策略训练，SimToolReal实现了无需特定对象训练的强大工具操作泛化能力，为机器人工具操作提供新范式

Abstract: The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behaviors is challenging, sim-to-real reinforcement learning (RL) is a promising alternative. However, prior approaches typically require substantial engineering effort to model objects and tune reward functions for each task. In this work, we propose SimToolReal, taking a step towards generalizing sim-to-real RL policies for tool manipulation. Instead of focusing on a single object and task, we procedurally generate a large variety of tool-like object primitives in simulation and train a single RL policy with the universal goal of manipulating each object to random goal poses. This approach enables SimToolReal to perform general dexterous tool manipulation at test-time without any object or task-specific training. We demonstrate that SimToolReal outperforms prior retargeting and fixed-grasp methods by 37% while matching the performance of specialist RL policies trained on specific target objects and tasks. Finally, we show that SimToolReal generalizes across a diverse set of everyday tools, achieving strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.

</details>


### [7] [Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads](https://arxiv.org/abs/2602.16870)
*Daniil Lisus,Katya M. Papais,Cedric Le Gentil,Elliot Preston-Krebs,Andrew Lambert,Keith Y. K. Leung,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: Boreas-RT数据集扩展了原有的Boreas数据集，包含643公里9条路线的60个序列，提供多传感器数据用于评估自动驾驶算法在多样化道路条件下的性能，特别是针对里程计和定位任务。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶算法在简单驾驶环境中容易过拟合，在多样化、挑战性道路条件下性能显著下降。需要一个新的数据集来评估多模态算法在不同道路条件下的鲁棒性。

Method: 在9条真实世界路线上收集643公里驾驶数据，每条路线多次遍历以评估相同环境下的不同交通和天气条件。使用包括5MP相机、360度雷达、128通道激光雷达、FMCW激光雷达、IMU和轮编码器的多传感器平台，提供厘米级GNSS-INS地面真值。

Result: 基准测试显示许多最先进的里程计和定位算法在简单驾驶环境中过拟合，在更具挑战性的Boreas-RT路线上性能显著下降。数据集提供了统一的多模态算法评估平台。

Conclusion: Boreas-RT为评估多样化道路条件下的多模态自动驾驶算法提供了全面的数据集，揭示了现有算法在复杂环境中的局限性，并提供了公开的开发工具和排行榜。

Abstract: The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose challenges for modern autonomous driving algorithms. Boreas-RT comprises 60 sequences collected over 9 real-world routes, totalling 643 km of driving. Each route is traversed multiple times, enabling evaluation in identical environments under varying traffic and, in some cases, weather conditions. The data collection platform includes a 5MP FLIR Blackfly S camera, a 360 degree Navtech RAS6 Doppler-enabled spinning radar, a 128-channel 360 degree Velodyne Alpha Prime lidar, an Aeva Aeries II FMCW Doppler-enabled lidar, a Silicon Sensing DMU41 inertial measurement unit, and a Dynapar wheel encoder. Centimetre-level ground truth is provided via post-processed Applanix POS LV GNSS-INS data. The dataset includes precise extrinsic and intrinsic calibrations, a publicly available development kit, and a live leaderboard for odometry and metric localization. Benchmark results show that many state-of-the-art odometry and localization algorithms overfit to simple driving environments and degrade significantly on the more challenging Boreas-RT routes. Boreas-RT provides a unified dataset for evaluating multi-modal algorithms across diverse road conditions. The dataset, leaderboard, and development kit are available at www.boreas.utias.utoronto.ca.

</details>


### [8] [MALLVI: a multi agent framework for integrated generalized robotics manipulation](https://arxiv.org/abs/2602.16898)
*Iman Ahmadi,Mehrshad Taji,Arad Mahdinezhad Kashani,AmirHossein Jadidi,Saina Kashani,Babak Khalaj*

Main category: cs.RO

TL;DR: MALLVi是一个多智能体大语言视觉框架，通过闭环反馈驱动的机器人操作，使用专门的智能体协调完成感知、定位、推理和规划，提高零样本操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的机器人任务规划方法通常依赖专门模型、微调或提示调整，且以开环方式运行，缺乏鲁棒的环境反馈，在动态环境中表现脆弱。

Method: MALLVi采用多智能体协调框架，包含分解器、定位器、思考器和反射器等专门智能体，通过视觉语言模型评估环境反馈，实现闭环控制。反射器支持针对性错误检测和恢复，避免完全重新规划。

Result: 在仿真和真实世界环境中的实验表明，迭代闭环多智能体协调提高了泛化能力，并在零样本操作任务中提升了成功率。

Conclusion: MALLVi框架通过多智能体协调和闭环反馈机制，为机器人操作任务提供了更鲁棒和自适应的解决方案，特别是在动态环境中表现出更好的性能。

Abstract: Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.We present MALLVi, a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step.Rather than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning.Experiments in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks.Code available at https://github.com/iman1234ahmadi/MALLVI.

</details>


### [9] [SparTa: Sparse Graphical Task Models from a Handful of Demonstrations](https://arxiv.org/abs/2602.16911)
*Adrian Röfer,Nick Heppert,Abhinav Valada*

Main category: cs.RO

TL;DR: 该论文提出了一种从演示中学习长时程操作任务的方法，通过图形化对象关系表示场景状态演化，使用演示分割和池化提取操作图，并估计任务各阶段的对象状态分布。


<details>
  <summary>Details</summary>
Motivation: 学习长时程操作任务是机器人学习中的核心挑战。现有方法主要关注在动作域中直接学习任务，而本文关注推断机器人应该实现什么目标（what），而不是如何实现（how）。

Method: 1. 使用图形化对象关系表示演化场景状态；2. 提出演示分割和池化方法，提取操作图并估计任务各阶段的对象状态分布；3. 使用预训练视觉特征进行对象匹配以提高多演示学习的鲁棒性；4. 捕获从控制开始到操作结束的完整对象交互。

Result: 1. 评估了演示分割的准确性；2. 验证了从多演示中学习对找到期望最小任务模型的效用；3. 在仿真和真实机器人上部署拟合模型，证明所得任务表示支持跨环境的可靠执行。

Conclusion: 该方法通过图形化对象关系表示和演示分割池化，能够有效学习长时程操作任务，捕获完整对象交互，并在多演示学习时保持鲁棒性，最终支持跨环境的可靠任务执行。

Abstract: Learning long-horizon manipulation tasks efficiently is a central challenge in robot learning from demonstration. Unlike recent endeavors that focus on directly learning the task in the action domain, we focus on inferring what the robot should achieve in the task, rather than how to do so. To this end, we represent evolving scene states using a series of graphical object relationships. We propose a demonstration segmentation and pooling approach that extracts a series of manipulation graphs and estimates distributions over object states across task phases. In contrast to prior graph-based methods that capture only partial interactions or short temporal windows, our approach captures complete object interactions spanning from the onset of control to the end of the manipulation. To improve robustness when learning from multiple demonstrations, we additionally perform object matching using pre-trained visual features. In extensive experiments, we evaluate our method's demonstration segmentation accuracy and the utility of learning from multiple demonstrations for finding a desired minimal task model. Finally, we deploy the fitted models both in simulation and on a real robot, demonstrating that the resulting task representations support reliable execution across environments.

</details>


### [10] [Benchmarking the Effects of Object Pose Estimation and Reconstruction on Robotic Grasping Success](https://arxiv.org/abs/2602.17101)
*Varun Burde,Pavel Burget,Torsten Sattler*

Main category: cs.RO

TL;DR: 该论文提出了一个基于物理的大规模基准测试，用于评估3D重建质量和6D姿态估计在机器人抓取任务中的功能有效性，发现重建伪影会减少抓取候选姿态数量，但对抓取性能影响有限。


<details>
  <summary>Details</summary>
Motivation: 当前3D重建方法虽然能产生视觉和几何上令人印象深刻的网格模型，但标准的几何评估无法反映重建质量如何影响机器人操作等下游任务。需要填补这一空白，评估感知系统与物体操作之间的关系。

Method: 引入大规模、基于物理的基准测试，通过在多种重建的3D网格上生成抓取姿态，并在真实模型上执行这些姿态，模拟使用不完美模型生成的抓取姿态如何影响与真实物体的交互。评估姿态误差、抓取鲁棒性和3D重建几何误差的综合影响。

Result: 重建伪影显著减少了抓取姿态候选数量，但在姿态准确估计的情况下对抓取性能影响可忽略。抓取成功与姿态误差的关系主要由空间误差主导，即使是简单的平移误差也能为对称物体的抓取姿态成功提供洞察。

Conclusion: 这项工作揭示了感知系统如何与机器人物体操作相关联，为评估3D重建和姿态估计在机器人抓取任务中的功能有效性提供了新的基准测试方法。

Abstract: 3D reconstruction serves as the foundational layer for numerous robotic perception tasks, including 6D object pose estimation and grasp pose generation. Modern 3D reconstruction methods for objects can produce visually and geometrically impressive meshes from multi-view images, yet standard geometric evaluations do not reflect how reconstruction quality influences downstream tasks such as robotic manipulation performance. This paper addresses this gap by introducing a large-scale, physics-based benchmark that evaluates 6D pose estimators and 3D mesh models based on their functional efficacy in grasping. We analyze the impact of model fidelity by generating grasps on various reconstructed 3D meshes and executing them on the ground-truth model, simulating how grasp poses generated with an imperfect model affect interaction with the real object. This assesses the combined impact of pose error, grasp robustness, and geometric inaccuracies from 3D reconstruction. Our results show that reconstruction artifacts significantly decrease the number of grasp pose candidates but have a negligible effect on grasping performance given an accurately estimated pose. Our results also reveal that the relationship between grasp success and pose error is dominated by spatial error, and even a simple translation error provides insight into the success of the grasping pose of symmetric objects. This work provides insight into how perception systems relate to object manipulation using robots.

</details>


### [11] [Grasp Synthesis Matching From Rigid To Soft Robot Grippers Using Conditional Flow Matching](https://arxiv.org/abs/2602.17110)
*Tanisha Parulekar,Ge Shi,Josh Pinskier,David Howard,Jen Jen Chung*

Main category: cs.RO

TL;DR: 提出使用条件流匹配(CFM)生成模型，将刚性夹爪的抓取姿态映射到软体Fin-ray夹爪，解决刚性抓取合成方法不适用于软体夹爪的问题。


<details>
  <summary>Details</summary>
Motivation: 现有抓取合成方法（如Anygrasp）主要针对刚性平行夹爪设计，直接应用于软体夹爪时无法捕捉其独特的柔顺行为，导致数据密集且模型不准确，存在刚性-软体抓取表示差距。

Method: 1. 建立数据收集流程生成配对的刚性-软体抓取姿态；2. 使用U-Net自编码器从深度图像中提取物体几何特征作为条件；3. 采用条件流匹配(CFM)生成模型学习从初始Anygrasp姿态到稳定Fin-ray夹爪姿态的连续映射。

Result: 在7自由度机器人上验证，CFM生成的姿态相比基线刚性姿态显著提升：已见物体成功率从6%提升至34%，未见物体从25%提升至46%。特别在圆柱体（已见50%/未见100%）和球体（已见25%/未见31%）上表现优异，能成功泛化到未见物体。

Conclusion: CFM是一种数据高效且有效的方法，可用于在不同软体机器人系统间转移抓取策略，为软体机器人抓取合成提供了可扩展的方法论。

Abstract: A representation gap exists between grasp synthesis for rigid and soft grippers. Anygrasp [1] and many other grasp synthesis methods are designed for rigid parallel grippers, and adapting them to soft grippers often fails to capture their unique compliant behaviors, resulting in data-intensive and inaccurate models. To bridge this gap, this paper proposes a novel framework to map grasp poses from a rigid gripper model to a soft Fin-ray gripper. We utilize Conditional Flow Matching (CFM), a generative model, to learn this complex transformation. Our methodology includes a data collection pipeline to generate paired rigid-soft grasp poses. A U-Net autoencoder conditions the CFM model on the object's geometry from a depth image, allowing it to learn a continuous mapping from an initial Anygrasp pose to a stable Fin-ray gripper pose. We validate our approach on a 7-DOF robot, demonstrating that our CFM-generated poses achieve a higher overall success rate for seen and unseen objects (34% and 46% respectively) compared to the baseline rigid poses (6% and 25% respectively) when executed by the soft gripper. The model shows significant improvements, particularly for cylindrical (50% and 100% success for seen and unseen objects) and spherical objects (25% and 31% success for seen and unseen objects), and successfully generalizes to unseen objects. This work presents CFM as a data-efficient and effective method for transferring grasp strategies, offering a scalable methodology for other soft robotic systems.

</details>


### [12] [Physical Human-Robot Interaction for Grasping in Augmented Reality via Rigid-Soft Robot Synergy](https://arxiv.org/abs/2602.17128)
*Huishi Huang,Jack Klusmann,Haozhe Wang,Shuchen Ji,Fengkang Ying,Yiyuan Zhang,John Nassour,Gordon Cheng,Daniela Rus,Jun Liu,Marcelo H Ang,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出基于增强现实的物理人机交互框架，用于混合刚柔机器人的直接遥操作，通过虚实一致建模实现简单抓取任务


<details>
  <summary>Details</summary>
Motivation: 混合刚柔机器人结合了刚性机械臂的精确性和柔性臂的顺应性，在非结构化环境中具有广阔应用前景，但协调控制面临建模、感知和跨域运动学等挑战

Method: 开发AR头显交互框架，将机器人仿真模型叠加到真实系统上；提出实到仿参数识别流程，利用软体机器人固有几何特性，精确建模其静态、动态行为及控制系统响应

Result: 实现了混合刚柔机器人的直接遥操作，通过虚实一致建模确保虚拟和物理机器人行为一致性，支持简单到达和抓取任务

Conclusion: AR-based物理人机交互框架为混合刚柔机器人协调控制提供了有效解决方案，通过虚实一致建模克服了传统控制挑战

Abstract: Hybrid rigid-soft robots combine the precision of rigid manipulators with the compliance and adaptability of soft arms, offering a promising approach for versatile grasping in unstructured environments. However, coordinating hybrid robots remains challenging, due to difficulties in modeling, perception, and cross-domain kinematics. In this work, we present a novel augmented reality (AR)-based physical human-robot interaction framework that enables direct teleoperation of a hybrid rigid-soft robot for simple reaching and grasping tasks. Using an AR headset, users can interact with a simulated model of the robotic system integrated into a general-purpose physics engine, which is superimposed on the real system, allowing simulated execution prior to real-world deployment. To ensure consistent behavior between the virtual and physical robots, we introduce a real-to-simulation parameter identification pipeline that leverages the inherent geometric properties of the soft robot, enabling accurate modeling of its static and dynamic behavior as well as the control system's response.

</details>


### [13] [Geometric Inverse Flight Dynamics on SO(3) and Application to Tethered Fixed-Wing Aircraft](https://arxiv.org/abs/2602.17166)
*Antonio Franchi,Chiara Gabellieri*

Main category: cs.RO

TL;DR: 提出了一种用于固定翼飞机的坐标无关逆飞行动力学公式，在SO(3)上建立几何框架，避免局部姿态坐标，推导出轨迹到输入的闭式映射，并应用于球形平行线上的系留飞行分析。


<details>
  <summary>Details</summary>
Motivation: 将航空领域的逆仿真与机器人学的几何建模相结合，为轨迹设计和可行性检查提供严格的数学基础，避免传统方法中局部坐标系的复杂性。

Method: 采用坐标无关的几何方法：在世界坐标系中建立平动力平衡，在机体坐标系中建立旋转动力学；几何定义气动方向（阻力、升力、侧力）；施加协调飞行条件（无侧滑），推导出从轨迹到姿态、角速度、推力-攻角对的闭式映射。

Result: 获得了球形平行线上系留飞行的解析表达式，识别出零倾斜轨迹（张力恰好平衡离心效应），揭示了气动协调与表观重力矢量的解耦关系；在简单升力/阻力定律下，最小推力攻角具有闭式解。

Conclusion: 该框架为轨迹设计和可行性检查提供了严格的数学基础，当轨迹和旋转动力学时不变时，点式准稳态逆解成为稳态飞行配平，实现了航空逆仿真与机器人几何建模的桥梁作用。

Abstract: We present a robotics-oriented, coordinate-free formulation of inverse flight dynamics for fixed-wing aircraft on SO(3). Translational force balance is written in the world frame and rotational dynamics in the body frame; aerodynamic directions (drag, lift, side) are defined geometrically, avoiding local attitude coordinates. Enforcing coordinated flight (no sideslip), we derive a closed-form trajectory-to-input map yielding the attitude, angular velocity, and thrust-angle-of-attack pair, and we recover the aerodynamic moment coefficients component-wise. Applying such a map to tethered flight on spherical parallels, we obtain analytic expressions for the required bank angle and identify a specific zero-bank locus where the tether tension exactly balances centrifugal effects, highlighting the decoupling between aerodynamic coordination and the apparent gravity vector. Under a simple lift/drag law, the minimal-thrust angle of attack admits a closed form. These pointwise quasi-steady inversion solutions become steady-flight trim when the trajectory and rotational dynamics are time-invariant. The framework bridges inverse simulation in aeronautics with geometric modeling in robotics, providing a rigorous building block for trajectory design and feasibility checks.

</details>


### [14] [Nonlinear Predictive Control of the Continuum and Hybrid Dynamics of a Suspended Deformable Cable for Aerial Pick and Place](https://arxiv.org/abs/2602.17199)
*Antonio Rapuano,Yaolei Shen,Federico Califano,Chiara Gabellieri,Antonio Franchi*

Main category: cs.RO

TL;DR: 该论文提出了一个结合高精度PDE模型与降阶表示的空中电缆操作框架，用于实现无人机携带柔性电缆的实时动态控制。


<details>
  <summary>Details</summary>
Motivation: 无人机携带柔性电缆进行空中操作时，电缆的复杂动力学特性（如振荡、变形）给实时控制带来挑战。需要既能准确描述电缆动态行为，又适合实时控制的计算高效模型。

Method: 1. 基于偏微分方程建立电缆高保真模型；2. 使用有限差分法离散化PDE；3. 采用本征正交分解提取降阶模型，保留主导变形模式；4. 基于ROM设计非线性模型预测控制方案，处理振荡稳定和负载附着/分离等混合过渡。

Result: 仿真验证表明：降阶模型具有稳定性、高效性和鲁棒性；控制器在各种操作条件下能有效调节电缆动力学；ROM在受限环境中的轨迹规划应用展示了方法的通用性。

Conclusion: 该框架成功实现了无人机携带悬挂柔性电缆的实时、动态感知控制，为空中电缆操作提供了有效的解决方案。

Abstract: This paper presents a framework for aerial manipulation of an extensible cable that combines a high-fidelity model based on partial differential equations (PDEs) with a reduced-order representation suitable for real-time control. The PDEs are discretised using a finite-difference method, and proper orthogonal decomposition is employed to extract a reduced-order model (ROM) that retains the dominant deformation modes while significantly reducing computational complexity. Based on this ROM, a nonlinear model predictive control scheme is formulated, capable of stabilizing cable oscillations and handling hybrid transitions such as payload attachment and detachment. Simulation results confirm the stability, efficiency, and robustness of the ROM, as well as the effectiveness of the controller in regulating cable dynamics under a range of operating conditions. Additional simulations illustrate the application of the ROM for trajectory planning in constrained environments, demonstrating the versatility of the proposed approach. Overall, the framework enables real-time, dynamics-aware control of unmanned aerial vehicles (UAVs) carrying suspended flexible cables.

</details>


### [15] [Multi-session Localization and Mapping Exploiting Topological Information](https://arxiv.org/abs/2602.17226)
*Lorenzo Montano-Olivan,Julio A. Placed,Luis Montano,Maria T. Lazaro*

Main category: cs.RO

TL;DR: 提出了一种基于地图定位的多会话框架，通过拓扑感知的决策机制选择性触发建图和闭环检测，提高重复访问环境中的地图一致性。


<details>
  <summary>Details</summary>
Motivation: 自主系统在重复访问相同环境时面临建图和定位的挑战，传统方法贪婪运行完整SLAM会话并尝试在结果地图间寻找对应关系存在局限性。

Method: 提出多会话框架，基于地图定位而非完整SLAM；采用拓扑感知、不确定性感知的决策机制分析位姿图结构，检测低连接区域，选择性触发建图和闭环模块；将结果地图和位姿图无缝集成到现有模型中。

Result: 在数据集重叠序列上验证了方法有效性，并在真实世界矿井类环境中展示了性能，能够减少累积误差并增强全局一致性。

Conclusion: 该框架为重复访问环境中的自主系统提供了更有效的建图和定位解决方案，相比传统方法能更好地处理多会话场景下的地图一致性挑战。

Abstract: Operating in previously visited environments is becoming increasingly crucial for autonomous systems, with direct applications in autonomous driving, surveying, and warehouse or household robotics. This repeated exposure to observing the same areas poses significant challenges for mapping and localization -- key components for enabling any higher-level task. In this work, we propose a novel multi-session framework that builds on map-based localization, in contrast to the common practice of greedily running full SLAM sessions and trying to find correspondences between the resulting maps. Our approach incorporates a topology-informed, uncertainty-aware decision-making mechanism that analyzes the pose-graph structure to detect low-connectivity regions, selectively triggering mapping and loop closing modules. The resulting map and pose-graph are seamlessly integrated into the existing model, reducing accumulated error and enhancing global consistency. We validate our method on overlapping sequences from datasets and demonstrate its effectiveness in a real-world mine-like environment.

</details>


### [16] [FRAPPE: Infusing World Modeling into Generalist Policies via Multiple Future Representation Alignment](https://arxiv.org/abs/2602.17259)
*Han Zhao,Jingbo Wang,Wenxuan Song,Shuai Chen,Yang Liu,Yan Wang,Haoang Li,Donglin Wang*

Main category: cs.RO

TL;DR: FRAPPE方法通过两阶段微调策略解决VLA模型世界建模中的像素重建过度强调和误差累积问题，提高机器人策略的世界感知能力


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在环境动态预测（世界建模）中存在两个主要问题：1.训练目标迫使模型过度强调像素级重建，限制了语义学习和泛化能力；2.推理过程中依赖预测的未来观察导致误差累积

Method: 提出FRAPPE方法，采用两阶段微调策略：中期训练阶段学习预测未来观察的潜在表示；后期训练阶段并行扩展计算工作量，同时与多个不同的视觉基础模型对齐表示

Result: 在RoboTwin基准测试和真实世界任务中，FRAPPE优于最先进方法，在长视野和未见场景中表现出强大的泛化能力

Conclusion: FRAPPE通过显著提高微调效率和减少对动作标注数据的依赖，为增强通用机器人策略的世界感知能力提供了可扩展且数据高效的途径

Abstract: Enabling VLA models to predict environmental dynamics, known as world modeling, has been recognized as essential for improving robotic reasoning and generalization. However, current approaches face two main issues: 1. The training objective forces models to over-emphasize pixel-level reconstruction, which constrains semantic learning and generalization 2. Reliance on predicted future observations during inference often leads to error accumulation. To address these challenges, we introduce Future Representation Alignment via Parallel Progressive Expansion (FRAPPE). Our method adopts a two-stage fine-tuning strategy: In the mid-training phase, the model learns to predict the latent representations of future observations; In the post-training phase, we expand the computational workload in parallel and align the representation simultaneously with multiple different visual foundation models. By significantly improving fine-tuning efficiency and reducing dependence on action-annotated data, FRAPPE provides a scalable and data-efficient pathway to enhance world-awareness in generalist robotic policies. Experiments on the RoboTwin benchmark and real-world tasks demonstrate that FRAPPE outperforms state-of-the-art approaches and shows strong generalization in long-horizon and unseen scenarios.

</details>


### [17] [Contact-Anchored Proprioceptive Odometry for Quadruped Robots](https://arxiv.org/abs/2602.17393)
*Minxing Sun,Yao Mao*

Main category: cs.RO

TL;DR: 提出了一种仅使用IMU和电机测量的纯本体感知状态估计器，通过接触腿作为运动学锚点、扭矩基足部力估计选择可靠接触、足部落点位置提供间歇性世界坐标系约束来抑制长期漂移，适用于双足、四足和轮腿机器人。


<details>
  <summary>Details</summary>
Motivation: 对于没有摄像头或激光雷达的腿式机器人，可靠的里程计仍然具有挑战性，因为IMU漂移和关节速度传感噪声会导致定位误差。需要一种仅依赖本体感知（IMU和电机测量）的鲁棒状态估计方法。

Method: 1) 将接触腿视为运动学锚点，基于关节扭矩的足部力估计选择可靠接触；2) 足部落点位置提供间歇性世界坐标系约束抑制长期漂移；3) 轻量级高度聚类和时间衰减校正防止高程漂移；4) 逆运动学立方卡尔曼滤波器直接从关节角度和速度滤波足端速度；5) 多接触几何一致性缓解偏航漂移。

Result: 在四个四足平台上评估：Astrall点足机器人A完成约200米水平环路误差0.1638米，约15米垂直环路误差0.219米；轮腿机器人B相应误差为0.2264米和0.199米；轮腿机器人C约700米水平环路误差7.68米，约20米垂直环路误差0.540米；Unitree Go2 EDU约120米水平环路误差2.2138米，约8米垂直环路垂直误差小于0.1米。

Conclusion: 该方法提供了一种有效的纯本体感知状态估计解决方案，能够显著抑制IMU漂移，适用于多种腿式机器人平台，在复杂环境中表现出良好的定位精度和鲁棒性。

Abstract: Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents a purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with a unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as a kinematic anchor: joint-torque--based foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce a lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to a kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and a Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot~A, a $\sim$200\,m horizontal loop and a $\sim$15\,m vertical loop return with 0.1638\,m and 0.219\,m error, respectively; on wheel-legged robot~B, the corresponding errors are 0.2264\,m and 0.199\,m. On wheel-legged robot~C, a $\sim$700\,m horizontal loop yields 7.68\,m error and a $\sim$20\,m vertical loop yields 0.540\,m error. Unitree Go2 EDU closes a $\sim$120\,m horizontal loop with 2.2138\,m error and a $\sim$8\,m vertical loop with less than 0.1\,m vertical error. github.com/ShineMinxing/Ros2Go2Estimator.git

</details>


### [18] [3D-printed Soft Optical sensor with a Lens (SOLen) for light guidance in mechanosensing](https://arxiv.org/abs/2602.17421)
*Diana Cafiso,Petr Trunin,Carolina Gay,Lucia Beccai*

Main category: cs.RO

TL;DR: 提出了一种用于3D打印软体光学传感(SOLen)的方法，通过在Y形波导前放置打印透镜，利用变形引起的透镜旋转和焦点平移来检测运动方向和幅度


<details>
  <summary>Details</summary>
Motivation: 增材制造使软体机器人几何形状日益复杂，需要与单材料、一步制造兼容的传感解决方案。现有光学软传感器性能常受环境耦合、泄漏、散射等影响，而缓解策略通常需要多材料界面

Method: 在Y形波导前放置打印透镜，利用变形引起的透镜旋转和焦点平移重新分配两个分支间的光功率，产生编码运动方向和幅度的差分输出。使用丙烯酸聚氨酯树脂与月桂基丙烯酸酯改性以提高柔顺性和光学透射率

Result: 通过单层光学表征获得波长相关折射率和透射率，模拟设计透镜轮廓并实现亚毫米精度打印。旋转测试显示多个周期内可重复的分支选择性信号切换

Conclusion: 建立了一个可转移的材料到光学工作流程，为具有透镜的软体光学传感器提供了新功能，适用于下一代软体机器人

Abstract: Additive manufacturing is enabling soft robots with increasingly complex geometries, creating a demand for sensing solutions that remain compatible with single-material, one-step fabrication. Optical soft sensors are attractive for monolithic printing, but their performance is often degraded by uncontrolled light propagation (ambient coupling, leakage, scattering), while common miti- gation strategies typically require multimaterial interfaces. Here, we present an approach for 3D printed soft optical sensing (SOLen), in which a printed lens is placed in front of an emitter within a Y-shaped waveguide. The sensing mechanism relies on deformation-induced lens rotation and focal-spot translation, redistributing optical power between the two branches to generate a differential output that encodes both motion direction and amplitude. An acrylate polyurethane resin was modified with lauryl acrylate to improve compliance and optical transmittance, and single-layer optical characterization was used to derive wavelength-dependent refractive index and transmittance while minimizing DLP layer-related artifacts. The measured refractive index was used in simulations to design a lens profile for a target focal distance, which was then printed with sub-millimeter fidelity. Rotational tests demonstrated reproducible branch-selective signal switching over multiple cycles. These results establish a transferable material-to-optics workflow for soft optical sensors with lens with new functionalities for next-generation soft robots

</details>


### [19] [A Cost-Effective and Climate-Resilient Air Pressure System for Rain Effect Reduction on Automated Vehicle Cameras](https://arxiv.org/abs/2602.17472)
*Mohamed Sabry,Joseba Gorospe,Cristina Olaverri-Monreal*

Main category: cs.RO

TL;DR: 本文提出了一种低成本硬件解决方案，用于提高自动驾驶车辆在雨天条件下的感知性能，通过兼容多个摄像头提升行人检测准确率从8.3%到41.6%。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在恶劣天气条件下的研究主要集中在感知算法改进，而物理硬件解决方案研究有限。现有方法如亲水/疏水镜头和喷雾只能部分缓解问题，工业级保护系统成本高且难以在汽车领域规模化部署。

Method: 提出了一种成本效益高的硬件解决方案，专门针对雨天条件设计，能够同时兼容多个摄像头。该系统与现有摄像头感知平台兼容，无需额外的高成本传感器或硬件更换。

Result: 该系统显著提升了深度学习模型的行人检测准确率，从8.3%提高到41.6%。同时支持可持续交通目标，通过延长自动驾驶车辆运行可靠性，减少资源消耗和排放。

Conclusion: 该硬件解决方案为自动驾驶车辆在恶劣天气条件下的可靠运行提供了经济有效的途径，支持模块化升级，促进自动驾驶技术在挑战性天气条件下的更高效部署。

Abstract: Recent advances in automated vehicles have focused on improving perception performance under adverse weather conditions; however, research on physical hardware solutions remains limited, despite their importance for perception critical applications such as vehicle platooning. Existing approaches, such as hydrophilic or hydrophobic lenses and sprays, provide only partial mitigation, while industrial protection systems imply high cost and they do not enable scalability for automotive deployment.
  To address these limitations, this paper presents a cost-effective hardware solution for rainy conditions, designed to be compatible with multiple cameras simultaneously.
  Beyond its technical contribution, the proposed solution supports sustainability goals in transportation systems. By enabling compatibility with existing camera-based sensing platforms, the system extends the operational reliability of automated vehicles without requiring additional high-cost sensors or hardware replacements. This approach reduces resource consumption, supports modular upgrades, and promotes more cost-efficient deployment of automated vehicle technologies, particularly in challenging weather conditions where system failures would otherwise lead to inefficiencies and increased emissions. The proposed system was able to increase pedestrian detection accuracy of a Deep Learning model from 8.3% to 41.6%.

</details>


### [20] [Optically Sensorized Electro-Ribbon Actuator (OS-ERA)](https://arxiv.org/abs/2602.17474)
*Carolina Gay,Petr Trunin,Diana Cafiso,Yuejun Xu,Majid Taghavi,Lucia Beccai*

Main category: cs.RO

TL;DR: OS-ERA是一种光学传感的Electro-Ribbon执行器，通过嵌入软光学波导传感器实现高精度弯曲状态分类，解决了传统电容传感精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统Electro-Ribbon执行器（ERAs）虽然具有超高的位移和快速运动能力，但其嵌入式传感依赖于精度有限的电容传感器，这阻碍了精确控制。需要一种不影响执行性能的可靠传感解决方案。

Method: 设计了OS-ERA，在ERA中嵌入两个软光学波导传感器来分析复杂曲率运动。训练分类器将传感信号映射到八个弯曲状态，并在六个独立试验中验证模型，与训练运行中学习到的信号轨迹进行比较。

Result: 在所有测试中，传感输出信号遵循训练流形，预测序列反映真实性能并确认可重复性。即使故意在驱动速度上设置训练-测试不匹配，信号轨迹仍保持其形状，分类保持准确，展示了实用的电压和速度不变性。

Conclusion: OS-ERA能够以高保真度分类弯曲状态，快速且可重复，解决了ERA长期存在的瓶颈问题，为实现闭环控制迈出了重要一步。

Abstract: Electro-Ribbon Actuators (ERAs) are lightweight flexural actuators that exhibit ultrahigh displacement and fast movement. However, their embedded sensing relies on capacitive sensors with limited precision, which hinders accurate control. We introduce OS-ERA, an optically sensorized ERA that yields reliable proprioceptive information, and we focus on the design and integration of a sensing solution without affecting actuation. To analyse the complex curvature of an ERA in motion, we design and embed two soft optical waveguide sensors. A classifier is trained to map the sensing signals in order to distinguish eight bending states. We validate our model on six held-out trials and compare it against signals' trajectories learned from training runs. Across all tests, the sensing output signals follow the training manifold, and the predicted sequence mirrors real performance and confirms repeatability. Despite deliberate train-test mismatches in actuation speed, the signal trajectories preserve their shape, and classification remains consistently accurate, demonstrating practical voltage- and speed-invariance. As a result, OS-ERA classifies bending states with high fidelity; it is fast and repeatable, solving a longstanding bottleneck of the ERA, enabling steps toward closed-loop control.

</details>


### [21] [Proximal powered knee placement: a case study](https://arxiv.org/abs/2602.17502)
*Kyle R. Embry,Lorenzo Vianello,Jim Lipsey,Frank Ursetta,Michael Stephens,Zhi Wang,Ann M. Simon,Andrea J. Ikeda,Suzanne B. Finucane,Shawana Anarwala,Levi J. Hargrove*

Main category: cs.RO

TL;DR: 探索性研究评估了动力假肢膝关节的膝上动力系统布置可行性，发现相比膝下布置，膝上配置能改善步行速度和步频，同时保持膝关节活动范围，为优化质量分布而非简单减重提供了初步证据。


<details>
  <summary>Details</summary>
Motivation: 下肢截肢影响全球数百万人，导致行动能力受损、步行速度下降和日常社交活动受限。动力假肢膝关节能通过主动辅助膝关节扭矩部分恢复行动能力，但动力组件增加的质量可能削弱这些益处，影响步态力学并增加代谢成本。因此，优化质量分布而非简单最小化总质量可能是更有效的解决方案。

Method: 本研究为探索性研究，在小规模队列中评估了动力假肢膝关节膝上动力系统布置的可行性。将膝上配置与膝下配置进行比较，测量了步行速度、步频、步态对称性、膝关节活动范围和峰值速度等指标。还在坡道和楼梯上进行了额外测试，以验证控制策略在不同运动任务中的鲁棒性。

Result: 相比膝下布置，膝上配置显示出改善的步行速度（一名参与者提高9.2%）和步频（提高3.6%），但对步态对称性的影响不一。运动学测量显示两种配置的膝关节活动范围和峰值速度相似。在坡道和楼梯上的额外测试证实了控制策略在多种运动任务中的鲁棒性。

Conclusion: 初步结果表明膝上布置在功能上是可行的，仔细的质量分布可以在保持动力辅助益处的同时减轻额外重量的不利影响。需要进一步研究来确认这些趋势，并为设计和临床建议提供指导。

Abstract: Lower limb amputation affects millions worldwide, leading to impaired mobility, reduced walking speed, and limited participation in daily and social activities. Powered prosthetic knees can partially restore mobility by actively assisting knee joint torque, improving gait symmetry, sit-to-stand transitions, and walking speed. However, added mass from powered components may diminish these benefits, negatively affecting gait mechanics and increasing metabolic cost. Consequently, optimizing mass distribution, rather than simply minimizing total mass, may provide a more effective and practical solution. In this exploratory study, we evaluated the feasibility of above-knee powertrain placement for a powered prosthetic knee in a small cohort. Compared to below-knee placement, the above-knee configuration demonstrated improved walking speed (+9.2% for one participant) and cadence (+3.6%), with mixed effects on gait symmetry. Kinematic measures indicated similar knee range of motion and peak velocity across configurations. Additional testing on ramps and stairs confirmed the robustness of the control strategy across multiple locomotion tasks. These preliminary findings suggest that above-knee placement is functionally feasible and that careful mass distribution can preserve the benefits of powered assistance while mitigating adverse effects of added weight. Further studies are needed to confirm these trends and guide design and clinical recommendations.

</details>


### [22] [IRIS: Learning-Driven Task-Specific Cinema Robot Arm for Visuomotor Motion Control](https://arxiv.org/abs/2602.17537)
*Qilong Cheng,Matthew Mackay,Ali Bereyhi*

Main category: cs.RO

TL;DR: IRIS是一个低成本、基于学习的6自由度机器人相机系统，通过3D打印硬件和视觉运动模仿学习实现自主电影级运动控制


<details>
  <summary>Details</summary>
Motivation: 工业级机器人相机系统成本高、操作复杂，限制了其在动态、可重复运动控制中的应用普及

Method: 采用全3D打印轻量化硬件设计，结合基于Action Chunking with Transformers (ACT)的目标条件视觉运动模仿学习框架，直接从人类演示中学习物体感知和平滑的相机轨迹

Result: 系统成本低于1000美元，支持1.5公斤负载，重复精度约1毫米，实验显示能准确跟踪轨迹、可靠自主执行，并泛化到多种电影级运动

Conclusion: IRIS通过低成本硬件和学习驱动的方法，实现了无需显式几何编程的自主电影级相机控制，为机器人相机系统提供了可访问的解决方案

Abstract: Robotic camera systems enable dynamic, repeatable motion beyond human capabilities, yet their adoption remains limited by the high cost and operational complexity of industrial-grade platforms. We present the Intelligent Robotic Imaging System (IRIS), a task-specific 6-DOF manipulator designed for autonomous, learning-driven cinematic motion control. IRIS integrates a lightweight, fully 3D-printed hardware design with a goal-conditioned visuomotor imitation learning framework based on Action Chunking with Transformers (ACT). The system learns object-aware and perceptually smooth camera trajectories directly from human demonstrations, eliminating the need for explicit geometric programming. The complete platform costs under $1,000 USD, supports a 1.5 kg payload, and achieves approximately 1 mm repeatability. Real-world experiments demonstrate accurate trajectory tracking, reliable autonomous execution, and generalization across diverse cinematic motions.

</details>


### [23] [FR-GESTURE: An RGBD Dataset For Gesture-based Human-Robot Interaction In First Responder Operations](https://arxiv.org/abs/2602.17573)
*Konstantinos Foteinos,Georgios Angelidis,Aggelos Psiris,Vasileios Argyriou,Panagiotis Sarigiannidis,Georgios Th. Papadopoulos*

Main category: cs.RO

TL;DR: 本文提出了首个专门为急救人员设计的基于手势的无人地面车辆控制数据集FR-GESTURE，包含12种手势命令、3312个RGBD图像对，并提供了评估协议和基线实验。


<details>
  <summary>Details</summary>
Motivation: 灾害强度和频率不断增加，使得急救人员的工作更加困难。人工智能和机器人解决方案可以协助他们的操作，弥补这些困难。目前缺乏专门为急救人员设计的基于手势的UGV控制数据集。

Method: 1. 设计了12种手势命令，灵感来源于现有急救人员手势和战术手语，并经过经验丰富的急救人员反馈完善；2. 从2个视角和7个距离收集了3312个RGBD图像对；3. 定义了评估协议并进行基线实验。

Result: 创建了首个专门用于急救人员手势控制UGV的数据集FR-GESTURE，包含12种手势命令、3312个RGBD图像对，数据已公开可用。基线实验为后续改进提供了基础。

Conclusion: FR-GESTURE数据集填补了急救人员手势控制UGV领域的数据空白，为未来研究提供了重要资源，有望促进人工智能和机器人技术在灾害响应中的应用。

Abstract: The ever increasing intensity and number of disasters make even more difficult the work of First Responders (FRs). Artificial intelligence and robotics solutions could facilitate their operations, compensating these difficulties. To this end, we propose a dataset for gesture-based UGV control by FRs, introducing a set of 12 commands, drawing inspiration from existing gestures used by FRs and tactical hand signals and refined after incorporating feedback from experienced FRs. Then we proceed with the data collection itself, resulting in 3312 RGBD pairs captured from 2 viewpoints and 7 distances. To the best of our knowledge, this is the first dataset especially intended for gesture-based UGV guidance by FRs. Finally we define evaluation protocols for our RGBD dataset, termed FR-GESTURE, and we perform baseline experiments, which are put forward for improvement. We have made data publicly available to promote future research on the domain: https://doi.org/10.5281/zenodo.18131333.

</details>


### [24] [Hybrid System Planning using a Mixed-Integer ADMM Heuristic and Hybrid Zonotopes](https://arxiv.org/abs/2602.17574)
*Joshua A. Robbins,Andrew F. Thompson,Jonah J. Glunt,Herschel C. Pangborn*

Main category: cs.RO

TL;DR: 本文提出了一种基于混合zonotopes和ADMM启发式算法的混合系统运动规划框架，用于解决嵌入式优化规划中的混合整数规划计算难题。


<details>
  <summary>Details</summary>
Motivation: 嵌入式混合系统优化规划面临混合整数规划计算量大、对数值公式敏感的挑战，需要更高效的规划方法。

Method: 采用混合zonotopes集合表示法，结合新的ADMM混合整数规划启发式算法，处理分段仿射系统可达性分析并构建最优规划问题。

Result: 提出的方法比现有技术产生更低内存复杂度和更紧凸松弛的集合，ADMM启发式算法收敛速度优于现有混合整数规划启发式算法。

Conclusion: 该方法成功应用于自动驾驶的行为和运动规划场景，为嵌入式硬件上的混合系统规划提供了有效解决方案。

Abstract: Embedded optimization-based planning for hybrid systems is challenging due to the use of mixed-integer programming, which is computationally intensive and often sensitive to the specific numerical formulation. To address that challenge, this article proposes a framework for motion planning of hybrid systems that pairs hybrid zonotopes - an advanced set representation - with a new alternating direction method of multipliers (ADMM) mixed-integer programming heuristic. A general treatment of piecewise affine (PWA) system reachability analysis using hybrid zonotopes is presented and extended to formulate optimal planning problems. Sets produced using the proposed identities have lower memory complexity and tighter convex relaxations than equivalent sets produced from preexisting techniques. The proposed ADMM heuristic makes efficient use of the hybrid zonotope structure. For planning problems formulated as hybrid zonotopes, the proposed heuristic achieves improved convergence rates as compared to state-of-the-art mixed-integer programming heuristics. The proposed methods for hybrid system planning on embedded hardware are experimentally applied in a combined behavior and motion planning scenario for autonomous driving.

</details>


### [25] [Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space](https://arxiv.org/abs/2602.17586)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: Deep-Flow是一个无监督的安全关键异常检测框架，使用最优传输条件流匹配来表征专家人类驾驶行为的连续概率密度，通过PCA瓶颈约束生成过程到低秩谱流形，实现稳定、确定性的对数似然估计。


<details>
  <summary>Details</summary>
Motivation: 当前L4级自动驾驶车辆的安全验证受限于无法使用传统基于规则的启发式方法扩展检测罕见、高风险的长尾场景，需要更有效的安全关键异常检测方法。

Method: 采用最优传输条件流匹配(OT-CFM)表征专家驾驶行为的概率密度；通过PCA瓶颈将生成过程约束到低秩谱流形；使用带车道感知目标条件的早期融合Transformer编码器解决多模态歧义；引入运动学复杂度加权方案优先处理高能量机动。

Result: 在Waymo Open Motion Dataset上评估，AUC-ROC达到0.766；揭示了运动学危险与语义违规之间的根本区别；识别出传统安全过滤器忽略的分布外行为，如车道边界违规和非规范交叉口机动。

Conclusion: 该工作为定义统计安全门提供了数学严谨的基础，使自动驾驶车队的安全部署能够进行客观、数据驱动的验证。

Abstract: Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.

</details>
