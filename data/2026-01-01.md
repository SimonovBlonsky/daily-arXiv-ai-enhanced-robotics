<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [SHIELD: Spherical-Projection Hybrid-Frontier Integration for Efficient LiDAR-based Drone Exploration](https://arxiv.org/abs/2512.23972)
*Liangtao Feng,Zhenchang Liu,Feng Zhang,Xuefeng Ren*

Main category: cs.RO

TL;DR: SHIELD是一种用于无人机LiDAR探索的球形投影混合前沿集成方法，通过维护观测质量占据地图、混合前沿方法和向外球形投影射线投射策略，解决LiDAR点云质量不一致、计算负担重和开放区域安全探索等问题。


<details>
  <summary>Details</summary>
Motivation: 虽然激光LiDAR具有宽视场的优势，但在无人机探索应用中仍面临多个挑战：LiDAR点云的观测质量通常低于深度相机；基于已知和未知区域的传统前沿方法计算负担重，特别是在处理LiDAR宽视场时；没有点云的区域也难以通过射线投射分类为自由空间。

Method: SHIELD方法包括：1) 维护观测质量占据地图，在该地图上进行射线投射以解决探索过程中点云质量不一致的问题；2) 使用混合前沿方法处理计算负担和点云质量限制；3) 提出向外球形投影射线投射策略，共同确保开放区域的飞行安全和探索效率。

Result: 模拟和飞行实验证明了SHIELD的有效性。该方法将开源贡献给研究社区。

Conclusion: SHIELD通过创新的球形投影混合前沿集成方法，有效解决了LiDAR在无人机探索中的关键问题，包括点云质量不一致、计算效率低和开放区域安全探索等挑战，为LiDAR-based无人机探索提供了高效可靠的解决方案。

Abstract: This paper introduces SHIELD, a Spherical-Projection Hybrid-Frontier Integration for Efficient LiDAR-based Drone exploration method. Although laser LiDAR offers the advantage of a wide field of view, its application in UAV exploration still faces several challenges. The observation quality of LiDAR point clouds is generally inferior to that of depth cameras. Traditional frontier methods based on known and unknown regions impose a heavy computational burden, especially when handling the wide field of view of LiDAR. In addition, regions without point cloud are also difficult to classify as free space through raycasting. To address these problems, the SHIELD is proposed. It maintains an observation-quality occupancy map and performs ray-casting on this map to address the issue of inconsistent point-cloud quality during exploration. A hybrid frontier method is used to tackle both the computational burden and the limitations of point-cloud quality exploration. In addition, an outward spherical-projection ray-casting strategy is proposed to jointly ensure flight safety and exploration efficiency in open areas. Simulations and flight experiments prove the effectiveness of SHIELD. This work will be open-sourced to contribute to the research community.

</details>


### [2] [Unified Embodied VLM Reasoning with Robotic Action via Autoregressive Discretized Pre-training](https://arxiv.org/abs/2512.24125)
*Yi Liu,Sukai Wang,Dafeng Wei,Xiaowei Cai,Linqing Zhong,Jiange Yang,Guanghui Ren,Jinyu Zhang,Maoqing Yao,Chuankang Li,Xindong He,Liliang Chen,Jianlan Luo*

Main category: cs.RO

TL;DR: 论文提出了ERIQ基准和FACT方法来解决机器人操作中推理与精确执行之间的权衡问题，通过解耦评估和统一优化提升通用机器人的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器人在开放世界环境中需要同时实现广泛泛化和高精度动作执行，但现有VLA模型难以平衡这两者。大型视觉语言模型虽然提升了语义泛化能力，但缺乏具身推理会导致脆弱行为；而强推理能力本身又不足以实现精确控制。

Method: 1. 提出ERIQ基准：包含6K+问答对，覆盖四个推理维度，解耦推理与执行以进行系统评估；2. 提出FACT方法：基于流匹配的动作分词器，将连续控制转换为离散序列，同时保持高保真轨迹重建；3. 开发GenieReasoner：在统一空间中联合优化推理和动作。

Result: ERIQ揭示了具身推理能力与端到端VLA泛化之间的强正相关关系。GenieReasoner在真实世界任务中优于连续动作和先前离散动作基线，FACT方法有效弥合了从推理到精确执行的差距。

Conclusion: ERIQ和FACT提供了一个原则性框架来诊断和克服推理-精度权衡问题，推动了鲁棒、通用机器人操作的发展。通过解耦评估和统一优化，实现了更好的泛化能力和精确执行。

Abstract: General-purpose robotic systems operating in open-world environments must achieve both broad generalization and high-precision action execution, a combination that remains challenging for existing Vision-Language-Action (VLA) models. While large Vision-Language Models (VLMs) improve semantic generalization, insufficient embodied reasoning leads to brittle behavior, and conversely, strong reasoning alone is inadequate without precise control. To provide a decoupled and quantitative assessment of this bottleneck, we introduce Embodied Reasoning Intelligence Quotient (ERIQ), a large-scale embodied reasoning benchmark in robotic manipulation, comprising 6K+ question-answer pairs across four reasoning dimensions. By decoupling reasoning from execution, ERIQ enables systematic evaluation and reveals a strong positive correlation between embodied reasoning capability and end-to-end VLA generalization. To bridge the gap from reasoning to precise execution, we propose FACT, a flow-matching-based action tokenizer that converts continuous control into discrete sequences while preserving high-fidelity trajectory reconstruction. The resulting GenieReasoner jointly optimizes reasoning and action in a unified space, outperforming both continuous-action and prior discrete-action baselines in real-world tasks. Together, ERIQ and FACT provide a principled framework for diagnosing and overcoming the reasoning-precision trade-off, advancing robust, general-purpose robotic manipulation.

</details>


### [3] [ROBOPOL: Social Robotics Meets Vehicular Communications for Cooperative Automated Driving](https://arxiv.org/abs/2512.24129)
*Manuel Bied,John Arockiasamy,Andy Comeca,Maximilian Schrapel,Victoria Yang,Alexey Rolich,Barbara Bruno,Maike Schwammberger,Dieter Fiems,Alexey Vinel*

Main category: cs.RO

TL;DR: 提出使用社交机器人作为自动驾驶车辆与弱势道路使用者之间的协调者，通过整合四个关键技术实现安全高效的道路共享


<details>
  <summary>Details</summary>
Motivation: 在实现完全自动驾驶的过程中，自动驾驶车辆与人类（包括行人）共享道路是不可避免的。即使所有车辆都实现自动化，行人仍需过马路，因此需要一种机制来协调自动驾驶车辆与弱势道路使用者之间的互动。

Method: 提出整合四个关键使能技术：1) 高级感知技术让机器人感知环境；2) 车辆通信技术让联网车辆共享意图，机器人发送引导指令；3) 社交人机交互技术让机器人有效与弱势道路使用者和驾驶员沟通；4) 形式化规范让机器人理解交通规则并进行规划。

Result: 论文概述了这四个关键使能技术，并报告了前三个技术的首次概念验证集成，展示了一个社交机器人在与协作式自动电动自行车场景中为行人提供建议的应用。

Conclusion: 社交机器人可以作为自动驾驶车辆与弱势道路使用者之间的有效协调者，通过整合感知、通信、人机交互和形式化规范等技术，能够促进混合交通环境中的安全高效互动。

Abstract: On the way towards full autonomy, sharing roads between automated vehicles and human actors in so-called mixed traffic is unavoidable. Moreover, even if all vehicles on the road were autonomous, pedestrians would still be crossing the streets. We propose social robots as moderators between autonomous vehicles and vulnerable road users (VRU). To this end, we identify four enablers requiring integration: (1) advanced perception, allowing the robot to see the environment; (2) vehicular communications allowing connected vehicles to share intentions and the robot to send guiding commands; (3) social human-robot interaction allowing the robot to effectively communicate with VRUs and drivers; (4) formal specification allowing the robot to understand traffic and plan accordingly. This paper presents an overview of the key enablers and report on a first proof-of-concept integration of the first three enablers envisioning a social robot advising pedestrians in scenarios with a cooperative automated e-bike.

</details>


### [4] [GR-Dexter Technical Report](https://arxiv.org/abs/2512.24210)
*Ruoshi Wen,Guangzeng Chen,Zhongren Cui,Min Du,Yang Gou,Zhigang Han,Liqun Huang,Mingyu Lei,Yunfei Li,Zhuohang Li,Wenlei Liu,Yuxiao Liu,Xiao Ma,Hao Niu,Yutao Ouyang,Zeyu Ren,Haixin Shi,Wei Xu,Haoxiang Zhang,Jiajun Zhang,Xiao Zhang,Liwei Zheng,Weiheng Zhong,Yifei Zhou,Zhengming Zhu,Hang Li*

Main category: cs.RO

TL;DR: GR-Dexter是一个用于双手机器人灵巧手操作的VLA框架，通过硬件设计、遥操作系统和训练方法解决高自由度灵巧手操作的数据收集和策略扩展挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型主要局限于夹爪机器人，扩展到具有高自由度灵巧手的双手机器人面临动作空间扩大、手部遮挡和数据收集成本高等挑战。

Method: 设计了紧凑的21自由度机器人手，开发了直观的双手机器人遥操作系统用于真实机器人数据收集，并提出了利用遥操作轨迹、大规模视觉语言数据和跨具身数据集的训练方法。

Result: 在长期日常操作和泛化拾放任务中，GR-Dexter实现了强大的域内性能，并对未见过的物体和指令表现出更好的鲁棒性。

Conclusion: GR-Dexter为通用灵巧手机器人操作提供了实用的解决方案，是向通用灵巧手机器人操作迈出的重要一步。

Abstract: Vision-language-action (VLA) models have enabled language-conditioned, long-horizon robot manipulation, but most existing systems are limited to grippers. Scaling VLA policies to bimanual robots with high degree-of-freedom (DoF) dexterous hands remains challenging due to the expanded action space, frequent hand-object occlusions, and the cost of collecting real-robot data. We present GR-Dexter, a holistic hardware-model-data framework for VLA-based generalist manipulation on a bimanual dexterous-hand robot. Our approach combines the design of a compact 21-DoF robotic hand, an intuitive bimanual teleoperation system for real-robot data collection, and a training recipe that leverages teleoperated robot trajectories together with large-scale vision-language and carefully curated cross-embodiment datasets. Across real-world evaluations spanning long-horizon everyday manipulation and generalizable pick-and-place, GR-Dexter achieves strong in-domain performance and improved robustness to unseen objects and unseen instructions. We hope GR-Dexter serves as a practical step toward generalist dexterous-hand robotic manipulation.

</details>


### [5] [RANGER: A Monocular Zero-Shot Semantic Navigation Framework through Contextual Adaptation](https://arxiv.org/abs/2512.24212)
*Ming-Ming Yu,Yi Chen,Börje F. Karlsson,Wenjun Wu*

Main category: cs.RO

TL;DR: RANGER是一个零样本、开放词汇的语义导航框架，仅使用单目相机，无需深度和姿态信息，通过3D基础模型和上下文学习能力实现高效目标搜索


<details>
  <summary>Details</summary>
Motivation: 现有零样本目标导航方法存在两个关键限制：1) 过度依赖模拟器提供的精确深度和姿态信息，限制了在真实世界的应用；2) 缺乏上下文学习能力，难以快速适应新环境

Method: 提出RANGER框架，包含关键帧3D重建、语义点云生成、VLM驱动的探索价值估计、高层自适应路径点选择和低层动作执行等组件，仅需单目相机输入

Result: 在HM3D基准测试和真实环境中，RANGER在导航成功率和探索效率方面达到竞争性性能，并展现出优越的上下文学习适应能力，无需环境先验3D地图

Conclusion: RANGER通过消除对深度和姿态的依赖并增强上下文学习能力，为真实世界机器人导航提供了更实用的零样本解决方案，仅需观察短视频即可显著提升任务效率

Abstract: Efficiently finding targets in complex environments is fundamental to real-world embodied applications. While recent advances in multimodal foundation models have enabled zero-shot object goal navigation, allowing robots to search for arbitrary objects without fine-tuning, existing methods face two key limitations: (1) heavy reliance on precise depth and pose information provided by simulators, which restricts applicability in real-world scenarios; and (2) lack of in-context learning (ICL) capability, making it difficult to quickly adapt to new environments, as in leveraging short videos. To address these challenges, we propose RANGER, a novel zero-shot, open-vocabulary semantic navigation framework that operates using only a monocular camera. Leveraging powerful 3D foundation models, RANGER eliminates the dependency on depth and pose while exhibiting strong ICL capability. By simply observing a short video of a new environment, the system can also significantly improve task efficiency without requiring architectural modifications or fine-tuning. The framework integrates several key components: keyframe-based 3D reconstruction, semantic point cloud generation, vision-language model (VLM)-driven exploration value estimation, high-level adaptive waypoint selection, and low-level action execution. Experiments on the HM3D benchmark and real-world environments demonstrate that RANGER achieves competitive performance in terms of navigation success rate and exploration efficiency, while showing superior ICL adaptability, with no previous 3D mapping of the environment required.

</details>


### [6] [Heteroscedastic Bayesian Optimization-Based Dynamic PID Tuning for Accurate and Robust UAV Trajectory Tracking](https://arxiv.org/abs/2512.24249)
*Fuqiang Gu,Jiangshan Ai,Xu Lu,Xianlei Long,Yan Li,Tao Jiang,Chao Chen,Huidong Liu*

Main category: cs.RO

TL;DR: 提出HBO-PID控制算法，将异方差贝叶斯优化与经典PID控制器结合，显著提升无人机轨迹跟踪精度和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 无人机在多种应用中需要精确轨迹跟踪，但由于四旋翼系统的欠驱动、非线性和强耦合特性，传统控制算法性能有限

Method: 提出HBO-PID算法，将异方差贝叶斯优化框架与PID控制器集成，通过显式建模输入依赖的噪声方差来适应动态复杂环境，采用两阶段优化策略加速收敛

Result: 实验表明该方法显著优于现有方法，位置精度提升24.7%-42.9%，角度精度提升40.9%-78.4%

Conclusion: HBO-PID算法通过结合异方差贝叶斯优化和PID控制，有效解决了无人机轨迹跟踪中的精度和鲁棒性问题

Abstract: Unmanned Aerial Vehicles (UAVs) play an important role in various applications, where precise trajectory tracking is crucial. However, conventional control algorithms for trajectory tracking often exhibit limited performance due to the underactuated, nonlinear, and highly coupled dynamics of quadrotor systems. To address these challenges, we propose HBO-PID, a novel control algorithm that integrates the Heteroscedastic Bayesian Optimization (HBO) framework with the classical PID controller to achieve accurate and robust trajectory tracking. By explicitly modeling input-dependent noise variance, the proposed method can better adapt to dynamic and complex environments, and therefore improve the accuracy and robustness of trajectory tracking. To accelerate the convergence of optimization, we adopt a two-stage optimization strategy that allow us to more efficiently find the optimal controller parameters. Through experiments in both simulation and real-world scenarios, we demonstrate that the proposed method significantly outperforms state-of-the-art (SOTA) methods. Compared to SOTA methods, it improves the position accuracy by 24.7% to 42.9%, and the angular accuracy by 40.9% to 78.4%.

</details>


### [7] [Real-world Reinforcement Learning from Suboptimal Interventions](https://arxiv.org/abs/2512.24288)
*Yinuo Zhao,Huiqian Jin,Lechun Jiang,Xinyi Zhang,Kun Wu,Pei Ren,Zhiyuan Xu,Zhengping Che,Lei Sun,Dapeng Wu,Chi Harold Liu,Jian Tang*

Main category: cs.RO

TL;DR: SiLRI是一种状态级拉格朗日强化学习算法，通过将在线机器人操作问题建模为约束优化问题，有效利用可能次优的人类干预来加速学习，在真实世界机器人操作任务中显著提升学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有真实世界强化学习方法通常假设人类干预在整个状态空间都是最优的，但现实中即使是专家操作者也无法在所有状态下都提供最优动作或完全避免错误。盲目混合干预数据与机器人收集的数据会继承RL的样本低效性，而纯粹模仿干预数据又会限制最终性能。如何有效利用可能次优和嘈杂的人类干预来加速学习而不受其限制是一个开放问题。

Method: 提出SiLRI（状态级拉格朗日强化学习算法），将在线操作问题建模为约束RL优化问题，其中每个状态的约束边界由人类干预的不确定性决定。引入状态级拉格朗日乘子，通过最小-最大优化联合优化策略和拉格朗日乘子以达到鞍点。该方法建立在人类作为副驾驶的遥操作系统之上。

Result: 实验结果表明，SiLRI能有效利用人类次优干预，与最先进的RL方法HIL-SERL相比，达到90%成功率所需时间至少减少50%。在长时程操作任务中，其他RL方法难以成功的情况下，SiLRI实现了100%的成功率。

Conclusion: SiLRI通过状态级约束优化框架，成功解决了如何有效利用可能次优的人类干预来加速真实世界机器人强化学习的问题，在多样化的操作任务中表现出显著优越性，为真实世界机器人学习提供了有效解决方案。

Abstract: Real-world reinforcement learning (RL) offers a promising approach to training precise and dexterous robotic manipulation policies in an online manner, enabling robots to learn from their own experience while gradually reducing human labor. However, prior real-world RL methods often assume that human interventions are optimal across the entire state space, overlooking the fact that even expert operators cannot consistently provide optimal actions in all states or completely avoid mistakes. Indiscriminately mixing intervention data with robot-collected data inherits the sample inefficiency of RL, while purely imitating intervention data can ultimately degrade the final performance achievable by RL. The question of how to leverage potentially suboptimal and noisy human interventions to accelerate learning without being constrained by them thus remains open. To address this challenge, we propose SiLRI, a state-wise Lagrangian reinforcement learning algorithm for real-world robot manipulation tasks. Specifically, we formulate the online manipulation problem as a constrained RL optimization, where the constraint bound at each state is determined by the uncertainty of human interventions. We then introduce a state-wise Lagrange multiplier and solve the problem via a min-max optimization, jointly optimizing the policy and the Lagrange multiplier to reach a saddle point. Built upon a human-as-copilot teleoperation system, our algorithm is evaluated through real-world experiments on diverse manipulation tasks. Experimental results show that SiLRI effectively exploits human suboptimal interventions, reducing the time required to reach a 90% success rate by at least 50% compared with the state-of-the-art RL method HIL-SERL, and achieving a 100% success rate on long-horizon manipulation tasks where other RL methods struggle to succeed. Project website: https://silri-rl.github.io/.

</details>


### [8] [World In Your Hands: A Large-Scale and Open-source Ecosystem for Learning Human-centric Manipulation in the Wild](https://arxiv.org/abs/2512.24310)
*TARS Robotics,Yuhang Zheng,Jichao Peng,Weize Li,Yupeng Zheng,Xiang Li,Yujie Jin,Julong Wei,Guanhua Zhang,Ruiling Zheng,Ming Cao,Songen Gu,Zhenhong Zou,Kaige Li,Ke Wu,Mingmin Yang,Jiahao Liu,Pengfei Li,Hengjie Si,Feiyu Zhu,Wang Fu,Likun Wang,Ruiwen Yao,Jieru Zhao,Yilun Chen,Wenchao Din*

Main category: cs.RO

TL;DR: WiYH是一个大规模开源生态系统，用于以人为中心的灵巧手操作学习，包含数据收集套件、多模态数据集和基准测试，显著提升操作策略的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前灵巧手操作数据存在规模有限、多样性不足、模态不对齐和基准测试不充分等问题，限制了策略的泛化能力，需要构建大规模、多样化的人类中心操作数据集。

Method: 开发了WiYH生态系统，包含：(1) Oracle Suite可穿戴数据收集套件和自动标注流水线；(2) WiYH数据集，包含超过1000小时的多模态操作数据，涵盖数百种技能和多样化场景；(3) 丰富的标注和基准测试支持从感知到动作的任务。

Result: 实验表明，整合WiYH的人类中心数据显著提升了灵巧手策略在桌面操作任务中的泛化能力和鲁棒性。

Conclusion: WiYH为社区带来了人类中心数据收集和策略学习的新见解，有望推动灵巧手操作研究的发展。

Abstract: Large-scale pre-training is fundamental for generalization in language and vision models, but data for dexterous hand manipulation remains limited in scale and diversity, hindering policy generalization. Limited scenario diversity, misaligned modalities, and insufficient benchmarking constrain current human manipulation datasets. To address these gaps, we introduce World In Your Hands (WiYH), a large-scale open-source ecosystem for human-centric manipulation learning. WiYH includes (1) the Oracle Suite, a wearable data collection kit with an auto-labeling pipeline for accurate motion capture; (2) the WiYH Dataset, featuring over 1,000 hours of multi-modal manipulation data across hundreds of skills in diverse real-world scenarios; and (3) extensive annotations and benchmarks supporting tasks from perception to action. Furthermore, experiments based on the WiYH ecosystem show that integrating WiYH's human-centric data significantly enhances the generalization and robustness of dexterous hand policies in tabletop manipulation tasks. We believe that World In Your Hands will bring new insights into human-centric data collection and policy learning to the community.

</details>


### [9] [3D Path-Following Guidance via Nonlinear Model Predictive Control for Fixed-Wing Small UAS](https://arxiv.org/abs/2512.24326)
*Camron Alexander Hirst,Chris Reale,Eric Frew*

Main category: cs.RO

TL;DR: 本文提出了两种基于非线性模型预测控制（MPC）的3D路径跟踪制导算法，应用于固定翼小型无人机系统，通过飞行测试验证了其在实际高速飞行中的可行性和优越性能。


<details>
  <summary>Details</summary>
Motivation: 针对固定翼小型无人机系统在3D路径跟踪中的挑战，特别是高曲率路径下的精确跟踪需求，需要开发更先进的制导算法来提升飞行性能和适应性。

Method: 首先对RAAVEN小型无人机进行控制增强建模和系统辨识以支持MPC。然后设计了两种MPC算法：第一种在MPC时域内调度静态参考路径速率，激励恒定惯性速度；第二种受模型预测轮廓控制启发，在控制器时域内动态优化参考路径速率，允许在路径进展和路径距离这两个竞争目标之间进行加权权衡。两种控制器都针对一般平滑3D弧长参数化曲线设计。

Result: 在多个高曲率测试路径上进行了飞行测试，与基线前瞻制导律进行比较。结果显示非线性MPC在3D路径跟踪制导中具有实际可行性，并且在高达36米/秒的地面速度下表现出优越性能。

Conclusion: 非线性MPC为固定翼小型无人机的3D路径跟踪制导提供了有效的解决方案，特别是动态优化参考路径速率的第二种方法能够在路径跟踪精度和飞行效率之间实现更好的平衡，展示了在实际高速飞行应用中的潜力。

Abstract: This paper presents the design, implementation, and flight test results of two novel 3D path-following guidance algorithms based on nonlinear model predictive control (MPC), with specific application to fixed-wing small uncrewed aircraft systems. To enable MPC, control-augmented modelling and system identification of the RAAVEN small uncrewed aircraft is presented. Two formulations of MPC are then showcased. The first schedules a static reference path rate over the MPC horizon, incentivizing a constant inertial speed. The second, with inspiration from model predictive contouring control, dynamically optimizes for the reference path rate over the controller horizon as the system operates. This allows for a weighted tradeoff between path progression and distance from path, two competing objectives in path-following guidance. Both controllers are formulated to operate over general smooth 3D arc-length parameterized curves. The MPC guidance algorithms are flown over several high-curvature test paths, with comparison to a baseline lookahead guidance law. The results showcase the real-world feasibility and superior performance of nonlinear MPC for 3D path-following guidance at ground speeds up to 36 meters per second.

</details>


### [10] [Geometric Multi-Session Map Merging with Learned Local Descriptors](https://arxiv.org/abs/2512.24384)
*Yanlong Ma,Nakul S. Joshi,Christa S. Robison,Philip R. Osteen,Brett T. Lopez*

Main category: cs.RO

TL;DR: GMLD是一个基于学习的局部描述符框架，用于大规模多会话点云地图合并，通过关键点感知编码器和平面几何变换器提取特征，结合因子图优化实现准确的地图对齐。


<details>
  <summary>Details</summary>
Motivation: 大规模环境中多会话地图合并对于扩展自主操作至关重要，需要系统地对齐不同会话收集的重叠区域地图。

Method: 使用关键点感知编码器和基于平面的几何变换器提取判别性特征，用于闭环检测和相对位姿估计；在因子图优化阶段加入会话间扫描匹配成本因子以提高全局一致性。

Result: 在公共数据集和自收集的多样化环境数据上评估，结果显示准确且鲁棒的地图合并，学习到的特征在闭环检测和相对位姿估计中都表现出色。

Conclusion: GMLD框架能够有效实现大规模多会话点云地图的准确合并，为扩展自主操作提供了可靠的技术方案。

Abstract: Multi-session map merging is crucial for extended autonomous operations in large-scale environments. In this paper, we present GMLD, a learning-based local descriptor framework for large-scale multi-session point cloud map merging that systematically aligns maps collected across different sessions with overlapping regions. The proposed framework employs a keypoint-aware encoder and a plane-based geometric transformer to extract discriminative features for loop closure detection and relative pose estimation. To further improve global consistency, we include inter-session scan matching cost factors in the factor-graph optimization stage. We evaluate our framework on the public datasets, as well as self-collected data from diverse environments. The results show accurate and robust map merging with low error, and the learned features deliver strong performance in both loop closure detection and relative pose estimation.

</details>


### [11] [Fast and Realistic Automated Scenario Simulations and Reporting for an Autonomous Racing Stack](https://arxiv.org/abs/2512.24402)
*Giovanni Lambertini,Matteo Pini,Eugenio Mascaro,Francesco Moretti,Ayoub Raji,Marko Bertogna*

Main category: cs.RO

TL;DR: 本文描述了一个用于自动驾驶赛车软件栈的自动化仿真与报告流水线，能够以最高3倍实时速度运行仿真，支持本地和GitHub CI/CD环境，包含场景初始化、故障注入和自动化报告功能。


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶赛车软件栈开发一个高效的自动化仿真和验证系统，以有效测试关键模块如高速超车和定位，这些是自动驾驶赛车中最具挑战性的方面。

Method: 基于高保真车辆模型构建仿真系统，使用功能模拟单元接口；设计场景初始化系统支持不同初始条件；实现故障注入模块模拟传感器延迟和扰动；开发自动化报告流程优化仿真分析效果。

Result: 开发了一个完整的自动化仿真和报告流水线，能够以最高3倍实时速度执行软件栈和仿真，支持本地和云端CI/CD环境，具备场景配置、故障注入和自动化报告功能。

Conclusion: 该自动化仿真和报告流水线为自动驾驶赛车软件栈提供了高效的验证工具，能够有效测试关键挑战性模块，通过故障注入和自动化报告提高了系统可靠性和开发效率。

Abstract: In this paper, we describe the automated simulation and reporting pipeline implemented for our autonomous racing stack, ur.autopilot. The backbone of the simulation is based on a high-fidelity model of the vehicle interfaced as a Functional Mockup Unit (FMU). The pipeline can execute the software stack and the simulation up to three times faster than real-time, locally or on GitHub for Continuous Integration/- Continuous Delivery (CI/CD). As the most important input of the pipeline, there is a set of running scenarios. Each scenario allows the initialization of the ego vehicle in different initial conditions (position and speed), as well as the initialization of any other configuration of the stack. This functionality is essential to validate efficiently critical modules, like the one responsible for high-speed overtaking maneuvers or localization, which are among the most challenging aspects of autonomous racing. Moreover, we describe how we implemented a fault injection module, capable of introducing sensor delays and perturbations as well as modifying outputs of any node of the stack. Finally, we describe the design of our automated reporting process, aimed at maximizing the effectiveness of the simulation analysis.

</details>


### [12] [Subsecond 3D Mesh Generation for Robot Manipulation](https://arxiv.org/abs/2512.24428)
*Qian Wang,Omar Abdellall,Tony Gao,Xiatao Sun,Daniel Rakita*

Main category: cs.RO

TL;DR: 该研究提出了一种端到端系统，能够在1秒内从单张RGB-D图像生成高质量、上下文接地的3D网格，解决了机器人感知中网格生成速度慢和缺乏上下文信息的问题。


<details>
  <summary>Details</summary>
Motivation: 3D网格在机器人领域具有重要价值，但现有自动生成方法存在两个关键问题：1）生成高保真网格速度过慢（通常需要数十秒），无法满足实时需求；2）网格本身缺乏上下文信息，需要额外的分割、配准等步骤，而这些步骤又会成为新的瓶颈。

Method: 提出端到端系统，集成三个优化模块：开放词汇对象分割、加速的基于扩散的网格生成、鲁棒的点云配准，每个模块都针对速度和准确性进行了优化。

Result: 系统能够在1秒内从单张RGB-D图像生成高质量、上下文接地的3D网格，并在真实世界操作任务中验证了其有效性，使网格能够作为机器人感知和规划的实用、按需表示。

Conclusion: 该工作解决了机器人感知中3D网格生成的实时性和上下文接地问题，使网格能够真正成为机器人交互的实用表示，为机器人感知和规划提供了新的可能性。

Abstract: 3D meshes are a fundamental representation widely used in computer science and engineering. In robotics, they are particularly valuable because they capture objects in a form that aligns directly with how robots interact with the physical world, enabling core capabilities such as predicting stable grasps, detecting collisions, and simulating dynamics. Although automatic 3D mesh generation methods have shown promising progress in recent years, potentially offering a path toward real-time robot perception, two critical challenges remain. First, generating high-fidelity meshes is prohibitively slow for real-time use, often requiring tens of seconds per object. Second, mesh generation by itself is insufficient. In robotics, a mesh must be contextually grounded, i.e., correctly segmented from the scene and registered with the proper scale and pose. Additionally, unless these contextual grounding steps remain efficient, they simply introduce new bottlenecks. In this work, we introduce an end-to-end system that addresses these challenges, producing a high-quality, contextually grounded 3D mesh from a single RGB-D image in under one second. Our pipeline integrates open-vocabulary object segmentation, accelerated diffusion-based mesh generation, and robust point cloud registration, each optimized for both speed and accuracy. We demonstrate its effectiveness in a real-world manipulation task, showing that it enables meshes to be used as a practical, on-demand representation for robotics perception and planning.

</details>


### [13] [Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models](https://arxiv.org/abs/2512.24470)
*Kim Alexander Christensen,Andreas Gudahl Tufte,Alexey Gusev,Rohan Sinha,Milan Ganai,Ole Andreas Alsos,Marco Pavoned,Martin Steinert*

Main category: cs.RO

TL;DR: 论文提出Semantic Lookout系统，使用视觉语言模型为自主船舶在异常情况下选择安全后备机动动作，满足IMO MASS Code要求


<details>
  <summary>Details</summary>
Motivation: IMO MASS草案要求自主船舶能够检测操作设计域偏离并执行安全后备机动，传统自主系统难以处理依赖语义理解的异常情况（如潜水旗、火灾等）

Method: 提出Semantic Lookout系统：基于视觉语言模型的语义感知，采用快慢异常检测管道，从水有效、世界锚定的轨迹中选择谨慎动作或保持位置，支持持续人工授权

Result: 在40个港口场景测试中，10秒内模型保持与较慢SOTA模型相当的感知能力；后备机动选择器优于几何基线，在火灾场景增加安全距离；现场测试验证端到端运行

Conclusion: 视觉语言模型可作为符合IMO MASS Code要求的语义后备机动选择器，未来工作应结合基础模型语义与多传感器鸟瞰感知及短时重规划

Abstract: The draft IMO MASS Code requires autonomous and remotely supervised maritime vessels to detect departures from their operational design domain, enter a predefined fallback that notifies the operator, permit immediate human override, and avoid changing the voyage plan without approval. Meeting these obligations in the alert-to-takeover gap calls for a short-horizon, human-overridable fallback maneuver. Classical maritime autonomy stacks struggle when the correct action depends on meaning (e.g., diver-down flag means people in the water, fire close by means hazard). We argue (i) that vision-language models (VLMs) provide semantic awareness for such out-of-distribution situations, and (ii) that a fast-slow anomaly pipeline with a short-horizon, human-overridable fallback maneuver makes this practical in the handover window. We introduce Semantic Lookout, a camera-only, candidate-constrained vision-language model (VLM) fallback maneuver selector that selects one cautious action (or station-keeping) from water-valid, world-anchored trajectories under continuous human authority. On 40 harbor scenes we measure per-call scene understanding and latency, alignment with human consensus (model majority-of-three voting), short-horizon risk-relief on fire hazard scenes, and an on-water alert->fallback maneuver->operator handover. Sub-10 s models retain most of the awareness of slower state-of-the-art models. The fallback maneuver selector outperforms geometry-only baselines and increases standoff distance on fire scenes. A field run verifies end-to-end operation. These results support VLMs as semantic fallback maneuver selectors compatible with the draft IMO MASS Code, within practical latency budgets, and motivate future work on domain-adapted, hybrid autonomy that pairs foundation-model semantics with multi-sensor bird's-eye-view perception and short-horizon replanning.

</details>


### [14] [DISF: Disentangled Iterative Surface Fitting for Contact-stable Grasp Planning with Grasp Pose Alignment to the Object Center of Mass](https://arxiv.org/abs/2512.24550)
*Tomoya Yamanokuchi,Alberto Bacchin,Emilio Olivastri,Ryotaro Arifuku,Takamitsu Matsubara,Emanuele Menegatti*

Main category: cs.RO

TL;DR: 提出DISF算法，通过解耦抓取姿态优化为旋转、平移和夹爪开度三步，在保持几何兼容性的同时提升接触稳定性，从而提高抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于表面拟合的抓取规划算法主要关注夹爪与物体表面的几何对齐，但忽视了接触点分布的稳定性，导致因接触配置不足而产生不稳定抓取。

Method: 受人类抓取行为启发，将抓取姿态优化解耦为三个顺序步骤：1) 旋转优化以对齐接触法线；2) 平移细化以改善夹爪坐标系原点与物体质心的对齐；3) 夹爪开度调整以优化接触点分布。

Result: 在仿真中验证了15个物体（已知形状和观测形状设置），包括三个机器人-夹爪平台的跨平台抓取执行。在UR3e机器人上进行了真实世界抓取实验。DISF减少了质心错位，同时保持了几何兼容性，在仿真和真实世界执行中都获得了比基线更高的抓取成功率。

Conclusion: DISF算法通过整合接触稳定性到表面拟合过程中，在保持几何兼容性的同时显著提升了抓取稳定性，为机器人抓取规划提供了更可靠的解决方案。

Abstract: In this work, we address the limitation of surface fitting-based grasp planning algorithm, which primarily focuses on geometric alignment between the gripper and object surface while overlooking the stability of contact point distribution, often resulting in unstable grasps due to inadequate contact configurations. To overcome this limitation, we propose a novel surface fitting algorithm that integrates contact stability while preserving geometric compatibility. Inspired by human grasping behavior, our method disentangles the grasp pose optimization into three sequential steps: (1) rotation optimization to align contact normals, (2) translation refinement to improve the alignment between the gripper frame origin and the object Center of Mass (CoM), and (3) gripper aperture adjustment to optimize contact point distribution. We validate our approach in simulation across 15 objects under both Known-shape (with clean CAD-derived dataset) and Observed-shape (with YCB object dataset) settings, including cross-platform grasp execution on three robot--gripper platforms. We further validate the method in real-world grasp experiments on a UR3e robot. Overall, DISF reduces CoM misalignment while maintaining geometric compatibility, translating into higher grasp success in both simulation and real-world execution compared to baselines. Additional videos and supplementary results are available on our project page: https://tomoya-yamanokuchi.github.io/disf-ras-project-page/

</details>


### [15] [Resolving State Ambiguity in Robot Manipulation via Adaptive Working Memory Recoding](https://arxiv.org/abs/2512.24638)
*Qingda Hu,Ziheng Qiu,Zijun Xu,Kaizhao Zhang,Xizhou Bu,Zuolei Sun,Bo Zhang,Jieru Zhao,Zhongxue Gan,Wenchao Ding*

Main category: cs.RO

TL;DR: PAM是一种配备自适应工作记忆的视觉运动策略，能够处理机器人操作中的状态模糊性问题，支持300帧历史窗口并保持20Hz以上的推理速度。


<details>
  <summary>Details</summary>
Motivation: 机器人操作中普遍存在状态模糊问题，相同观测可能对应多个有效行为轨迹。现有方法要么历史窗口有限，要么计算成本高且容易过拟合，需要一种能有效利用历史信息的方法。

Method: 采用两阶段训练方式，包含层次化帧特征提取器（提取运动基元和时序消歧特征）、上下文路由器（使用范围特定查询生成紧凑上下文特征）以及重构历史信息的辅助目标函数。

Result: PAM能够同时处理多种状态模糊场景，支持约10秒（300帧）的历史窗口，保持稳定训练和20Hz以上的推理速度，且仅需最小额外训练成本。

Conclusion: PAM通过自适应工作记忆机制有效解决了机器人操作中的状态模糊问题，在保持高效推理的同时显著扩展了历史信息利用能力，为复杂操作任务提供了新思路。

Abstract: State ambiguity is common in robotic manipulation. Identical observations may correspond to multiple valid behavior trajectories. The visuomotor policy must correctly extract the appropriate types and levels of information from the history to identify the current task phase. However, naively extending the history window is computationally expensive and may cause severe overfitting. Inspired by the continuous nature of human reasoning and the recoding of working memory, we introduce PAM, a novel visuomotor Policy equipped with Adaptive working Memory. With minimal additional training cost in a two-stage manner, PAM supports a 300-frame history window while maintaining high inference speed. Specifically, a hierarchical frame feature extractor yields two distinct representations for motion primitives and temporal disambiguation. For compact representation, a context router with range-specific queries is employed to produce compact context features across multiple history lengths. And an auxiliary objective of reconstructing historical information is introduced to ensure that the context router acts as an effective bottleneck. We meticulously design 7 tasks and verify that PAM can handle multiple scenarios of state ambiguity simultaneously. With a history window of approximately 10 seconds, PAM still supports stable training and maintains inference speeds above 20Hz. Project website: https://tinda24.github.io/pam/

</details>


### [16] [Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation](https://arxiv.org/abs/2512.24651)
*Yury Kolomeytsev,Dmitry Golembiovsky*

Main category: cs.RO

TL;DR: HMP-DRL：一种结合图全局规划器和深度强化学习局部控制的混合运动规划框架，用于复杂动态环境中的机器人导航，通过语义感知奖励机制提升安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统图规划器擅长长距离路径规划但缺乏反应性，而深度强化学习方法在避障方面表现良好但缺乏全局上下文，难以到达远距离目标。需要一种能结合两者优势的混合方法来解决复杂动态环境中的机器人导航问题。

Method: 提出HMP-DRL混合框架：1）使用图全局规划器生成路径；2）将路径转化为检查点序列，编码到局部DRL策略的状态空间和奖励函数中；3）采用实体感知奖励结构，根据周围智能体的语义类型动态调整安全边界和惩罚。

Result: 在基于真实地图数据的仿真环境中进行广泛测试，HMP-DRL在机器人导航关键指标（成功率、碰撞率、到达目标时间）上持续优于其他方法，包括最先进的方法。

Conclusion: 将长期路径指导与语义感知的局部控制相结合，显著增强了复杂人本环境中自主导航的安全性和可靠性。

Abstract: Autonomous mobile robots operating in complex, dynamic environments face the dual challenge of navigating large-scale, structurally diverse spaces with static obstacles while safely interacting with various moving agents. Traditional graph-based planners excel at long-range pathfinding but lack reactivity, while Deep Reinforcement Learning (DRL) methods demonstrate strong collision avoidance but often fail to reach distant goals due to a lack of global context. We propose Hybrid Motion Planning with Deep Reinforcement Learning (HMP-DRL), a hybrid framework that bridges this gap. Our approach utilizes a graph-based global planner to generate a path, which is integrated into a local DRL policy via a sequence of checkpoints encoded in both the state space and reward function. To ensure social compliance, the local planner employs an entity-aware reward structure that dynamically adjusts safety margins and penalties based on the semantic type of surrounding agents. We validate the proposed method through extensive testing in a realistic simulation environment derived from real-world map data. Comprehensive experiments demonstrate that HMP-DRL consistently outperforms other methods, including state-of-the-art approaches, in terms of key metrics of robot navigation: success rate, collision rate, and time to reach the goal. Overall, these findings confirm that integrating long-term path guidance with semantically-aware local control significantly enhances both the safety and reliability of autonomous navigation in complex human-centric settings.

</details>


### [17] [RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence](https://arxiv.org/abs/2512.24653)
*Chengkai Hou,Kun Wu,Jiaming Liu,Zhengping Che,Di Wu,Fei Liao,Guangrun Li,Jingyang He,Qiuxuan Feng,Zhao Jin,Chenyang Gu,Zhuoyang Liu,Nuowei Han,Xiangju Mi,Yaoxu Lv,Yankai Fu,Gaole Dai,Langzhe Gu,Tao Li,Yuheng Zhang,Yixue Zhang,Xinhua Wang,Shichao Fan,Meng Li,Zhen Zhao,Ning Liu,Zhiyuan Xu,Pei Ren,Junjie Ji,Haonan Liu,Kuan Cheng,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: RoboMIND 2.0是一个包含31万条双机械臂操作轨迹的真实世界数据集，涵盖6种机器人平台和739个复杂任务，包含触觉增强和移动操作数据，并配套20K模拟轨迹用于sim-to-real研究。


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法受限于大规模、多样化真实世界演示数据的稀缺，导致模型在长时程双机械臂任务和非结构化环境中的移动操作方面泛化能力有限。

Method: 提出了RoboMIND 2.0数据集和MIND-2系统。数据集包含31万条双机械臂操作轨迹、1.2万条触觉增强轨迹和2万条移动操作轨迹，并构建了高保真数字孪生环境。MIND-2系统采用分层双系统框架，通过离线强化学习优化，包含高层语义规划器(MIND-2-VLM)和低层视觉-语言-动作执行器(MIND-2-VLA)。

Result: 构建了一个全面的真实世界机器人操作数据集，涵盖多种机器人平台和复杂任务，并提出了配套的分层系统框架来充分利用该数据集。

Conclusion: RoboMIND 2.0数据集和MIND-2系统为解决数据稀缺问题提供了重要资源，有望推动机器人操作在长时程双机械臂任务和非结构化环境移动操作方面的研究进展。

Abstract: While data-driven imitation learning has revolutionized robotic manipulation, current approaches remain constrained by the scarcity of large-scale, diverse real-world demonstrations. Consequently, the ability of existing models to generalize across long-horizon bimanual tasks and mobile manipulation in unstructured environments remains limited. To bridge this gap, we present RoboMIND 2.0, a comprehensive real-world dataset comprising over 310K dual-arm manipulation trajectories collected across six distinct robot embodiments and 739 complex tasks. Crucially, to support research in contact-rich and spatially extended tasks, the dataset incorporates 12K tactile-enhanced episodes and 20K mobile manipulation trajectories. Complementing this physical data, we construct high-fidelity digital twins of our real-world environments, releasing an additional 20K-trajectory simulated dataset to facilitate robust sim-to-real transfer. To fully exploit the potential of RoboMIND 2.0, we propose MIND-2 system, a hierarchical dual-system frame-work optimized via offline reinforcement learning. MIND-2 integrates a high-level semantic planner (MIND-2-VLM) to decompose abstract natural language instructions into grounded subgoals, coupled with a low-level Vision-Language-Action executor (MIND-2-VLA), which generates precise, proprioception-aware motor actions.

</details>


### [18] [Antagonistic Bowden-Cable Actuation of a Lightweight Robotic Hand: Toward Dexterous Manipulation for Payload Constrained Humanoids](https://arxiv.org/abs/2512.24657)
*Sungjae Min,Hyungjoo Kim,David Hyunchul Shim*

Main category: cs.RO

TL;DR: 提出一种轻量化仿人机械手，采用鲍登线驱动和滚动接触关节优化，实现单电机控制、高抓握力和低远端质量


<details>
  <summary>Details</summary>
Motivation: 仿人机器人需要具备高抓握力、快速驱动、多自由度、轻量化且符合人体尺寸的机械手，但现有设计难以同时满足这些相互冲突的要求

Method: 采用鲍登线驱动系统，结合滚动接触关节优化和拮抗式线缆驱动，实现单电机控制；将驱动模块移至躯干以降低远端质量

Result: 机械手远端质量仅236g，指尖力超过18N，能举起超过自身质量100倍的负载；通过Cutkosky分类抓握和扰动条件下的轨迹一致性验证了鲁棒性

Conclusion: 该设计成功解决了仿人机械手在轻量化、高抓握力和多自由度之间的权衡问题，为达到人类水平灵巧性提供了可行方案

Abstract: Humanoid robots toward human-level dexterity require robotic hands capable of simultaneously providing high grasping force, rapid actuation speeds, multiple degrees of freedom, and lightweight structures within human-like size constraints. Meeting these conflicting requirements remains challenging, as satisfying this combination typically necessitates heavier actuators and bulkier transmission systems, significantly restricting the payload capacity of robot arms. In this letter, we present a lightweight anthropomorphic hand actuated by Bowden cables, which uniquely combines rolling-contact joint optimization with antagonistic cable actuation, enabling single-motor-per-joint control with negligible cable-length deviation. By relocating the actuator module to the torso, the design substantially reduces distal mass while maintaining anthropomorphic scale and dexterity. Additionally, this antagonistic cable actuation eliminates the need for synchronization between motors. Using the proposed methods, the hand assembly with a distal mass of 236g (excluding remote actuators and Bowden sheaths) demonstrated reliable execution of dexterous tasks, exceeding 18N fingertip force and lifting payloads over one hundred times its own mass. Furthermore, robustness was validated through Cutkosky taxonomy grasps and trajectory consistency under perturbed actuator-hand transformations.

</details>


### [19] [VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots](https://arxiv.org/abs/2512.24673)
*Yongsheng Zhao,Lei Zhao,Baoping Cheng,Gongxin Yao,Xuanzhang Wen,Han Gao*

Main category: cs.RO

TL;DR: VLA-RAIL框架通过异步推理和轨迹平滑技术，解决了VLA模型在机器人控制中的抖动、停滞问题，实现了平滑连续的高速动作执行。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在机器人动作执行中存在抖动、停滞甚至暂停的问题，这不仅限制了执行速度，还降低了任务成功率。需要一种能够保证平滑、连续、高速动作执行的新框架。

Method: 提出VLA-RAIL框架，核心包括：1) 轨迹平滑器：使用多项式拟合过滤单个动作块的轨迹噪声和抖动；2) 块融合器：无缝对齐当前执行轨迹和新到达的动作块，确保连续动作块之间的位置、速度和加速度连续性。采用异步推理和机器人运动控制架构。

Result: 在动态仿真任务和多个真实世界操作任务上的实验表明，VLA-RAIL显著减少了运动抖动，提升了执行速度，提高了任务成功率。

Conclusion: VLA-RAIL将成为VLA模型大规模部署的关键基础设施，解决了现有方法的执行不连续性问题，实现了平滑连续的高速机器人动作控制。

Abstract: Vision-Language-Action (VLA) models have achieved remarkable breakthroughs in robotics, with the action chunk playing a dominant role in these advances. Given the real-time and continuous nature of robotic motion control, the strategies for fusing a queue of successive action chunks have a profound impact on the overall performance of VLA models. Existing methods suffer from jitter, stalling, or even pauses in robotic action execution, which not only limits the achievable execution speed but also reduces the overall success rate of task completion. This paper introduces VLA-RAIL (A Real-Time Asynchronous Inference Linker), a novel framework designed to address these issues by conducting model inference and robot motion control asynchronously and guaranteeing smooth, continuous, and high-speed action execution. The core contributions of the paper are two fold: a Trajectory Smoother that effectively filters out the noise and jitter in the trajectory of one action chunk using polynomial fitting and a Chunk Fuser that seamlessly align the current executing trajectory and the newly arrived chunk, ensuring position, velocity, and acceleration continuity between two successive action chunks. We validate the effectiveness of VLA-RAIL on a benchmark of dynamic simulation tasks and several real-world manipulation tasks. Experimental results demonstrate that VLA-RAIL significantly reduces motion jitter, enhances execution speed, and improves task success rates, which will become a key infrastructure for the large-scale deployment of VLA models.

</details>


### [20] [ReSPIRe: Informative and Reusable Belief Tree Search for Robot Probabilistic Search and Tracking in Unknown Environments](https://arxiv.org/abs/2512.24680)
*Kangjie Zhou,Zhaoyang Li,Han Gao,Yao Su,Hangxin Liu,Junzhi Yu,Chang Liu*

Main category: cs.RO

TL;DR: ReSPIRe是一种用于未知杂乱环境中目标搜索与跟踪的信息轨迹规划方法，通过sigma点近似估计互信息奖励，采用分层粒子结构处理先验信息不确定性，并使用可重用信念树搜索进行在线规划。


<details>
  <summary>Details</summary>
Motivation: 目标搜索与跟踪是机器人应用中的基本问题，但在未知杂乱环境中，面临先验目标信息不准确、传感器视野有限等挑战，需要高效的信息轨迹规划方法。

Method: 1) 提出sigma点近似方法快速准确估计非高斯信念分布下的互信息奖励；2) 设计分层粒子结构提取关键粒子进行全局路径引导并自适应调整粒子数量；3) 开发可重用信念树搜索方法构建在线轨迹规划的策略树。

Result: ReSPIRe在仿真和真实实验中优于基准方法，具有更小的互信息近似误差、更高的搜索效率和更稳定的跟踪性能，同时保持了出色的计算效率。

Conclusion: ReSPIRe方法能够有效处理未知杂乱环境中目标搜索与跟踪的挑战，通过创新的互信息估计、分层粒子结构和可重用树搜索，实现了高效、准确且计算高效的轨迹规划。

Abstract: Target search and tracking (SAT) is a fundamental problem for various robotic applications such as search and rescue and environmental exploration. This paper proposes an informative trajectory planning approach, namely ReSPIRe, for SAT in unknown cluttered environments under considerably inaccurate prior target information and limited sensing field of view. We first develop a novel sigma point-based approximation approach to fast and accurately estimate mutual information reward under non-Gaussian belief distributions, utilizing informative sampling in state and observation spaces to mitigate the computational intractability of integral calculation. To tackle significant uncertainty associated with inadequate prior target information, we propose the hierarchical particle structure in ReSPIRe, which not only extracts critical particles for global route guidance, but also adjusts the particle number adaptively for planning efficiency. Building upon the hierarchical structure, we develop the reusable belief tree search approach to build a policy tree for online trajectory planning under uncertainty, which reuses rollout evaluation to improve planning efficiency. Extensive simulations and real-world experiments demonstrate that ReSPIRe outperforms representative benchmark methods with smaller MI approximation error, higher search efficiency, and more stable tracking performance, while maintaining outstanding computational efficiency.

</details>


### [21] [CREPES-X: Hierarchical Bearing-Distance-Inertial Direct Cooperative Relative Pose Estimation System](https://arxiv.org/abs/2512.24688)
*Zhehan Li,Zheng Wang,Jiadong Lu,Qi Liu,Zhiren Xun,Yue Wang,Fei Gao,Chao Xu,Yanjun Cao*

Main category: cs.RO

TL;DR: CREPES-X是一个用于多机器人系统的分层相对定位框架，通过紧凑硬件设计和两级估计器实现高速、精确和鲁棒的相对位姿估计，无需全局信息。


<details>
  <summary>Details</summary>
Motivation: 现有多机器人相对定位方法要么依赖共享环境特征或惯性假设，要么在复杂环境中受非视距干扰和异常值影响，难以在数十个机器人系统中鲁棒高效地融合多种测量信息。

Method: 采用紧凑硬件设计（红外LED、红外相机、超宽带模块和IMU），实现两级分层估计器：单帧相对估计器通过闭式解和鲁棒方位异常值剔除提供即时相对位姿；多帧相对估计器通过机器人中心相对运动学结合松耦合和紧耦合优化探索IMU预积分。

Result: 实验验证了CREPES-X的有效性，能抵抗高达90%的方位异常值，在挑战性条件下表现出韧性，在真实世界数据集中达到0.073米和1.817°的RMSE。

Conclusion: CREPES-X提供了一个无需全局信息的分层相对定位框架，在速度、精度和鲁棒性方面优于现有方法，适用于复杂环境下的多机器人协作系统。

Abstract: Relative localization is critical for cooperation in autonomous multi-robot systems. Existing approaches either rely on shared environmental features or inertial assumptions or suffer from non-line-of-sight degradation and outliers in complex environments. Robust and efficient fusion of inter-robot measurements such as bearings, distances, and inertials for tens of robots remains challenging. We present CREPES-X (Cooperative RElative Pose Estimation System with multiple eXtended features), a hierarchical relative localization framework that enhances speed, accuracy, and robustness under challenging conditions, without requiring any global information. CREPES-X starts with a compact hardware design: InfraRed (IR) LEDs, an IR camera, an ultra-wideband module, and an IMU housed in a cube no larger than 6cm on each side. Then CREPES-X implements a two-stage hierarchical estimator to meet different requirements, considering speed, accuracy, and robustness. First, we propose a single-frame relative estimator that provides instant relative poses for multi-robot setups through a closed-form solution and robust bearing outlier rejection. Then a multi-frame relative estimator is designed to offer accurate and robust relative states by exploring IMU pre-integration via robocentric relative kinematics with loosely- and tightly-coupled optimization. Extensive simulations and real-world experiments validate the effectiveness of CREPES-X, showing robustness to up to 90% bearing outliers, proving resilience in challenging conditions, and achieving RMSE of 0.073m and 1.817° in real-world datasets.

</details>


### [22] [Dynamic Policy Learning for Legged Robot with Simplified Model Pretraining and Model Homotopy Transfer](https://arxiv.org/abs/2512.24698)
*Dongyun Kang,Min-Gyu Kim,Tae-Gyu Song,Hajun Kim,Sehoon Ha,Hae-Won Park*

Main category: cs.RO

TL;DR: 本文提出了一种基于延续学习的方法，通过简化模型预训练和模型同伦转移，高效生成和优化四足机器人的动态运动行为。


<details>
  <summary>Details</summary>
Motivation: 为四足机器人生成动态运动是一个挑战性问题。虽然强化学习在各种腿部运动任务中取得了显著成功，但要产生高度动态行为通常需要大量奖励调整或高质量演示。利用简化模型可以缓解这些挑战，但模型差异在将策略转移到全身动力学环境时带来了显著困难。

Method: 提出一个延续学习框架，包含两个阶段：1）使用单刚体模型在简化环境中预训练策略，捕捉核心运动模式；2）采用延续策略逐步将策略转移到全身环境，通过模型同伦从单刚体模型平滑过渡到全身模型，逐渐重新分配躯干和腿部之间的质量和惯性。

Result: 该方法不仅实现了更快的收敛速度，而且在转移过程中表现出比基线方法更优越的稳定性。该框架在一系列动态任务（包括翻转和墙壁辅助机动）上得到验证，并成功部署在真实的四足机器人上。

Conclusion: 提出的延续学习框架有效地解决了简化模型与全身模型之间的转移问题，能够高效生成和优化复杂的动态行为，为四足机器人的动态运动控制提供了一种实用且稳定的解决方案。

Abstract: Generating dynamic motions for legged robots remains a challenging problem. While reinforcement learning has achieved notable success in various legged locomotion tasks, producing highly dynamic behaviors often requires extensive reward tuning or high-quality demonstrations. Leveraging reduced-order models can help mitigate these challenges. However, the model discrepancy poses a significant challenge when transferring policies to full-body dynamics environments. In this work, we introduce a continuation-based learning framework that combines simplified model pretraining and model homotopy transfer to efficiently generate and refine complex dynamic behaviors. First, we pretrain the policy using a single rigid body model to capture core motion patterns in a simplified environment. Next, we employ a continuation strategy to progressively transfer the policy to the full-body environment, minimizing performance loss. To define the continuation path, we introduce a model homotopy from the single rigid body model to the full-body model by gradually redistributing mass and inertia between the trunk and legs. The proposed method not only achieves faster convergence but also demonstrates superior stability during the transfer process compared to baseline methods. Our framework is validated on a range of dynamic tasks, including flips and wall-assisted maneuvers, and is successfully deployed on a real quadrupedal robot.

</details>


### [23] [LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving](https://arxiv.org/abs/2512.24712)
*Qian Cheng,Weitao Zhou,Cheng Jing,Nanshan Deng,Junze Wen,Zhaoyang Liu,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: LSRE框架将稀疏采样的视觉语言模型判断转换为循环世界模型潜在空间中的决策边界，实现实时语义风险评估，无需逐帧VLM查询


<details>
  <summary>Details</summary>
Motivation: 现实世界自动驾驶需要遵守复杂的人类社会规则，这些语义约束（如让行紧急车辆、遵守交警手势等）对人类直观但难以显式编码。虽然大型视觉语言模型能解释这些语义，但其推理成本过高，不适合实时部署。

Method: 提出LSRE（潜在语义规则编码）框架，将稀疏采样的VLM判断转换为循环世界模型潜在空间中的决策边界，通过将语言定义的安全语义编码到轻量级潜在分类器中，实现实时语义风险评估。

Result: 在CARLA中的六个语义失败场景实验中，LSRE达到与大型VLM基线相当的语义风险检测准确率，同时提供更早的危险预测，并保持低计算延迟。LSRE还能泛化到罕见但语义相似的测试案例。

Conclusion: 语言引导的潜在分类为自动驾驶中的语义安全监控提供了有效且可部署的机制，能够在保持实时性能的同时实现准确的语义风险评估。

Abstract: Real-world autonomous driving must adhere to complex human social rules that extend beyond legally codified traffic regulations. Many of these semantic constraints, such as yielding to emergency vehicles, complying with traffic officers' gestures, or stopping for school buses, are intuitive for humans yet difficult to encode explicitly. Although large vision-language models (VLMs) can interpret such semantics, their inference cost makes them impractical for real-time deployment.This work proposes LSRE, a Latent Semantic Rule Encoding framework that converts sparsely sampled VLM judgments into decision boundaries within the latent space of a recurrent world model. By encoding language-defined safety semantics into a lightweight latent classifier, LSRE enables real-time semantic risk assessment at 10 Hz without per-frame VLM queries. Experiments on six semantic-failure scenarios in CARLA demonstrate that LSRE attains semantic risk detection accuracy comparable to a large VLM baseline, while providing substantially earlier hazard anticipation and maintaining low computational latency. LSRE further generalizes to rarely seen semantic-similar test cases, indicating that language-guided latent classification offers an effective and deployable mechanism for semantic safety monitoring in autonomous driving.

</details>


### [24] [Control of Microrobots with Reinforcement Learning under On-Device Compute Constraints](https://arxiv.org/abs/2512.24740)
*Yichen Liu,Kesava Viswanadha,Zhongyu Li,Nelson Lojo,Kristofer S. J. Pister*

Main category: cs.RO

TL;DR: 该研究探索了在资源受限的微机器人上部署边缘机器学习控制器的方法，通过强化学习训练紧凑的MLP策略，并进行整数量化以在ARM Cortex-M0微控制器上实现高效推理，提出了基于功率预算的步态调度策略。


<details>
  <summary>Details</summary>
Motivation: 微机器人需要在计算、内存和功率受限的条件下实现稳健的地形移动能力。传统方法难以在资源受限的硬件上实现低延迟控制，因此需要探索边缘机器学习方法来实现设备上的高效控制。

Method: 1. 使用大规模并行GPU仿真训练紧凑的FP32多层感知机（MLP）策略（隐藏层[128, 64]）
2. 通过域随机化增强鲁棒性
3. 研究整数（Int8）量化（每张量和每特征）以提高推理更新频率
4. 基于Cortex-M0的推理周期模型连接硬件功率预算与可实现的更新频率
5. 提出资源感知的步态调度方法：根据功率预算选择最大化RL奖励的步态模式（小跑/中间/疾驰）

Result: 1. 成功在超小型系统级芯片SCμM-3C（5 MHz ARM Cortex-M0）上部署了MLP策略
2. 量化方法允许在资源受限硬件上实现更高的推理更新频率
3. 域随机化训练提高了分布外稳定性
4. 在真实世界大型机器人的不平坦地形上进行了部署验证
5. 注：本研究未声称实现真实世界大型机器人的零样本迁移

Conclusion: 该研究展示了边缘机器学习方法在微机器人运动控制中的可行性，通过强化学习训练、量化和资源感知调度，能够在计算、内存和功率受限的硬件上实现高效控制，为自主微机器人的实际应用提供了重要技术路径。

Abstract: An important function of autonomous microrobots is the ability to perform robust movement over terrain. This paper explores an edge ML approach to microrobot locomotion, allowing for on-device, lower latency control under compute, memory, and power constraints. This paper explores the locomotion of a sub-centimeter quadrupedal microrobot via reinforcement learning (RL) and deploys the resulting controller on an ultra-small system-on-chip (SoC), SC$μ$M-3C, featuring an ARM Cortex-M0 microcontroller running at 5 MHz. We train a compact FP32 multilayer perceptron (MLP) policy with two hidden layers ($[128, 64]$) in a massively parallel GPU simulation and enhance robustness by utilizing domain randomization over simulation parameters. We then study integer (Int8) quantization (per-tensor and per-feature) to allow for higher inference update rates on our resource-limited hardware, and we connect hardware power budgets to achievable update frequency via a cycles-per-update model for inference on our Cortex-M0. We propose a resource-aware gait scheduling viewpoint: given a device power budget, we can select the gait mode (trot/intermediate/gallop) that maximizes expected RL reward at a corresponding feasible update frequency. Finally, we deploy our MLP policy on a real-world large-scale robot on uneven terrain, qualitatively noting that domain-randomized training can improve out-of-distribution stability. We do not claim real-world large-robot empirical zero-shot transfer in this work.

</details>


### [25] [Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow](https://arxiv.org/abs/2512.24766)
*Karthik Dharmarajan,Wenlong Huang,Jiajun Wu,Li Fei-Fei,Ruohan Zhang*

Main category: cs.RO

TL;DR: Dream2Flow框架通过3D物体流作为中间表示，将视频生成模型与机器人控制连接起来，实现零样本的开放世界物体操作


<details>
  <summary>Details</summary>
Motivation: 生成视频模型在零样本推理物理交互方面表现出色，但难以直接转化为机器人所需的低级动作。需要一种方法将人类引导的运动转化为机器人可执行的控制命令

Method: 提出Dream2Flow框架：1) 从初始图像和任务指令生成视频；2) 从生成视频中重建3D物体运动；3) 将操作任务定义为物体轨迹跟踪；4) 通过轨迹优化或强化学习将3D物体流转化为可执行的低级命令

Result: Dream2Flow能够处理多种物体类别（刚性、铰接、可变形、颗粒状），在仿真和真实世界实验中展示了3D物体流作为通用可扩展接口的有效性

Conclusion: 3D物体流是连接视频生成模型与开放世界机器人操作的通用且可扩展的接口，通过分离状态变化与执行器实现，克服了具身化差距

Abstract: Generative video modeling has emerged as a compelling tool to zero-shot reason about plausible physical interactions for open-world manipulation. Yet, it remains a challenge to translate such human-led motions into the low-level actions demanded by robotic systems. We observe that given an initial image and task instruction, these models excel at synthesizing sensible object motions. Thus, we introduce Dream2Flow, a framework that bridges video generation and robotic control through 3D object flow as an intermediate representation. Our method reconstructs 3D object motions from generated videos and formulates manipulation as object trajectory tracking. By separating the state changes from the actuators that realize those changes, Dream2Flow overcomes the embodiment gap and enables zero-shot guidance from pre-trained video models to manipulate objects of diverse categories-including rigid, articulated, deformable, and granular. Through trajectory optimization or reinforcement learning, Dream2Flow converts reconstructed 3D object flow into executable low-level commands without task-specific demonstrations. Simulation and real-world experiments highlight 3D object flow as a general and scalable interface for adapting video generation models to open-world robotic manipulation. Videos and visualizations are available at https://dream2flow.github.io/.

</details>


### [26] [ArtiSG: Functional 3D Scene Graph Construction via Human-demonstrated Articulated Objects Manipulation](https://arxiv.org/abs/2512.24845)
*Qiuyi Gu,Yuze Sheng,Jincheng Yu,Jiahao Tang,Xiaolong Shan,Zhaoyang Shen,Tinghao Yi,Xiaodan Liang,Xinlei Chen,Yu Wang*

Main category: cs.RO

TL;DR: ArtiSG框架通过人类演示构建功能性3D场景图，解决现有方法在关节物体功能理解和精细功能元素检测方面的不足，显著提升功能元素召回率和关节估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图缺乏关节物体的功能信息，传统方法在视觉模糊性、固定摄像头设置和小型功能元素检测方面存在局限，需要更鲁棒的功能理解框架。

Method: 利用便携式设备收集关节数据，准确估计6自由度关节轨迹和轴线；将运动学先验整合到分层开放词汇图中；利用交互数据发现视觉感知遗漏的精细功能元素。

Result: 在真实世界实验中，ArtiSG在功能元素召回率和关节估计精度方面显著优于基线方法；构建的图作为可靠的功能记忆，能有效指导机器人执行语言指令的操纵任务。

Conclusion: ArtiSG通过编码人类演示到结构化机器人记忆中，成功构建了功能性3D场景图，解决了关节物体功能理解的挑战，为机器人操纵任务提供了有效的功能记忆支持。

Abstract: 3D scene graphs have empowered robots with semantic understanding for navigation and planning, yet they often lack the functional information required for physical manipulation, particularly regarding articulated objects. Existing approaches for inferring articulation mechanisms from static observations are prone to visual ambiguity, while methods that estimate parameters from state changes typically rely on constrained settings such as fixed cameras and unobstructed views. Furthermore, fine-grained functional elements like small handles are frequently missed by general object detectors. To bridge this gap, we present ArtiSG, a framework that constructs functional 3D scene graphs by encoding human demonstrations into structured robotic memory. Our approach leverages a robust articulation data collection pipeline utilizing a portable setup to accurately estimate 6-DoF articulation trajectories and axes even under camera ego-motion. We integrate these kinematic priors into a hierarchical and open-vocabulary graph while utilizing interaction data to discover inconspicuous functional elements missed by visual perception. Extensive real-world experiments demonstrate that ArtiSG significantly outperforms baselines in functional element recall and articulation estimation precision. Moreover, we show that the constructed graph serves as a reliable functional memory that effectively guides robots to perform language-directed manipulation tasks in real-world environments containing diverse articulated objects.

</details>


### [27] [Hierarchical Deformation Planning and Neural Tracking for DLOs in Constrained Environments](https://arxiv.org/abs/2512.24974)
*Yunxi Tang,Tianqi Yang,Jing Huang,Xiangyu Chu,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 提出了一种结合分层变形规划和神经跟踪的框架，用于在受限环境中操纵可变形线性物体，通过路径集生成和优化实现全局变形合成，并通过神经模型预测控制进行局部变形跟踪。


<details>
  <summary>Details</summary>
Motivation: 可变形线性物体（DLOs）操纵面临高维状态空间和复杂变形动力学的挑战，现实工作空间中的广泛障碍物进一步增加了操纵难度，需要高效的变形规划和鲁棒的变形跟踪方法。

Method: 提出分层变形规划与神经跟踪相结合的新框架：1）变形规划器首先生成满足DLO关键点路径同伦约束的空间路径集；2）采用路径集引导的优化方法合成DLO的最优时间变形序列；3）在操纵执行阶段，设计基于数据驱动变形模型的神经模型预测控制方法，精确跟踪规划的DLO变形序列。

Result: 在广泛的受限DLO操纵任务中验证了所提框架的有效性，证明了其在全局变形合成和局部变形跟踪方面的可靠性能。

Conclusion: 该框架通过结合分层变形规划和神经跟踪，成功解决了受限环境中DLO操纵的挑战，为复杂工作空间中的可变形物体操纵提供了有效的解决方案。

Abstract: Deformable linear objects (DLOs) manipulation presents significant challenges due to DLOs' inherent high-dimensional state space and complex deformation dynamics. The wide-populated obstacles in realistic workspaces further complicate DLO manipulation, necessitating efficient deformation planning and robust deformation tracking. In this work, we propose a novel framework for DLO manipulation in constrained environments. This framework combines hierarchical deformation planning with neural tracking, ensuring reliable performance in both global deformation synthesis and local deformation tracking. Specifically, the deformation planner begins by generating a spatial path set that inherently satisfies the homotopic constraints associated with DLO keypoint paths. Next, a path-set-guided optimization method is applied to synthesize an optimal temporal deformation sequence for the DLO. In manipulation execution, a neural model predictive control approach, leveraging a data-driven deformation model, is designed to accurately track the planned DLO deformation sequence. The effectiveness of the proposed framework is validated in extensive constrained DLO manipulation tasks.

</details>


### [28] [Coordinated Humanoid Manipulation with Choice Policies](https://arxiv.org/abs/2512.25072)
*Haozhi Qi,Yen-Jen Wang,Toru Lin,Brent Yi,Yi Ma,Koushil Sreenath,Jitendra Malik*

Main category: cs.RO

TL;DR: 结合模块化遥操作界面与可扩展学习框架，实现人形机器人头、手、腿的全身协调控制，在洗碗机装载和白板擦拭任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在以人为中心的环境中具有巨大潜力，但实现头、手、腿的鲁棒全身协调仍然是一个主要挑战。需要解决高质量演示数据收集和复杂多模态行为建模的问题。

Method: 提出模块化遥操作界面将人形控制分解为手眼协调、抓取基元、手臂末端执行器跟踪和运动等直观子模块，便于高效收集高质量演示。在此基础上引入Choice Policy模仿学习方法，生成多个候选动作并学习评分，实现快速推理和多模态行为建模。

Result: 在洗碗机装载和全身运动操作（白板擦拭）两个真实世界任务中验证，Choice Policy显著优于扩散策略和标准行为克隆。结果表明手眼协调对于长时域任务的成功至关重要。

Conclusion: 该工作展示了在非结构化环境中实现可扩展数据收集和人形机器人协调操作的实际路径，为复杂人形机器人控制提供了有效的系统框架。

Abstract: Humanoid robots hold great promise for operating in human-centric environments, yet achieving robust whole-body coordination across the head, hands, and legs remains a major challenge. We present a system that combines a modular teleoperation interface with a scalable learning framework to address this problem. Our teleoperation design decomposes humanoid control into intuitive submodules, which include hand-eye coordination, grasp primitives, arm end-effector tracking, and locomotion. This modularity allows us to collect high-quality demonstrations efficiently. Building on this, we introduce Choice Policy, an imitation learning approach that generates multiple candidate actions and learns to score them. This architecture enables both fast inference and effective modeling of multimodal behaviors. We validate our approach on two real-world tasks: dishwasher loading and whole-body loco-manipulation for whiteboard wiping. Experiments show that Choice Policy significantly outperforms diffusion policies and standard behavior cloning. Furthermore, our results indicate that hand-eye coordination is critical for success in long-horizon tasks. Our work demonstrates a practical path toward scalable data collection and learning for coordinated humanoid manipulation in unstructured environments.

</details>
