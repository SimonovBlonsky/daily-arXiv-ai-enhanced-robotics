<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 44]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [StepNav: Structured Trajectory Priors for Efficient and Multimodal Visual Navigation](https://arxiv.org/abs/2602.02590)
*Xubo Luo,Aodi Wu,Haodong Han,Xue Wan,Wei Zhang,Leizheng Shu,Ruisuo Wang*

Main category: cs.RO

TL;DR: StepNav：一种基于结构化多模态轨迹先验的视觉导航框架，通过变分原理生成更安全高效的轨迹，相比传统生成模型在不确定环境中表现更优


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在视觉导航中依赖非结构化噪声先验，导致生成不安全、低效或单模态的轨迹规划，无法满足实时需求。需要一种能生成可靠轨迹的方法来应对杂乱和不确定环境中的导航挑战。

Method: StepNav框架首先学习几何感知的成功概率场来识别所有可行的导航通道，然后构建显式的多模态混合先验来初始化条件流匹配过程。该细化过程被表述为具有显式平滑性和安全性正则化的最优控制问题。

Result: 在仿真和真实世界基准测试中，StepNav在鲁棒性、效率和安全性方面始终优于最先进的生成规划器，用更少的步骤生成更安全高效的规划。

Conclusion: StepNav通过用物理基础候选替代非结构化噪声，为实际自主导航提供了可靠的轨迹生成方法，在杂乱和不确定环境中显著提升了视觉导航的性能。

Abstract: Visual navigation is fundamental to autonomous systems, yet generating reliable trajectories in cluttered and uncertain environments remains a core challenge. Recent generative models promise end-to-end synthesis, but their reliance on unstructured noise priors often yields unsafe, inefficient, or unimodal plans that cannot meet real-time requirements. We propose StepNav, a novel framework that bridges this gap by introducing structured, multimodal trajectory priors derived from variational principles. StepNav first learns a geometry-aware success probability field to identify all feasible navigation corridors. These corridors are then used to construct an explicit, multi-modal mixture prior that initializes a conditional flow-matching process. This refinement is formulated as an optimal control problem with explicit smoothness and safety regularization. By replacing unstructured noise with physically-grounded candidates, StepNav generates safer and more efficient plans in significantly fewer steps. Experiments in both simulation and real-world benchmarks demonstrate consistent improvements in robustness, efficiency, and safety over state-of-the-art generative planners, advancing reliable trajectory generation for practical autonomous navigation. The code has been released at https://github.com/LuoXubo/StepNav.

</details>


### [2] [AROLA: A Modular Layered Architecture for Scaled Autonomous Racing](https://arxiv.org/abs/2602.02730)
*Fam Shihata,Mohammed Abdelazim,Ahmed Hussein*

Main category: cs.RO

TL;DR: AROLA是一个模块化、分层的自动驾驶赛车软件架构，通过标准化ROS 2接口将碎片化和单体设计重组为可互换的层和组件，配合Race Monitor框架实现实时性能评估。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶赛车在缩小规模平台上的快速发展，现有软件架构存在碎片化和单体设计问题，需要更模块化、可互换的架构来支持快速模块替换和客观性能评估。

Method: 提出AROLA模块化分层架构，将自动驾驶流程分解为感知、预处理、感知、定位与建图、规划、行为、控制和执行等层次，通过标准化ROS 2接口连接；同时开发Race Monitor框架，实时记录圈速、轨迹质量和计算负载，并生成标准化赛后分析。

Result: AROLA在仿真和RoboRacer硬件平台上得到验证，包括在2025年RoboRacer IV25比赛中的实际部署。系统展示了模块化、透明接口和系统化评估能够加速开发并提高可重复性。

Conclusion: 模块化架构、透明接口和系统化性能评估框架能够显著加速自动驾驶赛车的开发进程，提高研究的可重复性和比较性，为领域发展提供标准化基础。

Abstract: Autonomous racing has advanced rapidly, particularly on scaled platforms, and software stacks must evolve accordingly. In this work, AROLA is introduced as a modular, layered software architecture in which fragmented and monolithic designs are reorganized into interchangeable layers and components connected through standardized ROS 2 interfaces. The autonomous-driving pipeline is decomposed into sensing, pre-processing, perception, localization and mapping, planning, behavior, control, and actuation, enabling rapid module replacement and objective benchmarking without reliance on custom message definitions. To support consistent performance evaluation, a Race Monitor framework is introduced as a lightweight system through which lap timing, trajectory quality, and computational load are logged in real time and standardized post-race analyses are generated. AROLA is validated in simulation and on hardware using the RoboRacer platform, including deployment at the 2025 RoboRacer IV25 competition. Together, AROLA and Race Monitor demonstrate that modularity, transparent interfaces, and systematic evaluation can accelerate development and improve reproducibility in scaled autonomous racing.

</details>


### [3] [PokeNet: Learning Kinematic Models of Articulated Objects from Human Observations](https://arxiv.org/abs/2602.02741)
*Anmol Gupta,Weiwei Gu,Omkar Patil,Jun Ki Lee,Nakul Gopalan*

Main category: cs.RO

TL;DR: PokeNet是一个端到端框架，通过单次人类演示学习未知物体的关节参数，无需先验知识，并能推断操作顺序和跟踪关节状态。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要物体先验知识（如关节数量或类型），无法恢复交互中才显露的遮挡关节，需要大量多视角图像，且忽略了多自由度物体中必要的操作顺序。

Method: PokeNet是一个端到端框架，通过单次人类演示序列的点云观测，预测关节参数、推断操作顺序，并随时间跟踪关节状态，无需物体先验知识。

Result: PokeNet在关节轴和状态估计精度上平均提升超过27%，在包括新颖和未见类别在内的多样物体上优于现有方法，在仿真和真实环境中均验证了性能提升。

Conclusion: PokeNet通过单次人类演示有效学习未知物体的关节模型，解决了现有方法的多个局限性，为下游技能学习和规划提供了更好的基础。

Abstract: Articulation modeling enables robots to learn joint parameters of articulated objects for effective manipulation which can then be used downstream for skill learning or planning. Existing approaches often rely on prior knowledge about the objects, such as the number or type of joints. Some of these approaches also fail to recover occluded joints that are only revealed during interaction. Others require large numbers of multi-view images for every object, which is impractical in real-world settings. Furthermore, prior works neglect the order of manipulations, which is essential for many multi-DoF objects where one joint must be operated before another, such as a dishwasher. We introduce PokeNet, an end-to-end framework that estimates articulation models from a single human demonstration without prior object knowledge. Given a sequence of point cloud observations of a human manipulating an unknown object, PokeNet predicts joint parameters, infers manipulation order, and tracks joint states over time. PokeNet outperforms existing state-of-the-art methods, improving joint axis and state estimation accuracy by an average of over 27% across diverse objects, including novel and unseen categories. We demonstrate these gains in both simulation and real-world environments.

</details>


### [4] [Bimanual High-Density EMG Control for In-Home Mobile Manipulation by a User with Quadriplegia](https://arxiv.org/abs/2602.02773)
*Jehan Yang,Eleanor Hodgson,Cindy Sun,Zackory Erickson,Doug Weber*

Main category: cs.RO

TL;DR: 首个为四肢瘫痪患者设计的双前臂高密度肌电控制移动机械臂系统，支持家庭环境下的日常任务执行


<details>
  <summary>Details</summary>
Motivation: 颈椎脊髓损伤患者无法使用传统机器人控制接口（如操纵杆、键盘），需要开发新的控制方式使其能够在家中执行日常物理家务任务

Method: 1. 开发定制化织物集成高密度肌电前臂袖套，捕捉临床瘫痪自由度的残余神经运动活动；2. 集成视觉、语言和运动规划模块，构建共享自主框架，支持稳健的用户驱动远程操作；3. 进行为期12天的家庭用户研究，评估可穿戴肌电接口的实际使用效果

Result: 系统成功实现了四肢瘫痪患者在家庭环境中对移动机械臂的有效控制，能够执行日常生活活动和家务任务

Conclusion: 该系统为四肢瘫痪患者提供了创新的机器人控制解决方案，通过高密度肌电接口和共享自主框架的结合，使患者能够在真实家庭环境中独立完成日常任务

Abstract: Mobile manipulators in the home can enable people with cervical spinal cord injury (cSCI) to perform daily physical household tasks that they could not otherwise do themselves. However, paralysis in these users often limits access to traditional robot control interfaces such as joysticks or keyboards. In this work, we introduce and deploy the first system that enables a user with quadriplegia to control a mobile manipulator in their own home using bimanual high-density electromyography (HDEMG). We develop a pair of custom, fabric-integrated HDEMG forearm sleeves, worn on both arms, that capture residual neuromotor activity from clinically paralyzed degrees of freedom and support real-time gesture-based robot control. Second, by integrating vision, language, and motion planning modules, we introduce a shared autonomy framework that supports robust and user-driven teleoperation, with particular benefits for navigation-intensive tasks in home environments. Finally, to demonstrate the system in the wild, we present a twelve-day in-home user study evaluating real-time use of the wearable EMG interface for daily robot control. Together, these system components enable effective robot control for performing activities of daily living and other household tasks in a real home environment.

</details>


### [5] [Adaptive Linear Path Model-Based Diffusion](https://arxiv.org/abs/2602.02831)
*Yutaka Shimizu,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 论文提出LP-MBD方法，用线性概率路径替换方差保持调度，简化扩散模型参数调优，并进一步提出ALP-MBD，利用强化学习自适应调整扩散步骤和噪声水平，提高机器人控制的鲁棒性和实时效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人控制中表现出色，但其性能对调度参数选择高度敏感，参数调优成为关键挑战。现有方法需要复杂的参数调整，限制了实际应用。

Method: 1. 提出LP-MBD：用流匹配启发的线性概率路径替换传统的方差保持调度，获得几何可解释且解耦的参数化；2. 提出ALP-MBD：在LP-MBD基础上，利用强化学习根据任务复杂度和环境条件自适应调整扩散步骤和噪声水平。

Result: 在数值研究、Brax基准测试和移动机器人轨迹跟踪实验中，LP-MBD简化了调度同时保持强大性能，ALP-MBD进一步提高了鲁棒性、适应性和实时效率。

Conclusion: LP-MBD为基于扩散的模型控制提供了稳定基础，ALP-MBD通过自适应调整机制增强了系统对复杂任务和动态环境的适应能力，推动了扩散模型在机器人控制中的实际应用。

Abstract: The interest in combining model-based control approaches with diffusion models has been growing. Although we have seen many impressive robotic control results in difficult tasks, the performance of diffusion models is highly sensitive to the choice of scheduling parameters, making parameter tuning one of the most critical challenges. We introduce Linear Path Model-Based Diffusion (LP-MBD), which replaces the variance-preserving schedule with a flow-matching-inspired linear probability path. This yields a geometrically interpretable and decoupled parameterization that reduces tuning complexity and provides a stable foundation for adaptation. Building on this, we propose Adaptive LP-MBD (ALP-MBD), which leverages reinforcement learning to adjust diffusion steps and noise levels according to task complexity and environmental conditions. Across numerical studies, Brax benchmarks, and mobile-robot trajectory tracking, LP-MBD simplifies scheduling while maintaining strong performance, and ALP-MBD further improves robustness, adaptability, and real-time efficiency.

</details>


### [6] [Language Movement Primitives: Grounding Language Models in Robot Motion](https://arxiv.org/abs/2602.02839)
*Yinlong Dai,Benjamin A. Christie,Daniel J. Evans,Dylan P. Losey,Simon Stepputtis*

Main category: cs.RO

TL;DR: 提出Language Movement Primitives (LMPs)框架，将视觉语言模型的推理能力与动态运动基元参数化相结合，实现零样本机器人操作任务


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：视觉语言模型擅长任务分解但难以将步骤转化为具体机器人运动；机器人基础模型需要领域微调才能执行新任务。核心挑战是如何连接抽象任务推理与低级运动控制

Method: 提出LMPs框架，利用动态运动基元(DMPs)的可解释参数特性，让视觉语言模型通过设置这些参数来生成多样化、连续、稳定的轨迹，从而将自然语言任务描述转化为具体的运动控制

Result: 在20个真实世界操作任务中，LMPs实现了80%的任务成功率，而最佳基线方法只有31%的成功率

Conclusion: LMPs框架成功连接了高级任务推理与低级运动控制，通过将视觉语言模型与动态运动基元相结合，实现了零样本机器人操作能力，显著优于现有方法

Abstract: Enabling robots to perform novel manipulation tasks from natural language instructions remains a fundamental challenge in robotics, despite significant progress in generalized problem solving with foundational models. Large vision and language models (VLMs) are capable of processing high-dimensional input data for visual scene and language understanding, as well as decomposing tasks into a sequence of logical steps; however, they struggle to ground those steps in embodied robot motion. On the other hand, robotics foundation models output action commands, but require in-domain fine-tuning or experience before they are able to perform novel tasks successfully. At its core, there still remains the fundamental challenge of connecting abstract task reasoning with low-level motion control. To address this disconnect, we propose Language Movement Primitives (LMPs), a framework that grounds VLM reasoning in Dynamic Movement Primitive (DMP) parameterization. Our key insight is that DMPs provide a small number of interpretable parameters, and VLMs can set these parameters to specify diverse, continuous, and stable trajectories. Put another way: VLMs can reason over free-form natural language task descriptions, and semantically ground their desired motions into DMPs -- bridging the gap between high-level task reasoning and low-level position and velocity control. Building on this combination of VLMs and DMPs, we formulate our LMP pipeline for zero-shot robot manipulation that effectively completes tabletop manipulation problems by generating a sequence of DMP motions. Across 20 real-world manipulation tasks, we show that LMP achieves 80% task success as compared to 31% for the best-performing baseline. See videos at our website: https://collab.me.vt.edu/lmp

</details>


### [7] [Kino-PAX$^+$: Near-Optimal Massively Parallel Kinodynamic Sampling-based Motion Planner](https://arxiv.org/abs/2602.02846)
*Nicolas Perrault,Qi Heng Ho,Morteza Lahijanian*

Main category: cs.RO

TL;DR: Kino-PAX⁺是一个大规模并行的运动规划算法，通过并行化传统串行操作实现实时性能，同时保证渐进近最优性


<details>
  <summary>Details</summary>
Motivation: 现有的基于采样的运动规划器（SBMPs）由于串行计算设计难以实现实时性能，而现有的并行化方法虽然加速了可行解搜索，但无法保证目标函数优化

Method: 将传统串行操作分解为三个大规模并行子程序：1）稀疏树构建，2）局部邻域内最有前景节点的传播，3）轨迹细化。算法专注于最有前景节点的计算

Result: Kino-PAX⁺比现有串行方法快三个数量级，且比最先进的GPU规划器获得更低的解成本，同时保持概率δ-鲁棒完备性和渐进δ-鲁棒近最优性

Conclusion: Kino-PAX⁺首次实现了大规模并行运动规划器，在保证渐进近最优性的同时显著提升计算速度，解决了传统SBMPs的实时性能瓶颈

Abstract: Sampling-based motion planners (SBMPs) are widely used for robot motion planning with complex kinodynamic constraints in high-dimensional spaces, yet they struggle to achieve \emph{real-time} performance due to their serial computation design. Recent efforts to parallelize SBMPs have achieved significant speedups in finding feasible solutions; however, they provide no guarantees of optimizing an objective function. We introduce Kino-PAX$^{+}$, a massively parallel kinodynamic SBMP with asymptotic near-optimal guarantees. Kino-PAX$^{+}$ builds a sparse tree of dynamically feasible trajectories by decomposing traditionally serial operations into three massively parallel subroutines. The algorithm focuses computation on the most promising nodes within local neighborhoods for propagation and refinement, enabling rapid improvement of solution cost. We prove that, while maintaining probabilistic $δ$-robust completeness, this focus on promising nodes ensures asymptotic $δ$-robust near-optimality. Our results show that Kino-PAX$^{+}$ finds solutions up to three orders of magnitude faster than existing serial methods and achieves lower solution costs than a state-of-the-art GPU-based planner.

</details>


### [8] [Accelerating Structured Chain-of-Thought in Autonomous Vehicles](https://arxiv.org/abs/2602.02864)
*Yi Gu,Yan Wang,Yuxiao Chen,Yurong You,Wenjie Luo,Yue Wang,Wenhao Ding,Boyi Li,Heng Yang,Boris Ivanovic,Marco Pavone*

Main category: cs.RO

TL;DR: FastDriveCoT提出并行解码方法加速自动驾驶中的思维链推理，将推理过程分解为依赖图，并行生成独立推理步骤，实现3-4倍加速


<details>
  <summary>Details</summary>
Motivation: 思维链推理增强了自动驾驶视觉-语言-动作模型的决策能力，但其自回归特性引入了显著的推理延迟，使其不适用于实时应用

Method: 引入FastDriveCoT并行解码方法，将推理过程分解为不同子任务的依赖图（如识别关键对象、总结交通规则等），在单次前向传播中并行生成多个独立推理步骤

Result: 实验显示思维链生成速度提升3-4倍，端到端延迟显著降低，同时保持了思维链推理带来的下游任务改进

Conclusion: FastDriveCoT通过并行解码有效解决了思维链推理的延迟问题，使其适用于自动驾驶等实时应用场景

Abstract: Chain-of-Thought (CoT) reasoning enhances the decision-making capabilities of vision-language-action models in autonomous driving, but its autoregressive nature introduces significant inference latency, making it impractical for real-time applications. To address this, we introduce FastDriveCoT, a novel parallel decoding method that accelerates template-structured CoT. Our approach decomposes the reasoning process into a dependency graph of distinct sub-tasks, such as identifying critical objects and summarizing traffic rules, some of which can be generated in parallel. By generating multiple independent reasoning steps concurrently within a single forward pass, we significantly reduce the number of sequential computations. Experiments demonstrate a 3-4$\times$ speedup in CoT generation and a substantial reduction in end-to-end latency across various model architectures, all while preserving the original downstream task improvements brought by incorporating CoT reasoning.

</details>


### [9] [Moving On, Even When You're Broken: Fail-Active Trajectory Generation via Diffusion Policies Conditioned on Embodiment and Task](https://arxiv.org/abs/2602.02895)
*Gilberto G. Briscoe-Martinez,Yaashia Gautam,Rahul Shetty,Anuj Pasricha,Marco M. Nicotra,Alessandro Roncone*

Main category: cs.RO

TL;DR: DEFT是一种基于扩散模型的轨迹生成器，能够在机器人执行器故障时生成适应当前身体状态和任务约束的轨迹，实现故障主动操作，在仿真和真实场景中均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 机器人故障通常需要人工干预恢复，影响系统运行。研究目标是实现故障主动操作，即在受损状态下仍能安全完成任务。

Method: 提出DEFT（扩散式轨迹生成器），基于扩散模型生成轨迹，条件化于机器人当前身体状态和任务约束。该方法能泛化到不同类型故障，支持约束和非约束运动，适应任意故障配置。

Result: 在仿真中，DEFT在数千个关节故障案例中表现优于基线方法达2倍；在未见过的故障类型上仍优于基线，显示良好泛化能力。真实世界实验中，DEFT成功完成抽屉操作和白板擦除任务，而传统方法失败。

Conclusion: DEFT能够实现跨任意故障配置的故障主动操作，并在真实部署中有效，为机器人故障恢复提供了有前景的解决方案。

Abstract: Robot failure is detrimental and disruptive, often requiring human intervention to recover. Maintaining safe operation under impairment to achieve task completion, i.e. fail-active operation, is our target. Focusing on actuation failures, we introduce DEFT, a diffusion-based trajectory generator conditioned on the robot's current embodiment and task constraints. DEFT generalizes across failure types, supports constrained and unconstrained motions, and enables task completion under arbitrary failure. We evaluated DEFT in both simulation and real-world scenarios using a 7-DoF robotic arm. In simulation over thousands of joint-failure cases across multiple tasks, DEFT outperformed the baseline by up to 2 times. On failures unseen during training, it continued to outperform the baseline, indicating robust generalization in simulation. Further, we performed real-world evaluations on two multi-step tasks, drawer manipulation and whiteboard erasing. These experiments demonstrated DEFT succeeding on tasks where classical methods failed. Our results show that DEFT achieves fail-active manipulation across arbitrary failure configurations and real-world deployments.

</details>


### [10] [Modular Isoperimetric Soft Robotic Truss for Lunar Applications](https://arxiv.org/abs/2602.02915)
*Mihai Stanciu,Isaac Weaver,Adam Rose,James Wade,Kaden Paxton,Chris Paul,Spencer Stowell,Nathan Usevitch*

Main category: cs.RO

TL;DR: 提出了一种用于月球应用的大型可重构机器人系统，采用充气织物管构成三角形桁架结构，通过球形关节连接，可实现太阳能阵列和移动功能


<details>
  <summary>Details</summary>
Motivation: 为可持续月球操作和未来太空任务开发轻量、模块化、可重构的机器人系统，解决空间应用中的关键挑战

Method: 使用连续充气织物管通过两个机器人滚轮单元和一个连接单元形成三角形桁架结构；新开发的球形关节允许多个三角形在顶点连接；滚轮单元夹紧管子形成有效关节，电机驱动滚轮沿管移动改变形状

Result: 系统收拢体积比达1:18.3；展示为12自由度太阳能阵列（倾斜60度，旋转360度）和14自由度移动装置（步进滑动步态）；无需额外压缩空气即可实现形状变化

Conclusion: 这种模块化、形状自适应的系统为可持续月球操作和未来太空任务提供了创新解决方案，具有轻量、紧凑和多功能的特点

Abstract: We introduce a large-scale robotic system designed as a lightweight, modular, and reconfigurable structure for lunar applications. The system consists of truss-like robotic triangles formed by continuous inflated fabric tubes routed through two robotic roller units and a connecting unit. A newly developed spherical joint enables up to three triangles to connect at a vertex, allowing construction of truss assemblies beyond a single octahedron. When deflated, the triangles compact to approximately the volume of the roller units, achieving a stowed-to-deployed volume ratio of 1:18.3. Upon inflation, the roller units pinch the tubes, locally reducing bending stiffness to form effective joints. Electric motors then translate the roller units along the tube, shifting the pinch point by lengthening one edge while shortening another at the same rate, thereby preserving a constant perimeter (isoperimetric). This shape-changing process requires no additional compressed air, enabling untethered operation after initial inflation. We demonstrate the system as a 12-degree-of-freedom solar array capable of tilting up to 60 degrees and sweeping 360 degrees, and as a 14-degree-of-freedom locomotion device using a step-and-slide gait. This modular, shape-adaptive system addresses key challenges for sustainable lunar operations and future space missions.

</details>


### [11] [Embodiment-Aware Generalist Specialist Distillation for Unified Humanoid Whole-Body Control](https://arxiv.org/abs/2602.02960)
*Quanquan Peng,Yunfeng Lin,Yufei Xue,Jiangmiao Pang,Weinan Zhang*

Main category: cs.RO

TL;DR: EAGLE是一个迭代的通用-专家蒸馏框架，通过循环训练产生单一统一策略，能够控制多个异构人形机器人，无需为每个机器人单独调整奖励函数。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的人形机器人全身控制器通常针对单一机器人设计，难以适应不同机器人在动力学、自由度、运动学拓扑结构上的差异。同时，需要开发不仅能跨平台迁移，还能支持更丰富行为（如深蹲、倾斜等）的通用策略。

Method: 提出EAGLE迭代蒸馏框架：1）从当前通用策略派生出针对特定机器人的专家策略；2）在各自机器人上精炼专家策略；3）将新学到的技能通过池化训练蒸馏回通用策略。循环此过程直到性能收敛，最终获得能控制多个异构人形机器人的统一策略。

Result: 在仿真中测试了5个不同机器人，在真实世界中测试了4个机器人（包括Unitree H1、G1和Fourier N1）。定量评估显示，相比其他方法，EAGLE实现了更高的跟踪精度和鲁棒性。

Conclusion: EAGLE框架为可扩展的、面向机群级别的人形机器人控制迈出了重要一步，能够产生单一统一策略来控制多个异构人形机器人，无需为每个机器人单独调整奖励函数。

Abstract: Humanoid Whole-Body Controllers trained with reinforcement learning (RL) have recently achieved remarkable performance, yet many target a single robot embodiment. Variations in dynamics, degrees of freedom (DoFs), and kinematic topology still hinder a single policy from commanding diverse humanoids. Moreover, obtaining a generalist policy that not only transfers across embodiments but also supports richer behaviors-beyond simple walking to squatting, leaning-remains especially challenging. In this work, we tackle these obstacles by introducing EAGLE, an iterative generalist-specialist distillation framework that produces a single unified policy that controls multiple heterogeneous humanoids without per-robot reward tuning. During each cycle, embodiment-specific specialists are forked from the current generalist, refined on their respective robots, and new skills are distilled back into the generalist by training on the pooled embodiment set. Repeating this loop until performance convergence produces a robust Whole-Body Controller validated on robots such as Unitree H1, G1, and Fourier N1. We conducted experiments on five different robots in simulation and four in real-world settings. Through quantitative evaluations, EAGLE achieves high tracking accuracy and robustness compared to other methods, marking a step toward scalable, fleet-level humanoid control. See more details at https://eagle-wbc.github.io/

</details>


### [12] [RPL: Learning Robust Humanoid Perceptive Locomotion on Challenging Terrains](https://arxiv.org/abs/2602.03002)
*Yuanhang Zhang,Younggyo Seo,Juyue Chen,Yifu Yuan,Koushil Sreenath,Pieter Abbeel,Carmelo Sferrazza,Karen Liu,Rocky Duan,Guanya Shi*

Main category: cs.RO

TL;DR: RPL是一个两阶段训练框架，通过专家策略训练和Transformer策略蒸馏，实现人形机器人在复杂地形上的多方向运动与负载能力


<details>
  <summary>Details</summary>
Motivation: 人形机器人感知运动虽已取得进展，但在复杂地形上实现鲁棒的多方向运动仍待探索，特别是在负载条件下的适应性

Method: 1. 第一阶段：使用特权高度图训练地形特定专家策略，掌握解耦的运动和操作技能
2. 第二阶段：将专家策略蒸馏到基于多深度相机的Transformer策略中
3. 引入深度特征缩放和随机侧边掩码技术增强鲁棒性
4. 开发高效多深度系统，实现5倍加速的深度渲染

Result: 在真实世界实验中，实现了带负载（2kg）的鲁棒多方向运动，成功应对20°斜坡、不同步长楼梯（22cm、25cm、30cm）以及25cm×25cm、间隔60cm的踏石地形

Conclusion: RPL框架通过两阶段训练和高效深度系统，成功解决了复杂地形上人形机器人多方向运动的挑战，展示了在实际场景中的鲁棒性和实用性

Abstract: Humanoid perceptive locomotion has made significant progress and shows great promise, yet achieving robust multi-directional locomotion on complex terrains remains underexplored. To tackle this challenge, we propose RPL, a two-stage training framework that enables multi-directional locomotion on challenging terrains, and remains robust with payloads. RPL first trains terrain-specific expert policies with privileged height map observations to master decoupled locomotion and manipulation skills across different terrains, and then distills them into a transformer policy that leverages multiple depth cameras to cover a wide range of views. During distillation, we introduce two techniques to robustify multi-directional locomotion, depth feature scaling based on velocity commands and random side masking, which are critical for asymmetric depth observations and unseen widths of terrains. For scalable depth distillation, we develop an efficient multi-depth system that ray-casts against both dynamic robot meshes and static terrain meshes in massively parallel environments, achieving a 5-times speedup over the depth rendering pipelines in existing simulators while modeling realistic sensor latency, noise, and dropout. Extensive real-world experiments demonstrate robust multi-directional locomotion with payloads (2kg) across challenging terrains, including 20° slopes, staircases with different step lengths (22 cm, 25 cm, 30 cm), and 25 cm by 25 cm stepping stones separated by 60 cm gaps.

</details>


### [13] [Training and Simulation of Quadrupedal Robot in Adaptive Stair Climbing for Indoor Firefighting: An End-to-End Reinforcement Learning Approach](https://arxiv.org/abs/2602.03087)
*Baixiao Huang,Baiyu Huang,Yu Hou*

Main category: cs.RO

TL;DR: 本文提出了一种两阶段端到端深度强化学习框架，使四足机器人能够在复杂室内环境中自主导航并攀爬不同类型的楼梯，包括直梯、L形梯和螺旋梯。


<details>
  <summary>Details</summary>
Motivation: 在室内火灾初期搜救中，四足机器人需要进行快速全面的受害者搜索和易燃物监测。然而，复杂室内环境中的态势感知和快速攀爬不同类型楼梯仍然是机器人辅助搜救面临的主要挑战。

Method: 采用两阶段端到端深度强化学习方法：第一阶段在Isaac Lab的金字塔楼梯地形中训练四足机器人（Unitree Go2）攀爬技能；第二阶段将学习到的策略迁移到Isaac Lab引擎中的各种真实室内楼梯环境（直梯、L形梯、螺旋梯）。使用基于中心线的导航公式，实现导航和运动的统一学习。

Result: 实现了从抽象金字塔地形到真实室内楼梯拓扑的技能迁移；通过仅使用局部高度图感知，展示了策略在不同楼梯类型上的泛化能力；对楼梯难度递增情况下的成功率、效率和失败模式进行了实证分析。

Conclusion: 该研究探索了如何平衡导航和运动，以及端到端强化学习方法如何使四足机器人适应不同形状的楼梯。提出的框架能够实现导航和运动的统一学习，无需分层规划，为复杂环境中的机器人搜救提供了有效解决方案。

Abstract: Quadruped robots are used for primary searches during the early stages of indoor fires. A typical primary search involves quickly and thoroughly looking for victims under hazardous conditions and monitoring flammable materials. However, situational awareness in complex indoor environments and rapid stair climbing across different staircases remain the main challenges for robot-assisted primary searches. In this project, we designed a two-stage end-to-end deep reinforcement learning (RL) approach to optimize both navigation and locomotion. In the first stage, the quadrupeds, Unitree Go2, were trained to climb stairs in Isaac Lab's pyramid-stair terrain. In the second stage, the quadrupeds were trained to climb various realistic indoor staircases in the Isaac Lab engine, with the learned policy transferred from the previous stage. These indoor staircases are straight, L-shaped, and spiral, to support climbing tasks in complex environments. This project explores how to balance navigation and locomotion and how end-to-end RL methods can enable quadrupeds to adapt to different stair shapes. Our main contributions are: (1) A two-stage end-to-end RL framework that transfers stair-climbing skills from abstract pyramid terrain to realistic indoor stair topologies. (2) A centerline-based navigation formulation that enables unified learning of navigation and locomotion without hierarchical planning. (3) Demonstration of policy generalization across diverse staircases using only local height-map perception. (4) An empirical analysis of success, efficiency, and failure modes under increasing stair difficulty.

</details>


### [14] [A Unified Candidate Set with Scene-Adaptive Refinement via Diffusion for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.03112)
*Zhengfei Wu,Shuaixi Pan,Shuohan Chen,Shuo Yang,Yanjun Huang*

Main category: cs.RO

TL;DR: CdDrive提出了一种结合固定轨迹词汇和场景自适应扩散候选的自动驾驶规划方法，通过词汇条件扩散去噪生成增强候选轨迹，使用共享选择模块进行评分，并引入HATNA提升扩散候选的平滑性和几何连续性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶规划中，固定轨迹词汇在常规驾驶中提供稳定覆盖，但在复杂交互中常错过最优解；而场景自适应细化在简单场景中可能过度修正已足够好的词汇轨迹。需要一种方法在保持词汇稳定性的同时，在复杂场景中生成更优解。

Method: CdDrive保留原始词汇候选，并通过词汇条件扩散去噪生成场景自适应候选。两种候选由共享选择模块联合评分。引入HATNA（Horizon-Aware Trajectory Noise Adapter）通过时间平滑和视界感知噪声调制来提升扩散候选的平滑性和几何连续性。

Result: 在NAVSIM v1和NAVSIM v2数据集上的实验展示了领先性能，消融研究验证了每个组件的贡献。

Conclusion: CdDrive通过结合固定轨迹词汇和场景自适应扩散候选，实现了在常规和高交互场景中的可靠性能，HATNA进一步提升了扩散候选的质量，为自动驾驶规划提供了有效的解决方案。

Abstract: End-to-end autonomous driving is increasingly adopting a multimodal planning paradigm that generates multiple trajectory candidates and selects the final plan, making candidate-set design critical. A fixed trajectory vocabulary provides stable coverage in routine driving but often misses optimal solutions in complex interactions, while scene-adaptive refinement can cause over-correction in simple scenarios by unnecessarily perturbing already strong vocabulary trajectories.We propose CdDrive, which preserves the original vocabulary candidates and augments them with scene-adaptive candidates generated by vocabulary-conditioned diffusion denoising. Both candidate types are jointly scored by a shared selection module, enabling reliable performance across routine and highly interactive scenarios. We further introduce HATNA (Horizon-Aware Trajectory Noise Adapter) to improve the smoothness and geometric continuity of diffusion candidates via temporal smoothing and horizon-aware noise modulation. Experiments on NAVSIM v1 and NAVSIM v2 demonstrate leading performance, and ablations verify the contribution of each component.

</details>


### [15] [Multi-function Robotized Surgical Dissector for Endoscopic Pulmonary Thromboendarterectomy: Preclinical Study and Evaluation](https://arxiv.org/abs/2602.03147)
*Runfeng Zhu,Xin Zhong,Qingxiang Zhao,Jing Lin,Zhong Wu,Kang Li*

Main category: cs.RO

TL;DR: 开发了一种基于同心推拉机器人结构的机器人化剥离器，用于慢性严重肺血栓栓塞症手术，具有细长双段弯曲灵活性，可进入肺动脉薄分支。


<details>
  <summary>Details</summary>
Motivation: 慢性严重肺血栓栓塞症患者需要进行肺动脉内膜切除术，但现有工具刚性直杆，缺乏远端灵活性，难以进入肺动脉的薄分支。

Method: 设计基于同心推拉机器人结构的机器人化剥离器，直径3.5mm，具有中空薄壁结构，中心腔容纳冲洗和尖端工具通道以及内窥镜信号线。建立基于优化的运动学模型实现精确定位。

Result: 实现了2mm的尖端工具定位精度（60mm长度），在开环控制策略下。通过实验评估了刚度、运动精度和可操作性，并在离体猪肺上进行手术模拟，展示了其灵活性和在肺动脉内膜切除术中的优势。

Conclusion: 该机器人化剥离器具有细长双段弯曲灵活性，可进入肺动脉薄分支，结合内窥镜可将传统肺动脉内膜切除术升级为内窥镜手术，为慢性严重肺血栓栓塞症治疗提供了创新解决方案。

Abstract: Patients suffering chronic severe pulmonary thromboembolism need Pulmonary Thromboendarterectomy (PTE) to remove the thromb and intima located inside pulmonary artery (PA). During the surgery, a surgeon holds tweezers and a dissector to delicately strip the blockage, but available tools for this surgery are rigid and straight, lacking distal dexterity to access into thin branches of PA. Therefore, this work presents a novel robotized dissector based on concentric push/pull robot (CPPR) structure, enabling entering deep thin branch of tortuous PA. Compared with conventional rigid dissectors, our design characterizes slenderness and dual-segment-bending dexterity. Owing to the hollow and thin-walled structure of the CPPR-based dissector as it has a slender body of 3.5mm in diameter, the central lumen accommodates two channels for irrigation and tip tool, and space for endoscopic camera's signal wire. To provide accurate surgical manipulation, optimization-based kinematics model was established, realizing a 2mm accuracy in positioning the tip tool (60mm length) under open-loop control strategy. As such, with the endoscopic camera, traditional PTE is possible to be upgraded as endoscopic PTE. Basic physic performance of the robotized dissector including stiffness, motion accuracy and maneuverability was evaluated through experiments. Surgery simulation on ex vivo porcine lung also demonstrates its dexterity and notable advantages in PTE.

</details>


### [16] [When Attention Betrays: Erasing Backdoor Attacks in Robotic Policies by Reconstructing Visual Tokens](https://arxiv.org/abs/2602.03153)
*Xuetao Li,Pinhan Fu,Wenke Huang,Nengyuan Pan,Songhua Yang,Kaiyan Zhao,Guancheng Wan,Mengde Li,Jifeng Xuan,Miao Li*

Main category: cs.RO

TL;DR: Bera是一种针对视觉-语言-动作模型后门攻击的测试时防御框架，通过检测异常注意力、掩蔽可疑区域并重建无触发图像来消除后门，无需重新训练模型


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型的下游微调存在后门攻击风险，现有防御方法要么缺乏对多模态后门机制的理解，要么需要全模型重新训练导致计算成本过高

Method: 发现后门攻击的深层注意力抓取机制：后门会重定向后期注意力并在干净流形附近形成紧凑嵌入簇。基于此，提出Bera框架：1）通过潜在空间定位检测异常注意力标记；2）使用深层线索掩蔽可疑区域；3）重建无触发图像以打破触发-不安全动作映射

Result: 在多个具身平台和任务上的实验表明，Bera能有效保持正常性能，显著降低攻击成功率，并持续从后门输出中恢复良性行为

Conclusion: Bera为保护机器人系统提供了一个鲁棒且实用的防御机制，无需重新训练VLA模型或改变训练流程，实现了测试时的后门擦除

Abstract: Downstream fine-tuning of vision-language-action (VLA) models enhances robotics, yet exposes the pipeline to backdoor risks. Attackers can pretrain VLAs on poisoned data to implant backdoors that remain stealthy but can trigger harmful behavior during inference. However, existing defenses either lack mechanistic insight into multimodal backdoors or impose prohibitive computational costs via full-model retraining. To this end, we uncover a deep-layer attention grabbing mechanism: backdoors redirect late-stage attention and form compact embedding clusters near the clean manifold. Leveraging this insight, we introduce Bera, a test-time backdoor erasure framework that detects tokens with anomalous attention via latent-space localization, masks suspicious regions using deep-layer cues, and reconstructs a trigger-free image to break the trigger-unsafe-action mapping while restoring correct behavior. Unlike prior defenses, Bera requires neither retraining of VLAs nor any changes to the training pipeline. Extensive experiments across multiple embodied platforms and tasks show that Bera effectively maintains nominal performance, significantly reduces attack success rates, and consistently restores benign behavior from backdoored outputs, thereby offering a robust and practical defense mechanism for securing robotic systems.

</details>


### [17] [Estimation of Ground Reaction Forces from Kinematic Data during Locomotion](https://arxiv.org/abs/2602.03177)
*Gautami Golani,Dong Anh Khoa To,Ananda Sidarta,Arun-Kumar Kaliya-Perumal,Oliver Roberts,Lek Syn Lim,Jim Patton,Domenico Campolo*

Main category: cs.RO

TL;DR: 提出了一种仅使用运动捕捉数据、无需测力台的足底反作用力估计方法，适用于临床广泛部署


<details>
  <summary>Details</summary>
Motivation: 足底反作用力在步态分析中很重要，但由于测力台系统的实际限制，在临床工作流程中未得到充分利用

Method: 使用16个身体段的运动学数据估计质心位置，计算足底反作用力，并通过最小化方法将其分解为各个分量

Result: 实验结果表明仅基于运动学数据估计质心和足底反作用力的可行性，支持无测力台的步态分析

Conclusion: 该方法能够识别步态支撑相并提供临床有意义的动力学测量，无需专用测力台系统

Abstract: Ground reaction forces (GRFs) provide fundamental insight into human gait mechanics and are widely used to assess joint loading, limb symmetry, balance control, and motor function. Despite their clinical relevance, the use of GRF remains underutilised in clinical workflows due to the practical limitations of force plate systems. In this work, we present a force-plate-free approach for estimating GRFs using only marker-based motion capture data. This kinematics only method to estimate and decompose GRF makes it well suited for widespread clinical depolyment. By using kinematics from sixteen body segments, we estimate the centre of mass (CoM) and compute GRFs, which are subsequently decomposed into individual components through a minimization-based approach. Through this framework, we can identify gait stance phases and provide access to clinically meaningful kinetic measures without a dedicated force plate system. Experimental results demonstrate the viability of CoM and GRF estimation based solely on kinematic data, supporting force-plate-free gait analysis.

</details>


### [18] [Hierarchical Proportion Models for Motion Generation via Integration of Motion Primitives](https://arxiv.org/abs/2602.03188)
*Yu-Han Shu,Toshiaki Tsuji,Sho Sakaino*

Main category: cs.RO

TL;DR: 本文提出了一种分层模仿学习框架，通过运动基元与比例合成方法提高机器人学习的数据效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 模仿学习需要大量高质量数据且难以处理复杂或长时程任务，需要提高数据效率和适应性。

Method: 采用双层架构：上层进行长期规划，下层学习独立运动基元，通过特定比例组合基元。提出了三种变体：学习型比例模型、采样型比例模型和回放型比例模型。

Result: 在真实机器人拾放实验中，模型成功生成了基元集中未包含的复杂运动。采样型和回放型比例模型比标准分层模型更稳定、适应性更强。

Conclusion: 比例运动合成方法有效提升了机器人学习的实用性和适应性。

Abstract: Imitation learning (IL) enables robots to acquire human-like motion skills from demonstrations, but it still requires extensive high-quality data and retraining to handle complex or long-horizon tasks. To improve data efficiency and adaptability, this study proposes a hierarchical IL framework that integrates motion primitives with proportion-based motion synthesis. The proposed method employs a two-layer architecture, where the upper layer performs long-term planning, while a set of lower-layer models learn individual motion primitives, which are combined according to specific proportions. Three model variants are introduced to explore different trade-offs between learning flexibility, computational cost, and adaptability: a learning-based proportion model, a sampling-based proportion model, and a playback-based proportion model, which differ in how the proportions are determined and whether the upper layer is trainable. Through real-robot pick-and-place experiments, the proposed models successfully generated complex motions not included in the primitive set. The sampling-based and playback-based proportion models achieved more stable and adaptable motion generation than the standard hierarchical model, demonstrating the effectiveness of proportion-based motion integration for practical robot learning.

</details>


### [19] [HUSKY: Humanoid Skateboarding System via Physics-Aware Whole-Body Control](https://arxiv.org/abs/2602.03205)
*Jinrui Han,Dewei Wang,Chenyun Zhang,Xinzhe Liu,Ping Luo,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: HUSKY框架通过集成人形滑板系统建模和物理感知全身控制，实现了人形机器人在滑板上的稳定动态操控，解决了非完整约束和紧密耦合的人-物交互挑战。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人全身控制框架主要依赖静态环境假设，难以应对高动态性和复杂交互的任务。滑板运动作为典型挑战，需要在不稳定的轮式平台上实现动态操控，涉及非完整约束和紧密耦合的人-物交互。

Method: 提出HUSKY学习框架：1）建模滑板倾斜与转向角度之间的耦合关系，进行系统动力学分析；2）使用对抗运动先验学习类人推动动作；3）采用物理引导、面向航向的策略实现倾斜转向行为；4）轨迹引导机制确保推动和转向之间的平滑稳定过渡。

Result: 在Unitree G1人形机器人平台上的实验结果表明，该框架能够在真实场景中实现滑板上的稳定和敏捷操控。

Conclusion: HUSKY框架成功解决了人形机器人滑板运动这一高挑战性任务，通过系统建模和学习控制相结合的方法，实现了在动态不稳定平台上的稳定动态操控。

Abstract: While current humanoid whole-body control frameworks predominantly rely on the static environment assumptions, addressing tasks characterized by high dynamism and complex interactions presents a formidable challenge. In this paper, we address humanoid skateboarding, a highly challenging task requiring stable dynamic maneuvering on an underactuated wheeled platform. This integrated system is governed by non-holonomic constraints and tightly coupled human-object interactions. Successfully executing this task requires simultaneous mastery of hybrid contact dynamics and robust balance control on a mechanically coupled, dynamically unstable skateboard. To overcome the aforementioned challenges, we propose HUSKY, a learning-based framework that integrates humanoid-skateboard system modeling and physics-aware whole-body control. We first model the coupling relationship between board tilt and truck steering angles, enabling a principled analysis of system dynamics. Building upon this, HUSKY leverages Adversarial Motion Priors (AMP) to learn human-like pushing motions and employs a physics-guided, heading-oriented strategy for lean-to-steer behaviors. Moreover, a trajectory-guided mechanism ensures smooth and stable transitions between pushing and steering. Experimental results on the Unitree G1 humanoid platform demonstrate that our framework enables stable and agile maneuvering on skateboards in real-world scenarios. The project page is available on https://husky-humanoid.github.io/.

</details>


### [20] [Depth Completion in Unseen Field Robotics Environments Using Extremely Sparse Depth Measurements](https://arxiv.org/abs/2602.03209)
*Marco Job,Thomas Stastny,Eleni Kelasidi,Roland Siegwart,Michael Pantic*

Main category: cs.RO

TL;DR: 提出一种用于野外机器人的深度补全模型，利用合成数据和稀疏深度测量在嵌入式平台上实现实时密集度量深度预测


<details>
  <summary>Details</summary>
Motivation: 野外机器人在非结构化环境中需要鲁棒的感知能力，单目深度估计虽然成本低但缺乏可靠尺度线索、纹理条件差且缺乏大规模数据集，限制了其在野外机器人中的应用

Method: 提出深度补全模型，使用合成数据训练，结合稀疏深度传感器测量来预测密集度量深度；开发了针对野外机器人的合成数据集生成流程，利用运动恢复结构的纹理3D网格和照片级真实感渲染来模拟多样化场景

Result: 在Nvidia Jetson AGX Orin上实现每帧53毫秒的端到端延迟，可在嵌入式平台上实时部署；在多样化真实世界野外机器人场景中表现出有竞争力的性能

Conclusion: 该方法通过合成数据训练和稀疏深度测量相结合，解决了野外机器人中单目深度估计的局限性，实现了实时、可靠的密集深度感知

Abstract: Autonomous field robots operating in unstructured environments require robust perception to ensure safe and reliable operations. Recent advances in monocular depth estimation have demonstrated the potential of low-cost cameras as depth sensors; however, their adoption in field robotics remains limited due to the absence of reliable scale cues, ambiguous or low-texture conditions, and the scarcity of large-scale datasets. To address these challenges, we propose a depth completion model that trains on synthetic data and uses extremely sparse measurements from depth sensors to predict dense metric depth in unseen field robotics environments. A synthetic dataset generation pipeline tailored to field robotics enables the creation of multiple realistic datasets for training purposes. This dataset generation approach utilizes textured 3D meshes from Structure from Motion and photorealistic rendering with novel viewpoint synthesis to simulate diverse field robotics scenarios. Our approach achieves an end-to-end latency of 53 ms per frame on a Nvidia Jetson AGX Orin, enabling real-time deployment on embedded platforms. Extensive evaluation demonstrates competitive performance across diverse real-world field robotics scenarios.

</details>


### [21] [Omnidirectional Solid-State mmWave Radar Perception for UAV Power Line Collision Avoidance](https://arxiv.org/abs/2602.03229)
*Nicolaj Haarhøj Malle,Emad Ebeid*

Main category: cs.RO

TL;DR: 该论文提出了一种基于毫米波雷达的无人机感知系统，用于全方位检测和避让电力线，提高飞行安全性。


<details>
  <summary>Details</summary>
Motivation: 无人机（无论是人工操控还是自主飞行）在检测和估计电力线距离方面存在困难，增加了意外碰撞的风险，需要一种可靠的感知系统来提升安全性。

Method: 集成多个紧凑型固态毫米波雷达模块，合成全方位视野，开发针对电力线环境的检测与避让算法，并保持系统轻量化。

Result: 现场实验显示：检测距离达10米，飞行速度超过10米/秒时仍能成功避让，可检测直径小至1.2毫米的导线。

Conclusion: 该方法适合作为自主和手动无人机飞行的额外安全层，能够有效检测和避让电力线，降低碰撞风险。

Abstract: Detecting and estimating distances to power lines is a challenge for both human UAV pilots and autonomous systems, which increases the risk of unintended collisions. We present a mmWave radar-based perception system that provides spherical sensing coverage around a small UAV for robust power line detection and avoidance. The system integrates multiple compact solid-state mmWave radar modules to synthesize an omnidirectional field of view while remaining lightweight. We characterize the sensing behavior of this omnidirectional radar arrangement in power line environments and develop a robust detection-and-avoidance algorithm tailored to that behavior. Field experiments on real power lines demonstrate reliable detection at ranges up to 10 m, successful avoidance maneuvers at flight speeds upwards of 10 m/s, and detection of wires as thin as 1.2 mm in diameter. These results indicate the approach's suitability as an additional safety layer for both autonomous and manual UAV flight.

</details>


### [22] [A thin and soft optical tactile sensor for highly sensitive object perception](https://arxiv.org/abs/2602.03248)
*Yanchen Shen,Kohei Tsuji,Haruto Koizumi,Jiseon Hong,Tomoaki Niiyama,Hiroyuki Kuwabara,Hayato Ishida,Jun Hiramitsu,Mitsuhito Mase,Satoshi Sunada*

Main category: cs.RO

TL;DR: 提出了一种基于散斑图案的薄型、紧凑、柔软的触觉传感器，无需复杂光学组件，通过机器学习实现精确力测量和纹理识别。


<details>
  <summary>Details</summary>
Motivation: 现有光学触觉传感器（特别是基于视觉的）依赖复杂的镜头和相机组件，导致体积大、刚性且对校准敏感。需要开发更紧凑、柔软且无需校准的光学触觉传感器。

Method: 采用柔软硅胶材料中的散斑图案变化来检测变形，通过机器学习算法分析散斑图案变化，实现力测量和纹理识别。

Result: 力测量均方根误差为40 mN，对九类纹理表面（包括麻将牌）的分类准确率达到93.33%。

Conclusion: 基于散斑的方法提供了一种紧凑、易于制造、机械顺从的平台，将光学传感与柔性形状自适应架构相结合，展示了在软体机器人和可穿戴触觉界面中的潜力。

Abstract: Tactile sensing is crucial in robotics and wearable devices for safe perception and interaction with the environment. Optical tactile sensors have emerged as promising solutions, as they are immune to electromagnetic interference and have high spatial resolution. However, existing optical approaches, particularly vision-based tactile sensors, rely on complex optical assemblies that involve lenses and cameras, resulting in bulky, rigid, and alignment-sensitive designs. In this study, we present a thin, compact, and soft optical tactile sensor featuring an alignment-free configuration. The soft optical sensor operates by capturing deformation-induced changes in speckle patterns generated within a soft silicone material, thereby enabling precise force measurements and texture recognition via machine learning. The experimental results show a root-mean-square error of 40 mN in the force measurement and a classification accuracy of 93.33% over nine classes of textured surfaces, including Mahjong tiles. The proposed speckle-based approach provides a compact, easily fabricated, and mechanically compliant platform that bridges optical sensing with flexible shape-adaptive architectures, thereby demonstrating its potential as a novel tactile-sensing paradigm for soft robotics and wearable haptic interfaces.

</details>


### [23] [Collision Detection with Analytical Derivatives of Contact Kinematics](https://arxiv.org/abs/2602.03250)
*Anup Teejo Mathew,Anees Peringal,Daniele Caradonna,Frederic Boyer,Federico Renda*

Main category: cs.RO

TL;DR: iDCOL：基于严格凸隐式表示的隐式可微碰撞检测与接触运动学框架，通过几何正则化解决零曲率或未定义曲率形状的接触映射非光滑问题


<details>
  <summary>Details</summary>
Motivation: 机器人学中基于梯度的方法需要可微的接触运动学，但当形状具有零曲率或未定义曲率时，从机器人状态到接触距离、位置和法向的映射会变得非光滑，这限制了梯度方法的有效性

Method: 通过选择性正则化将几何体转化为严格凸的隐式表示，恢复接触映射的唯一性和光滑性；基于几何缩放凸优化公式推导固定大小的非线性系统，通过隐函数定理计算接触运动学量的解析导数；开发快速牛顿求解器

Result: 开发了iDCOL框架的C++开源实现；通过广泛的碰撞仿真和基准测试验证了方法的鲁棒性；在基于梯度的运动路径规划和可微接触物理中展示了应用价值

Conclusion: iDCOL通过几何正则化解决了接触运动学的非光滑问题，为机器人学中的梯度优化方法提供了可靠的可微碰撞检测和接触运动学计算框架

Abstract: Differentiable contact kinematics are essential for gradient-based methods in robotics, yet the mapping from robot state to contact distance, location, and normal becomes non-smooth in degenerate configurations of shapes with zero or undefined curvature. We address this inherent limitation by selectively regularizing such geometries into strictly convex implicit representations, restoring uniqueness and smoothness of the contact map. Leveraging this geometric regularization, we develop iDCOL, an implicit differentiable collision detection and contact kinematics framework. iDCOL represents colliding bodies using strictly convex implicit surfaces and computes collision detection and contact kinematics by solving a fixed-size nonlinear system derived from a geometric scaling-based convex optimization formulation. By applying the Implicit Function Theorem to the resulting system residual, we derive analytical derivatives of the contact kinematic quantities. We develop a fast Newton-based solver for iDCOL and provide an open-source C++ implementation of the framework. The robustness of the approach is evaluated through extensive collision simulations and benchmarking, and applicability is demonstrated in gradient-based kinematic path planning and differentiable contact physics, including multi-body rigid collisions and a soft-robot interaction example.

</details>


### [24] [RDT2: Exploring the Scaling Limit of UMI Data Towards Zero-Shot Cross-Embodiment Generalization](https://arxiv.org/abs/2602.03310)
*Songming Liu,Bangguo Li,Kai Ma,Lingxuan Wu,Hengkai Tan,Xiao Ouyang,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: RDT2是一个基于70亿参数视觉语言模型的机器人基础模型，通过三阶段训练方法实现零样本部署到新硬件平台，在多样化任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型面临数据稀缺、架构效率低下以及无法跨硬件平台泛化的问题，需要开发能够零样本部署到新机器人平台的基础模型。

Method: 收集了超过10,000小时的多样化机器人演示数据，使用增强的、与具体实现无关的通用操作接口；采用三阶段训练方法，通过残差向量量化、流匹配和蒸馏技术将离散语言知识与连续控制对齐，实现实时推理。

Result: RDT2成为首批能够同时零样本泛化到未见过的物体、场景、指令甚至机器人平台的模型之一，在灵巧操作、长时程和动态下游任务（如打乒乓球）中超越了最先进的基线方法。

Conclusion: RDT2通过大规模数据收集和创新的三阶段训练方法，成功解决了VLA模型的数据稀缺和跨平台泛化问题，为通用机器人基础模型的发展提供了重要进展。

Abstract: Vision-Language-Action (VLA) models hold promise for generalist robotics but currently struggle with data scarcity, architectural inefficiencies, and the inability to generalize across different hardware platforms. We introduce RDT2, a robotic foundation model built upon a 7B parameter VLM designed to enable zero-shot deployment on novel embodiments for open-vocabulary tasks. To achieve this, we collected one of the largest open-source robotic datasets--over 10,000 hours of demonstrations in diverse families--using an enhanced, embodiment-agnostic Universal Manipulation Interface (UMI). Our approach employs a novel three-stage training recipe that aligns discrete linguistic knowledge with continuous control via Residual Vector Quantization (RVQ), flow-matching, and distillation for real-time inference. Consequently, RDT2 becomes one of the first models that simultaneously zero-shot generalizes to unseen objects, scenes, instructions, and even robotic platforms. Besides, it outperforms state-of-the-art baselines in dexterous, long-horizon, and dynamic downstream tasks like playing table tennis. See https://rdt-robotics.github.io/rdt2/ for more information.

</details>


### [25] [Manipulation via Force Distribution at Contact](https://arxiv.org/abs/2602.03350)
*Haegu Lee,Yitaek Kim,Casper Hewson Rask,Christoffer Sloth*

Main category: cs.RO

TL;DR: 本文提出了一种力分布线接触模型用于接触丰富的操作任务，相比传统点接触模型，该模型能更好地模拟摩擦动力学和扭矩生成，通过双层优化框架实现更高效、鲁棒的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 现有接触丰富操作任务多依赖计算高效的点接触模型，但这些简单模型无法捕捉人类操作中关键的摩擦动力学和扭矩生成机制，限制了实现类人接触操作的能力。

Method: 引入力分布线接触模型，构建双层优化框架：下层优化解决接触力计算问题，上层优化应用iLQR进行轨迹优化，通过对比点接触模型展示FDLC的优势。

Result: FDLC模型能够生成沿接触线非均匀力分布的轨迹，相比点接触模型需要更低的控制努力和更少的机器人运动，在盒子旋转任务中验证了方法的有效性。

Conclusion: 力分布线接触模型在接触丰富操作中优于传统点接触模型，能够生成更高效、鲁棒的轨迹，为实现类人接触操作提供了更好的建模基础。

Abstract: Efficient and robust trajectories play a crucial role in contact-rich manipulation, which demands accurate mod- eling of object-robot interactions. Many existing approaches rely on point contact models due to their computational effi- ciency. Simple contact models are computationally efficient but inherently limited for achieving human-like, contact-rich ma- nipulation, as they fail to capture key frictional dynamics and torque generation observed in human manipulation. This study introduces a Force-Distributed Line Contact (FDLC) model in contact-rich manipulation and compares it against conventional point contact models. A bi-level optimization framework is constructed, in which the lower-level solves an optimization problem for contact force computation, and the upper-level optimization applies iLQR for trajectory optimization. Through this framework, the limitations of point contact are demon- strated, and the benefits of the FDLC in generating efficient and robust trajectories are established. The effectiveness of the proposed approach is validated by a box rotating task, demonstrating that FDLC enables trajectories generated via non-uniform force distributions along the contact line, while requiring lower control effort and less motion of the robot.

</details>


### [26] [Learning-based Adaptive Control of Quadruped Robots for Active Stabilization on Moving Platforms](https://arxiv.org/abs/2602.03367)
*Minsung Yoon,Heechan Shin,Jeil Jeong,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: LAS-MP是一种基于学习的四足机器人主动稳定系统，用于在六自由度移动平台上保持平衡，通过自适应姿态调整和状态估计器应对平台运动带来的惯性力挑战。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在地铁、公交车、飞机、游艇等六自由度移动平台上会面临平衡挑战，因为平台独立运动会产生多样化的惯性力作用于机器人。

Method: 提出LAS-MP系统，包含自平衡策略和系统状态估计器。策略自适应调整机器人姿态响应平台运动，估计器基于本体感知传感器数据推断机器人和平台状态。引入平台轨迹生成和调度方法进行系统化训练。

Result: 评估显示在多个指标上相比三个基线方法具有优越的平衡性能。通过消融研究和估计器评估验证了各组成部分的有效性。

Conclusion: LAS-MP系统能有效解决四足机器人在移动平台上的平衡问题，通过自适应姿态调整和状态估计实现稳定控制。

Abstract: A quadruped robot faces balancing challenges on a six-degrees-of-freedom moving platform, like subways, buses, airplanes, and yachts, due to independent platform motions and resultant diverse inertia forces on the robot. To alleviate these challenges, we present the Learning-based Active Stabilization on Moving Platforms (\textit{LAS-MP}), featuring a self-balancing policy and system state estimators. The policy adaptively adjusts the robot's posture in response to the platform's motion. The estimators infer robot and platform states based on proprioceptive sensor data. For a systematic training scheme across various platform motions, we introduce platform trajectory generation and scheduling methods. Our evaluation demonstrates superior balancing performance across multiple metrics compared to three baselines. Furthermore, we conduct a detailed analysis of the \textit{LAS-MP}, including ablation studies and evaluation of the estimators, to validate the effectiveness of each component.

</details>


### [27] [PlanTRansformer: Unified Prediction and Planning with Goal-conditioned Transformer](https://arxiv.org/abs/2602.03376)
*Constantin Selzer,Fabina B. Flohr*

Main category: cs.RO

TL;DR: PlanTRansformer (PTR)是一个统一的Transformer框架，将轨迹预测和规划整合，通过目标条件预测、动态可行性、交互感知和车道级拓扑推理，解决了预测与规划之间的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中轨迹预测和规划是分离的组件：预测模型在未知意图下预测周围智能体运动，产生多模态分布；而规划假设已知自身目标并生成确定性轨迹。这种不匹配造成关键瓶颈：预测缺乏对智能体意图的监督，而规划需要这些信息。现有预测模型尽管在基准测试中表现良好，但往往与规划约束（如碰撞避免和动态可行性）脱节。

Method: 提出PlanTRansformer (PTR)，一个统一的高斯混合Transformer框架，集成了目标条件预测、动态可行性、交互感知和车道级拓扑推理。采用师生训练策略，在训练过程中逐步掩码周围智能体的命令，以与推理条件（智能体意图不可用）对齐。该架构无关的设计可应用于各种基于Transformer的预测模型。

Result: 与基线Motion Transformer (MTR)相比，在边际/联合mAP上实现了4.3%/3.5%的改进；与GameFormer相比，在5秒时间范围内规划误差减少了15.5%。

Conclusion: PTR通过统一的框架有效解决了自动驾驶中预测与规划之间的不匹配问题，提高了预测准确性和规划性能，其架构无关的设计使其具有广泛的适用性。

Abstract: Trajectory prediction and planning are fundamental yet disconnected components in autonomous driving. Prediction models forecast surrounding agent motion under unknown intentions, producing multimodal distributions, while planning assumes known ego objectives and generates deterministic trajectories. This mismatch creates a critical bottleneck: prediction lacks supervision for agent intentions, while planning requires this information. Existing prediction models, despite strong benchmarking performance, often remain disconnected from planning constraints such as collision avoidance and dynamic feasibility. We introduce Plan TRansformer (PTR), a unified Gaussian Mixture Transformer framework integrating goal-conditioned prediction, dynamic feasibility, interaction awareness, and lane-level topology reasoning. A teacher-student training strategy progressively masks surrounding agent commands during training to align with inference conditions where agent intentions are unavailable. PTR achieves 4.3%/3.5% improvement in marginal/joint mAP compared to the baseline Motion Transformer (MTR) and 15.5% planning error reduction at 5s horizon compared to GameFormer. The architecture-agnostic design enables application to diverse Transformer-based prediction models. Project Website: https://github.com/SelzerConst/PlanTRansformer

</details>


### [28] [Enhancing Navigation Efficiency of Quadruped Robots via Leveraging Personal Transportation Platforms](https://arxiv.org/abs/2602.03397)
*Minsung Yoon,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: 提出RL-ATR方法让四足机器人骑乘个人交通工具（如Segway）以提高长距离导航效率


<details>
  <summary>Details</summary>
Motivation: 四足机器人依赖腿部运动，长距离导航效率有限，需要扩展其运动模式以提高操作范围和效率

Method: 基于强化学习的主动交通工具骑乘方法，包含骑乘策略和两个状态估计器，策略根据交通工具特定控制动力学设计机动策略，估计器通过推断不可观测状态解决非惯性坐标系中的传感器模糊问题

Result: 仿真验证显示该方法在不同交通工具-机器人模型上具有熟练的命令跟踪能力，相比腿部运动减少了能量消耗，消融研究量化了各组件贡献

Conclusion: 骑乘能力可以扩展四足机器人的运动模式，潜在地扩大其操作范围和效率

Abstract: Quadruped robots face limitations in long-range navigation efficiency due to their reliance on legs. To ameliorate the limitations, we introduce a Reinforcement Learning-based Active Transporter Riding method (\textit{RL-ATR}), inspired by humans' utilization of personal transporters, including Segways. The \textit{RL-ATR} features a transporter riding policy and two state estimators. The policy devises adequate maneuvering strategies according to transporter-specific control dynamics, while the estimators resolve sensor ambiguities in non-inertial frames by inferring unobservable robot and transporter states. Comprehensive evaluations in simulation validate proficient command tracking abilities across various transporter-robot models and reduced energy consumption compared to legged locomotion. Moreover, we conduct ablation studies to quantify individual component contributions within the \textit{RL-ATR}. This riding ability could broaden the locomotion modalities of quadruped robots, potentially expanding the operational range and efficiency.

</details>


### [29] [Deep-Learning-Based Control of a Decoupled Two-Segment Continuum Robot for Endoscopic Submucosal Dissection](https://arxiv.org/abs/2602.03406)
*Yuancheng Shao,Yao Zhang,Jia Gu,Zixi Chen,Di Wu,Yuqiao Chen,Bo Lu,Wenjie Liu,Cesare Stefanini,Peng Qi*

Main category: cs.RO

TL;DR: DESectBot是一种新型双段连续体机器人，具有解耦结构和集成手术钳，用于内镜黏膜下剥离术（ESD）。采用基于门控循环单元（GRU）的深度学习控制器，在轨迹跟踪和方向控制方面表现最佳，并在离体ESD演示中验证了其临床适用性。


<details>
  <summary>Details</summary>
Motivation: 传统手动ESD技术难度大，现有单段机器人工具灵活性有限，需要开发更先进的解决方案来提高ESD手术的精准度和可操作性。

Method: 开发了DESectBot双段连续体机器人，具有解耦结构和集成手术钳，提供6自由度尖端灵活性。提出了基于GRU的深度学习控制器，用于同时控制尖端位置和方向，有效处理连续体段之间的非线性耦合。

Result: GRU控制器在嵌套矩形和利萨如轨迹跟踪任务中取得最低的位置/方向RMSE：1.11 mm/4.62°和0.81 mm/2.59°。在固定位置方向控制中，平均RMSE为0.14 mm和0.72°。在peg转移任务中，成功率达100%，平均转移时间11.8秒。离体ESD演示证实了机器人能够有效处理厚胃黏膜。

Conclusion: 基于GRU的控制显著提高了ESD手术训练场景中的精度、可靠性和可用性，DESectBot为ESD手术提供了足够的刚度和操作空间，适合处理大面积病变。

Abstract: Manual endoscopic submucosal dissection (ESD) is technically demanding, and existing single-segment robotic tools offer limited dexterity. These limitations motivate the development of more advanced solutions. To address this, DESectBot, a novel dual segment continuum robot with a decoupled structure and integrated surgical forceps, enabling 6 degrees of freedom (DoFs) tip dexterity for improved lesion targeting in ESD, was developed in this work. Deep learning controllers based on gated recurrent units (GRUs) for simultaneous tip position and orientation control, effectively handling the nonlinear coupling between continuum segments, were proposed. The GRU controller was benchmarked against Jacobian based inverse kinematics, model predictive control (MPC), a feedforward neural network (FNN), and a long short-term memory (LSTM) network. In nested-rectangle and Lissajous trajectory tracking tasks, the GRU achieved the lowest position/orientation RMSEs: 1.11 mm/ 4.62° and 0.81 mm/ 2.59°, respectively. For orientation control at a fixed position (four target poses), the GRU attained a mean RMSE of 0.14 mm and 0.72°, outperforming all alternatives. In a peg transfer task, the GRU achieved a 100% success rate (120 success/120 attempts) with an average transfer time of 11.8s, the STD significantly outperforms novice-controlled systems. Additionally, an ex vivo ESD demonstration grasping, elevating, and resecting tissue as the scalpel completed the cut confirmed that DESectBot provides sufficient stiffness to divide thick gastric mucosa and an operative workspace adequate for large lesions.These results confirm that GRU-based control significantly enhances precision, reliability, and usability in ESD surgical training scenarios.

</details>


### [30] [Learning-based Initialization of Trajectory Optimization for Path-following Problems of Redundant Manipulators](https://arxiv.org/abs/2602.03418)
*Minsung Yoon,Mincheul Kang,Daehyung Park,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: 提出基于学习的初始轨迹生成方法，通过示例引导强化学习快速生成高质量初始轨迹，提升轨迹优化的性能和效率


<details>
  <summary>Details</summary>
Motivation: 轨迹优化的性能很大程度上取决于初始轨迹的质量，但高质量初始轨迹的选择非常困难，因为解空间极大且缺乏任务约束的先验知识，需要大量时间预算

Method: 采用示例引导强化学习，提出零空间投影模仿奖励机制，有效学习专家演示中的运动学可行运动，考虑零空间约束

Result: 仿真统计评估显示，与三个基线方法相比，使用该方法输出的轨迹优化在最优性、效率和适用性方面都有显著提升；七自由度机械臂真实实验验证了性能改进和可行性

Conclusion: 提出的学习型初始轨迹生成方法能够在短时间内生成高质量初始轨迹，有效提升轨迹优化的性能，并通过真实实验验证了其可行性和实用性

Abstract: Trajectory optimization (TO) is an efficient tool to generate a redundant manipulator's joint trajectory following a 6-dimensional Cartesian path. The optimization performance largely depends on the quality of initial trajectories. However, the selection of a high-quality initial trajectory is non-trivial and requires a considerable time budget due to the extremely large space of the solution trajectories and the lack of prior knowledge about task constraints in configuration space. To alleviate the issue, we present a learning-based initial trajectory generation method that generates high-quality initial trajectories in a short time budget by adopting example-guided reinforcement learning. In addition, we suggest a null-space projected imitation reward to consider null-space constraints by efficiently learning kinematically feasible motion captured in expert demonstrations. Our statistical evaluation in simulation shows the improved optimality, efficiency, and applicability of TO when we plug in our method's output, compared with three other baselines. We also show the performance improvement and feasibility via real-world experiments with a seven-degree-of-freedom manipulator.

</details>


### [31] [ProAct: A Benchmark and Multimodal Framework for Structure-Aware Proactive Response](https://arxiv.org/abs/2602.03430)
*Xiaomeng Zhu,Fengming Zhu,Weijie Zhou,Ye Tian,Zhenlin Hu,Yufei Huang,Yuchun Guo,Xinyu Wu,Zhengyou Zhang,Fangzhen Lin,Xuantang Xiong*

Main category: cs.RO

TL;DR: ProAct-75是一个用于训练和评估主动智能体的基准数据集，包含75个任务和91,581个步骤级标注，配有显式任务图。基于此提出的ProAct-Helper基线模型通过状态检测和多模态大语言模型，结合熵驱动启发式搜索，在触发检测、步骤节省和并行动作方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 主动智能体能够根据高层目标（如协助和安全）持续监控环境并决定何时行动，但缺乏专门的训练和评估资源阻碍了其发展。需要创建专门的基准来促进主动智能体的研发。

Method: 1. 提出ProAct-75基准：包含75个任务，91,581个步骤级标注，配有显式任务图编码步骤依赖和并行执行可能性；2. 提出ProAct-Helper基线模型：基于多模态大语言模型，通过状态检测进行决策，利用任务图实现熵驱动启发式搜索进行动作选择，支持并行线程独立执行。

Result: ProAct-Helper在实验中表现优异：触发检测mF1提升6.21%，在线单步决策中节省0.25个步骤，并行动作率提高15.58%，优于强闭源模型。

Conclusion: ProAct-75基准为主动智能体的训练和评估提供了重要资源，ProAct-Helper模型展示了基于任务图和熵驱动搜索的有效性，为主动智能体的发展提供了有力工具。

Abstract: While passive agents merely follow instructions, proactive agents align with higher-level objectives, such as assistance and safety by continuously monitoring the environment to determine when and how to act. However, developing proactive agents is hindered by the lack of specialized resources. To address this, we introduce ProAct-75, a benchmark designed to train and evaluate proactive agents across diverse domains, including assistance, maintenance, and safety monitoring. Spanning 75 tasks, our dataset features 91,581 step-level annotations enriched with explicit task graphs. These graphs encode step dependencies and parallel execution possibilities, providing the structural grounding necessary for complex decision-making. Building on this benchmark, we propose ProAct-Helper, a reference baseline powered by a Multimodal Large Language Model (MLLM) that grounds decision-making in state detection, and leveraging task graphs to enable entropy-driven heuristic search for action selection, allowing agents to execute parallel threads independently rather than mirroring the human's next step. Extensive experiments demonstrate that ProAct-Helper outperforms strong closed-source models, improving trigger detection mF1 by 6.21%, saving 0.25 more steps in online one-step decision, and increasing the rate of parallel actions by 15.58%.

</details>


### [32] [Model-based Optimal Control for Rigid-Soft Underactuated Systems](https://arxiv.org/abs/2602.03435)
*Daniele Caradonna,Nikhil Nair,Anup Teejo Mathew,Daniel Feliu Talegón,Imran Afgan,Egidio Falotico,Cosimo Della Santina,Federico Renda*

Main category: cs.RO

TL;DR: 该研究针对连续体软机器人动态控制挑战，基于几何变应变模型，比较了三种最优控制策略在刚性-软体机器人动态摆起任务中的性能


<details>
  <summary>Details</summary>
Motivation: 连续体软机器人本质上是欠驱动的，且受内在输入约束，使得动态控制特别具有挑战性。现有方法多关注准静态行为，而动态任务需要准确利用连续体动力学。基于模型的优化控制提供了系统解决方案，但应用于刚性-软体机器人时受到计算成本和数值微分不准确性的限制。

Method: 基于几何变应变模型实现解析导数，研究三种最优控制策略：直接配点法、微分动态规划和非线性模型预测控制。采用隐式积分方案和热启动策略处理刚性的连续体动力学和约束驱动，提高数值鲁棒性和计算效率。

Result: 在三个刚性-软体和高阶软体基准系统（软体小车摆、软体双摆和软体Furuta摆）上进行仿真评估，突出了各种方法的性能和计算权衡。

Conclusion: 该研究为欠驱动软体系统的动态控制提供了系统的最优控制框架，通过几何变应变模型和数值优化技术，成功解决了连续体软机器人动态任务中的计算挑战。

Abstract: Continuum soft robots are inherently underactuated and subject to intrinsic input constraints, making dynamic control particularly challenging, especially in hybrid rigid-soft robots. While most existing methods focus on quasi-static behaviors, dynamic tasks such as swing-up require accurate exploitation of continuum dynamics. This has led to studies on simple low-order template systems that often fail to capture the complexity of real continuum deformations. Model-based optimal control offers a systematic solution; however, its application to rigid-soft robots is often limited by the computational cost and inaccuracy of numerical differentiation for high-dimensional models. Building on recent advances in the Geometric Variable Strain model that enable analytical derivatives, this work investigates three optimal control strategies for underactuated soft systems-Direct Collocation, Differential Dynamic Programming, and Nonlinear Model Predictive Control-to perform dynamic swing-up tasks. To address stiff continuum dynamics and constrained actuation, implicit integration schemes and warm-start strategies are employed to improve numerical robustness and computational efficiency. The methods are evaluated in simulation on three Rigid-Soft and high-order soft benchmark systems-the Soft Cart-Pole, the Soft Pendubot, and the Soft Furuta Pendulum- highlighting their performance and computational trade-offs.

</details>


### [33] [HetroD: A High-Fidelity Drone Dataset and Benchmark for Autonomous Driving in Heterogeneous Traffic](https://arxiv.org/abs/2602.03447)
*Yu-Hsiang Chen,Wei-Jer Chang,Christian Kotulla,Thomas Keutgens,Steffen Runde,Tobias Moers,Christoph Klas,Wei Zhan,Masayoshi Tomizuka,Yi-Ting Chen*

Main category: cs.RO

TL;DR: HetroD是一个用于异构交通环境下自动驾驶系统开发的无人机数据集和基准测试，重点关注弱势道路使用者（行人、自行车、摩托车）的复杂行为，包含6.54万条高精度轨迹，其中70%来自弱势道路使用者。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶数据集主要关注结构化、有车道纪律的交通场景，而现实世界中存在大量弱势道路使用者主导的异构交通环境，这些场景中复杂的交互行为（如钩形转弯、车道分割、非正式路权协商）对自动驾驶系统构成重大挑战，但现有数据集对此代表性不足。

Method: 通过无人机采集大规模交通场景数据，提供厘米级精度标注、高清地图和交通信号状态。开发模块化工具包提取每个智能体的场景，支持下游任务开发。数据集包含超过6.54万条高保真智能体轨迹。

Result: 评估结果显示，当前最先进的预测和规划模型在HetroD数据集上表现不佳：无法预测弱势道路使用者的横向移动，不能处理非结构化机动，在密集和多智能体场景中性能有限，凸显了异构交通场景需要更鲁棒的方法。

Conclusion: HetroD填补了现有自动驾驶数据集在异构交通环境中的空白，为弱势道路使用者行为建模提供了标准化基准，揭示了当前自动驾驶技术在处理复杂异构交通场景时的局限性，推动了更鲁棒的自动驾驶系统发展。

Abstract: We present HetroD, a dataset and benchmark for developing autonomous driving systems in heterogeneous environments. HetroD targets the critical challenge of navi- gating real-world heterogeneous traffic dominated by vulner- able road users (VRUs), including pedestrians, cyclists, and motorcyclists that interact with vehicles. These mixed agent types exhibit complex behaviors such as hook turns, lane splitting, and informal right-of-way negotiation. Such behaviors pose significant challenges for autonomous vehicles but remain underrepresented in existing datasets focused on structured, lane-disciplined traffic. To bridge the gap, we collect a large- scale drone-based dataset to provide a holistic observation of traffic scenes with centimeter-accurate annotations, HD maps, and traffic signal states. We further develop a modular toolkit for extracting per-agent scenarios to support downstream task development. In total, the dataset comprises over 65.4k high- fidelity agent trajectories, 70% of which are from VRUs. HetroD supports modeling of VRU behaviors in dense, het- erogeneous traffic and provides standardized benchmarks for forecasting, planning, and simulation tasks. Evaluation results reveal that state-of-the-art prediction and planning models struggle with the challenges presented by our dataset: they fail to predict lateral VRU movements, cannot handle unstructured maneuvers, and exhibit limited performance in dense and multi-agent scenarios, highlighting the need for more robust approaches to heterogeneous traffic. See our project page for more examples: https://hetroddata.github.io/HetroD/

</details>


### [34] [CMR: Contractive Mapping Embeddings for Robust Humanoid Locomotion on Unstructured Terrains](https://arxiv.org/abs/2602.03511)
*Qixin Zeng,Hongyin Zhang,Shangke Lyu,Junxi Jin,Donglin Wang,Chao Huang*

Main category: cs.RO

TL;DR: 提出CMR框架，通过收缩映射将高维噪声观测映射到潜在空间，增强人形机器人在非结构化地形上的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在非结构化地形上的鲁棒抗干扰是一个长期挑战，感知信息（如高度图）虽然能增强地形感知，但传感器噪声和仿真到现实的差距会导致策略在实际中不稳定。

Method: 提出收缩映射鲁棒性（CMR）框架，将高维、易受干扰的观测映射到潜在空间，通过对比表示学习和Lipschitz正则化来保持任务相关几何特性并显式控制敏感性。

Result: CMR框架可以作为辅助损失项轻松集成到现代深度强化学习流程中，在人形机器人实验中，CMR在噪声增加的情况下显著优于其他运动算法。

Conclusion: 通过理论分析证明在观测噪声下，当诱导的潜在动态具有收缩性时，可以限制回报差距，CMR框架有效提升了人形机器人在噪声环境下的鲁棒性。

Abstract: Robust disturbance rejection remains a longstanding challenge in humanoid locomotion, particularly on unstructured terrains where sensing is unreliable and model mismatch is pronounced. While perception information, such as height map, enhances terrain awareness, sensor noise and sim-to-real gaps can destabilize policies in practice. In this work, we provide theoretical analysis that bounds the return gap under observation noise, when the induced latent dynamics are contractive. Furthermore, we present Contractive Mapping for Robustness (CMR) framework that maps high-dimensional, disturbance-prone observations into a latent space, where local perturbations are attenuated over time. Specifically, this approach couples contrastive representation learning with Lipschitz regularization to preserve task-relevant geometry while explicitly controlling sensitivity. Notably, the formulation can be incorporated into modern deep reinforcement learning pipelines as an auxiliary loss term with minimal additional technical effort required. Further, our extensive humanoid experiments show that CMR potently outperforms other locomotion algorithms under increased noise.

</details>


### [35] [Investigating the Influence of Spatial Ability in Augmented Reality-assisted Robot Programming](https://arxiv.org/abs/2602.03544)
*Nicolas Leins,Jana Gonnermann-Müller,Malte Teichmann,Sebastian Pokutta*

Main category: cs.RO

TL;DR: AR辅助机器人编程对学习体验的影响研究：空间能力起调节作用，AR对低空间能力学习者有补偿效应


<details>
  <summary>Details</summary>
Motivation: 增强现实(AR)为学习提供了新机会，但其机制和效果尚未完全理解。随着学习日益个性化，考虑学习者个体特征变得更重要。本研究探讨空间能力在AR学习体验中的调节作用。

Method: 采用组间实验设计(N=71)，比较传统机器人编程与头戴式AR辅助编程。使用心理旋转测试评估空间能力，通过系统可用性量表(SUS)和认知负荷测量学习体验。

Result: AR支持相比传统方法并未显著改善学习体验。但在控制组中，空间能力与SUS分数显著正相关，与外在认知负荷负相关；而在AR条件下这些关系消失，表明AR缓解了低空间能力学习者的劣势。

Conclusion: AR具有补偿功能，能减少学习者特征的影响。未来研究应进一步探索AR的补偿作用，以设计满足不同学习者需求、降低认知差异障碍的个性化学习环境。

Abstract: Augmented Reality (AR) offers promising opportunities to enhance learning, but its mechanisms and effects are not yet fully understood. As learning becomes increasingly personalized, considering individual learner characteristics becomes more important. This study investigates the moderating effect of spatial ability on learning experience with AR in the context of robot programming. A between-subjects experiment ($N=71$) compared conventional robot programming to an AR-assisted approach using a head-mounted display. Participants' spatial ability was assessed using the Mental Rotation Test. The learning experience was measured through the System Usability Scale (SUS) and cognitive load. The results indicate that AR support does not significantly improve the learning experience compared to the conventional approach. However, AR appears to have a compensatory effect on the influence of spatial ability. In the control group, spatial ability was significantly positively associated with SUS scores and negatively associated with extraneous cognitive load, indicating that higher spatial ability predicts a better learning experience. In the AR condition, these relationships were not observable, suggesting that AR mitigated the disadvantage typically experienced by learners with lower spatial abilities. These findings suggest that AR can serve a compensatory function by reducing the influence of learner characteristics. Future research should further explore this compensatory role of AR to guide the design of personalized learning environments that address diverse learner needs and reduce barriers for learners with varying cognitive profiles.

</details>


### [36] [AffordanceGrasp-R1:Leveraging Reasoning-Based Affordance Segmentation with Reinforcement Learning for Robotic Grasping](https://arxiv.org/abs/2602.03547)
*Dingyi Zhou,Mu He,Zhuowei Fang,Xiangtong Yao,Yinlong Liu,Alois Knoll,Hu Cao*

Main category: cs.RO

TL;DR: AffordanceGrasp-R1是一个结合思维链冷启动策略和强化学习的推理驱动抓取框架，通过全局场景点云生成抓取候选并基于指令条件进行过滤，在基准数据集和真实机器人实验中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法在处理复杂语言条件操作场景时，缺乏有效的推理能力和上下文感知能力，需要开发能够结合高级推理和空间定位的抓取框架。

Method: 1. 采用思维链（CoT）冷启动策略增强推理和空间定位能力；2. 重新设计抓取流程：从全局场景点云生成抓取候选，然后使用指令条件affordance掩码进行过滤；3. 结合强化学习优化性能。

Result: 在基准数据集上持续优于现有最先进方法，真实世界机器人抓取评估进一步验证了其在复杂语言条件操作场景下的鲁棒性和泛化能力。

Conclusion: AffordanceGrasp-R1通过推理驱动的affordance分割框架，成功提升了机器人抓取在复杂语言指令下的性能，为上下文感知的机器人操作提供了有效解决方案。

Abstract: We introduce AffordanceGrasp-R1, a reasoning-driven affordance segmentation framework for robotic grasping that combines a chain-of-thought (CoT) cold-start strategy with reinforcement learning to enhance deduction and spatial grounding. In addition, we redesign the grasping pipeline to be more context-aware by generating grasp candidates from the global scene point cloud and subsequently filtering them using instruction-conditioned affordance masks. Extensive experiments demonstrate that AffordanceGrasp-R1 consistently outperforms state-of-the-art (SOTA) methods on benchmark datasets, and real-world robotic grasping evaluations further validate its robustness and generalization under complex language-conditioned manipulation scenarios.

</details>


### [37] [Multi-Player, Multi-Strategy Quantum Game Model for Interaction-Aware Decision-Making in Autonomous Driving](https://arxiv.org/abs/2602.03571)
*Karim Essalmi,Fernando Garrido,Fawzi Nashashibi*

Main category: cs.RO

TL;DR: 提出量子博弈决策模型（QGDM），将经典博弈论与量子力学原理结合，用于自动驾驶决策，在复杂交互场景中显著提升成功率并降低碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶决策方法在交互感知方面存在不足，通常过度简化车辆间交互，且忽略周围智能体之间的相互影响。经典博弈论假设理性玩家，而人类行为常表现出不确定性和非理性特征。

Method: 提出量子博弈决策模型（QGDM），融合经典博弈论与量子力学原理（如叠加态、纠缠和干涉），处理多玩家、多策略的决策问题。该模型可在标准计算机上实时运行，无需量子硬件。

Result: 在环岛、并道、高速公路等多种场景的仿真测试中，QGDM相比多种基线方法显著提高了成功率并降低了碰撞率，特别是在高交互场景中表现尤为突出。

Conclusion: 量子博弈决策模型为自动驾驶决策提供了新思路，能够更好地处理复杂交互场景中的不确定性和非理性行为，是量子博弈论在自动驾驶领域的创新应用。

Abstract: Although significant progress has been made in decision-making for automated driving, challenges remain for deployment in the real world. One challenge lies in addressing interaction-awareness. Most existing approaches oversimplify interactions between the ego vehicle and surrounding agents, and often neglect interactions among the agents themselves. A common solution is to model these interactions using classical game theory. However, its formulation assumes rational players, whereas human behavior is frequently uncertain or irrational. To address these challenges, we propose the Quantum Game Decision-Making (QGDM) model, a novel framework that combines classical game theory with quantum mechanics principles (such as superposition, entanglement, and interference) to tackle multi-player, multi-strategy decision-making problems. To the best of our knowledge, this is one of the first studies to apply quantum game theory to decision-making for automated driving. QGDM runs in real time on a standard computer, without requiring quantum hardware. We evaluate QGDM in simulation across various scenarios, including roundabouts, merging, and highways, and compare its performance with multiple baseline methods. Results show that QGDM significantly improves success rates and reduces collision rates compared to classical approaches, particularly in scenarios with high interaction.

</details>


### [38] [Human-in-the-Loop Failure Recovery with Adaptive Task Allocation](https://arxiv.org/abs/2602.03603)
*Lorena Maria Genua,Nikita Boguslavskii,Zhi Li*

Main category: cs.RO

TL;DR: 提出ARFA方法，自适应地将机器人故障分配给最适合的人类操作员，以减少机器人闲置时间并提高系统性能


<details>
  <summary>Details</summary>
Motivation: 尽管移动机械臂和人形辅助机器人在护理领域的自主性有所提高，但在动态非结构化环境中仍经常出现故障需要人工干预。需要有效的协作机制，让机器人能从最合适的操作员那里获得帮助，减少工作负担并最小化任务执行中断。

Method: 提出ARFA（自适应机器人故障分配）方法：1）建模人类操作员能力，并根据实际故障恢复表现持续更新这些信念；2）对每个待解决的故障，通过奖励函数计算预期结果，考虑操作员能力、历史数据、任务紧急性和当前工作负载分布；3）将故障分配给预期奖励最高的操作员。

Result: 模拟和用户研究表明，ARFA优于随机分配方法，显著减少了机器人闲置时间，提高了整体系统性能，并使操作员之间的工作负载分布更加均衡。

Conclusion: ARFA方法通过自适应地将机器人故障分配给最合适的操作员，有效改善了人机协作系统在动态环境中的性能，减少了机器人停机时间并优化了工作负载分配。

Abstract: Since the recent Covid-19 pandemic, mobile manipulators and humanoid assistive robots with higher levels of autonomy have increasingly been adopted for patient care and living assistance. Despite advancements in autonomy, these robots often struggle to perform reliably in dynamic and unstructured environments and require human intervention to recover from failures. Effective human-robot collaboration is essential to enable robots to receive assistance from the most competent operator, in order to reduce their workload and minimize disruptions in task execution. In this paper, we propose an adaptive method for allocating robotic failures to human operators (ARFA). Our proposed approach models the capabilities of human operators, and continuously updates these beliefs based on their actual performance for failure recovery. For every failure to be resolved, a reward function calculates expected outcomes based on operator capabilities and historical data, task urgency, and current workload distribution. The failure is then assigned to the operator with the highest expected reward. Our simulations and user studies show that ARFA outperforms random allocation, significantly reducing robot idle time, improving overall system performance, and leading to a more distributed workload among operators.

</details>


### [39] [Self-supervised Physics-Informed Manipulation of Deformable Linear Objects with Non-negligible Dynamics](https://arxiv.org/abs/2602.03623)
*Youyuan Long,Gokhan Solak,Sara Zeynalpour,Heng Zhang,Arash Ajoudani*

Main category: cs.RO

TL;DR: SPiD是一个物理信息自监督学习框架，用于可变形线性物体的动态操控，通过耦合精确的物体模型与增强的自监督训练策略，在绳稳定任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决可变形线性物体（如绳索）的动态操控问题，传统方法难以准确建模物体动力学，需要数据高效且具有强泛化能力的框架。

Method: 1. 扩展质量-弹簧模型以更准确捕捉物体动力学；2. 使用任务导向成本训练神经控制器，通过可微分物体模型进行端到端优化；3. 提出自监督DAgger变体，检测部署中的分布偏移并进行离线自校正。

Result: 在绳稳定任务中，控制器实现了快速平滑的稳定效果，能够泛化到未见过的初始状态、绳长、质量、非均匀质量分布和外部扰动。在仿真和真实实验中均表现良好，且对噪声和低频状态更新具有鲁棒性。

Conclusion: SPiD提供了一个数据高效、鲁棒且物理基础扎实的框架，用于可变形线性物体的动态操控，具有强大的仿真到现实泛化能力，并可扩展到其他任务如轨迹跟踪。

Abstract: We address dynamic manipulation of deformable linear objects by presenting SPiD, a physics-informed self-supervised learning framework that couples an accurate deformable object model with an augmented self-supervised training strategy. On the modeling side, we extend a mass-spring model to more accurately capture object dynamics while remaining lightweight enough for high-throughput rollouts during self-supervised learning. On the learning side, we train a neural controller using a task-oriented cost, enabling end-to-end optimization through interaction with the differentiable object model. In addition, we propose a self-supervised DAgger variant that detects distribution shift during deployment and performs offline self-correction to further enhance robustness without expert supervision. We evaluate our method primarily on the rope stabilization task, where a robot must bring a swinging rope to rest as quickly and smoothly as possible. Extensive experiments in both simulation and the real world demonstrate that the proposed controller achieves fast and smooth rope stabilization, generalizing across unseen initial states, rope lengths, masses, non-uniform mass distributions, and external disturbances. Additionally, we develop an affordable markerless rope perception method and demonstrate that our controller maintains performance with noisy and low-frequency state updates. Furthermore, we demonstrate the generality of the framework by extending it to the rope trajectory tracking task. Overall, SPiD offers a data-efficient, robust, and physically grounded framework for dynamic manipulation of deformable linear objects, featuring strong sim-to-real generalization.

</details>


### [40] [Variance-Reduced Model Predictive Path Integral via Quadratic Model Approximation](https://arxiv.org/abs/2602.03639)
*Fabian Schramm,Franki Nguimatsia Tiofack,Nicolas Perrin-Gilbert,Marc Toussaint,Justin Carpentier*

Main category: cs.RO

TL;DR: 提出一种混合方差缩减MPPI框架，通过将目标函数分解为已知近似模型和残差项，降低采样方差，提高样本效率


<details>
  <summary>Details</summary>
Motivation: 基于采样的控制器（如MPPI）虽然灵活，但存在高方差和低样本效率的问题，限制了其在采样成本高昂或受限场景中的实用性

Method: 将目标函数分解为已知近似模型和残差项，采用二次近似推导出闭式模型引导先验，有效将样本集中在信息丰富区域，框架对几何信息来源保持不可知性

Result: 在标准优化基准、非线性欠驱动倒立摆控制任务和接触丰富的非光滑动力学操作问题上验证，相比标准MPPI在低样本区域实现了更快的收敛和更优的性能

Conclusion: 该方法使基于采样的控制策略在采样成本高昂或受限的场景中更加实用，通过模型引导先验有效提高了样本效率和收敛速度

Abstract: Sampling-based controllers, such as Model Predictive Path Integral (MPPI) methods, offer substantial flexibility but often suffer from high variance and low sample efficiency. To address these challenges, we introduce a hybrid variance-reduced MPPI framework that integrates a prior model into the sampling process. Our key insight is to decompose the objective function into a known approximate model and a residual term. Since the residual captures only the discrepancy between the model and the objective, it typically exhibits a smaller magnitude and lower variance than the original objective. Although this principle applies to general modeling choices, we demonstrate that adopting a quadratic approximation enables the derivation of a closed-form, model-guided prior that effectively concentrates samples in informative regions. Crucially, the framework is agnostic to the source of geometric information, allowing the quadratic model to be constructed from exact derivatives, structural approximations (e.g., Gauss- or Quasi-Newton), or gradient-free randomized smoothing. We validate the approach on standard optimization benchmarks, a nonlinear, underactuated cart-pole control task, and a contact-rich manipulation problem with non-smooth dynamics. Across these domains, we achieve faster convergence and superior performance in low-sample regimes compared to standard MPPI. These results suggest that the method can make sample-based control strategies more practical in scenarios where obtaining samples is expensive or limited.

</details>


### [41] [MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction](https://arxiv.org/abs/2602.03668)
*Jung Min Lee,Dohyeok Lee,Seokhun Ju,Taehyun Cho,Jin Woo Koo,Li Zhao,Sangwoo Hong,Jungwoo Lee*

Main category: cs.RO

TL;DR: MVP-LAM通过多视角视频学习离散潜在动作，利用跨视角重建目标使潜在动作更关注真实动作信息，提升VLA预训练效果


<details>
  <summary>Details</summary>
Motivation: 从多样化人类视频中学习潜在动作可以扩展机器人学习范围，但现有方法缺乏真实动作标签，需要确保潜在动作包含底层智能体的动作信息

Method: 提出MVP-LAM模型，从时间同步的多视角视频中学习离散潜在动作，采用跨视角重建目标训练，使从一个视角推断的潜在动作必须能解释另一个视角的未来状态

Result: 在Bridge V2数据集上，MVP-LAM产生更动作中心的潜在动作，与真实动作的互信息更高，动作预测性能更好，包括在分布外评估中；使用MVP-LAM潜在动作预训练的VLA在SIMPLER和LIBERO-Long基准测试中提升了下游操作性能

Conclusion: MVP-LAM通过多视角学习机制有效提取动作信息丰富的潜在动作，显著改善了VLA预训练效果和下游机器人操作任务性能

Abstract: Learning \emph{latent actions} from diverse human videos enables scaling robot learning beyond embodiment-specific robot datasets, and these latent actions have recently been used as pseudo-action labels for vision-language-action (VLA) model pretraining. To make VLA pretraining effective, latent actions should contain information about the underlying agent's actions despite the absence of ground-truth labels. We propose \textbf{M}ulti-\textbf{V}iew\textbf{P}oint \textbf{L}atent \textbf{A}ction \textbf{M}odel (\textbf{MVP-LAM}), which learns discrete latent actions that are highly informative about ground-truth actions from time-synchronized multi-view videos. MVP-LAM trains latent actions with a \emph{cross-viewpoint reconstruction} objective, so that a latent action inferred from one view must explain the future in another view, reducing reliance on viewpoint-specific cues. On Bridge V2, MVP-LAM produces more action-centric latent actions, achieving higher mutual information with ground-truth actions and improved action prediction, including under out-of-distribution evaluation. Finally, pretraining VLAs with MVP-LAM latent actions improves downstream manipulation performance on the SIMPLER and LIBERO-Long benchmarks.

</details>


### [42] [A Scene Graph Backed Approach to Open Set Semantic Mapping](https://arxiv.org/abs/2602.03781)
*Martin Günther,Felix Igelbrink,Oscar Lima,Lennart Niecksch,Marian Renz,Martin Atzmueller*

Main category: cs.RO

TL;DR: 提出了一种以3D语义场景图（3DSSG）为后端基础架构的映射方法，将场景图作为整个映射过程的主要知识表示，实现实时增量更新，连接原始传感器数据与高层符号推理。


<details>
  <summary>Details</summary>
Motivation: 现有开放集语义映射和3D语义场景图方法通常将感知与表示解耦，将场景图作为后处理生成的衍生层，这限制了系统的一致性和可扩展性。需要一种更有效的架构来支持大规模真实环境中的高层推理。

Method: 采用以3D语义场景图作为基础后端的映射架构，利用增量场景图预测技术实时推断和更新图结构。维护显式的空间基础表示，支持平面和分层拓扑结构，连接亚符号原始传感器数据与高层符号推理。

Result: 该方法确保地图在拓扑上保持一致且计算高效，即使在大规模环境中的长时间操作也能保持稳定。提供可验证的结构，使知识驱动框架（从知识图谱、本体到大型语言模型）能够直接利用。

Conclusion: 提出的架构弥合了感知与表示之间的差距，为智能体提供了增强的可解释性、可信度和与人类概念对齐的能力，支持大规模真实环境中的高层推理任务。

Abstract: While Open Set Semantic Mapping and 3D Semantic Scene Graphs (3DSSGs) are established paradigms in robotic perception, deploying them effectively to support high-level reasoning in large-scale, real-world environments remains a significant challenge. Most existing approaches decouple perception from representation, treating the scene graph as a derivative layer generated post hoc. This limits both consistency and scalability. In contrast, we propose a mapping architecture where the 3DSSG serves as the foundational backend, acting as the primary knowledge representation for the entire mapping process.
  Our approach leverages prior work on incremental scene graph prediction to infer and update the graph structure in real-time as the environment is explored. This ensures that the map remains topologically consistent and computationally efficient, even during extended operations in large-scale settings. By maintaining an explicit, spatially grounded representation that supports both flat and hierarchical topologies, we bridge the gap between sub-symbolic raw sensor data and high-level symbolic reasoning. Consequently, this provides a stable, verifiable structure that knowledge-driven frameworks, ranging from knowledge graphs and ontologies to Large Language Models (LLMs), can directly exploit, enabling agents to operate with enhanced interpretability, trustworthiness, and alignment to human concepts.

</details>


### [43] [BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks](https://arxiv.org/abs/2602.03793)
*Yixiang Chen,Peiyan Li,Jiabing Yang,Keji He,Xiangnan Wu,Yuan Xu,Kai Wang,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.RO

TL;DR: BridgeV2W提出了一种新的具身世界模型，通过将坐标空间动作转换为像素对齐的实体掩码，并注入预训练视频生成模型，解决了动作与视频不对齐、相机视角敏感和架构不统一的问题。


<details>
  <summary>Details</summary>
Motivation: 现有具身世界模型面临三个关键挑战：1）坐标空间动作与像素空间视频之间的不对齐；2）对相机视角的敏感性；3）不同实体间架构不统一。这些问题限制了世界模型的泛化能力和实用性。

Method: BridgeV2W将坐标空间动作转换为从URDF和相机参数渲染的像素对齐实体掩码，通过ControlNet风格路径注入预训练视频生成模型。该方法还引入了基于光流的运动损失，专注于学习动态和任务相关区域，避免对静态背景的过拟合。

Result: 在单臂（DROID）和双臂（AgiBot-G1）数据集上的实验表明，BridgeV2W在多样且具有挑战性的条件下（包括未见过的视角和场景）相比先前最先进方法提高了视频生成质量。进一步展示了在下游实际任务中的潜力，包括策略评估和目标条件规划。

Conclusion: BridgeV2W通过将坐标空间动作与像素空间视频对齐、适应相机视角并提供统一的跨实体架构，有效解决了现有具身世界模型的关键挑战，为机器人学习和规划任务提供了更强大的世界模型基础。

Abstract: Embodied world models have emerged as a promising paradigm in robotics, most of which leverage large-scale Internet videos or pretrained video generation models to enrich visual and motion priors. However, they still face key challenges: a misalignment between coordinate-space actions and pixel-space videos, sensitivity to camera viewpoint, and non-unified architectures across embodiments. To this end, we present BridgeV2W, which converts coordinate-space actions into pixel-aligned embodiment masks rendered from the URDF and camera parameters. These masks are then injected into a pretrained video generation model via a ControlNet-style pathway, which aligns the action control signals with predicted videos, adds view-specific conditioning to accommodate camera viewpoints, and yields a unified world model architecture across embodiments. To mitigate overfitting to static backgrounds, BridgeV2W further introduces a flow-based motion loss that focuses on learning dynamic and task-relevant regions. Experiments on single-arm (DROID) and dual-arm (AgiBot-G1) datasets, covering diverse and challenging conditions with unseen viewpoints and scenes, show that BridgeV2W improves video generation quality compared to prior state-of-the-art methods. We further demonstrate the potential of BridgeV2W on downstream real-world tasks, including policy evaluation and goal-conditioned planning. More results can be found on our project website at https://BridgeV2W.github.io .

</details>


### [44] [Conformal Reachability for Safe Control in Unknown Environments](https://arxiv.org/abs/2602.03799)
*Xinhang Ma,Junlin Wu,Yiannis Kantaros,Yevgeniy Vorobeychik*

Main category: cs.RO

TL;DR: 提出结合共形预测与可达性分析的未知动态系统概率验证框架，用于设计具有可证明安全保证的控制策略


<details>
  <summary>Details</summary>
Motivation: 现有可证明安全控制方法大多假设系统动态已知、确定或状态/动作空间有限，限制了实际应用范围，需要开发适用于未知动态系统的安全验证框架

Method: 结合共形预测与可达性分析：使用共形预测获得未知动态在每个时间步的有效不确定性区间，然后通过可达性分析验证在共形不确定性边界内是否保持安全性；开发训练控制策略的算法方法，优化名义奖励同时最大化具有可靠概率安全保证的规划范围

Result: 在7个安全控制场景（涵盖4个领域：cartpole、车道跟随、无人机控制、安全导航）中评估，针对线性和非线性安全规范，所学习策略实现了最强的可证明安全保证，同时保持高平均奖励

Conclusion: 提出的概率验证框架成功解决了未知动态系统的可证明安全控制问题，在保持高性能的同时提供了可靠的安全保证，扩展了安全控制的应用范围

Abstract: Designing provably safe control is a core problem in trustworthy autonomy. However, most prior work in this regard assumes either that the system dynamics are known or deterministic, or that the state and action space are finite, significantly limiting application scope. We address this limitation by developing a probabilistic verification framework for unknown dynamical systems which combines conformal prediction with reachability analysis. In particular, we use conformal prediction to obtain valid uncertainty intervals for the unknown dynamics at each time step, with reachability then verifying whether safety is maintained within the conformal uncertainty bounds. Next, we develop an algorithmic approach for training control policies that optimize nominal reward while also maximizing the planning horizon with sound probabilistic safety guarantees. We evaluate the proposed approach in seven safe control settings spanning four domains -- cartpole, lane following, drone control, and safe navigation -- for both affine and nonlinear safety specifications. Our experiments show that the policies we learn achieve the strongest provable safety guarantees while still maintaining high average reward.

</details>
