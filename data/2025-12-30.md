<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 36]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs](https://arxiv.org/abs/2512.22342)
*Wensi Huang,Shaohao Zhu,Meng Wei,Jinming Xu,Xihui Liu,Hanqing Wang,Tai Wang,Feng Zhao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出了交互式实例对象导航任务IION和VL-LN基准，通过主动对话解决现实导航中的模糊指令问题


<details>
  <summary>Details</summary>
Motivation: 现有具身导航任务中的指令通常定义明确且无歧义，但现实世界的导航指令往往是模糊和含糊的，需要智能体通过主动对话来消除不确定性并推断用户意图

Method: 提出交互式实例对象导航任务IION，扩展了实例对象导航ION，允许智能体在导航过程中自由使用自然语言咨询oracle。基于此任务构建了VL-LN基准，包含大规模自动生成的数据集和全面的评估协议

Result: VL-LN包含超过41k个长时程对话增强轨迹用于训练，以及能够响应智能体查询的自动评估协议。训练出的具备对话能力的导航模型相比基线有显著改进

Conclusion: VL-LN基准对于推进具备对话能力的具身导航研究具有有效性和可靠性，更贴近实际应用场景

Abstract: In most existing embodied navigation tasks, instructions are well-defined and unambiguous, such as instruction following and object searching. Under this idealized setting, agents are required solely to produce effective navigation outputs conditioned on vision and language inputs. However, real-world navigation instructions are often vague and ambiguous, requiring the agent to resolve uncertainty and infer user intent through active dialog. To address this gap, we propose Interactive Instance Object Navigation (IION), a task that requires agents not only to generate navigation actions but also to produce language outputs via active dialog, thereby aligning more closely with practical settings. IION extends Instance Object Navigation (ION) by allowing agents to freely consult an oracle in natural language while navigating. Building on this task, we present the Vision Language-Language Navigation (VL-LN) benchmark, which provides a large-scale, automatically generated dataset and a comprehensive evaluation protocol for training and assessing dialog-enabled navigation models. VL-LN comprises over 41k long-horizon dialog-augmented trajectories for training and an automatic evaluation protocol with an oracle capable of responding to agent queries. Using this benchmark, we train a navigation model equipped with dialog capabilities and show that it achieves significant improvements over the baselines. Extensive experiments and analyses further demonstrate the effectiveness and reliability of VL-LN for advancing research on dialog-enabled embodied navigation. Code and dataset: https://0309hws.github.io/VL-LN.github.io/

</details>


### [2] [A Unified AI, Embedded, Simulation, and Mechanical Design Approach to an Autonomous Delivery Robot](https://arxiv.org/abs/2512.22408)
*Amro Gamar,Ahmed Abduljalil,Alargam Mohammed,Ali Elhenidy,Abeer Tawakol*

Main category: cs.RO

TL;DR: 开发了一个集机械工程、嵌入式系统和人工智能于一体的全自主送货机器人，采用异构计算架构，实现了AI感知、路径规划和实时电机控制，解决了资源受限平台上的计算优化和低延迟通信等关键技术挑战。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在现实世界中部署的、稳健的全自主送货机器人系统，整合机械工程、嵌入式系统和人工智能等多个学科领域，解决资源受限平台上的计算密集型AI算法优化和低延迟可靠通信等关键技术挑战。

Method: 采用异构计算架构：RPi 5和ROS 2处理基于AI的感知和路径规划，ESP32运行FreeRTOS确保实时电机控制。机械设计通过精确的电机选择和材料工程优化了有效载荷能力和移动性。实施了AWS IoT监控和固件级电机停机故障保护机制。

Result: 通过严格的内存和任务管理实现了确定性的PID电机控制，通过AWS IoT监控和固件级故障保护机制增强了系统可靠性。开发出了一个稳健且可操作的自主送货系统，具备现实世界部署能力。

Conclusion: 这项工作展示了一种统一的多学科方法论，成功开发出了一个能够在现实世界中部署的稳健自主送货机器人系统，解决了资源受限平台上的计算优化和低延迟通信等关键技术挑战。

Abstract: This paper presents the development of a fully autonomous delivery robot integrating mechanical engineering, embedded systems, and artificial intelligence. The platform employs a heterogeneous computing architecture, with RPi 5 and ROS 2 handling AI-based perception and path planning, while ESP32 running FreeRTOS ensures real-time motor control. The mechanical design was optimized for payload capacity and mobility through precise motor selection and material engineering. Key technical challenges addressed include optimizing computationally intensive AI algorithms on a resource-constrained platform and implementing a low-latency, reliable communication link between the ROS 2 host and embedded controller. Results demonstrate deterministic, PID-based motor control through rigorous memory and task management, and enhanced system reliability via AWS IoT monitoring and a firmware-level motor shutdown failsafe. This work highlights a unified, multi-disciplinary methodology, resulting in a robust and operational autonomous delivery system capable of real-world deployment.

</details>


### [3] [Emergence of Human to Robot Transfer in Vision-Language-Action Models](https://arxiv.org/abs/2512.22414)
*Simar Kareer,Karl Pertsch,James Darpinian,Judy Hoffman,Danfei Xu,Sergey Levine,Chelsea Finn,Suraj Nair*

Main category: cs.RO

TL;DR: 该研究探索了利用人类视频数据训练视觉-语言-动作模型的可能性，发现当模型在足够多样的场景、任务和具身形式上进行预训练后，能够实现从人类到机器人的技能迁移。


<details>
  <summary>Details</summary>
Motivation: 人类视频数据覆盖了丰富的真实世界场景且易于获取，但将其用于训练视觉-语言-动作模型面临挑战。研究旨在探索是否像大语言模型一样，视觉-语言-动作模型也能通过规模化学习从人类视频中获得泛化能力。

Method: 引入简单的协同训练方法，让视觉-语言-动作模型在大量不同的场景、任务和具身形式上进行预训练，研究人类到机器人技能迁移的涌现现象。

Result: 研究发现，当预训练数据足够多样化时，模型能够学习到人类和机器人数据的具身无关表示，从而实现从人类到机器人的技能迁移。在仅有人类数据的泛化场景中，该方法可将性能提升近一倍。

Conclusion: 视觉-语言-动作模型能够通过多样化的预训练学习具身无关的表示，从而实现从人类视频到机器人技能的迁移，这为利用丰富的人类视频数据提升机器人学习能力提供了新途径。

Abstract: Vision-language-action (VLA) models can enable broad open world generalization, but require large and diverse datasets. It is appealing to consider whether some of this data can come from human videos, which cover diverse real-world situations and are easy to obtain. However, it is difficult to train VLAs with human videos alone, and establishing a mapping between humans and robots requires manual engineering and presents a major research challenge. Drawing inspiration from advances in large language models, where the ability to learn from diverse supervision emerges with scale, we ask whether a similar phenomenon holds for VLAs that incorporate human video data. We introduce a simple co-training recipe, and find that human-to-robot transfer emerges once the VLA is pre-trained on sufficient scenes, tasks, and embodiments. Our analysis suggests that this emergent capability arises because diverse pretraining produces embodiment-agnostic representations for human and robot data. We validate these findings through a series of experiments probing human to robot skill transfer and find that with sufficiently diverse robot pre-training our method can nearly double the performance on generalization settings seen only in human data.

</details>


### [4] [Bugs with Features: Vision-Based Fault-Tolerant Collective Motion Inspired by Nature](https://arxiv.org/abs/2512.22448)
*Peleg Shefi,Amir Ayali,Gal A. Kaminka*

Main category: cs.RO

TL;DR: 该论文提出两种受蝗虫启发的机制来增强人工群体运动的鲁棒性：结合视觉感知水平与垂直尺寸的鲁棒距离估计方法，以及间歇性运动机制来检测并规避故障机器人。


<details>
  <summary>Details</summary>
Motivation: 自然群体运动具有鲁棒性，但大多数人工群体系统却很脆弱，特别是在使用视觉作为感知方式时，由于视觉感知固有的模糊性和信息丢失问题，导致系统容易失效。

Method: 1. 开发鲁棒距离估计方法：结合视觉感知邻居的水平与垂直尺寸来估计距离；2. 引入间歇性运动机制：允许机器人可靠检测未能跟上群体的故障同伴，并中断群体运动；3. 提出故障机器人规避策略：对故障分类错误具有鲁棒性。

Result: 通过大量基于物理的仿真实验，显示使用这些技术后群体韧性得到显著改善。这些方法既适用于基于距离的避让-吸引模型，也适用于依赖对齐的模型，在广泛的实验设置中均有效。

Conclusion: 受蝗虫启发的鲁棒距离估计和间歇性运动机制能够显著增强人工群体系统的韧性，解决视觉感知带来的脆弱性问题，使群体运动更加稳定可靠。

Abstract: In collective motion, perceptually-limited individuals move in an ordered manner, without centralized control. The perception of each individual is highly localized, as is its ability to interact with others. While natural collective motion is robust, most artificial swarms are brittle. This particularly occurs when vision is used as the sensing modality, due to ambiguities and information-loss inherent in visual perception. This paper presents mechanisms for robust collective motion inspired by studies of locusts. First, we develop a robust distance estimation method that combines visually perceived horizontal and vertical sizes of neighbors. Second, we introduce intermittent locomotion as a mechanism that allows robots to reliably detect peers that fail to keep up, and disrupt the motion of the swarm. We show how such faulty robots can be avoided in a manner that is robust to errors in classifying them as faulty. Through extensive physics-based simulation experiments, we show dramatic improvements to swarm resilience when using these techniques. We show these are relevant to both distance-based Avoid-Attract models, as well as to models relying on Alignment, in a wide range of experiment settings.

</details>


### [5] [Asymmetric Friction in Geometric Locomotion](https://arxiv.org/abs/2512.22484)
*Ross L. Hatton,Yousef Salaman,Shai Revzen*

Main category: cs.RO

TL;DR: 论文将几何力学中的亚黎曼方法扩展到亚芬斯勒方法，以处理更一般的非对称摩擦系统


<details>
  <summary>Details</summary>
Motivation: 现有几何力学模型主要处理各向同性或各向异性的线性摩擦，但实际系统中摩擦可能具有非对称性（向前和向后运动系数不同），需要更一般的理论框架

Method: 将黎曼度量替换为芬斯勒度量，将亚黎曼方法扩展到亚芬斯勒方法，构建系统运动能力图

Result: 成功建立了亚芬斯勒框架，识别了类似于亚黎曼系统中约束曲率的系统特性，能够表征具有非对称摩擦系统的运动能力

Conclusion: 亚芬斯勒方法为处理更一般的非对称摩擦系统提供了理论框架，扩展了几何力学在机器人运动分析中的应用范围

Abstract: Geometric mechanics models of locomotion have provided insight into how robots and animals use environmental interactions to convert internal shape changes into displacement through the world, encoding this relationship in a ``motility map''. A key class of such motility maps arises from (possibly anisotropic) linear drag acting on the system's individual body parts, formally described via Riemannian metrics on the motions of the system's individual body parts. The motility map can then be generated by invoking a sub-Riemannian constraint on the aggregate system motion under which the position velocity induced by a given shape velocity is that which minimizes the power dissipated via friction. The locomotion of such systems is ``geometric'' in the sense that the final position reached by the system depends only on the sequence of shapes that the system passes through, but not on the rate with which the shape changes are made.
  In this paper, we consider a far more general class of systems in which the drag may be not only anisotropic (with different coefficients for forward/backward and left/right motions), but also asymmetric (with different coefficients for forward and backward motions). Formally, including asymmetry in the friction replaces the Riemannian metrics on the body parts with Finsler metrics. We demonstrate that the sub-Riemannian approach to constructing the system motility map extends naturally to a sub-Finslerian approach and identify system properties analogous to the constraint curvature of sub-Riemannian systems that allow for the characterization of the system motion capabilities.

</details>


### [6] [Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces](https://arxiv.org/abs/2512.22502)
*Shen Changqing,Xu Bingzhou,Qi Bosong,Zhang Xiaojian,Yan Sijie,Ding Han*

Main category: cs.RO

TL;DR: 提出一种基于保形缝隙映射和拓扑保持网格变形的球头铣削路径规划方法，解决多连通自由曲面加工中的边界一致性、梯度奇异性和路径连续性难题。


<details>
  <summary>Details</summary>
Motivation: 汽车和航空航天制造中，多连通自由曲面上的球头铣削路径规划对高质量高效加工至关重要。现有标量场优化方法难以同时保持边界一致性、消除导致等值线分支或终止的零梯度奇点，从而破坏刀具路径连续性。

Method: 采用保形缝隙映射构建无奇点的初始标量场；将优化重构为边界同步更新的拓扑保持网格变形，实现全局优化的间距、残留高度均匀性和平滑轨迹过渡。

Result: 生成的刀具路径连续、边界一致且无自相交。铣削实验表明，相比最先进的保形缝隙映射方法，加工效率提高14.24%，残留高度均匀性改善5.70%，铣削冲击引起的振动降低超过10%。

Conclusion: 该方法为高性能加工场景提供了广泛适用的解决方案，能有效解决多连通自由曲面加工中的路径规划难题。

Abstract: Ball-end milling path planning on multiply connected freeform surfaces is pivotal for high-quality and efficient machining of components in automotive and aerospace manufacturing. Although scalar-field-based optimization provides a unified framework for multi-objective toolpath generation, maintaining boundary conformity while eliminating zero-gradient singularities that cause iso-curve branching or termination and disrupt toolpath continuity remains challenging on multiply connected surfaces. We propose an efficient strategy to robustly enforce these constraints throughout optimization. Conformal slit mapping is employed to construct a feasible, singularity-free initial scalar field. The optimization is reformulated as a topology-preserving mesh deformation governed by boundary-synchronous updates, enabling globally optimized spacing, scallop-height uniformity, and smooth trajectory transitions. Consequently, the toolpaths are continuous, boundary-conforming, and free of self-intersections. Milling experiments demonstrate that, compared with a state-of-the-art conformal slit mapping-based method, the proposed approach increases machining efficiency by 14.24%, improves scallop-height uniformity by 5.70%, and reduces milling impact-induced vibrations by over 10%. The strategy offers broad applicability in high-performance machining scenarios.

</details>


### [7] [Clutter-Resistant Vision-Language-Action Models through Object-Centric and Geometry Grounding](https://arxiv.org/abs/2512.22519)
*Khoa Vo,Taisei Hanyu,Yuki Ikebe,Trong Thang Pham,Nhat Chung,Minh Nhat Vu,Duy Nguyen Ho Minh,Anh Nguyen,Anthony Gunderman,Chase Rainwater,Ngan Le*

Main category: cs.RO

TL;DR: OBEYED-VLA框架通过显式解耦感知与动作推理，利用物体中心化和几何感知的观察增强VLA模型，显著提升机器人操作的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型将感知与控制耦合在单一管道中，导致语言条件接地能力下降，在真实场景中出现过度抓取、受干扰物影响、过拟合背景外观等问题。

Method: 提出OBEYED-VLA框架，包含基于VLM的物体中心接地阶段（选择任务相关物体区域）和互补的几何接地阶段（强调物体3D结构而非外观），然后将接地视图输入预训练VLA策略进行微调。

Result: 在真实UR10e桌面设置中，OBEYED-VLA在四个挑战性场景（干扰物、目标缺失拒绝、背景外观变化、未见物体杂乱操作）中显著优于现有VLA基线，消融研究证实语义接地和几何接地都至关重要。

Conclusion: 将感知作为显式的物体中心组件是增强和泛化基于VLA的机器人操作的有效方法，解耦感知与动作推理能提升系统鲁棒性。

Abstract: Recent Vision-Language-Action (VLA) models have made impressive progress toward general-purpose robotic manipulation by post-training large Vision-Language Models (VLMs) for action prediction. Yet most VLAs entangle perception and control in a monolithic pipeline optimized purely for action, which can erode language-conditioned grounding. In our real-world tabletop tests, policies over-grasp when the target is absent, are distracted by clutter, and overfit to background appearance.
  To address these issues, we propose OBEYED-VLA (OBject-centric and gEometrY groundED VLA), a framework that explicitly disentangles perceptual grounding from action reasoning. Instead of operating directly on raw RGB, OBEYED-VLA augments VLAs with a perception module that grounds multi-view inputs into task-conditioned, object-centric, and geometry-aware observations. This module includes a VLM-based object-centric grounding stage that selects task-relevant object regions across camera views, along with a complementary geometric grounding stage that emphasizes the 3D structure of these objects over their appearance. The resulting grounded views are then fed to a pretrained VLA policy, which we fine-tune exclusively on single-object demonstrations collected without environmental clutter or non-target objects.
  On a real-world UR10e tabletop setup, OBEYED-VLA substantially improves robustness over strong VLA baselines across four challenging regimes and multiple difficulty levels: distractor objects, absent-target rejection, background appearance changes, and cluttered manipulation of unseen objects. Ablation studies confirm that both semantic grounding and geometry-aware grounding are critical to these gains. Overall, the results indicate that making perception an explicit, object-centric component is an effective way to strengthen and generalize VLA-based robotic manipulation.

</details>


### [8] [VLA-Arena: An Open-Source Framework for Benchmarking Vision-Language-Action Models](https://arxiv.org/abs/2512.22539)
*Borong Zhang,Jiahao Li,Jiachen Shen,Yishuai Cai,Yuhao Zhang,Yuanpei Chen,Juntao Dai,Jiaming Ji,Yaodong Yang*

Main category: cs.RO

TL;DR: VLA-Arena是一个用于系统评估视觉-语言-动作模型能力的综合基准测试，通过结构化任务设计框架量化三个正交维度（任务结构、语言指令、视觉观察）的难度，揭示现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型快速发展，但缺乏定量理解其限制和失败模式的方法。需要系统化的评估框架来精确测量模型能力边界。

Method: 提出结构化任务设计框架，从三个正交维度量化难度：1) 任务结构（安全、干扰、外推、长时域四个维度，170个任务，3个难度级别）；2) 语言指令（W0-W4扰动）；3) 视觉观察（V0-V4扰动）。仅使用L0难度进行微调以评估泛化能力。

Result: 对最先进VLA模型的评估揭示了几个关键局限性：强烈倾向于记忆而非泛化、非对称鲁棒性、缺乏安全约束考虑、无法组合学习技能处理长时域任务。

Conclusion: VLA-Arena提供了一个全面的评估框架，能够系统分析VLA模型的能力边界和失败模式，为未来研究提供基准测试工具和数据集，促进可复现性研究。

Abstract: While Vision-Language-Action models (VLAs) are rapidly advancing towards generalist robot policies, it remains difficult to quantitatively understand their limits and failure modes. To address this, we introduce a comprehensive benchmark called VLA-Arena. We propose a novel structured task design framework to quantify difficulty across three orthogonal axes: (1) Task Structure, (2) Language Command, and (3) Visual Observation. This allows us to systematically design tasks with fine-grained difficulty levels, enabling a precise measurement of model capability frontiers. For Task Structure, VLA-Arena's 170 tasks are grouped into four dimensions: Safety, Distractor, Extrapolation, and Long Horizon. Each task is designed with three difficulty levels (L0-L2), with fine-tuning performed exclusively on L0 to assess general capability. Orthogonal to this, language (W0-W4) and visual (V0-V4) perturbations can be applied to any task to enable a decoupled analysis of robustness. Our extensive evaluation of state-of-the-art VLAs reveals several critical limitations, including a strong tendency toward memorization over generalization, asymmetric robustness, a lack of consideration for safety constraints, and an inability to compose learned skills for long-horizon tasks. To foster research addressing these challenges and ensure reproducibility, we provide the complete VLA-Arena framework, including an end-to-end toolchain from task definition to automated evaluation and the VLA-Arena-S/M/L datasets for fine-tuning. Our benchmark, data, models, and leaderboard are available at https://vla-arena.github.io.

</details>


### [9] [Modeling of UAV Tether Aerodynamics for Real-Time Simulation](https://arxiv.org/abs/2512.22588)
*Max Beffert,Andreas Zell*

Main category: cs.RO

TL;DR: 本文提出了两种实时准静态系绳建模方法，用于解决系留无人机在移动平台或强风条件下的系绳力建模问题，包括基于悬链线理论的解析方法和基于离散化的数值方法。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机受电池限制飞行时间短，通过地面系绳供电是连续运行的实用方案。然而，在快速移动平台或强风条件下，需要考虑系绳力（包括空气动力学效应）的建模，这是现有研究中的主要限制。

Method: 提出了两种互补的实时准静态系绳建模方法：1）基于悬链线理论和均匀阻力假设的解析方法，求解时间低于1ms；2）将系绳离散为分段和集中质量的数值方法，使用CasADi和IPOPT求解平衡方程，通过热启动和解析初始化等策略实现5ms的实时性能。

Result: 两种方法均通过使用测力传感器的真实世界测试验证。解析方法在大多数系留无人机应用中提供足够精度且计算成本最小；数值方法在需要时提供更高的灵活性和物理精度。

Conclusion: 这两种方法构成了一个轻量级且可扩展的实时系绳模拟框架，适用于离线优化和在线任务（如模拟、控制和轨迹规划），为系留无人机系统提供了有效的建模工具。

Abstract: One of the main limitations of multirotor UAVs is their short flight time due to battery constraints. A practical solution for continuous operation is to power the drone from the ground via a tether. While this approach has been demonstrated for stationary systems, scenarios with a fast-moving base vehicle or strong wind conditions require modeling the tether forces, including aerodynamic effects. In this work, we propose two complementary approaches for real-time quasi-static tether modeling with aerodynamics. The first is an analytical method based on catenary theory with a uniform drag assumption, achieving very fast solve times below 1ms. The second is a numerical method that discretizes the tether into segments and lumped masses, solving the equilibrium equations using CasADi and IPOPT. By leveraging initialization strategies, such as warm starting and analytical initialization, real-time performance was achieved with a solve time of 5ms, while allowing for flexible force formulations. Both approaches were validated in real-world tests using a load cell to measure the tether force. The results show that the analytical method provides sufficient accuracy for most tethered UAV applications with minimal computational cost, while the numerical method offers higher flexibility and physical accuracy when required. These approaches form a lightweight and extensible framework for real-time tether simulation, applicable to both offline optimization and online tasks such as simulation, control, and trajectory planning.

</details>


### [10] [Sistema de navegación de cobertura para vehículos no holonómicos en ambientes de exterior](https://arxiv.org/abs/2512.22734)
*Michelle Valenzuela,Francisco Leiva,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出了一种用于非完整机器人的覆盖导航系统，旨在实现特定区域的完全覆盖，并能在遇到动态障碍时进行规避和恢复，为采矿等行业自动化提供概念验证。


<details>
  <summary>Details</summary>
Motivation: 移动机器人覆盖导航在清洁、采矿等工业应用中至关重要，但现有系统在非完整约束和动态障碍环境下存在挑战。采矿行业中的物料搬运、清洁、尾矿坝建设等单元过程需要自动化覆盖导航以提高安全性。

Method: 开发了非完整机器人的覆盖导航系统，包括计算覆盖特定区域的路径规划，并集成了恢复行为机制。系统能够处理动态障碍和未映射障碍物，执行规避机动和恢复后继续覆盖，确保区域完全覆盖。

Result: 在模拟和真实室外环境中测试，大多数实验获得了接近90%的覆盖率。系统能够有效处理动态障碍并恢复覆盖任务。

Conclusion: 该系统为采矿等行业中需要覆盖导航的单元过程自动化提供了可行的概念验证。下一步将扩展到采矿机械/车辆，并在真实环境中验证其操作。

Abstract: In mobile robotics, coverage navigation refers to the deliberate movement of a robot with the purpose of covering a certain area or volume. Performing this task properly is fundamental for the execution of several activities, for instance, cleaning a facility with a robotic vacuum cleaner. In the mining industry, it is required to perform coverage in several unit processes related with material movement using industrial machinery, for example, in cleaning tasks, in dumps, and in the construction of tailings dam walls. The automation of these processes is fundamental to enhance the security associated with their execution. In this work, a coverage navigation system for a non-holonomic robot is presented. This work is intended to be a proof of concept for the potential automation of various unit processes that require coverage navigation like the ones mentioned before. The developed system includes the calculation of routes that allow a mobile platform to cover a specific area, and incorporates recovery behaviors in case that an unforeseen event occurs, such as the arising of dynamic or previously unmapped obstacles in the terrain to be covered, e.g., other machines or pedestrians passing through the area, being able to perform evasive maneuvers and post-recovery to ensure a complete coverage of the terrain. The system was tested in different simulated and real outdoor environments, obtaining results near 90% of coverage in the majority of experiments. The next step of development is to scale up the utilized robot to a mining machine/vehicle whose operation will be validated in a real environment. The result of one of the tests performed in the real world can be seen in the video available in https://youtu.be/gK7_3bK1P5g.

</details>


### [11] [Active Constraint Learning in High Dimensions from Demonstrations](https://arxiv.org/abs/2512.22757)
*Zheng Qiu,Chih-Yuan Chiu,Glen Chou*

Main category: cs.RO

TL;DR: 提出了一种迭代式主动约束学习算法，在演示学习框架下智能地请求信息丰富的演示轨迹，用于推断演示者环境中的未知约束。


<details>
  <summary>Details</summary>
Motivation: 在从演示中学习时，演示者环境中的未知约束会影响学习效果。传统方法可能无法高效地获取信息丰富的演示数据来准确推断这些约束。

Method: 采用迭代式主动约束学习算法：1) 在可用演示数据集上训练高斯过程来表示未知约束；2) 使用GP后验查询起始/目标状态；3) 生成信息丰富的演示并添加到数据集中。

Result: 在模拟和硬件实验中，使用高维非线性动力学和未知非线性约束，该方法在从迭代生成的稀疏但信息丰富的演示集中准确执行约束推断方面优于基于随机采样的基线方法。

Conclusion: 提出的主动约束学习方法能够通过智能选择信息丰富的演示，有效地学习未知约束，在约束推断准确性上优于随机采样方法。

Abstract: We present an iterative active constraint learning (ACL) algorithm, within the learning from demonstrations (LfD) paradigm, which intelligently solicits informative demonstration trajectories for inferring an unknown constraint in the demonstrator's environment. Our approach iteratively trains a Gaussian process (GP) on the available demonstration dataset to represent the unknown constraints, uses the resulting GP posterior to query start/goal states, and generates informative demonstrations which are added to the dataset. Across simulation and hardware experiments using high-dimensional nonlinear dynamics and unknown nonlinear constraints, our method outperforms a baseline, random-sampling based method at accurately performing constraint inference from an iteratively generated set of sparse but informative demonstrations.

</details>


### [12] [Two-Robot Computational Landscape: A Complete Characterization of Model Power in Minimal Mobile Robot Systems](https://arxiv.org/abs/2512.22770)
*Naoki Kitamura,Yuichi Sudo,Koichi Wada*

Main category: cs.RO

TL;DR: 本文首次完整刻画了两个自主移动机器人在所有主要模型（OBLOT、FSTA、FCOM、LUMI）和调度器（FSYNCH、SSYNCH、ASYNCH及其原子变体）下的计算能力，揭示了与一般情况根本不同的计算格局。


<details>
  <summary>Details</summary>
Motivation: 虽然LCM模型下自主移动机器人的计算能力已通过广泛的研究建立了层次结构，但两个机器人的确切计算能力结构一直未解决。本文旨在填补这一空白，完整刻画两个机器人在所有主要模型下的计算能力。

Method: 采用一种新颖的无模拟方法，避免了传统的模拟技术，提供统一且构造性的视角来分析两个机器人的层次结构。该方法能够直接推导出等价性和分离性结果。

Result: 1. 在完全同步下，FSTA^F和LUMI^F模型等价，表明完美同步可以替代内存和通信；2. FSTA和FCOM模型正交，存在在弱通信模型中可解但在强有限状态模型中不可解的问题；3. 获得了所有等价和分离结果的完整计算格局。

Conclusion: 本文首次为两个机器人提供了完整且精确的计算能力格局，揭示了在最小规模下协调的内在挑战。结果表明两个机器人的计算格局与一般情况根本不同，完美同步在某些情况下可以替代内存和通信能力。

Abstract: The computational power of autonomous mobile robots under the Look-Compute-Move (LCM) model has been widely studied through an extensive hierarchy of robot models defined by the presence of memory, communication, and synchrony assumptions. While the general n-robot landscape has been largely established, the exact structure for two robots has remained unresolved. This paper presents the first complete characterization of the computational power of two autonomous robots across all major models, namely OBLOT, FSTA, FCOM, and LUMI, under the full spectrum of schedulers (FSYNCH, SSYNCH, ASYNCH, and their atomic variants). Our results reveal a landscape that fundamentally differs from the general case. Most notably, we prove that FSTA^F and LUMI^F coincide under full synchrony, a surprising collapse indicating that perfect synchrony can substitute both memory and communication when only two robots exist. We also show that FSTA and FCOM are orthogonal: there exists a problem solvable in the weakest communication model but impossible even in the strongest finite-state model, completing the bidirectional incomparability. All equivalence and separation results are derived through a novel simulation-free method, providing a unified and constructive view of the two-robot hierarchy. This yields the first complete and exact computational landscape for two robots, highlighting the intrinsic challenges of coordination at the minimal scale.

</details>


### [13] [The body is not there to compute: Comment on "Informational embodiment: Computational role of information structure in codes and robots" by Pitti et al](https://arxiv.org/abs/2512.22868)
*Matej Hoffmann*

Main category: cs.RO

TL;DR: 该评论文章认为身体的主要功能不是计算，而是作为与环境交互的界面，挑战了将身体视为计算实体的观点。


<details>
  <summary>Details</summary>
Motivation: 作者旨在挑战当前将计算和信息理论过度应用于理解生物身体的观点，认为这种计算隐喻可能限制了我们对身体本质功能的理解。

Method: 通过哲学分析和概念论证，作者对目标文章中应用计算和信息理论来理解动物身体进化和机器人设计的做法提出批判性评论。

Result: 作者得出结论，身体的主要角色不是计算，而是作为生物体与环境之间的交互界面，这一观点挑战了将身体简化为计算实体的主流趋势。

Conclusion: 虽然计算和信息理论在理解神经系统方面有价值，但不应过度扩展到身体功能的理解，身体的核心功能在于其作为交互界面的物理存在，而非计算能力。

Abstract: Applying the lens of computation and information has been instrumental in driving the technological progress of our civilization as well as in empowering our understanding of the world around us. The digital computer was and for many still is the leading metaphor for how our mind operates. Information theory (IT) has also been important in our understanding of how nervous systems encode and process information. The target article deploys information and computation to bodies: to understand why they have evolved in particular ways (animal bodies) and to design optimal bodies (robots). In this commentary, I argue that the main role of bodies is not to compute.

</details>


### [14] [P-FABRIK: A General Intuitive and Robust Inverse Kinematics Method for Parallel Mechanisms Using FABRIK Approach](https://arxiv.org/abs/2512.22927)
*Daqian Cao,Quan Yuan,Weibang Bai*

Main category: cs.RO

TL;DR: 提出P-FABRIK方法，基于FABRIK算法为各种并联机构提供通用、直观、鲁棒的逆运动学求解方案


<details>
  <summary>Details</summary>
Motivation: 传统几何逆运动学方法依赖特定空间几何约束，对冗余并联机构约束复杂度增加，且当目标位姿超出工作空间时无解并导致不可预测的控制问题

Method: 基于FABRIK算法，通过新的拓扑分解策略将通用并联机构分解为多个串联子链，迭代修正各子链末端目标来计算逆运动学解

Result: 通过平面、标准和冗余并联机构的多案例研究验证了方法的通用性，数值仿真研究证实了其有效性、计算效率以及处理超出工作空间目标的鲁棒性

Conclusion: P-FABRIK方法为各种并联机构提供了一种通用、直观、鲁棒的逆运动学求解方案，能够有效处理传统方法面临的挑战

Abstract: Traditional geometric inverse kinematics methods for parallel mechanisms rely on specific spatial geometry constraints. However, their application to redundant parallel mechanisms is challenged due to the increased constraint complexity. Moreover, it will output no solutions and cause unpredictable control problems when the target pose lies outside its workspace. To tackle these challenging issues, this work proposes P-FABRIK, a general, intuitive, and robust inverse kinematics method to find one feasible solution for diverse parallel mechanisms based on the FABRIK algorithm. By decomposing the general parallel mechanism into multiple serial sub-chains using a new topological decomposition strategy, the end targets of each sub-chain can be subsequently revised to calculate the inverse kinematics solutions iteratively. Multiple case studies involving planar, standard, and redundant parallel mechanisms demonstrated the proposed method's generality across diverse parallel mechanisms. Furthermore, numerical simulation studies verified its efficacy and computational efficiency, as well as its robustness ability to handle out-of-workspace targets.

</details>


### [15] [PreGME: Prescribed Performance Control of Aerial Manipulators based on Variable-Gain ESO](https://arxiv.org/abs/2512.22957)
*Mengyu Ji,Shiliang Guo,Zhengzhen Li,Jiahao Shen,Huazi Cao,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于变增益扩展状态观测器的规定性能运动控制框架PreGME，用于解决空中机械臂的动态耦合问题，实现高精度鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 空中机械臂（多旋翼基座+机械臂）存在显著的动态耦合效应，实现精确鲁棒的运动控制具有挑战性但很重要。

Method: 提出PreGME框架：1）变增益扩展状态观测器实时估计动态耦合；2）规定性能飞行控制器，包含误差轨迹约束，引导系统沿预设轨迹演化。

Result: 实验验证包括空中转杆、空中调酒和空中拉车等任务。即使在机械臂快速运动（末端速度1.02 m/s，加速度5.10 m/s²）引起的动态耦合下，仍能实现高跟踪性能。

Conclusion: 提出的方法能准确估计快速变化的动态耦合，处理需要机械臂激进运动的任务；通过规定性能确保跟踪误差在预设性能包络内，实现高精度控制。

Abstract: An aerial manipulator, comprising a multirotor base and a robotic arm, is subject to significant dynamic coupling between these two components. Therefore, achieving precise and robust motion control is a challenging yet important objective. Here, we propose a novel prescribed performance motion control framework based on variable-gain extended state observers (ESOs), referred to as PreGME. The method includes variable-gain ESOs for real-time estimation of dynamic coupling and a prescribed performance flight control that incorporates error trajectory constraints. Compared with existing methods, the proposed approach exhibits the following two characteristics. First, the adopted variable-gain ESOs can accurately estimate rapidly varying dynamic coupling. This enables the proposed method to handle manipulation tasks that require aggressive motion of the robotic arm. Second, by prescribing the performance, a preset error trajectory is generated to guide the system evolution along this trajectory. This strategy allows the proposed method to ensure the tracking error remains within the prescribed performance envelope, thereby achieving high-precision control. Experiments on a real platform, including aerial staff twirling, aerial mixology, and aerial cart-pulling experiments, are conducted to validate the effectiveness of the proposed method.
  Experimental results demonstrate that even under the dynamic coupling caused by rapid robotic arm motion (end-effector velocity: 1.02 m/s, acceleration: 5.10 m/s$^2$), the proposed method achieves high tracking performance.

</details>


### [16] [Embodied Robot Manipulation in the Era of Foundation Models: Planning and Learning Perspectives](https://arxiv.org/abs/2512.22983)
*Shuanghao Bai,Wenxuan Song,Jiayi Chen,Yuheng Ji,Zhide Zhong,Jin Yang,Han Zhao,Wanqi Zhou,Zhe Li,Pengxiang Ding,Cheng Chi,Chang Xu,Xiaolong Zheng,Donglin Wang,Haoang Li,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 该论文是一篇关于机器人操作基础模型的综述，从算法角度将学习型方法统一为高层规划与底层控制的抽象框架，并提出了相应的分类体系和研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着视觉、语言和多模态学习的快速发展，机器人基础模型取得了显著进展，但机器人操作仍然是核心且具有挑战性的问题。需要从算法角度系统梳理学习型方法，为现代机器人操作基础模型提供清晰的设计空间。

Method: 采用高层规划与底层控制的统一抽象框架：1）高层规划扩展了经典任务规划概念，涵盖语言、代码、运动、功能性和3D表示推理；2）底层控制提出基于训练范式的分类法，按输入建模、潜在表示学习和策略学习组织现有方法。

Result: 建立了机器人操作学习型方法的系统分类框架，明确了高层规划与底层控制的关键技术维度，为理解现代机器人操作基础模型提供了结构化视角。

Conclusion: 该综述为机器人操作基础模型的设计空间提供了清晰框架，并识别出可扩展性、数据效率、多模态物理交互和安全性等开放挑战与未来研究方向。

Abstract: Recent advances in vision, language, and multimodal learning have substantially accelerated progress in robotic foundation models, with robot manipulation remaining a central and challenging problem. This survey examines robot manipulation from an algorithmic perspective and organizes recent learning-based approaches within a unified abstraction of high-level planning and low-level control. At the high level, we extend the classical notion of task planning to include reasoning over language, code, motion, affordances, and 3D representations, emphasizing their role in structured and long-horizon decision making. At the low level, we propose a training-paradigm-oriented taxonomy for learning-based control, organizing existing methods along input modeling, latent representation learning, and policy learning. Finally, we identify open challenges and prospective research directions related to scalability, data efficiency, multimodal physical interaction, and safety. Together, these analyses aim to clarify the design space of modern foundation models for robotic manipulation.

</details>


### [17] [Embodied Learning of Reward for Musculoskeletal Control with Vision Language Models](https://arxiv.org/abs/2512.23077)
*Saraswati Soedarmadji,Yunyue Wei,Chen Zhang,Yisong Yue,Yanan Sui*

Main category: cs.RO

TL;DR: MoVLR框架利用视觉语言模型将高层次运动目标转化为控制策略，通过迭代优化发现有效的奖励函数，解决高维肌肉骨骼系统运动控制中的奖励函数设计难题。


<details>
  <summary>Details</summary>
Motivation: 高维肌肉骨骼系统的运动控制面临奖励函数设计的根本挑战。虽然人类可以用自然语言描述运动目标（如"直立向前行走"），但实现这些目标的底层控制策略是隐式的，难以直接从高层次目标和语言描述设计奖励函数。

Method: 提出MoVLR框架，利用视觉语言模型在目标规范与运动控制之间建立桥梁。通过控制优化与VLM反馈的迭代交互探索奖励空间，将语言和视觉评估转化为结构化指导，实现具身学习中的奖励函数发现和优化。

Result: MoVLR能够为高维肌肉骨骼系统的运动和操作任务发现和优化奖励函数，使控制策略与物理协调行为对齐，证明了VLMs能够将抽象运动描述基于生理运动控制的隐式原理。

Conclusion: 视觉语言模型可以有效地将抽象运动描述基于生理运动控制的隐式原理，为解决高维肌肉骨骼系统运动控制中的奖励函数设计问题提供了新途径。

Abstract: Discovering effective reward functions remains a fundamental challenge in motor control of high-dimensional musculoskeletal systems. While humans can describe movement goals explicitly such as "walking forward with an upright posture," the underlying control strategies that realize these goals are largely implicit, making it difficult to directly design rewards from high-level goals and natural language descriptions. We introduce Motion from Vision-Language Representation (MoVLR), a framework that leverages vision-language models (VLMs) to bridge the gap between goal specification and movement control. Rather than relying on handcrafted rewards, MoVLR iteratively explores the reward space through iterative interaction between control optimization and VLM feedback, aligning control policies with physically coordinated behaviors. Our approach transforms language and vision-based assessments into structured guidance for embodied learning, enabling the discovery and refinement of reward functions for high-dimensional musculoskeletal locomotion and manipulation. These results suggest that VLMs can effectively ground abstract motion descriptions in the implicit principles governing physiological motor control.

</details>


### [18] [APOLLO Blender: A Robotics Library for Visualization and Animation in Blender](https://arxiv.org/abs/2512.23103)
*Peter Messina,Daniel Rakita*

Main category: cs.RO

TL;DR: 开发了一个轻量级软件库，为机器人研究人员提供简单的Blender脚本接口，用于快速创建高质量的出版物可视化内容。


<details>
  <summary>Details</summary>
Motivation: Blender作为强大的免费3D图形平台，学习曲线陡峭且缺乏机器人专用集成，使得研究人员难以有效使用，需要简化机器人可视化流程。

Method: 开发了一个轻量级软件库，提供三个主要功能：1）从URDF等标准描述直接导入机器人和环境；2）基于Python的脚本工具用于关键帧设置；3）方便生成基本3D形状用于示意图和动画。

Result: 通过一系列概念验证示例展示了该库的功能，使机器人研究人员无需深入的Blender专业知识就能快速创建出版物就绪的图像、动画和解释性示意图。

Conclusion: 该库填补了机器人研究与Blender之间的空白，讨论了当前局限性和未来扩展机会，为机器人可视化提供了高效工具。

Abstract: High-quality visualizations are an essential part of robotics research, enabling clear communication of results through figures, animations, and demonstration videos. While Blender is a powerful and freely available 3D graphics platform, its steep learning curve and lack of robotics-focused integrations make it difficult and time-consuming for researchers to use effectively. In this work, we introduce a lightweight software library that bridges this gap by providing simple scripting interfaces for common robotics visualization tasks. The library offers three primary capabilities: (1) importing robots and environments directly from standardized descriptions such as URDF; (2) Python-based scripting tools for keyframing robot states and visual attributes; and (3) convenient generation of primitive 3D shapes for schematic figures and animations. Together, these features allow robotics researchers to rapidly create publication-ready images, animations, and explanatory schematics without needing extensive Blender expertise. We demonstrate the library through a series of proof-of-concept examples and conclude with a discussion of current limitations and opportunities for future extensions.

</details>


### [19] [Pole-centric Descriptors for Robust Robot Localization: Evaluation under Pole-at-Distance (PaD) Observations using the Small Pole Landmark (SPL) Dataset](https://arxiv.org/abs/2512.23141)
*Wuhao Xie,Kanji Tanaka*

Main category: cs.RO

TL;DR: 该论文研究了远距离杆状结构识别中的描述符鲁棒性问题，建立了专门的评估框架和数据集，对比了对比学习和监督学习两种范式，发现对比学习在稀疏几何特征空间中表现更优。


<details>
  <summary>Details</summary>
Motivation: 在大型城市环境中，远距离杆状结构（Pole-at-Distance）的识别可靠性显著下降，现有方法主要关注描述符设计，而缺乏对描述符鲁棒性的系统研究。

Method: 1. 建立了专门的小型杆状地标（SPL）数据集，通过自动跟踪关联管道捕获多视角、多距离的同一物理地标观测，无需人工标注；2. 构建了专门的评估框架；3. 对比分析了对比学习（CL）和监督学习（SL）两种范式。

Result: 对比学习在稀疏几何特征空间中诱导出更鲁棒的特征表示，在5-10米距离范围内表现出优越的检索性能。

Conclusion: 该工作为评估具有挑战性的真实场景中地标独特性提供了实证基础和可扩展方法，表明对比学习范式在远距离杆状结构识别中具有更好的鲁棒性。

Abstract: While pole-like structures are widely recognized as stable geometric anchors for long-term robot localization, their identification reliability degrades significantly under Pole-at-Distance (Pad) observations typical of large-scale urban environments. This paper shifts the focus from descriptor design to a systematic investigation of descriptor robustness. Our primary contribution is the establishment of a specialized evaluation framework centered on the Small Pole Landmark (SPL) dataset. This dataset is constructed via an automated tracking-based association pipeline that captures multi-view, multi-distance observations of the same physical landmarks without manual annotation. Using this framework, we present a comparative analysis of Contrastive Learning (CL) and Supervised Learning (SL) paradigms. Our findings reveal that CL induces a more robust feature space for sparse geometry, achieving superior retrieval performance particularly in the 5--10m range. This work provides an empirical foundation and a scalable methodology for evaluating landmark distinctiveness in challenging real-world scenarios.

</details>


### [20] [Towards the Automation in the Space Station: Feasibility Study and Ground Tests of a Multi-Limbed Intra-Vehicular Robot](https://arxiv.org/abs/2512.23153)
*Seiko Piotr Yamaguchi,Kentaro Uno,Yasumaru Fujii,Masazumi Imai,Kazuki Takada,Taku Okawara,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 研究评估了多肢车内机器人在国际空间站自主执行物流任务的可行性，通过仿真和原型测试验证了其在微重力环境下自主运输货物的能力。


<details>
  <summary>Details</summary>
Motivation: 宇航员在国际空间站上花费大量时间进行货物准备、收集和运输等物流任务，减少了执行关键任务的时间。需要开发自主移动机械臂来支持这些操作，减少机组人员和地面操作人员的工作量。

Method: 通过仿真模拟机器人在3D空间中的运动规划，并使用原型机在2D平台上测试实际运动执行，模拟微重力环境下的操作。

Result: 研究结果表明，多肢车内机器人能够以最小的人力干预执行物流任务，证明了在国际空间站上实现自主操作的可行性。

Conclusion: 自主多肢车内机器人为提高国际空间站的操作效率提供了有前景的解决方案，能够显著减少宇航员的物流工作负担。

Abstract: This paper presents a feasibility study, including simulations and prototype tests, on the autonomous operation of a multi-limbed intra-vehicular robot (mobile manipulator), shortly MLIVR, designed to assist astronauts with logistical tasks on the International Space Station (ISS). Astronauts spend significant time on tasks such as preparation, close-out, and the collection and transportation of goods, reducing the time available for critical mission activities. Our study explores the potential for a mobile manipulator to support these operations, emphasizing the need for autonomous functionality to minimize crew and ground operator effort while enabling real-time task execution. We focused on the robot's transportation capabilities, simulating its motion planning in 3D space. The actual motion execution was tested with a prototype on a 2D table to mimic a microgravity environment. The results demonstrate the feasibility of performing these tasks with minimal human intervention, offering a promising solution to enhance operational efficiency on the ISS.

</details>


### [21] [A Sequential Hermaphrodite Coupling Mechanism for Lattice-based Modular Robots](https://arxiv.org/abs/2512.23154)
*Keigo Torii,Kentaro Uno,Shreya Santra,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出一种新型形状匹配机械耦合机制，满足单侧耦合/解耦、解耦时表面平整、能与被动接口耦合等复杂需求，适用于模块化机器人系统和机械臂工具更换器


<details>
  <summary>Details</summary>
Motivation: 晶格型模块化机器人系统在极端环境（如太空）的大规模建造中需要满足复杂耦合需求：单侧耦合/解耦、解耦时表面平整、能与被动接口耦合以及耦合机制间的互耦行为

Method: 提出形状匹配机械耦合机制，实现可控的男/女状态顺序转换。解耦时所有机制处于女状态；耦合过程中一侧切换为男状态实现单侧耦合；单侧解耦不仅可从男侧进行，也可通过强制将对方男状态转为女状态从女侧实现

Result: 该机制满足所有设计要求：单侧耦合和解耦能力、解耦时表面平整、能与被动耦合接口工作，并支持耦合机制间的互耦行为

Conclusion: 提出的形状匹配机械耦合机制解决了异构结构模块的复杂耦合需求，可应用于各种模块化机器人系统和机械臂工具更换器，为极端环境下的建造任务提供了关键技术

Abstract: Lattice-based modular robot systems are envisioned for large-scale construction in extreme environments, such as space. Coupling mechanisms for heterogeneous structural modules should meet all of the following requirements: single-sided coupling and decoupling, flat surfaces when uncoupled, and coupling to passive coupling interfaces as well as coupling behavior between coupling mechanisms. The design requirements for such a coupling mechanism are complex. We propose a novel shape-matching mechanical coupling mechanism that satisfies these design requirements. This mechanism enables controlled, sequential transitions between male and female states. When uncoupled, all mechanisms are in the female state. To enable single-sided coupling, one side of the mechanisms switches to the male state during the coupling process. Single-sided decoupling is possible not only from the male side but also from the female side by forcibly switching the opposite mechanism's male state to the female state. This coupling mechanism can be applied to various modular robot systems and robot arm tool changers.

</details>


### [22] [SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling](https://arxiv.org/abs/2512.23162)
*Yufan He,Pengfei Guo,Mengya Xu,Zhaoshuo Li,Andriy Myronenko,Dillan Imans,Bingjie Liu,Dongren Yang,Mingxue Gu,Yongnan Ji,Yueming Jin,Ren Zhao,Baiyong Shen,Daguang Xu*

Main category: cs.RO

TL;DR: 通过SurgWorld世界模型和SATA数据集，利用未标记手术视频生成合成配对视频-动作数据，训练出的手术VLA策略在真实手术机器人平台上显著优于仅使用真实演示训练的模型。


<details>
  <summary>Details</summary>
Motivation: 手术机器人领域面临数据稀缺问题，虽然有大量手术视频但缺乏对应的动作标签，无法直接应用模仿学习或VLA训练，而家庭和工业操作领域已通过多样化配对视频-动作数据实现了良好泛化能力。

Method: 1. 构建SATA数据集，包含手术机器人的详细动作描述；2. 基于最先进的物理AI世界模型和SATA构建SurgWorld，能生成多样化、可泛化且真实的手术视频；3. 首次使用逆动力学模型从合成手术视频推断伪运动学，生成合成配对视频-动作数据；4. 用这些增强数据训练手术VLA策略。

Result: 使用增强数据训练的手术VLA策略在真实手术机器人平台上显著优于仅使用真实演示训练的模型，为自主手术技能获取提供了可扩展路径。

Conclusion: 通过利用未标记手术视频和生成式世界建模，该方法为通用化和数据高效的手术机器人策略开辟了新途径，解决了手术机器人领域的数据稀缺问题。

Abstract: Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.

</details>


### [23] [A Human-Oriented Cooperative Driving Approach: Integrating Driving Intention, State, and Conflict](https://arxiv.org/abs/2512.23220)
*Qin Wang,Shanmin Pang,Jianwu Fang,Shengye Dong,Fuhao Liu,Jianru Xue,Chen Lv*

Main category: cs.RO

TL;DR: 提出了一种以人为导向的协同驾驶方法，通过意图感知轨迹规划和基于强化学习的控制权分配，减少人机冲突，提升驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 人车协同驾驶是实现完全自动驾驶的重要桥梁，但现有方法在人机交互自然性和有效性方面存在不足，需要减少人机冲突并建立驾驶员信任。

Method: 采用战术层和操作层双层次方法：战术层设计意图感知轨迹规划，使用意图一致性成本评估轨迹；操作层开发基于强化学习的控制权分配策略，通过奖励函数优化策略。

Result: 仿真和人在环实验表明，该方法在轨迹规划上与驾驶员意图一致，实现合理的控制权分配，相比其他协同驾驶方法显著提升驾驶性能并减少人机冲突。

Conclusion: 提出的以人为导向的协同驾驶方法通过优先考虑驾驶员意图和状态，有效减少人机冲突，为向完全自动驾驶过渡提供了更自然的交互桥梁。

Abstract: Human-vehicle cooperative driving serves as a vital bridge to fully autonomous driving by improving driving flexibility and gradually building driver trust and acceptance of autonomous technology. To establish more natural and effective human-vehicle interaction, we propose a Human-Oriented Cooperative Driving (HOCD) approach that primarily minimizes human-machine conflict by prioritizing driver intention and state. In implementation, we take both tactical and operational levels into account to ensure seamless human-vehicle cooperation. At the tactical level, we design an intention-aware trajectory planning method, using intention consistency cost as the core metric to evaluate the trajectory and align it with driver intention. At the operational level, we develop a control authority allocation strategy based on reinforcement learning, optimizing the policy through a designed reward function to achieve consistency between driver state and authority allocation. The results of simulation and human-in-the-loop experiments demonstrate that our proposed approach not only aligns with driver intention in trajectory planning but also ensures a reasonable authority allocation. Compared to other cooperative driving approaches, the proposed HOCD approach significantly enhances driving performance and mitigates human-machine conflict.The code is available at https://github.com/i-Qin/HOCD.

</details>


### [24] [Beyond Coverage Path Planning: Can UAV Swarms Perfect Scattered Regions Inspections?](https://arxiv.org/abs/2512.23257)
*Socratis Gkelios,Savvas D. Apostolidis,Pavlos Ch. Kapoutsis,Elias B. Kosmatopoulos,Athanasios Ch. Kapoutsis*

Main category: cs.RO

TL;DR: 本文针对无人机在多个分散区域进行快速巡检的问题，提出了mUDAI方法，通过优化图像采集位置和飞行轨迹，平衡数据分辨率与操作时间，减少冗余数据收集和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 无人机在巡检任务中面临电池限制问题，现有覆盖路径规划方法在检查多个非连接区域时效率低下，需要开发优化的飞行路径和数据采集技术。

Method: 提出mUDAI方法，采用双重优化程序：计算最佳图像采集位置和最高效的无人机轨迹，平衡数据分辨率和操作时间，最小化冗余数据收集和资源消耗。

Result: 通过仿真评估和实际部署验证，该方法能够提高操作效率，同时保持高质量数据采集，在安全基础设施评估、农业检查和应急现场评估等应用中表现有效。

Conclusion: mUDAI方法能够实现分散区域的快速高效巡检，提供了开源Python实现、实验数据和在线平台，便于研究人员和从业者使用和扩展。

Abstract: Unmanned Aerial Vehicles (UAVs) have revolutionized inspection tasks by offering a safer, more efficient, and flexible alternative to traditional methods. However, battery limitations often constrain their effectiveness, necessitating the development of optimized flight paths and data collection techniques. While existing approaches like coverage path planning (CPP) ensure comprehensive data collection, they can be inefficient, especially when inspecting multiple non connected Regions of Interest (ROIs). This paper introduces the Fast Inspection of Scattered Regions (FISR) problem and proposes a novel solution, the multi UAV Disjoint Areas Inspection (mUDAI) method. The introduced approach implements a two fold optimization procedure, for calculating the best image capturing positions and the most efficient UAV trajectories, balancing data resolution and operational time, minimizing redundant data collection and resource consumption. The mUDAI method is designed to enable rapid, efficient inspections of scattered ROIs, making it ideal for applications such as security infrastructure assessments, agricultural inspections, and emergency site evaluations. A combination of simulated evaluations and real world deployments is used to validate and quantify the method's ability to improve operational efficiency while preserving high quality data capture, demonstrating its effectiveness in real world operations. An open source Python implementation of the mUDAI method can be found on GitHub (https://github.com/soc12/mUDAI) and the collected and processed data from the real world experiments are all hosted on Zenodo (https://zenodo.org/records/13866483). Finally, this online platform (https://sites.google.com/view/mudai-platform/) allows interested readers to interact with the mUDAI method and generate their own multi UAV FISR missions.

</details>


### [25] [PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering](https://arxiv.org/abs/2512.23318)
*Sheng-Kai Chen,Jie-Yu Chao,Jr-Yu Chang,Po-Lien Wu,Po-Chiang Lin*

Main category: cs.RO

TL;DR: PCR-ORB是一种增强的ORB-SLAM3框架，通过深度学习点云精炼和YOLOv8语义分割来减少动态物体对vSLAM系统的干扰，在KITTI数据集上部分序列表现优异但效果存在场景依赖性。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的移动物体严重影响了视觉SLAM系统的跟踪精度和地图一致性，传统方法难以有效处理动态物体干扰，需要更智能的解决方案来提升系统在复杂环境中的鲁棒性。

Method: 提出PCR-ORB框架，集成深度学习点云精炼技术，使用YOLOv8进行语义分割，结合CUDA加速实现实时处理，采用多阶段过滤策略包括地面平面估计、天空区域移除、边缘过滤和时间一致性验证。

Result: 在KITTI数据集序列00-09上的评估显示混合性能，部分序列表现显著提升，如序列04的ATE RMSE改善25.9%，ATE中值改善30.4%，但效果因场景而异，表明方法的有效性具有场景依赖性。

Conclusion: PCR-ORB框架通过深度学习点云精炼有效减轻了动态物体对vSLAM系统的干扰，为复杂环境中的鲁棒导航提供了有价值的见解，但性能受场景影响，需要进一步优化以适应更广泛的环境条件。

Abstract: Visual Simultaneous Localization and Mapping (vSLAM) systems encounter substantial challenges in dynamic environments where moving objects compromise tracking accuracy and map consistency. This paper introduces PCR-ORB (Point Cloud Refinement ORB), an enhanced ORB-SLAM3 framework that integrates deep learning-based point cloud refinement to mitigate dynamic object interference. Our approach employs YOLOv8 for semantic segmentation combined with CUDA-accelerated processing to achieve real-time performance. The system implements a multi-stage filtering strategy encompassing ground plane estimation, sky region removal, edge filtering, and temporal consistency validation. Comprehensive evaluation on the KITTI dataset (sequences 00-09) demonstrates performance characteristics across different environmental conditions and scene types. Notable improvements are observed in specific sequences, with sequence 04 achieving 25.9% improvement in ATE RMSE and 30.4% improvement in ATE median. However, results show mixed performance across sequences, indicating scenario-dependent effectiveness. The implementation provides insights into dynamic object filtering challenges and opportunities for robust navigation in complex environments.

</details>


### [26] [Theory of Mind for Explainable Human-Robot Interaction](https://arxiv.org/abs/2512.23482)
*Marie Bauer,Julia Gachot,Matthias Kerzel,Cornelius Weber,Stefan Wermter*

Main category: cs.RO

TL;DR: 该论文提出将人机交互中的心智理论视为可解释人工智能的一种形式，通过VXAI框架评估，以解决当前ToM方法缺乏验证解释与机器人实际推理对应性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互中的心智理论方法存在一个关键缺陷：很少评估解释是否与机器人的实际内部推理相符。同时，现有可解释人工智能研究主要关注AI系统本身，缺乏以用户为中心的解释。

Method: 提出将心智理论整合到可解释人工智能框架中，特别是通过eValuation XAI框架及其七个期望特性来评估ToM。通过将ToM原则嵌入XAI，实现视角转变，从系统为中心转向用户为中心。

Result: 通过将ToM视为XAI的一种形式，能够更好地评估解释的准确性，并确保机器人提供的解释与其实际推理过程一致，从而提高人机交互的透明度和可信度。

Conclusion: 将心智理论整合到可解释人工智能框架中可以解决当前ToM方法的关键局限性，实现从系统为中心到用户为中心的转变，提升人机交互的解释质量和用户体验。

Abstract: Within the context of human-robot interaction (HRI), Theory of Mind (ToM) is intended to serve as a user-friendly backend to the interface of robotic systems, enabling robots to infer and respond to human mental states. When integrated into robots, ToM allows them to adapt their internal models to users' behaviors, enhancing the interpretability and predictability of their actions. Similarly, Explainable Artificial Intelligence (XAI) aims to make AI systems transparent and interpretable, allowing humans to understand and interact with them effectively. Since ToM in HRI serves related purposes, we propose to consider ToM as a form of XAI and evaluate it through the eValuation XAI (VXAI) framework and its seven desiderata. This paper identifies a critical gap in the application of ToM within HRI, as existing methods rarely assess the extent to which explanations correspond to the robot's actual internal reasoning. To address this limitation, we propose to integrate ToM within XAI frameworks. By embedding ToM principles inside XAI, we argue for a shift in perspective, as current XAI research focuses predominantly on the AI system itself and often lacks user-centered explanations. Incorporating ToM would enable a change in focus, prioritizing the user's informational needs and perspective.

</details>


### [27] [Robust Deep Learning Control with Guaranteed Performance for Safe and Reliable Robotization in Heavy-Duty Machinery](https://arxiv.org/abs/2512.23505)
*Mehdi Heydari Shahna*

Main category: cs.RO

TL;DR: 该论文开发了一个控制框架，用于简化重型移动机械的电气化控制设计，并通过分层控制策略在保证安全的前提下部分集成人工智能。


<details>
  <summary>Details</summary>
Motivation: 重型移动机械面临两个转型：从柴油液压驱动转向清洁电气系统，以及从人工监督转向更高自主性。但完全电气化面临技术经济挑战，而人工智能在重型机械中的应用受限于严格的安全要求。

Method: 开发了一个通用模块化控制框架，包含：(1) 能源独立的通用控制设计方法；(2) 分层控制策略，在保证安全性能的前提下部分集成AI；(3) 针对多体重型机械的鲁棒控制策略；(4) 在不确定性和故障下保持严格性能的控制方案；(5) 解释和信任黑盒学习策略的方法。

Result: 框架在三个案例研究中验证，涵盖不同执行器和条件，包括重型移动机器人和机械臂。成果发表在五篇同行评审论文和一篇未发表手稿中，推进了非线性控制和机器人技术。

Conclusion: 该控制框架支持重型移动机械的双重转型，简化了电气化控制设计，同时通过安全保证的分层策略实现了AI的部分集成，为行业转型提供了技术基础。

Abstract: Today's heavy-duty mobile machines (HDMMs) face two transitions: from diesel-hydraulic actuation to clean electric systems driven by climate goals, and from human supervision toward greater autonomy. Diesel-hydraulic systems have long dominated, so full electrification, via direct replacement or redesign, raises major technical and economic challenges. Although advanced artificial intelligence (AI) could enable higher autonomy, adoption in HDMMs is limited by strict safety requirements, and these machines still rely heavily on human supervision.
  This dissertation develops a control framework that (1) simplifies control design for electrified HDMMs through a generic modular approach that is energy-source independent and supports future modifications, and (2) defines hierarchical control policies that partially integrate AI while guaranteeing safety-defined performance and stability.
  Five research questions align with three lines of investigation: a generic robust control strategy for multi-body HDMMs with strong stability across actuation types and energy sources; control solutions that keep strict performance under uncertainty and faults while balancing robustness and responsiveness; and methods to interpret and trust black-box learning strategies so they can be integrated stably and verified against international safety standards.
  The framework is validated in three case studies spanning different actuators and conditions, covering heavy-duty mobile robots and robotic manipulators. Results appear in five peer-reviewed publications and one unpublished manuscript, advancing nonlinear control and robotics and supporting both transitions.

</details>


### [28] [Act2Goal: From World Model To General Goal-conditioned Policy](https://arxiv.org/abs/2512.23541)
*Pengfei Zhou,Liliang Chen,Shengcong Chen,Di Chen,Wenzhi Zhao,Rongjun Jin,Guanghui Ren,Jianlan Luo*

Main category: cs.RO

TL;DR: Act2Goal：一种结合目标条件视觉世界模型与多尺度时间控制的通用目标条件操作策略，通过生成中间视觉状态序列实现长时程操作，并利用多尺度时间哈希分解轨迹进行精细控制


<details>
  <summary>Details</summary>
Motivation: 现有目标条件策略在长时程操作任务中存在局限性，主要依赖单步动作预测而缺乏对任务进度的显式建模，需要更表达性和精确的任务规范方法

Method: 提出Act2Goal框架：1）目标条件视觉世界模型生成合理的中间视觉状态序列；2）多尺度时间哈希（MSTH）将想象轨迹分解为密集近端帧（精细闭环控制）和稀疏远端帧（全局任务一致性）；3）通过端到端交叉注意力耦合表示与运动控制

Result: 在零样本泛化方面表现优异，能适应新物体、空间布局和环境；通过事后目标重标记和LoRA微调实现无奖励在线适应；真实机器人实验中，在具有挑战性的分布外任务上成功率从30%提升至90%

Conclusion: 目标条件世界模型与多尺度时间控制相结合，为鲁棒的长时程操作提供了必要的结构化指导，实现了表达性和精确的任务规范

Abstract: Specifying robotic manipulation tasks in a manner that is both expressive and precise remains a central challenge. While visual goals provide a compact and unambiguous task specification, existing goal-conditioned policies often struggle with long-horizon manipulation due to their reliance on single-step action prediction without explicit modeling of task progress. We propose Act2Goal, a general goal-conditioned manipulation policy that integrates a goal-conditioned visual world model with multi-scale temporal control. Given a current observation and a target visual goal, the world model generates a plausible sequence of intermediate visual states that captures long-horizon structure. To translate this visual plan into robust execution, we introduce Multi-Scale Temporal Hashing (MSTH), which decomposes the imagined trajectory into dense proximal frames for fine-grained closed-loop control and sparse distal frames that anchor global task consistency. The policy couples these representations with motor control through end-to-end cross-attention, enabling coherent long-horizon behavior while remaining reactive to local disturbances. Act2Goal achieves strong zero-shot generalization to novel objects, spatial layouts, and environments. We further enable reward-free online adaptation through hindsight goal relabeling with LoRA-based finetuning, allowing rapid autonomous improvement without external supervision. Real-robot experiments demonstrate that Act2Goal improves success rates from 30% to 90% on challenging out-of-distribution tasks within minutes of autonomous interaction, validating that goal-conditioned world models with multi-scale temporal control provide structured guidance necessary for robust long-horizon manipulation. Project page: https://act2goal.github.io/

</details>


### [29] [Soft Robotic Technological Probe for Speculative Fashion Futures](https://arxiv.org/abs/2512.23570)
*Amy Ingold,Loong Yi Lee,Richard Suphapol Diteesawat,Ajmal Roshan,Yael Zekaria,Edith-Clare Hall,Enrico Werner,Nahian Rahman,Elaine Czech,Jonathan Rossiter*

Main category: cs.RO

TL;DR: Sumbrella是一款软机器人服装，作为推测性时尚探针，探索可穿戴机器人技术的社会意义和伦理影响。


<details>
  <summary>Details</summary>
Motivation: 新兴的可穿戴机器人技术需要不仅关注功能，还要考虑社会意义的设计方法。研究旨在探索软机器人服装如何影响社会互动、伦理接受度以及公共生活中的可接受性。

Method: 设计并制造了Sumbrella软机器人服装，包含序列化折纸启发的双稳态单元、织物气动驱动室、线缆驱动形状变形机制、计算机视觉组件，以及集成在帽子和夹克中的电源控制系统。通过12名创意技术专家的焦点小组，将其作为技术探针来探索人们对软机器人可穿戴设备的理解、互动和未来关系想象。

Result: 参与者围绕推测性未来和表达潜力进行了丰富讨论，但也提出了对剥削、监控以及将生物传感技术嵌入公共生活的个人风险和社会伦理的担忧。研究为HRI领域贡献了设计软机器人服装的关键考虑因素和建议。

Conclusion: 推测性设计方法使HRI研究人员不仅能考虑功能性，还能探索可穿戴机器人如何影响公共环境中可接受或理想行为的定义。研究强调了运动交流潜力、技术对社会动态的影响以及伦理指南的重要性。

Abstract: Emerging wearable robotics demand design approaches that address not only function, but also social meaning. In response, we present Sumbrella, a soft robotic garment developed as a speculative fashion probe. We first detail the design and fabrication of the Sumbrella, including sequenced origami-inspired bistable units, fabric pneumatic actuation chambers, cable driven shape morphing mechanisms, computer vision components, and an integrated wearable system comprising a hat and bolero jacket housing power and control electronics. Through a focus group with twelve creative technologists, we then used Sumbrella as a technological probe to explore how people interpreted, interacted, and imagined future relationships with soft robotic wearables. While Sumbrella allowed our participants to engage in rich discussion around speculative futures and expressive potential, it also surfaced concerns about exploitation, surveillance, and the personal risks and societal ethics of embedding biosensing technologies in public life. We contribute to the Human-Robot Interaction (HRI) field key considerations and recommendations for designing soft robotic garments, including the potential for kinesic communication, the impact of such technologies on social dynamics, and the importance of ethical guidelines. Finally, we provide a reflection on our application of speculative design; proposing that it allows HRI researchers to not only consider functionality, but also how wearable robots influence definitions of what is considered acceptable or desirable in public settings.

</details>


### [30] [A Kalman Filter-Based Disturbance Observer for Steer-by-Wire Systems](https://arxiv.org/abs/2512.23593)
*Nikolai Beving,Jonas Marxen,Steffen Mueller,Johannes Betz*

Main category: cs.RO

TL;DR: 本文提出了一种基于卡尔曼滤波的扰动观测器，用于估计线控转向系统中的高频驾驶员扭矩扰动，仅使用电机状态测量，无需昂贵的扭矩传感器，实现了14ms延迟的准确估计。


<details>
  <summary>Details</summary>
Motivation: 线控转向系统虽然具有重量轻、设计灵活和兼容自动驾驶等优势，但容易受到驾驶员无意扭矩产生的高频扰动（驾驶员阻抗）影响，从而降低转向性能。现有方法要么依赖昂贵的直接扭矩传感器，要么缺乏捕捉快速高频驾驶员扰动的时间分辨率。

Method: 设计基于卡尔曼滤波的扰动观测器，使用PT1滞后近似将驾驶员被动扭矩建模为扩展状态，并将其集成到线性和非线性线控转向系统模型中。评估了不同的卡尔曼滤波器变体，包括非线性扩展卡尔曼滤波器来处理摩擦非线性。

Result: 提出的扰动观测器能够仅使用电机状态测量准确重建驾驶员引起的扰动，延迟仅为14ms。非线性扩展卡尔曼滤波器在处理从静态到动态摩擦的过渡时表现优于线性对应物，提高了估计精度。

Conclusion: 该方法成功解决了线控转向系统中高频驾驶员扭矩扰动的估计问题，无需昂贵的扭矩传感器。非线性扩展卡尔曼滤波器在处理摩擦非线性方面表现更佳。但由于研究方法限制，仅进行了仿真验证，未来需要在实际驾驶条件下研究观测器的鲁棒性。

Abstract: Steer-by-Wire systems replace mechanical linkages, which provide benefits like weight reduction, design flexibility, and compatibility with autonomous driving. However, they are susceptible to high-frequency disturbances from unintentional driver torque, known as driver impedance, which can degrade steering performance. Existing approaches either rely on direct torque sensors, which are costly and impractical, or lack the temporal resolution to capture rapid, high-frequency driver-induced disturbances. We address this limitation by designing a Kalman filter-based disturbance observer that estimates high-frequency driver torque using only motor state measurements. We model the drivers passive torque as an extended state using a PT1-lag approximation and integrate it into both linear and nonlinear Steer-by-Wire system models. In this paper, we present the design, implementation and simulation of this disturbance observer with an evaluation of different Kalman filter variants. Our findings indicate that the proposed disturbance observer accurately reconstructs driver-induced disturbances with only minimal delay 14ms. We show that a nonlinear extended Kalman Filter outperforms its linear counterpart in handling frictional nonlinearities, improving estimation during transitions from static to dynamic friction. Given the study's methodology, it was unavoidable to rely on simulation-based validation rather than real-world experimentation. Further studies are needed to investigate the robustness of the observers under real-world driving conditions.

</details>


### [31] [Interactive Robot Programming for Surface Finishing via Task-Centric Mixed Reality Interfaces](https://arxiv.org/abs/2512.23616)
*Christoph Willibald,Lugh Martensen,Thomas Eiband,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出了一种面向非专家的机器人编程方法，通过交互式任务导向工作流程，让用户直观地编程机器人进行表面处理任务


<details>
  <summary>Details</summary>
Motivation: 当前机器人部署需要专业知识，设置过程复杂，这阻碍了机器人在高产品变异性和小批量生产环境中的应用。协作机器人虽然具备先进的传感和控制能力，但在小型工艺和制造场景中很少用于表面处理任务。

Method: 开发了一种新的表面分割算法，结合人工输入来识别和细化工件处理区域。在整个编程过程中，用户通过连续视觉反馈了解机器人学习模型，可以迭代优化分割结果。基于分割后的表面模型，生成机器人轨迹以覆盖目标处理区域。通过两个全面的用户研究评估了多种交互设计。

Result: 通过用户研究得出了最优界面设计，显著降低了用户工作负荷，提高了可用性，即使对于实践经验有限的用户也能实现有效的任务编程。

Conclusion: 提出的机器人编程方法通过交互式任务导向工作流程，使非专家用户能够直观地编程机器人进行表面处理任务，解决了机器人部署中的专业知识障碍问题。

Abstract: Lengthy setup processes that require robotics expertise remain a major barrier to deploying robots for tasks involving high product variability and small batch sizes. As a result, collaborative robots, despite their advanced sensing and control capabilities, are rarely used for surface finishing in small-scale craft and manufacturing settings. To address this gap, we propose a novel robot programming approach that enables non-experts to intuitively program robots through interactive, task-focused workflows. For that, we developed a new surface segmentation algorithm that incorporates human input to identify and refine workpiece regions for processing. Throughout the programming process, users receive continuous visual feedback on the robot's learned model, enabling them to iteratively refine the segmentation result. Based on the segmented surface model, a robot trajectory is generated to cover the desired processing area. We evaluated multiple interaction designs across two comprehensive user studies to derive an optimal interface that significantly reduces user workload, improves usability and enables effective task programming even for users with limited practical experience.

</details>


### [32] [The N-5 Scaling Law: Topological Dimensionality Reduction in the Optimal Design of Fully-actuated Multirotors](https://arxiv.org/abs/2512.23619)
*Antonio Franchi*

Main category: cs.RO

TL;DR: 论文研究N旋翼飞行器的几何设计，发现最优配置空间具有拓扑结构，受底盘对称性影响，存在N-5缩放定律，允许保持最优各向同性控制能力的连续重构。


<details>
  <summary>Details</summary>
Motivation: 传统N旋翼飞行器设计采用参数优化方法寻找单一最优解，本文旨在探索优化景观的固有拓扑结构，揭示设计空间的本质特性。

Method: 在投影线乘积流形RP^2^N上建立设计问题，固定转子位置于多面体底盘顶点，变化作用线方向，最小化坐标不变的Log-Volume各向同性度量。

Result: 发现全局最优解的拓扑结构严格受底盘对称性支配：不规则顶点排列产生离散孤立点；规则几何导致相变，形成N维环面；提出N-5缩放定律，最优配置空间由K=N-5个不连通的1维拓扑分支组成。

Conclusion: 拓扑结构揭示了设计冗余性，允许最优保持的形态变化：飞行器可沿这些分支连续重构，同时保持最优的各向同性控制能力，为N旋翼飞行器设计提供了新的理论框架。

Abstract: The geometric design of fully-actuated and omnidirectional N-rotor aerial vehicles is conventionally formulated as a parametric optimization problem, seeking a single optimal set of N orientations within a fixed architectural family. This work departs from that paradigm to investigate the intrinsic topological structure of the optimization landscape itself. We formulate the design problem on the product manifold of Projective Lines \RP^2^N, fixing the rotor positions to the vertices of polyhedral chassis while varying their lines of action. By minimizing a coordinate-invariant Log-Volume isotropy metric, we reveal that the topology of the global optima is governed strictly by the symmetry of the chassis. For generic (irregular) vertex arrangements, the solutions appear as a discrete set of isolated points. However, as the chassis geometry approaches regularity, the solution space undergoes a critical phase transition, collapsing onto an N-dimensional Torus of the lines tangent at the vertexes to the circumscribing sphere of the chassis, and subsequently reducing to continuous 1-dimensional curves driven by Affine Phase Locking. We synthesize these observations into the N-5 Scaling Law: an empirical relationship holding for all examined regular planar polygons and Platonic solids (N <= 10), where the space of optimal configurations consists of K=N-5 disconnected 1D topological branches. We demonstrate that these locking patterns correspond to a sequence of admissible Star Polygons {N/q}, allowing for the exact prediction of optimal phases for arbitrary N. Crucially, this topology reveals a design redundancy that enables optimality-preserving morphing: the vehicle can continuously reconfigure along these branches while preserving optimal isotropic control authority.

</details>


### [33] [RoboMirror: Understand Before You Imitate for Video to Humanoid Locomotion](https://arxiv.org/abs/2512.23649)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Tao Huang,Zhenguo Sun,Yibo Peng,Pengwei Wang,Zhongyuan Wang,Fangzhou Liu,Chang Xu,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboMirror是一个无需重定向的视频到运动框架，通过视觉语言模型理解视频中的运动意图，直接控制人形机器人进行物理合理的运动，无需显式的姿态重建或重定向。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人运动系统依赖运动捕捉轨迹或文本指令，存在视觉理解与控制之间的鸿沟。文本到运动方法存在语义稀疏性和流水线错误，而基于视频的方法只进行机械的姿态模仿，缺乏真正的视觉理解。

Method: 提出RoboMirror框架，利用视觉语言模型从原始第一人称/第三人称视频中提取视觉运动意图，这些意图直接条件化基于扩散的策略，生成物理合理、语义对齐的运动，无需显式姿态重建或重定向。

Result: 实验验证了RoboMirror的有效性：通过第一人称视频实现远程呈现，将第三人称控制延迟降低80%，任务成功率比基线方法提高3.7%。

Conclusion: 通过围绕视频理解重新构建人形机器人控制，RoboMirror弥合了视觉理解与行动之间的鸿沟，实现了"先理解后模仿"的范式。

Abstract: Humans learn locomotion through visual observation, interpreting visual content first before imitating actions. However, state-of-the-art humanoid locomotion systems rely on either curated motion capture trajectories or sparse text commands, leaving a critical gap between visual understanding and control. Text-to-motion methods suffer from semantic sparsity and staged pipeline errors, while video-based approaches only perform mechanical pose mimicry without genuine visual understanding. We propose RoboMirror, the first retargeting-free video-to-locomotion framework embodying "understand before you imitate". Leveraging VLMs, it distills raw egocentric/third-person videos into visual motion intents, which directly condition a diffusion-based policy to generate physically plausible, semantically aligned locomotion without explicit pose reconstruction or retargeting. Extensive experiments validate the effectiveness of RoboMirror, it enables telepresence via egocentric videos, drastically reduces third-person control latency by 80%, and achieves a 3.7% higher task success rate than baselines. By reframing humanoid control around video understanding, we bridge the visual understanding and action gap.

</details>


### [34] [Do You Have Freestyle? Expressive Humanoid Locomotion via Audio Control](https://arxiv.org/abs/2512.23650)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Tao Huang,Zhenguo Sun,Yibo Peng,Pengwei Wang,Zhongyuan Wang,Fangzhou Liu,Chang Xu,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboPerform：首个统一的音频到运动框架，可直接从音频生成音乐驱动的舞蹈和语音驱动的协同手势，无需显式运动重建，实现低延迟和高保真度。


<details>
  <summary>Details</summary>
Motivation: 人类能直觉地随声音移动，但现有人形机器人缺乏即兴表达能力，局限于预定义动作或稀疏指令。现有方法依赖显式运动重建，导致级联错误、高延迟和声学-驱动映射不连贯。

Method: 基于"运动=内容+风格"的核心原则，将音频视为隐式风格信号，无需显式运动重建。采用ResMoE教师策略适应多样化运动模式，结合扩散式学生策略进行音频风格注入。

Result: 实验验证显示RoboPerform在物理合理性和音频对齐方面取得有希望的结果，成功将机器人转变为能够响应音频的表演者。

Conclusion: RoboPerform通过免重定向设计实现了低延迟和高保真度，为机器人提供了表达性即兴表演能力，将音频直接转化为自然运动。

Abstract: Humans intuitively move to sound, but current humanoid robots lack expressive improvisational capabilities, confined to predefined motions or sparse commands. Generating motion from audio and then retargeting it to robots relies on explicit motion reconstruction, leading to cascaded errors, high latency, and disjointed acoustic-actuation mapping. We propose RoboPerform, the first unified audio-to-locomotion framework that can directly generate music-driven dance and speech-driven co-speech gestures from audio. Guided by the core principle of "motion = content + style", the framework treats audio as implicit style signals and eliminates the need for explicit motion reconstruction. RoboPerform integrates a ResMoE teacher policy for adapting to diverse motion patterns and a diffusion-based student policy for audio style injection. This retargeting-free design ensures low latency and high fidelity. Experimental validation shows that RoboPerform achieves promising results in physical plausibility and audio alignment, successfully transforming robots into responsive performers capable of reacting to audio.

</details>


### [35] [The Bulldozer Technique: Efficient Elimination of Local Minima Traps for APF-Based Robot Navigation](https://arxiv.org/abs/2512.23672)
*Mohammed Baziyad,Manal Al Shohna,Tamer Rabie*

Main category: cs.RO

TL;DR: 本文提出了一种名为"推土机"的新型路径规划技术，通过后填充机制解决人工势场法中的局部极小值陷阱问题，同时保持了APF的实时响应和低计算成本优势。


<details>
  <summary>Details</summary>
Motivation: 人工势场法在自主移动机器人路径规划中因简单、实时响应和低计算需求而广受欢迎，但其主要局限是局部极小值陷阱问题，机器人会陷入无法向目标前进的位置。需要一种既能解决此问题又能保持APF优势的方法。

Method: 提出"推土机"技术，引入后填充机制系统性地识别并消除局部极小值区域，通过增加其势能值来填充这些"坑洞"。还加入了斜坡增强机制，帮助机器人从局部极小值区域中逃脱。使用物理移动机器人在不同复杂度地图上进行实验验证。

Result: 与标准APF、自适应APF以及A*、PRM、RRT等成熟算法比较，推土机技术有效解决了局部极小值问题，同时实现了更优的执行速度和具有竞争力的路径质量。通过运动学跟踪控制器评估，确认规划路径平滑且适合实际执行。

Conclusion: 推土机技术成功解决了人工势场法的局部极小值陷阱问题，同时保持了APF的实时响应和低计算成本优势，为实际机器人导航提供了有效的路径规划解决方案。

Abstract: Path planning is a fundamental component in autonomous mobile robotics, enabling a robot to navigate from its current location to a desired goal while avoiding obstacles. Among the various techniques, Artificial Potential Field (APF) methods have gained popularity due to their simplicity, real-time responsiveness, and low computational requirements. However, a major limitation of conventional APF approaches is the local minima trap problem, where the robot becomes stuck in a position with no clear direction toward the goal. This paper proposes a novel path planning technique, termed the Bulldozer, which addresses the local minima issue while preserving the inherent advantages of APF. The Bulldozer technique introduces a backfilling mechanism that systematically identifies and eliminates local minima regions by increasing their potential values, analogous to a bulldozer filling potholes in a road. Additionally, a ramp-based enhancement is incorporated to assist the robot in escaping trap areas when starting within a local minimum. The proposed technique is experimentally validated using a physical mobile robot across various maps with increasing complexity. Comparative analyses are conducted against standard APF, adaptive APF, and well-established planning algorithms such as A*, PRM, and RRT. Results demonstrate that the Bulldozer technique effectively resolves the local minima problem while achieving superior execution speed and competitive path quality. Furthermore, a kinematic tracking controller is employed to assess the smoothness and traceability of the planned paths, confirming their suitability for real-world execution.

</details>


### [36] [Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation](https://arxiv.org/abs/2512.23703)
*Huajie Tan,Sixiang Chen,Yijie Xu,Zixiao Wang,Yuheng Ji,Cheng Chi,Yaoxu Lyu,Zhongxia Zhao,Xiansheng Chen,Peterson Co,Shaoxuan Xie,Guocai Yao,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: Dopamine-Reward提出了一种新颖的奖励建模方法，通过多视角输入学习通用、步骤感知的过程奖励模型，解决了传统RL在机器人应用中奖励函数设计的核心问题。


<details>
  <summary>Details</summary>
Motivation: 将强化学习应用于真实世界机器人的主要障碍是设计有效的奖励函数。现有的基于学习的过程奖励模型存在两个根本性限制：缺乏步骤感知理解能力、依赖单视角感知导致对精细操作进展评估不可靠；奖励塑造过程理论不健全，常导致误导策略优化的语义陷阱。

Method: 提出Dopamine-Reward方法，核心是通用奖励模型（GRM），在3400+小时数据集上训练，采用步骤奖励离散化实现结构化理解，多视角奖励融合克服感知限制。基于此提出Dopamine-RL框架，采用理论健全的策略不变奖励塑造方法，使智能体能够利用密集奖励进行高效自我改进而不改变最优策略。

Result: GRM在奖励评估方面达到最先进准确率，基于GRM的Dopamine-RL显著提高策略学习效率。GRM通过单次专家轨迹适应新任务后，奖励模型使Dopamine-RL仅用150次在线rollout（约1小时真实机器人交互）就能将策略成功率从接近零提升到95%，并保持跨任务的强泛化能力。

Conclusion: Dopamine-Reward通过创新的步骤感知奖励建模和多视角融合，结合理论健全的奖励塑造方法，有效解决了机器人强化学习中的奖励设计难题，实现了高效、可靠的策略学习，为真实世界机器人应用提供了实用解决方案。

Abstract: The primary obstacle for applying reinforcement learning (RL) to real-world robotics is the design of effective reward functions. While recently learning-based Process Reward Models (PRMs) are a promising direction, they are often hindered by two fundamental limitations: their reward models lack step-aware understanding and rely on single-view perception, leading to unreliable assessments of fine-grained manipulation progress; and their reward shaping procedures are theoretically unsound, often inducing a semantic trap that misguides policy optimization. To address these, we introduce Dopamine-Reward, a novel reward modeling method for learning a general-purpose, step-aware process reward model from multi-view inputs. At its core is our General Reward Model (GRM), trained on a vast 3,400+ hour dataset, which leverages Step-wise Reward Discretization for structural understanding and Multi-Perspective Reward Fusion to overcome perceptual limitations. Building upon Dopamine-Reward, we propose Dopamine-RL, a robust policy learning framework that employs a theoretically-sound Policy-Invariant Reward Shaping method, which enables the agent to leverage dense rewards for efficient self-improvement without altering the optimal policy, thereby fundamentally avoiding the semantic trap. Extensive experiments across diverse simulated and real-world tasks validate our approach. GRM achieves state-of-the-art accuracy in reward assessment, and Dopamine-RL built on GRM significantly improves policy learning efficiency. For instance, after GRM is adapted to a new task in a one-shot manner from a single expert trajectory, the resulting reward model enables Dopamine-RL to improve the policy from near-zero to 95% success with only 150 online rollouts (approximately 1 hour of real robot interaction), while retaining strong generalization across tasks. Project website: https://robo-dopamine.github.io

</details>
