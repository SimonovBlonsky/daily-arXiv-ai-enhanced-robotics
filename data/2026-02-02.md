<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Advanced techniques and applications of LiDAR Place Recognition in Agricultural Environments: A Comprehensive Survey](https://arxiv.org/abs/2601.22198)
*Judith Vilella-Cantos,Mónica Ballesta,David Valiente,María Flores,Luis Payá*

Main category: cs.RO

TL;DR: 本文是第一篇专注于农业环境中基于LiDAR定位的综述，分析了深度学习在农业环境中的应用和LiDAR地点识别技术，讨论了该领域的挑战、现有方法、数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 精准农业是能够从自主机器人系统中获益最多的领域之一，但农业环境缺乏显著特征且结构非结构化，使得地点识别具有挑战性。虽然LiDAR地点识别技术近年来被广泛用于实现精确定位，但主要应用于城市环境，农业环境中的研究相对缺乏。

Method: 本文采用综述研究方法，全面回顾了农业环境中深度学习应用和LiDAR地点识别技术的最新进展。重点分析了这些环境中出现的挑战，评估了现有方法、数据集和性能评估指标。

Result: 这是第一篇专注于农业环境中基于LiDAR定位的综述，系统分析了该领域的现状和挑战。研究发现农业环境的地点识别面临独特困难，现有方法、数据集和评估指标需要针对农业特点进行专门设计。

Conclusion: 农业环境中的LiDAR定位研究具有重要价值但面临特殊挑战。本文为这一专门领域提供了全面理解，并指出了未来研究方向，旨在促进该领域的进一步研究发展。

Abstract: An optimal solution to the localization problem is essential for developing autonomous robotic systems. Apart from autonomous vehicles, precision agriculture is one of the elds that can bene t most from these systems. Although LiDAR place recognition is a widely used technique in recent years to achieve accurate localization, it is mostly used in urban settings. However, the lack of distinctive features and the unstructured nature of agricultural environments make place recognition challenging. This work presents a comprehensive review of state-of-the-art the latest deep learning applications for agricultural environments and LPR techniques. We focus on the challenges that arise in these environments. We analyze the existing approaches, datasets, and metrics used to evaluate LPR system performance and discuss the limitations and future directions of research in this eld. This is the rst survey that focuses on LiDAR based localization in agricultural settings, with the aim of providing a thorough understanding and fostering further research in this specialized domain.

</details>


### [2] [ReloPush-BOSS: Optimization-guided Nonmonotone Rearrangement Planning for a Car-like Robot Pusher](https://arxiv.org/abs/2601.22289)
*Jeeho Ahn,Christoforos Mavrogiannis*

Main category: cs.RO

TL;DR: 本文提出ReloPush-BOSS框架，用于在密集杂乱环境中使用类车机器人推动器进行多物体重排规划，通过优化的预重定位和Dubins路径分类避免局部最优，实现高效可行的重排序列。


<details>
  <summary>Details</summary>
Motivation: 在密集杂乱环境中使用类车机器人推动器进行多物体重排面临运动学、几何和物理约束的挑战，导致非单调问题实例，需要将操作动作分解为多个部分。现有方法通过预重定位解决约束满足问题，但预重定位位置决策困难，容易陷入局部最优导致不可行或高成本路径。

Method: 提出ReloPush-BOSS框架：1) 基于Dubins路径分类引导预重定位优化，避免局部最优；2) 构建包含运动学、几何和推动约束的物体可遍历图；3) 采用深度优先搜索该图，生成高效可行的重排序列。

Result: 在包含最多13个物体的密集杂乱场景测试中，ReloPush-BOSS相比现有基线方法展现出最高的成功率和最短的推动路径。在1/10比例类车推动器上的硬件实验验证了方法的鲁棒性。

Conclusion: 通过优化的预重定位和Dubins路径分类指导，ReloPush-BOSS框架能够有效解决密集杂乱环境中的多物体重排规划问题，在成功率和路径效率方面优于现有方法，并在实际硬件中验证了可行性。

Abstract: We focus on multi-object rearrangement planning in densely cluttered environments using a car-like robot pusher. The combination of kinematic, geometric and physics constraints underlying this domain results in challenging nonmonotone problem instances which demand breaking each manipulation action into multiple parts to achieve a desired object rearrangement. Prior work tackles such instances by planning prerelocations, temporary object displacements that enable constraint satisfaction, but deciding where to prerelocate remains difficult due to local minima leading to infeasible or high-cost paths. Our key insight is that these minima can be avoided by steering a prerelocation optimization toward low-cost regions informed by Dubins path classification. These optimized prerelocations are integrated into an object traversability graph that encodes kinematic, geometric, and pushing constraints. Searching this graph in a depth-first fashion results in efficient, feasible rearrangement sequences. Across a series of densely cluttered scenarios with up to 13 objects, our framework, ReloPush-BOSS, exhibits consistently highest success rates and shortest pushing paths compared to state-of-the-art baselines. Hardware experiments on a 1/10 car-like pusher demonstrate the robustness of our approach. Code and footage from our experiments can be found at: https://fluentrobotics.com/relopushboss.

</details>


### [3] [Lantern: A Minimalist Robotic Object Platform](https://arxiv.org/abs/2601.22381)
*Victor Nikhil Antony,Zhili Gong,Guanchen Li,Clara Jeon,Chien-Ming Huang*

Main category: cs.RO

TL;DR: Lantern是一个低成本、简约的机器人对象平台，旨在通过简单形式激发人类社交互动，降低人机交互研究门槛


<details>
  <summary>Details</summary>
Motivation: 设计一个低成本、简约的机器人平台，利用人类倾向于为简单形式赋予社交意义的特性，降低人机交互研究的门槛

Method: 通过深入的机电架构设计和工程迭代，开发Lantern平台（成本约40美元），并进行多项评估：协同设计工作坊、感官室案例研究、分发到外部HRI实验室、整合到研究生HRI课程、以及面向老年人和儿童的公共展览

Result: Lantern能有效激发参与度，支持从情绪调节到专注工作等多种应用，是一个可行的平台，能降低HRI领域的入门门槛

Conclusion: Lantern作为一个低成本、开源的简约机器人对象平台，成功展示了其在激发人类参与、支持多样化人机交互场景方面的潜力，有助于推动HRI领域的发展

Abstract: Robotic objects are simple actuated systems that subtly blend into human environments. We design and introduce Lantern, a minimalist robotic object platform to enable building simple robotic artifacts. We conducted in-depth design and engineering iterations of Lantern's mechatronic architecture to meet specific design goals while maintaining a low build cost (~40 USD). As an extendable, open-source platform, Lantern aims to enable exploration of a range of HRI scenarios by leveraging human tendency to assign social meaning to simple forms. To evaluate Lantern's potential for HRI, we conducted a series of explorations: 1) a co-design workshop, 2) a sensory room case study, 3) distribution to external HRI labs, 4) integration into a graduate-level HRI course, and 5) public exhibitions with older adults and children. Our findings show that Lantern effectively evokes engagement, can support versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to HRI as a field.

</details>


### [4] [Plant-Inspired Robot Design Metaphors for Ambient HRI](https://arxiv.org/abs/2601.22387)
*Victor Nikhil Antony,Adithya R N,Sarah Derrick,Zhili Gong,Peter M. Donley,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 论文探索以植物为隐喻灵感设计人机交互，通过研究通过设计方法开发植物启发的机器人原型，研究植物形态如何重塑人机交互范式。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互主要基于拟人化和拟动物化范式，产生高需求、显性的互动形式。而植物提供了另一种模型：环境性、低需求的存在，通过时间节奏和微妙表达塑造氛围、日常和关系。研究旨在探索植物作为人机交互的隐喻灵感。

Method: 采用研究通过设计方法，进行迭代的构思、原型制作和反思循环。通过原型中心工作坊探索人们对植物启发机器人的感知和想象，深化设计和原型制作的学习。

Result: 开发了一套推测性、开源的原型，探索植物启发的存在感、时间性、形态和手势。贡献包括：(1) 植物启发机器人制品集合；(2) 关于人们如何感知植物启发机器人的设计洞察；(3) 指导如何使用植物隐喻重塑人机交互的设计考虑。

Conclusion: 植物作为隐喻灵感为人机交互提供了新的设计范式，从高需求、显性互动转向环境性、低需求的存在，通过时间节奏和微妙表达塑造互动体验。

Abstract: Plants offer a paradoxical model for interaction: they are ambient, low-demand presences that nonetheless shape atmosphere, routines, and relationships through temporal rhythms and subtle expressions. In contrast, most human-robot interaction (HRI) has been grounded in anthropomorphic and zoomorphic paradigms, producing overt, high-demand forms of engagement. Using a Research through Design (RtD) methodology, we explore plants as metaphoric inspiration for HRI; we conducted iterative cycles of ideation, prototyping, and reflection to investigate what design primitives emerge from plant metaphors and morphologies, and how these primitives can be combined into expressive robotic forms. We present a suite of speculative, open-source prototypes that help probe plant-inspired presence, temporality, form, and gestures. We deepened our learnings from design and prototyping through prototype-centered workshops that explored people's perceptions and imaginaries of plant-inspired robots. This work contributes: (1) Set of plant-inspired robotic artifacts; (2) Designerly insights on how people perceive plant-inspired robots; and (3) Design consideration to inform how to use plant metaphors to reshape HRI.

</details>


### [5] [Accurate Pedestrian Tracking in Urban Canyons: A Multi-Modal Fusion Approach](https://arxiv.org/abs/2601.22406)
*Shahar Dubiner,Peng Ren,Roberto Manduchi*

Main category: cs.RO

TL;DR: 提出了一种结合GNSS、惯性数据和地图先验的粒子滤波融合方法，用于城市环境中行人导航定位，特别针对GNSS信号受限场景，显著提升了定位精度和街道侧判断准确性。


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中GNSS性能下降导致的定位不准确问题，特别是对盲人或低视力用户来说，精确识别街道正确侧至关重要。传统基于摄像头的视觉定位方法不实用，需要一种能融合多种数据源的解决方案。

Method: 采用粒子滤波融合GNSS和惯性数据，结合地图空间先验（如不可通行建筑物和不可能行走区域），实现概率形式的地图匹配。惯性定位使用RoNIN机器学习方法，通过粒子权重调整实现与GNSS估计和不确定性的融合。

Result: 在旧金山市中心6条具有挑战性的步行路线上评估，使用三个与行人道正确性和定位误差相关的指标。结果显示融合方法（GNSS+RoNIN+PF）在大多数指标上显著优于仅使用GNSS的定位，仅使用惯性定位加粒子滤波也在关键指标（如行人道分配和跨街道误差）上超越GNSS单独定位。

Conclusion: 提出的融合方法能有效解决城市环境中GNSS信号受限时的行人导航定位问题，特别适合需要精确街道侧判断的盲人或低视力用户，为可靠的城市行人导航提供了实用解决方案。

Abstract: The contribution describes a pedestrian navigation approach designed to improve localization accuracy in urban environments where GNSS performance is degraded, a problem that is especially critical for blind or low-vision users who depend on precise guidance such as identifying the correct side of a street. To address GNSS limitations and the impracticality of camera-based visual positioning, the work proposes a particle filter based fusion of GNSS and inertial data that incorporates spatial priors from maps, such as impassable buildings and unlikely walking areas, functioning as a probabilistic form of map matching. Inertial localization is provided by the RoNIN machine learning method, and fusion with GNSS is achieved by weighting particles based on their consistency with GNSS estimates and uncertainty. The system was evaluated on six challenging walking routes in downtown San Francisco using three metrics related to sidewalk correctness and localization error. Results show that the fused approach (GNSS+RoNIN+PF) significantly outperforms GNSS only localization on most metrics, while inertial-only localization with particle filtering also surpasses GNSS alone for critical measures such as sidewalk assignment and across street error.

</details>


### [6] [High-Definition 5MP Stereo Vision Sensing for Robotics](https://arxiv.org/abs/2601.22445)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.RO

TL;DR: 该研究提出了一种用于5MP+高分辨率立体视觉系统的新型校准和立体匹配方法，旨在实现高精度和快速处理，并证明了高像素相机需要通过高精度校准才能生成高质量点云。


<details>
  <summary>Details</summary>
Motivation: 高分辨率（5MP+）立体视觉系统对于提升机器人能力至关重要，但传统方法往往无法满足高分辨率传感器所需的高校准精度和快速处理需求。

Method: 采用新型先进的帧间校准和立体匹配方法处理5MP相机图像，并引入通过对比实时视差图与计算密集型算法生成的地面真实视差图来评估实时性能的新方法。

Result: 研究表明，高像素相机只有通过实施高精度校准才能生成高质量的点云，验证了所提方法在精度和速度方面的有效性。

Conclusion: 实现高分辨率立体视觉系统的全部潜力需要相应的高精度校准和快速处理方法，该研究提出的方法为此提供了有效的解决方案。

Abstract: High-resolution (5MP+) stereo vision systems are essential for advancing robotic capabilities, enabling operation over longer ranges and generating significantly denser and accurate 3D point clouds. However, realizing the full potential of high-angular-resolution sensors requires a commensurately higher level of calibration accuracy and faster processing -- requirements often unmet by conventional methods. This study addresses that critical gap by processing 5MP camera imagery using a novel, advanced frame-to-frame calibration and stereo matching methodology designed to achieve both high accuracy and speed. Furthermore, we introduce a new approach to evaluate real-time performance by comparing real-time disparity maps with ground-truth disparity maps derived from more computationally intensive stereo matching algorithms. Crucially, the research demonstrates that high-pixel-count cameras yield high-quality point clouds only through the implementation of high-accuracy calibration.

</details>


### [7] [CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control](https://arxiv.org/abs/2601.22467)
*Jiaqi Shi,Xulong Zhang,Xiaoyang Qu,Jianzong Wang*

Main category: cs.RO

TL;DR: CARE是一个无需动作标注的视觉-语言-动作模型训练框架，仅使用视频-文本对进行预训练，通过连续潜在动作表示学习实现机器人控制。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖动作监督，限制了可扩展性和泛化能力。需要一种无需动作标注的弱监督方法来训练机器人控制模型。

Method: CARE框架仅使用视频-文本对进行预训练，通过新设计的多任务预训练目标学习连续潜在动作表示。微调阶段使用少量标注数据训练动作头进行控制。

Result: 在多个仿真任务中，CARE表现出更高的成功率、更好的语义可解释性，并能避免捷径学习，证明了其在弱监督机器人控制中的有效性。

Conclusion: CARE框架通过消除动作标注需求，显著提高了VLA模型的可扩展性、可解释性和机器人控制效果，为弱监督机器人学习提供了有效解决方案。

Abstract: Recent advances in Vision-Language-Action (VLA) models have shown promise for robot control, but their dependence on action supervision limits scalability and generalization. To address this challenge, we introduce CARE, a novel framework designed to train VLA models for robotic task execution. Unlike existing methods that depend on action annotations during pretraining, CARE eliminates the need for explicit action labels by leveraging only video-text pairs. These weakly aligned data sources enable the model to learn continuous latent action representations through a newly designed multi-task pretraining objective. During fine-tuning, a small set of labeled data is used to train the action head for control. Experimental results across various simulation tasks demonstrate CARE's superior success rate, semantic interpretability, and ability to avoid shortcut learning. These results underscore CARE's scalability, interpretability, and effectiveness in robotic control with weak supervision.

</details>


### [8] [RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing](https://arxiv.org/abs/2601.22517)
*Kangning Yin,Zhe Cao,Wentao Dong,Weishuai Zeng,Tianyi Zhang,Qiang Zhang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Weinan Zhang*

Main category: cs.RO

TL;DR: RoboStriker：一个三阶段分层框架，通过解耦高层战略推理与底层物理执行，实现人形机器人自主拳击。该方法首先从人类动作捕捉数据学习拳击技能，然后将其蒸馏到结构化潜在流形，最后在潜在动作空间进行多智能体竞争学习。


<details>
  <summary>Details</summary>
Motivation: 实现人形机器人达到人类水平的竞争智能和身体敏捷性是一个重大挑战，特别是在接触丰富且高度动态的任务如拳击中。虽然多智能体强化学习为战略交互提供了原则性框架，但其直接应用于人形控制受到高维接触动力学和缺乏强物理运动先验的阻碍。

Method: 提出RoboStriker三阶段分层框架：1）在人类动作捕捉数据上训练单智能体运动跟踪器学习全面的拳击技能库；2）将技能蒸馏到结构化潜在流形，通过将高斯参数化分布投影到单位超球面进行正则化；3）引入潜在空间神经虚拟自我博弈，让竞争智能体在潜在动作空间而非原始电机空间进行交互学习竞争策略。

Result: 实验结果表明，RoboStriker在仿真中实现了卓越的竞争性能，并展现出从仿真到现实的迁移能力。该方法显著稳定了多智能体训练过程。

Conclusion: RoboStriker通过分层解耦战略推理与物理执行，结合潜在空间正则化和多智能体学习，成功实现了人形机器人的自主拳击能力，为解决接触丰富动态任务中的机器人控制问题提供了有效框架。

Abstract: Achieving human-level competitive intelligence and physical agility in humanoid robots remains a major challenge, particularly in contact-rich and highly dynamic tasks such as boxing. While Multi-Agent Reinforcement Learning (MARL) offers a principled framework for strategic interaction, its direct application to humanoid control is hindered by high-dimensional contact dynamics and the absence of strong physical motion priors. We propose RoboStriker, a hierarchical three-stage framework that enables fully autonomous humanoid boxing by decoupling high-level strategic reasoning from low-level physical execution. The framework first learns a comprehensive repertoire of boxing skills by training a single-agent motion tracker on human motion capture data. These skills are subsequently distilled into a structured latent manifold, regularized by projecting the Gaussian-parameterized distribution onto a unit hypersphere. This topological constraint effectively confines exploration to the subspace of physically plausible motions. In the final stage, we introduce Latent-Space Neural Fictitious Self-Play (LS-NFSP), where competing agents learn competitive tactics by interacting within the latent action space rather than the raw motor space, significantly stabilizing multi-agent training. Experimental results demonstrate that RoboStriker achieves superior competitive performance in simulation and exhibits sim-to-real transfer. Our website is available at RoboStriker.

</details>


### [9] [Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios](https://arxiv.org/abs/2601.22545)
*Feng Tao,Luca Paparusso,Chenyi Gu,Robin Koehler,Chenxu Wu,Xinyu Huang,Christian Juette,David Paz,Ren Liu*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度强化学习的实时路径规划框架，专门用于解决受限环境（特别是停车场景）中的路径规划问题，相比传统规划器在成功率和效率上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统经典规划器在完美感知假设下有效，但对实际感知约束敏感且在线搜索计算成本高，难以在复杂环境中实现实时部署。需要一种更实用、轻量级的解决方案来处理受限环境中的路径规划问题。

Method: 采用深度强化学习框架，将路径规划任务建模为基于自行车模型动力学的序列决策问题，使智能体能够直接学习满足车辆运动学和环境约束的导航策略。开发了新的基准测试集支持训练和评估。

Result: 该方法在成功率和效率方面达到最先进水平，相比经典规划器基线，成功率提升96%，效率提升52%。

Conclusion: 提出的DRL框架能够实现实时路径规划，无需理想化感知结构，避免了定位和跟踪等额外模块，简化了实际部署。同时开源了基准测试集以促进未来研究。

Abstract: Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep Reinforcement Learning (DRL) framework for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new benchmark is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves state-of-the-art success rates and efficiency, surpassing classical planner baselines by +96% in success rate and +52% in efficiency. Furthermore, we release our benchmark as an open-source resource for the community to foster future research in autonomous systems. The benchmark and accompanying tools are available at https://github.com/dqm5rtfg9b-collab/Constrained_Parking_Scenarios.

</details>


### [10] [Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation](https://arxiv.org/abs/2601.22550)
*Geonho Leem,Jaedong Lee,Jehee Lee,Seungmoon Song,Jungdam Won*

Main category: cs.RO

TL;DR: Exo-plore：结合神经力学仿真与深度强化学习的模拟框架，无需真人实验即可优化髋关节外骨骼辅助控制


<details>
  <summary>Details</summary>
Motivation: 当前外骨骼控制器优化方法需要大量真人步行实验，这对行动不便者尤其困难，形成了"最需要帮助的人最难参与实验"的矛盾

Method: 结合神经力学仿真与深度强化学习，创建模拟框架来优化髋关节外骨骼辅助，无需真人实验

Result: 1) 生成捕捉人类适应辅助力的真实步态数据；2) 在步态随机性下仍能产生可靠优化结果；3) 可泛化到病理步态，病理严重程度与最优辅助呈强线性关系

Conclusion: Exo-plore框架解决了外骨骼优化中的实验瓶颈，为行动不便者提供个性化辅助优化方案，无需他们参与耗时实验

Abstract: Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current state-of-the-art approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assistance, such as individuals with mobility impairments, are rarely able to participate in such demanding procedures. We present Exo-plore, a simulation framework that combines neuromechanical simulation with deep reinforcement learning to optimize hip exoskeleton assistance without requiring real human experiments. Exo-plore can (1) generate realistic gait data that captures human adaptation to assistive forces, (2) produce reliable optimization results despite the stochastic nature of human gait, and (3) generalize to pathological gaits, showing strong linear relationships between pathology severity and optimal assistance.

</details>


### [11] [Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies](https://arxiv.org/abs/2601.22672)
*Theodora Kastritsi,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种为超数机器人身体提供动觉反馈的控制框架，通过虚拟夹具和在线姿态评估来改善人机协作中的工效学姿势


<details>
  <summary>Details</summary>
Motivation: 超数机器人身体可以增强人类负载能力，但在物理交互任务中，用户仍可能采用不舒适的、非工效学姿势，长期可能导致不适或伤害

Method: 开发了虚拟夹具方法，结合连续在线工效学姿态评估框架，当检测到非工效学姿势时提供动觉反馈以阻止不良行为；同时调整浮动基座位置以改善操作者与机器人的协调

Result: 实验结果表明该工效学驱动控制框架的功能和有效性，包括两个涉及14名受试者的实际移动操作任务的用户研究，与不考虑人类工效学的基线控制框架相比表现更好

Conclusion: 提出的控制框架能够促进长期工效学习习惯，在物理交互中改善姿势，增强超数机器人身体与人类操作者之间的协作

Abstract: Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.

</details>


### [12] [FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation](https://arxiv.org/abs/2601.22686)
*Biyu Ye,Na Fan,Zhengping Fan,Weiliang Deng,Hongming Chen,Qifeng Chen,Ximin Lyu*

Main category: cs.RO

TL;DR: 提出一种用于空中机械臂的机载框架，集成视觉预抓取惯性估计与抓取后自适应机制，实现实时惯性动力学估计与自适应控制


<details>
  <summary>Details</summary>
Motivation: 空中机械臂在实际部署中面临时变惯性参数的复杂性挑战，这些参数对有效载荷变化和机械臂配置高度敏感，需要更鲁棒的解决方案

Method: 集成视觉预抓取惯性估计模块与抓取后自适应机制，开发基于增益调度的惯性感知自适应控制策略，并通过频域系统辨识评估鲁棒性

Result: 为空中机械臂的抓取后控制提供新见解，真实世界实验验证了所提框架的有效性和可行性

Conclusion: 该框架通过实时惯性估计和自适应控制，显著提升了空中机械臂在载荷变化和配置变化下的鲁棒性和实用性

Abstract: Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.

</details>


### [13] [Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives](https://arxiv.org/abs/2601.22849)
*Christian Dietz,Sebastian Albrecht,Gianluca Frison,Moritz Diehl,Armin Nurkanović*

Main category: cs.RO

TL;DR: 本文提出了一种基于可微分物理仿真的高效装配运动规划方法，通过二阶解析导数显著减少规划所需的物理仿真步骤，并采用多场景轨迹优化确保鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器人装配运动规划长期面临效率挑战，传统方法依赖大量物理仿真。本文旨在开发一种样本效率高、鲁棒性强的优化控制方法，减少规划过程中的仿真需求。

Method: 构建可微分物理仿真器，提供二阶解析导数；采用基于内点法的平滑技术处理碰撞检测和接触解析；提出改进的基于优化的碰撞检测线性规划方法；设计多场景轨迹优化问题确保鲁棒性。

Result: 实验结果显示，在真实世界实验中实现了超过99%的成功执行率；验证了接触动力学平滑近似和鲁棒建模对成功率的影响；在模拟中测试不同peg-in-hole问题，展示了精确Hessian矩阵相比常用近似的优势。

Conclusion: 该方法通过可微分物理仿真和鲁棒优化控制，实现了高效、鲁棒的装配运动规划，显著减少了规划所需的仿真步骤，并在真实环境中表现出高成功率。

Abstract: Efficient planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with reinforcement learning and sampling-based methods by using extensive physics simulations. This paper proposes a sample-efficient robust optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the efficient use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. We propose a modified variant of an optimization-based formulation of collision detection formulated as a linear program and present an efficient implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory optimization problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and robust modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.

</details>


### [14] [Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs](https://arxiv.org/abs/2601.22927)
*Lars Ullrich,Michael Buchholz,Klaus Dietmayer,Knut Graichen*

Main category: cs.RO

TL;DR: 本文分析了人工智能在自动驾驶领域应用的挑战与机遇，重新审视了完全自动驾驶的实现路径


<details>
  <summary>Details</summary>
Motivation: 自动驾驶向完全自主驾驶的过渡面临开放世界的动态变化挑战，而AI技术展现出超越传统方法、处理更高复杂性的潜力，但同时也引发了安全性和可迁移性等问题

Method: 分析当前自动驾驶发展现状，识别局限性，预测技术可能性，并在前瞻性发展背景下考察各种挑战

Result: 识别了AI在自动驾驶功能方面带来的挑战和机遇，重新审视了完全自动驾驶的实现路径

Conclusion: 本文通过分析AI领域进展，重新思考完全自动驾驶的实现，并提出了相应的需求和未来研究方向

Abstract: Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of artificial intelligence (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of AI raises further questions of safety and transferability. To identify the challenges and opportunities arising from AI concerning autonomous driving functionalities, we have analyzed the current state of AD, outlined limitations, and identified foreseeable technological possibilities. Thereby, various further challenges are examined in the context of prospective developments. In this way, this article reconsiders fully autonomous driving with respect to advancements in the field of AI and carves out the respective needs and resulting research questions.

</details>


### [15] [MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2601.22930)
*Xidong Li,Mingyu Guo,Chenchao Xu,Bailin Li,Wenjing Zhu,Yangang Zou,Rui Chen,Zehuan Wang*

Main category: cs.RO

TL;DR: MTDrive是一个多轮轨迹规划框架，通过MLLMs与RL结合，实现基于环境反馈的迭代轨迹优化，在NAVSIM基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶轨迹规划方法局限于单轮推理，难以处理需要迭代优化的复杂场景，特别是长尾场景下的轨迹细化问题。

Method: 提出MTDrive多轮框架，引入mtGRPO算法缓解奖励稀疏性，构建交互式轨迹理解数据集，并进行系统级优化提升训练效率。

Result: 在NAVSIM基准上优于现有方法，验证了多轮推理范式的有效性，系统优化使训练吞吐量提升2.5倍。

Conclusion: 多轮推理框架能有效提升自动驾驶轨迹规划在复杂场景下的性能，为MLLMs与RL的深度整合提供了新思路。

Abstract: Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with Reinforcement Learning (RL) has shown promise in addressing "long-tail" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks requiring iterative refinement. To overcome this limitation, we present MTDrive, a multi-turn framework that enables MLLMs to iteratively refine trajectories based on environmental feedback. MTDrive introduces Multi-Turn Group Relative Policy Optimization (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns. We further construct an interactive trajectory understanding dataset from closed-loop simulation to support multi-turn training. Experiments on the NAVSIM benchmark demonstrate superior performance compared to existing methods, validating the effectiveness of our multi-turn reasoning paradigm. Additionally, we implement system-level optimizations to reduce data transfer overhead caused by high-resolution images and multi-turn sequences, achieving 2.5x training throughput. Our data, models, and code will be made available soon.

</details>


### [16] [Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation](https://arxiv.org/abs/2601.22965)
*Runhua Zhang,Junyi Hou,Changxu Cheng,Qiyi Chen,Tao Wang,Wuyue Zhao*

Main category: cs.RO

TL;DR: SIDP通过自模仿机制改进扩散策略，减少对专家演示的依赖，避免生成后过滤，实现更高效的实时视觉导航。


<details>
  <summary>Details</summary>
Motivation: 传统扩散策略依赖模仿学习，继承了专家演示的次优性和冗余，需要计算密集的"生成-过滤"流程和辅助选择器，导致推理效率低下。

Method: 提出自模仿扩散策略(SIDP)，引入奖励引导的自模仿机制，让策略选择性地模仿自身采样的轨迹；采用奖励驱动的课程学习和目标无关的探索进行轨迹增强。

Result: 在综合仿真基准上显著优于先前方法，真实世界实验验证了在多机器人平台上的有效性；在Jetson Orin Nano上推理速度比基线NavDP快2.5倍(110ms vs 273ms)。

Conclusion: SIDP通过自模仿学习机制有效解决了传统扩散策略的次优性和效率问题，实现了高质量轨迹的高效生成，适合实时部署。

Abstract: Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive "generate-then-filter" pipeline that relies on auxiliary selectors during inference. To address these challenges, we propose Self-Imitated Diffusion Policy (SIDP), a novel framework that learns improved planning by selectively imitating a set of trajectories sampled from itself. Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering. During training, we employ a reward-driven curriculum learning paradigm to mitigate inefficient data utility, and goal-agnostic exploration for trajectory augmentation to improve planning robustness. Extensive evaluations on a comprehensive simulation benchmark show that SIDP significantly outperforms previous methods, with real-world experiments confirming its effectiveness across multiple robotic platforms. On Jetson Orin Nano, SIDP delivers a 2.5$\times$ faster inference than the baseline NavDP, i.e., 110ms VS 273ms, enabling efficient real-time deployment.

</details>


### [17] [Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.22988)
*Di Zhang,Weicheng Duan,Dasen Gu,Hongye Lu,Hai Zhang,Hang Yu,Junqiao Zhao,Guang Chen*

Main category: cs.RO

TL;DR: MethodName提出了一种统一的表示-策略学习框架，通过单视图3D预训练和多步蒸馏实现机器人操作的视图泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有3D感知视觉表示存在三个主要限制：1) 推理时依赖多视图观测，在单视图受限场景中不实用；2) 场景建模不完整，无法捕捉精确操作所需的整体和细粒度几何结构；3) 缺乏有效的策略训练策略来保留和利用3D知识。

Method: MethodName采用单视图3D预训练范式，利用点云重建和前馈高斯泼溅在多视图监督下学习整体几何表示。在策略学习阶段，通过多步蒸馏保留预训练的几何理解，并将其有效转移到操作技能中。

Result: 在12个RLBench任务中，MethodName比先前最先进方法的平均成功率高出12.7%。在6个代表性任务的零样本视图泛化评估中，在中等和大幅视角偏移下，成功率分别仅下降22.0%和29.7%，而最先进方法的下降幅度更大（41.6%和51.5%）。

Conclusion: MethodName通过统一的表示-策略学习框架，有效解决了机器人操作中的视图泛化问题，在单视图受限场景下实现了更强的空间场景理解和泛化能力。

Abstract: Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge. To address these challenges, we present MethodName, a unified representation-policy learning framework for view-generalizable robotic manipulation. MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, MethodName performs multi-step distillation to preserve the pretrained geometric understanding and effectively transfer it to manipulation skills. We conduct experiments on 12 RLBench tasks, where our approach outperforms the previous state-of-the-art method by 12.7% in average success rate. Further evaluation on six representative tasks demonstrates strong zero-shot view generalization, with success rate drops of only 22.0% and 29.7% under moderate and large viewpoint shifts respectively, whereas the state-of-the-art method suffers larger decreases of 41.6% and 51.5%.

</details>


### [18] [Robust and Generalized Humanoid Motion Tracking](https://arxiv.org/abs/2601.23080)
*Yubiao Ma,Han Yu,Jiayin Xie,Changtai Lv,Qiang Luo,Chi Zhang,Yunpeng Yin,Boyang Xing,Xuemei Ren,Dongdong Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于动力学条件命令聚合框架的人形机器人全身控制器，通过因果时间编码器和多头交叉注意力机制选择性地聚合上下文信息，结合跌倒恢复课程学习，仅需3.5小时运动数据即可实现端到端训练，并展示了零样本迁移和鲁棒的仿真到现实迁移能力。


<details>
  <summary>Details</summary>
Motivation: 学习通用人形机器人全身控制器面临挑战：参考运动转移到机器人域后可能存在噪声和不一致性，闭环执行可能放大局部缺陷，导致动态和接触丰富行为中的漂移或失败。

Method: 提出动力学条件命令聚合框架：1) 使用因果时间编码器总结近期本体感知信息；2) 使用多头交叉注意力命令编码器基于当前动力学选择性地聚合上下文窗口；3) 集成跌倒恢复课程学习，包括随机不稳定初始化和退火向上辅助力以提高鲁棒性和抗干扰能力。

Result: 该方法仅需约3.5小时运动数据，支持单阶段端到端训练而无需蒸馏。在多样化参考输入和挑战性运动机制下评估，展示了零样本迁移到未见运动的能力，以及在物理人形机器人上实现鲁棒的仿真到现实迁移。

Conclusion: 提出的动力学条件命令聚合框架结合跌倒恢复课程学习，能够有效处理参考运动中的噪声和不一致性，实现鲁棒的人形机器人全身控制，支持零样本迁移和仿真到现实部署。

Abstract: Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation framework that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as robust sim-to-real transfer on a physical humanoid robot.

</details>


### [19] [Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation](https://arxiv.org/abs/2601.23087)
*Wu Songwei,Jiang Zhiduo,Xie Guanghu,Liu Yang,Liu Hong*

Main category: cs.RO

TL;DR: LG-Flow Policy是一种轨迹级模仿学习框架，通过在连续潜在动作空间进行流匹配，实现快速单步推理和稳定的长时程机器人操作执行。


<details>
  <summary>Details</summary>
Motivation: 现有生成策略在长时程机器人操作中存在挑战：扩散方法建模能力强但推理延迟高，流匹配方法可实现快速单步生成但在原始动作空间中直接应用会导致执行不稳定。

Method: 提出LG-Flow Policy框架：1）将动作序列编码为时间正则化的潜在轨迹；2）在连续潜在动作空间学习显式流匹配；3）结合几何感知点云条件；4）执行时多模态调制。

Result: 在仿真和物理机器人平台上的实验表明：LG-Flow Policy实现接近单步推理，显著提高轨迹平滑度和任务成功率，比原始动作空间的流匹配基线表现更好，比扩散策略更高效。

Conclusion: LG-Flow Policy通过潜在动作空间的流匹配，成功解决了长时程机器人操作中建模能力、推理速度和执行稳定性之间的权衡问题，为实际机器人应用提供了有效解决方案。

Abstract: Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space.
  We propose LG-Flow Policy, a trajectory-level imitation learning framework that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution.
  LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more efficient than diffusion-based policies.

</details>


### [20] [End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms](https://arxiv.org/abs/2601.23285)
*MH Farhadi,Ali Rabiee,Sima Ghafoori,Anna Cetera,Andrew Fisher,Reza Abiri*

Main category: cs.RO

TL;DR: BRACE框架通过贝叶斯意图推断和上下文自适应辅助的端到端梯度流，在共享自主系统中实现了更好的性能，在复杂、目标模糊场景中表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 共享自主系统需要从用户意图推断到辅助水平确定的统一方法，现有方法依赖静态混合比或将目标推断与辅助仲裁分离，导致在非结构化环境中性能不佳。

Method: 提出BRACE框架，通过端到端梯度流架构微调贝叶斯意图推断和上下文自适应辅助，将协作控制策略条件化于环境上下文和完整目标概率分布。

Result: 相比SOTA方法（IDA、DQN），在三维评估中实现了6.3%更高的成功率、41%的路径效率提升，相比无辅助控制有36.3%成功率和87%路径效率提升。

Conclusion: 集成优化在复杂、目标模糊场景中最为有益，可推广到需要目标导向辅助的机器人领域，推进了自适应共享自主系统的技术前沿。

Abstract: Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a novel framework that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our pipeline conditions collaborative control policies on environmental context and complete goal probability distributions. We provide analysis showing (1) optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, and (2) integrating belief information into policy learning yields a quadratic expected regret advantage over sequential approaches. We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints. We demonstrate improvements over SOTA, achieving 6.3% higher success rates and 41% increased path efficiency, and 36.3% success rate and 87% path efficiency improvement over unassisted control. Our results confirmed that integrated optimization is most beneficial in complex, goal-ambiguous scenarios, and is generalizable across robotic domains requiring goal-directed assistance, advancing the SOTA for adaptive shared autonomy.

</details>
