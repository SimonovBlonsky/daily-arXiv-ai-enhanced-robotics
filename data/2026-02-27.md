<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [SODA-CitrON: Static Object Data Association by Clustering Multi-Modal Sensor Detections Online](https://arxiv.org/abs/2602.22243)
*Jan Nausner,Kilian Wohlleben,Michael Hubner*

Main category: cs.RO

TL;DR: 提出SODA-CitrON方法，通过在线聚类多模态传感器检测来解决静态物体数据关联问题，同时估计位置并维护未知数量物体的持续跟踪。


<details>
  <summary>Details</summary>
Motivation: 静态物体从异构传感器检测中的在线融合和跟踪是机器人、自主系统和环境映射中的基本问题。传统数据关联方法（如JPDA）适用于动态目标，但对于间歇性观测且具有异构不确定性的静态物体效果较差，因为运动模型在区分杂波方面提供的信息有限。

Method: 提出SODA-CitrON方法，这是一种无监督机器学习方法，通过在线聚类多模态传感器检测来关联静态物体数据。方法完全在线运行，处理时间不相关和多传感器测量，具有最坏情况下对数线性复杂度，并提供完全可解释的输出。

Result: 在不同蒙特卡洛模拟场景中评估该方法，并与最先进方法（包括贝叶斯滤波、DBSTREAM聚类和JPDA）进行比较。结果表明，SODA-CitrON在研究的静态物体映射场景中，在F1分数、位置RMSE、MOTP和MOTA指标上始终优于比较方法。

Conclusion: SODA-CitrON为静态物体数据关联提供了一种有效的在线解决方案，能够处理异构传感器检测、未知物体数量，并在性能指标上优于现有方法。

Abstract: The online fusion and tracking of static objects from heterogeneous sensor detections is a fundamental problem in robotics, autonomous systems, and environmental mapping. Although classical data association approaches such as JPDA are well suited for dynamic targets, they are less effective for static objects observed intermittently and with heterogeneous uncertainties, where motion models provide minimal discriminative with respect to clutter. In this paper, we propose a novel method for static object data association by clustering multi-modal sensor detections online (SODA-CitrON), while simultaneously estimating positions and maintaining persistent tracks for an unknown number of objects. The proposed unsupervised machine learning approach operates in a fully online manner and handles temporally uncorrelated and multi-sensor measurements. Additionally, it has a worst-case loglinear complexity in the number of sensor detections while providing full output explainability. We evaluate the proposed approach in different Monte Carlo simulation scenarios and compare it against state-of-the-art methods, including Bayesian filtering, DBSTREAM clustering, and JPDA. The results demonstrate that SODA-CitrON consistently outperforms the compared methods in terms of F1 score, position RMSE, MOTP, and MOTA in the static object mapping scenarios studied.

</details>


### [2] [Hierarchical Trajectory Planning of Floating-Base Multi-Link Robot for Maneuvering in Confined Environments](https://arxiv.org/abs/2602.22459)
*Yicheng Chen,Jinjie Li,Haokun Liu,Zicheng Luo,Kotaro Kaneko,Moju Zhao*

Main category: cs.RO

TL;DR: 提出了一种用于浮基多连杆机器人的分层轨迹规划框架，结合全局引导与配置感知的局部优化，直接从点云数据生成连续、无碰撞、动态可行的轨迹。


<details>
  <summary>Details</summary>
Motivation: 浮基多连杆机器人在飞行中可以改变形态，适用于狭窄环境中的自主检查和搜救任务，但其轨迹规划面临高维、约束丰富的挑战，需要同时处理避障、运动学限制和动态可行性。

Method: 采用分层规划框架：1) 利用机器人双重特性（根连杆作为刚体引导，关节提供灵活性）生成全局锚点状态，将规划问题分解为可处理段；2) 设计局部轨迹规划器，并行优化各段，使用可微分目标和约束，系统确保运动学可行性，通过避免控制奇点保持动态可行性；3) 实现直接处理点云数据的完整系统，无需手工障碍物模型。

Result: 通过大量仿真和真实世界实验验证，该框架使关节式空中机器人能够利用其形态实现刚性机器人无法完成的机动。这是首个在真实机器人上演示的浮基多连杆机器人规划框架，能够直接从原始点云输入生成连续、无碰撞、动态可行的轨迹。

Conclusion: 该分层轨迹规划框架成功解决了浮基多连杆机器人在高维约束空间中的轨迹规划难题，通过全局引导与局部优化的结合，实现了直接从点云数据生成可行轨迹的能力，为关节式空中机器人在复杂环境中的应用提供了有效解决方案。

Abstract: Floating-base multi-link robots can change their shape during flight, making them well-suited for applications in confined environments such as autonomous inspection and search and rescue. However, trajectory planning for such systems remains an open challenge because the problem lies in a high-dimensional, constraint-rich space where collision avoidance must be addressed together with kinematic limits and dynamic feasibility. This work introduces a hierarchical trajectory planning framework that integrates global guidance with configuration-aware local optimization. First, we exploit the dual nature of these robots - the root link as a rigid body for guidance and the articulated joints for flexibility - to generate global anchor states that decompose the planning problem into tractable segments. Second, we design a local trajectory planner that optimizes each segment in parallel with differentiable objectives and constraints, systematically enforcing kinematic feasibility and maintaining dynamic feasibility by avoiding control singularities. Third, we implement a complete system that directly processes point-cloud data, eliminating the need for handcrafted obstacle models. Extensive simulations and real-world experiments confirm that this framework enables an articulated aerial robot to exploit its morphology for maneuvering that rigid robots cannot achieve. To the best of our knowledge, this is the first planning framework for floating-base multi-link robots that has been demonstrated on a real robot to generate continuous, collision-free, and dynamically feasible trajectories directly from raw point-cloud inputs, without relying on handcrafted obstacle models.

</details>


### [3] [EgoAVFlow: Robot Policy Learning with Active Vision from Human Egocentric Videos via 3D Flow](https://arxiv.org/abs/2602.22461)
*Daesol Cho,Youngseok Jang,Danfei Xu,Sehoon Ha*

Main category: cs.RO

TL;DR: EgoAVFlow：从第一人称视频学习机器人操作和主动视觉，通过共享的3D流表示实现几何可见性推理，无需机器人演示即可迁移


<details>
  <summary>Details</summary>
Motivation: 第一人称人类视频是操作演示的可扩展来源，但部署到机器人时需要主动视角控制来维持任务关键可见性。人类视角模仿常因人类特定先验而失败，需要新的方法

Method: 使用扩散模型预测机器人动作、未来3D流和相机轨迹，通过基于预测运动和场景几何的可见性感知奖励，在测试时进行奖励最大化的去噪来优化视角

Result: 在主动变化视角的真实世界实验中，EgoAVFlow始终优于先前基于人类演示的基线方法，展示了有效的可见性维护和无需机器人演示的鲁棒操作

Conclusion: EgoAVFlow通过共享3D流表示成功实现了从第一人称视频到机器人的操作和主动视觉学习，解决了视角控制问题，为机器人学习提供了无需机器人演示的有效途径

Abstract: Egocentric human videos provide a scalable source of manipulation demonstrations; however, deploying them on robots requires active viewpoint control to maintain task-critical visibility, which human viewpoint imitation often fails to provide due to human-specific priors. We propose EgoAVFlow, which learns manipulation and active vision from egocentric videos through a shared 3D flow representation that supports geometric visibility reasoning and transfers without robot demonstrations. EgoAVFlow uses diffusion models to predict robot actions, future 3D flow, and camera trajectories, and refines viewpoints at test time with reward-maximizing denoising under a visibility-aware reward computed from predicted motion and scene geometry. Real-world experiments under actively changing viewpoints show that EgoAVFlow consistently outperforms prior human-demo-based baselines, demonstrating effective visibility maintenance and robust manipulation without robot demonstrations.

</details>


### [4] [When to Act, Ask, or Learn: Uncertainty-Aware Policy Steering](https://arxiv.org/abs/2602.22474)
*Jessie Yuan,Yilin Wu,Andrea Bajcsy*

Main category: cs.RO

TL;DR: UPS是一个不确定性感知的策略引导框架，通过校准的视觉语言模型验证器来区分自信、模糊和无法处理的任务场景，并选择相应策略（执行、澄清或干预），同时通过残差学习持续改进预训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有策略引导框架假设视觉语言模型校准良好，但实际中VLM的过度自信判断会降低引导性能，特别是在任务语义不确定性和预训练策略动作不确定性或能力不足的情况下。

Method: 提出不确定性感知策略引导框架，联合推理语义任务不确定性和低层动作可行性，通过符合性预测校准VLM和预训练策略的组合，提供统计保证。部署时收集干预数据，采用残差学习改进预训练策略。

Result: 实验表明UPS能够区分自信、模糊和无法处理的场景，相比未校准基线和先前的人或机器人门控持续学习方法，显著减少了昂贵的用户干预。

Conclusion: UPS框架通过不确定性感知的策略引导，有效解决了VLM过度自信问题，实现了在最小化人类反馈情况下的持续学习，提升了机器人部署时的行为适应性。

Abstract: Policy steering is an emerging way to adapt robot behaviors at deployment-time: a learned verifier analyzes low-level action samples proposed by a pre-trained policy (e.g., diffusion policy) and selects only those aligned with the task. While Vision-Language Models (VLMs) are promising general-purpose verifiers due to their reasoning capabilities, existing frameworks often assume these models are well-calibrated. In practice, the overconfident judgment from VLM can degrade the steering performance under both high-level semantic uncertainty in task specifications and low-level action uncertainty or incapability of the pre-trained policy. We propose uncertainty-aware policy steering (UPS), a framework that jointly reasons about semantic task uncertainty and low-level action feasibility, and selects an uncertainty resolution strategy: execute a high-confidence action, clarify task ambiguity via natural language queries, or ask for action interventions to correct the low-level policy when it is deemed incapable at the task. We leverage conformal prediction to calibrate the composition of the VLM and the pre-trained base policy, providing statistical assurances that the verifier selects the correct strategy. After collecting interventions during deployment, we employ residual learning to improve the capability of the pre-trained policy, enabling the system to learn continually but with minimal expensive human feedback. We demonstrate our framework through experiments in simulation and on hardware, showing that UPS can disentangle confident, ambiguous, and incapable scenarios and minimizes expensive user interventions compared to uncalibrated baselines and prior human- or robot-gated continual learning approaches. Videos can be found at https://jessie-yuan.github.io/ups/

</details>


### [5] [SignVLA: A Gloss-Free Vision-Language-Action Framework for Real-Time Sign Language-Guided Robotic Manipulation](https://arxiv.org/abs/2602.22514)
*Xinyu Tan,Ningwei Bai,Harry Gardener,Zhengyang Zhong,Luoyu Zhang,Liuhaichen Yang,Zhekai Duan,Monkgogi Galeitsiwe,Zezhi Tang*

Main category: cs.RO

TL;DR: 首个基于手语驱动的视觉-语言-动作框架，采用无注释词范式，直接将视觉手势映射为语义指令，实现直观包容的人机交互。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖注释词作为中间监督，存在标注成本高和信息损失问题。需要更自然、可扩展的多模态交互方式，特别是在安全关键环境中实现可靠的人机通信。

Method: 采用无注释词范式，直接视觉手势到语义指令映射。专注于实时字母级拼写接口，通过几何归一化、时间平滑和词汇精炼将连续手势流转换为连贯语言命令。

Result: 实验结果表明，该系统在不同交互场景下能有效将手语指令转化为精确的机器人动作，展示了框架在实现可访问、可扩展多模态具身智能方面的潜力。

Conclusion: 该框架为直观包容的人机交互提供了新途径，支持未来基于Transformer的无注释词手语模型集成，有望推动可访问、可扩展的多模态具身智能发展。

Abstract: We present, to our knowledge, the first sign language-driven Vision-Language-Action (VLA) framework for intuitive and inclusive human-robot interaction. Unlike conventional approaches that rely on gloss annotations as intermediate supervision, the proposed system adopts a gloss-free paradigm and directly maps visual sign gestures to semantic instructions. This design reduces annotation cost and avoids the information loss introduced by gloss representations, enabling more natural and scalable multimodal interaction.
  In this work, we focus on a real-time alphabet-level finger-spelling interface that provides a robust and low-latency communication channel for robotic control. Compared with large-scale continuous sign language recognition, alphabet-level interaction offers improved reliability, interpretability, and deployment feasibility in safety-critical embodied environments. The proposed pipeline transforms continuous gesture streams into coherent language commands through geometric normalization, temporal smoothing, and lexical refinement, ensuring stable and consistent interaction.
  Furthermore, the framework is designed to support future integration of transformer-based gloss-free sign language models, enabling scalable word-level and sentence-level semantic understanding. Experimental results demonstrate the effectiveness of the proposed system in grounding sign-derived instructions into precise robotic actions under diverse interaction scenarios. These results highlight the potential of the framework to advance accessible, scalable, and multimodal embodied intelligence.

</details>


### [6] [Metamorphic Testing of Vision-Language Action-Enabled Robots](https://arxiv.org/abs/2602.22579)
*Pablo Valle,Sergio Segura,Shaukat Ali,Aitor Arrieta*

Main category: cs.RO

TL;DR: 该研究探索使用蜕变测试缓解视觉-语言-动作模型中的测试预言问题，提出了两种蜕变关系模式和五种蜕变关系，通过实验验证了该方法能有效检测多种类型的故障。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型面临测试预言问题：一方面需要为每个指令提示定义测试预言，过程复杂且不可泛化；另一方面现有测试预言通常只评估任务正确性，无法评估任务执行质量等其他关键方面。

Method: 提出了两种蜕变关系模式和五种蜕变关系，通过改变测试输入来评估VLA模型输出轨迹的变化。使用五个VLA模型、两个模拟机器人和四个机器人任务进行实证研究。

Result: 蜕变测试能有效缓解测试预言问题，自动检测包括未完成任务在内的多种类型故障。提出的蜕变关系具有泛化性，可应用于不同VLA模型、机器人和任务，即使在没有测试预言的情况下也能使用。

Conclusion: 蜕变测试是解决VLA模型测试预言问题的有效方法，提出的蜕变关系模式具有通用性，能够跨模型、机器人和任务应用，显著提高了VLA系统的测试能力。

Abstract: Vision-Language-Action (VLA) models are multimodal robotic task controllers that, given an instruction and visual inputs, produce a sequence of low-level control actions (or motor commands) enabling a robot to execute the requested task in the physical environment. These systems face the test oracle problem from multiple perspectives. On the one hand, a test oracle must be defined for each instruction prompt, which is a complex and non-generalizable approach. On the other hand, current state-of-the-art oracles typically capture symbolic representations of the world (e.g., robot and object states), enabling the correctness evaluation of a task, but fail to assess other critical aspects, such as the quality with which VLA-enabled robots perform a task. In this paper, we explore whether Metamorphic Testing (MT) can alleviate the test oracle problem in this context. To do so, we propose two metamorphic relation patterns and five metamorphic relations to assess whether changes to the test inputs impact the original trajectory of the VLA-enabled robots. An empirical study involving five VLA models, two simulated robots, and four robotic tasks shows that MT can effectively alleviate the test oracle problem by automatically detecting diverse types of failures, including, but not limited to, uncompleted tasks. More importantly, the proposed MRs are generalizable, making the proposed approach applicable across different VLA models, robots, and tasks, even in the absence of test oracles.

</details>


### [7] [Designing Robots for Families: In-Situ Prototyping for Contextual Reminders on Family Routines](https://arxiv.org/abs/2602.22628)
*Michael F. Xu,Enhui Zhao,Yawen Zhang,Joseph E. Michaelis,Sarah Sebo,Bilge Mutlu*

Main category: cs.RO

TL;DR: 研究探索如何通过家庭日常惯例作为切入点，让社交机器人可持续地融入家庭生活，通过共同设计、原型开发和家庭部署研究发现机器人提醒功能受到欢迎，但也揭示了时间安排、权威性和家庭动态等复杂问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器人越来越多地进入家庭生活，如何成功地将机器人融入家庭环境仍然是一个挑战。研究者希望探索家庭日常惯例作为理解机器人如何在家庭环境中找到可持续角色的关键切入点。

Method: 与10个家庭共同设计机器人交互和行为，考虑时间、参与者、地点和环境活动等情境因素，为机器人支持他们选择的日常惯例制定计划。然后设计、原型开发并部署一个移动社交机器人，进行为期四天的家庭用户研究。

Result: 家庭欢迎机器人的提醒功能，父母特别欣赏机器人分担了一些提醒任务。同时，访谈揭示了围绕时间安排、权威性和家庭动态的紧张关系，突显了将机器人整合到家庭中超越简单提醒任务的复杂性。

Conclusion: 基于这些发现，研究者提出了机器人促进情境提醒的设计启示，并讨论了为家庭环境设计机器人时更广泛的考虑因素，强调需要超越功能性任务，考虑家庭动态和社会关系。

Abstract: Robots are increasingly entering the daily lives of families, yet their successful integration into domestic life remains a challenge. We explore family routines as a critical entry point for understanding how robots might find a sustainable role in everyday family settings. Together with each of the ten families, we co-designed robot interactions and behaviors, and a plan for the robot to support their chosen routines, accounting for contextual factors such as timing, participants, locations, and the activities in the environment. We then designed, prototyped, and deployed a mobile social robot as a four-day, in-home user study. Families welcomed the robot's reminders, with parents especially appreciating the offloading of some reminding tasks. At the same time, interviews revealed tensions around timing, authority, and family dynamics, highlighting the complexity of integrating robots into households beyond the immediate task of reminders. Based on these insights, we offer design implications for robot-facilitated contextual reminders and discuss broader considerations for designing robots for family settings.

</details>


### [8] [Does the testing environment matter? Carsickness across on-road, test-track, and driving simulator conditions](https://arxiv.org/abs/2602.22671)
*Georgios Papaioannou,Barys Shyrokau*

Main category: cs.RO

TL;DR: 该研究比较了道路、试验场和驾驶模拟器三种环境下晕车症状的差异，发现模拟器因无法重现低频运动而显著降低了晕车评分。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆的发展，晕车问题日益受到关注，但缺乏标准化测量方法使得不同研究环境间的比较变得困难。现有研究最多只比较两种环境，缺乏多环境对比。

Method: 28名参与者在基于运动的驾驶模拟器中执行视线离开道路的非驾驶任务，使用痛苦量表实时报告晕车症状，实验后使用晕车评估问卷。同时测量加速度、客观指标和主观评分，并评估影响晕车的心理因素。

Result: 模拟器环境中的晕车评分显著低于道路和试验场条件，主要原因是模拟器的工作范围有限，无法重现诱发晕车最有效的低频（<0.5 Hz）运动。

Conclusion: 驾驶模拟器在晕车研究中存在局限性，特别是无法重现关键的低频运动，这影响了基于模拟器研究的有效性，强调了多环境比较的重要性。

Abstract: Carsickness has gained significant attention with the rise of automated vehicles, prompting extensive research across on-road, test-track, and driving simulator environments to understand its occurrence and develop mitigation strategies. However, the lack of carsickness standardization complicates comparisons across studies and environments. Previous works demonstrate measurement validity between two setups at most (e.g., on-road vs. driving simulator), leaving gaps in multi-environment comparisons. This study investigates the recreation of an on-road motion sickness exposure - previously replicated on a test track - using a motion-based driving simulator. Twenty-eight participants performed an eyes-off-road non-driving task while reporting motion sickness using the Misery Scale during the experiment and the Motion Sickness Assessment Questionnaire afterward. Psychological factors known to influence motion sickness were also assessed. The results present subjective and objective measurements for motion sickness across the considered environments. In this paper, acceleration measurements, objective metrics and subjective motion sickness ratings across environments are compared, highlighting key differences in sickness occurrence for simulator-based research validity. Significantly lower motion sickness scores are reported in the simulator compared to on-road and test-track conditions, due to its limited working envelope to reproduce low-frequency (<0.5 Hz) motions, which are the most provocative for motion sickness.

</details>


### [9] [SCOPE: Skeleton Graph-Based Computation-Efficient Framework for Autonomous UAV Exploration](https://arxiv.org/abs/2602.22707)
*Kai Li,Shengtao Zheng,Linkun Xiu,Yuze Sheng,Xiao-Ping Zhang,Dongyue Huang,Xinlei Chen*

Main category: cs.RO

TL;DR: SCOPE框架通过增量构建实时骨骼图和隐式未知区域分析，实现高效自主探索，在保持与全局规划器相当性能的同时，计算成本降低86.9%


<details>
  <summary>Details</summary>
Motivation: 当前自主探索方法依赖频繁全局优化，导致高计算延迟和轨迹振荡，特别是在资源受限的边缘设备上。需要一种更高效、低延迟的解决方案。

Method: 提出SCOPE框架：1) 增量构建实时骨骼图；2) 引入隐式未知区域分析进行高效空间推理；3) 采用分层按需规划策略：近端规划器生成高频局部轨迹，区域序列规划器仅在必要时优化全局访问顺序。

Result: 仿真对比评估显示，SCOPE实现了与最先进全局规划器相当的探索性能，同时平均计算成本降低86.9%。真实世界实验进一步验证了系统的鲁棒性和低延迟特性。

Conclusion: SCOPE框架通过创新的骨骼图构建和分层规划策略，成功解决了自主探索中的计算延迟和轨迹振荡问题，为资源受限环境下的机器人探索提供了高效解决方案。

Abstract: Autonomous exploration in unknown environments is key for mobile robots, helping them perceive, map, and make decisions in complex areas. However, current methods often rely on frequent global optimization, suffering from high computational latency and trajectory oscillation, especially on resource-constrained edge devices. To address these limitations, we propose SCOPE, a novel framework that incrementally constructs a real-time skeletal graph and introduces Implicit Unknown Region Analysis for efficient spatial reasoning. The planning layer adopts a hierarchical on-demand strategy: the Proximal Planner generates smooth, high-frequency local trajectories, while the Region-Sequence Planner is activated only when necessary to optimize global visitation order. Comparative evaluations in simulation demonstrate that SCOPE achieves competitive exploration performance comparable to state-of-the-art global planners, while reducing computational cost by an average of 86.9%. Real-world experiments further validate the system's robustness and low latency in practical scenarios.

</details>


### [10] [Robust Helicopter Ship Deck Landing With Guaranteed Timing Using Shrinking-Horizon Model Predictive Control](https://arxiv.org/abs/2602.22714)
*Philipp Schitz,Paolo Mercorelli,Johann C. Dauer*

Main category: cs.RO

TL;DR: 提出一种基于收缩时域模型预测控制(SHMPC)的运行时高效算法，用于直升机在移动舰船甲板上的自主降落，能在强风干扰下实现高精度着陆并满足时间约束。


<details>
  <summary>Details</summary>
Motivation: 需要开发一种能够在存在干扰（如强风）的情况下，确保直升机在移动舰船甲板上安全、精确着陆的自主控制算法，同时满足预定的机动时间和着陆时间窗口。

Method: 采用收缩时域模型预测控制(SHMPC)结合触地控制器阶段。首先推导出捕捉直升机完整非线性动力学相关方面的规划模型，然后设计带有干扰反馈的辅助控制器以提高干扰抑制性能。

Result: 仿真结果显示，所有机动动作在强风条件下都能实现高着陆精度，同时满足时间和操作约束，最大计算时间在毫秒范围内。

Conclusion: 该方法通过SHMPC和干扰反馈控制器的结合，能够在初始优化问题可行的情况下，保证给定目标位置和时间的直升机安全着陆，并满足终端条件要求。

Abstract: We present a runtime efficient algorithm for autonomous helicopter landings on moving ship decks based on Shrinking-Horizon Model Predictive Control (SHMPC). First, a suitable planning model capturing the relevant aspects of the full nonlinear helicopter dynamics is derived. Next, we use the SHMPC together with a touchdown controller stage to ensure a pre-specified maneuver time and an associated landing time window despite the presence of disturbances. A high disturbance rejection performance is achieved by designing an ancillary controller with disturbance feedback. Thus, given a target position and time, a safe landing with suitable terminal conditions is be guaranteed if the initial optimization problem is feasible. The efficacy of our approach is shown in simulation where all maneuvers achieve a high landing precision in strong winds while satisfying timing and operational constraints with maximum computation times in the millisecond range.

</details>


### [11] [Sapling-NeRF: Geo-Localised Sapling Reconstruction in Forests for Ecological Monitoring](https://arxiv.org/abs/2602.22731)
*Miguel Ángel Muñoz-Bañón,Nived Chebrolu,Sruthi M. Krishna Moorthy,Yifu Tao,Fernando Torres,Roberto Salguero-Gómez,Maurice Fallon*

Main category: cs.RO

TL;DR: 提出了一种融合NeRF、LiDAR SLAM和GNSS的管道，用于实现可重复、地理定位的树苗生态监测，解决了现有3D传感方法难以捕捉树苗细尺度结构特征的问题。


<details>
  <summary>Details</summary>
Motivation: 树苗是森林再生和健康的关键指标，但现有3D传感方法（如TLS、MLS、传统摄影测量）难以重建细枝、密集叶片，且缺乏长期监测所需的尺度一致性。隐式3D重建方法（如NeRF、3DGS）虽前景良好，但无法恢复场景真实尺度且缺乏精确定位能力。

Method: 提出三级表示管道：(1) 使用GNSS进行粗略地球坐标系定位；(2) 基于LiDAR的SLAM实现厘米级精确定位和重建；(3) NeRF衍生的以对象为中心的密集重建单个树苗。融合了NeRF、LiDAR SLAM和GNSS技术。

Result: 在英国Wytham Woods和芬兰Evo的森林样地实验中，相比TLS，能更准确地捕捉树干高度、分枝模式和叶木比。能够测量0.5-2米高树苗的精确树干骨架和叶片分布。

Conclusion: 该方法实现了可重复的定量评估和长期监测树苗特征，为生态学家提供了更丰富的结构和定量数据，用于分析森林动态。

Abstract: Saplings are key indicators of forest regeneration and overall forest health. However, their fine-scale architectural traits are difficult to capture with existing 3D sensing methods, which make quantitative evaluation difficult. Terrestrial Laser Scanners (TLS), Mobile Laser Scanners (MLS), or traditional photogrammetry approaches poorly reconstruct thin branches, dense foliage, and lack the scale consistency needed for long-term monitoring. Implicit 3D reconstruction methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) are promising alternatives, but cannot recover the true scale of a scene and lack any means to be accurately geo-localised. In this paper, we present a pipeline which fuses NeRF, LiDAR SLAM, and GNSS to enable repeatable, geo-localised ecological monitoring of saplings. Our system proposes a three-level representation: (i) coarse Earth-frame localisation using GNSS, (ii) LiDAR-based SLAM for centimetre-accurate localisation and reconstruction, and (iii) NeRF-derived object-centric dense reconstruction of individual saplings. This approach enables repeatable quantitative evaluation and long-term monitoring of sapling traits. Our experiments in forest plots in Wytham Woods (Oxford, UK) and Evo (Finland) show that stem height, branching patterns, and leaf-to-wood ratios can be captured with increased accuracy as compared to TLS. We demonstrate that accurate stem skeletons and leaf distributions can be measured for saplings with heights between 0.5m and 2m in situ, giving ecologists access to richer structural and quantitative data for analysing forest dynamics.

</details>


### [12] [Unleashing the Potential of Diffusion Models for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.22801)
*Yinan Zheng,Tianyi Tan,Bin Huang,Enguang Liu,Ruiming Liang,Jianlin Zhang,Jianwei Cui,Guang Chen,Kun Ma,Hangjun Ye,Long Chen,Ya-Qin Zhang,Xianyuan Zhan,Jingjing Liu*

Main category: cs.RO

TL;DR: 该研究系统探索了扩散模型在端到端自动驾驶规划中的应用，基于大量实车数据和道路测试，提出了Hyper Diffusion Planner框架，在真实世界测试中实现了10倍性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人决策任务中越来越受欢迎，但在自动驾驶领域的应用和评估仍局限于仿真或实验室环境。扩散模型在大规模、复杂真实世界场景（如端到端自动驾驶）中的潜力尚未充分探索。

Method: 基于大量实车数据和道路测试，系统研究扩散模型作为端到端自动驾驶规划器的潜力。通过全面控制研究，识别影响规划性能的关键因素（扩散损失空间、轨迹表示、数据缩放），并开发有效的强化学习后训练策略以增强安全性。

Result: 提出的Hyper Diffusion Planner框架在真实车辆平台上部署，在6个城市驾驶场景和200公里真实世界测试中评估，相比基础模型实现了10倍的性能提升。

Conclusion: 研究表明，当扩散模型经过适当设计和训练时，可以作为复杂真实世界自动驾驶任务的有效且可扩展的端到端规划器。

Abstract: Diffusion models have become a popular choice for decision-making tasks in robotics, and more recently, are also being considered for solving autonomous driving tasks. However, their applications and evaluations in autonomous driving remain limited to simulation-based or laboratory settings. The full strength of diffusion models for large-scale, complex real-world settings, such as End-to-End Autonomous Driving (E2E AD), remains underexplored. In this study, we conducted a systematic and large-scale investigation to unleash the potential of the diffusion models as planners for E2E AD, based on a tremendous amount of real-vehicle data and road testing. Through comprehensive and carefully controlled studies, we identify key insights into the diffusion loss space, trajectory representation, and data scaling that significantly impact E2E planning performance. Moreover, we also provide an effective reinforcement learning post-training strategy to further enhance the safety of the learned planner. The resulting diffusion-based learning framework, Hyper Diffusion Planner} (HDP), is deployed on a real-vehicle platform and evaluated across 6 urban driving scenarios and 200 km of real-world testing, achieving a notable 10x performance improvement over the base model. Our work demonstrates that diffusion models, when properly designed and trained, can serve as effective and scalable E2E AD planners for complex, real-world autonomous driving tasks.

</details>


### [13] [LeRobot: An Open-Source Library for End-to-End Robot Learning](https://arxiv.org/abs/2602.22818)
*Remi Cadene,Simon Aliberts,Francesco Capuano,Michel Aractingi,Adil Zouitine,Pepijn Kooijmans,Jade Choghari,Martino Russi,Caroline Pascal,Steven Palma,Mustafa Shukor,Jess Moss,Alexander Soare,Dana Aubakirova,Quentin Lhoest,Quentin Gallouédec,Thomas Wolf*

Main category: cs.RO

TL;DR: LeRobot是一个开源机器人学习库，整合了从底层电机控制到大规模数据集处理的完整技术栈，旨在降低机器人学习门槛并支持可扩展的学习方法。


<details>
  <summary>Details</summary>
Motivation: 机器人学习领域虽然因机器学习技术、廉价遥操作系统和开放数据集而快速发展，但现有工具往往碎片化、闭源且只针对特定子组件，阻碍了该领域的进步。

Method: 开发了一个开源库LeRobot，整合了完整的机器人学习技术栈，包括底层中间件通信、大规模数据集收集存储流式传输，支持多种硬件平台和最新算法实现，强调可扩展的学习方法而非手工技术。

Result: LeRobot提供了一个统一平台，支持从电机控制到高级学习的完整流程，实现了通用异步推理栈，支持多种最先进算法，提高了机器人学习的可访问性和可重复性。

Conclusion: LeRobot通过其可访问性、可扩展性和开放性，降低了机器人学习的研究和应用门槛，为可重复、最先进的机器人学习提供了平台，推动了该领域的进步。

Abstract: Robotics is undergoing a significant transformation powered by advances in high-level control techniques based on machine learning, giving rise to the field of robot learning. Recent progress in robot learning has been accelerated by the increasing availability of affordable teleoperation systems, large-scale openly available datasets, and scalable learning-based methods. However, development in the field of robot learning is often slowed by fragmented, closed-source tools designed to only address specific sub-components within the robotics stack. In this paper, we present \texttt{lerobot}, an open-source library that integrates across the entire robot learning stack, from low-level middleware communication for motor controls to large-scale dataset collection, storage and streaming. The library is designed with a strong focus on real-world robotics, supporting accessible hardware platforms while remaining extensible to new embodiments. It also supports efficient implementations for various state-of-the-art robot learning algorithms from multiple prominent paradigms, as well as a generalized asynchronous inference stack. Unlike traditional pipelines which heavily rely on hand-crafted techniques, \texttt{lerobot} emphasizes scalable learning approaches that improve directly with more data and compute. Designed for accessibility, scalability, and openness, \texttt{lerobot} lowers the barrier to entry for researchers and practitioners to robotics while providing a platform for reproducible, state-of-the-art robot learning.

</details>


### [14] [Performance and Experimental Analysis of Strain-based Models for Continuum Robots](https://arxiv.org/abs/2602.22854)
*Annika Delucchi,Vincenzo Di Paola,Andreas Müller,and Matteo Zoppi*

Main category: cs.RO

TL;DR: 该研究提出了一种用于连续体机器人形状重建的应变插值方法，通过实验验证其在多种变形条件下的性能，并与现有方法进行比较。


<details>
  <summary>Details</summary>
Motivation: 虽然基于应变的模型在机器人学中已被广泛采用，但缺乏超越均匀弯曲测试的公认性能评估方法。随着连续体机器人原型开发的增加，需要评估这些模型的适用性并进行全面的性能评估。

Method: 采用三阶应变插值方法研究其形状重建能力，考察其捕捉单独和组合变形效应的能力。将结果与几何变量应变方法进行比较。通过实验验证模拟结果，使用机械臂移动细杆末端并利用摄像头记录配置，通过反射标记提取形状，无需应变计或力传感器。

Result: 实验显示模型预测与观测形状吻合良好，平均误差为杆长的0.58%，每个配置的平均计算时间为0.32秒，优于现有模型。

Conclusion: 该研究提供了一种有效的连续体机器人形状重建方法，通过全面的实验验证证明了其准确性和计算效率，为连续体机器人的建模和控制提供了有价值的工具。

Abstract: Although strain-based models have been widely adopted in robotics, no comparison beyond the uniform bending test is commonly recognized to assess their performance. In addition, the increasing effort in prototyping continuum robots highlights the need to assess the applicability of these models and the necessity of comprehensive performance evaluation. To address this gap, this work investigates the shape reconstruction abilities of a third-order strain interpolation method, examining its ability to capture both individual and combined deformation effects. These results are compared and discussed against the Geometric-Variable Strain approach. Subsequently, simulation results are experimentally verified by reshaping a slender rod while recording the resulting configurations using cameras. The rod configuration is imposed using a manipulator displacing one of its tips and extracted through reflective markers, without the aid of any other external sensor -- i.e. strain gauges or wrench sensors placed along the rod. The experiments demonstrate good agreement between the model predictions and observed shapes, with average error of 0.58% of the rod length and average computational time of 0.32s per configuration, outperforming existing models.

</details>


### [15] [GraspLDP: Towards Generalizable Grasping Policy via Latent Diffusion](https://arxiv.org/abs/2602.22862)
*Enda Xiang,Haoxiang Ma,Xinzhu Ma,Zicheng Liu,Di Huang*

Main category: cs.RO

TL;DR: 该论文提出了一种将抓取先验知识融入扩散策略框架的方法，通过潜在扩散策略引导动作块解码，并引入自监督重建目标来嵌入抓取先验，显著提升了模仿学习策略的抓取精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 扩散策略学习已成为机器人操作任务的主流方法，但现有的模仿学习抓取技术存在抓取执行不精确、空间泛化能力有限和物体泛化能力差的问题。需要提升模仿学习策略的抓取精度和泛化能力。

Method: 1. 将抓取先验知识融入扩散策略框架；2. 使用潜在扩散策略通过抓取姿态先验引导动作块解码，确保生成的运动轨迹紧密遵循可行的抓取配置；3. 在扩散过程中引入自监督重建目标，从中间表示中重建手腕相机图像以嵌入抓取先验。

Result: 仿真和真实机器人实验表明，该方法显著优于基线方法，并展现出强大的动态抓取能力。

Conclusion: 通过将抓取先验知识融入扩散策略框架，能够有效提升模仿学习策略的抓取精度和泛化能力，为解决现有模仿学习抓取技术的局限性提供了有效方案。

Abstract: This paper focuses on enhancing the grasping precision and generalization of manipulation policies learned via imitation learning. Diffusion-based policy learning methods have recently become the mainstream approach for robotic manipulation tasks. As grasping is a critical subtask in manipulation, the ability of imitation-learned policies to execute precise and generalizable grasps merits particular attention. Existing imitation learning techniques for grasping often suffer from imprecise grasp executions, limited spatial generalization, and poor object generalization. To address these challenges, we incorporate grasp prior knowledge into the diffusion policy framework. In particular, we employ a latent diffusion policy to guide action chunk decoding with grasp pose prior, ensuring that generated motion trajectories adhere closely to feasible grasp configurations. Furthermore, we introduce a self-supervised reconstruction objective during diffusion to embed the graspness prior: at each reverse diffusion step, we reconstruct wrist-camera images back-projected the graspness from the intermediate representations. Both simulation and real robot experiments demonstrate that our approach significantly outperforms baseline methods and exhibits strong dynamic grasping capabilities.

</details>


### [16] [DySL-VLA: Efficient Vision-Language-Action Model Inference via Dynamic-Static Layer-Skipping for Robot Manipulation](https://arxiv.org/abs/2602.22896)
*Zebin Yang,Yijiahao Qi,Tong Xie,Bo Yu,Shaoshan Liu,Meng Li*

Main category: cs.RO

TL;DR: DySL-VLA：一种动态跳过VLA层的框架，通过识别动作重要性来降低计算成本，在保持精度的同时实现3.75倍加速


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人任务中表现出色，但高计算成本阻碍了实时应用。观察到任务中不同动作的重要性不同，关键步骤需要高精度，次要步骤可以容忍更多变化。

Method: 提出DySL-VLA框架，将VLA层分为信息层（始终执行）和增量层（可选择性跳过）。设计了先验-后验跳过指导机制来决定何时启动层跳过，并提出跳过感知的两阶段知识蒸馏算法来训练模型。

Result: 在Calvin数据集上，DySL-VLA相比Deer-VLA实现了2.1%的成功长度提升，同时将可训练参数减少85.7倍，在同等精度下相比RoboFlamingo基线提供3.75倍加速。

Conclusion: DySL-VLA通过动态跳过VLA层有效解决了计算成本问题，在保持性能的同时显著提升了效率，为实时机器人应用提供了可行的解决方案。

Abstract: Vision-Language-Action (VLA) models have shown remarkable success in robotic tasks like manipulation by fusing a language model's reasoning with a vision model's 3D understanding. However, their high computational cost remains a major obstacle for real-world applications that require real-time performance. We observe that the actions within a task have varying levels of importance: critical steps demand high precision, while less important ones can tolerate more variance. Leveraging this insight, we propose DySL-VLA, a novel framework that addresses computational cost by dynamically skipping VLA layers based on each action's importance. DySL-VLA categorizes its layers into two types: informative layers, which are consistently executed, and incremental layers, which can be selectively skipped. To intelligently skip layers without sacrificing accuracy, we invent a prior-post skipping guidance mechanism to determine when to initiate layer-skipping. We also propose a skip-aware two-stage knowledge distillation algorithm to efficiently train a standard VLA into a DySL-VLA. Our experiments indicate that DySL-VLA achieves 2.1% improvement in success length over Deer-VLA on the Calvin dataset, while simultaneously reducing trainable parameters by a factor of 85.7 and providing a 3.75x speedup relative to the RoboFlamingo baseline at iso-accuracy. Our code is available on https://github.com/PKU-SEC-Lab/DYSL_VLA.

</details>


### [17] [Bayesian Preference Elicitation: Human-In-The-Loop Optimization of An Active Prosthesis](https://arxiv.org/abs/2602.22922)
*Sophia Taddei,Wouter Koppen,Eligia Alfio,Stefano Nuzzo,Louis Flynn,Maria Alejandra Diaz,Sebastian Rojas Gonzalez,Tom Dhaene,Kevin De Pauw,Ivo Couckuyt,Tom Verstraten*

Main category: cs.RO

TL;DR: 提出了一种基于人类在环优化(HILO)的方法，利用用户偏好来个性化调整四参数假肢控制器，通过偏好驱动的多目标贝叶斯优化实现高效调优。


<details>
  <summary>Details</summary>
Motivation: 当前假肢调优过程耗时且依赖的指标可能无法完全反映用户需求，需要更高效、用户中心的个性化调优方法。

Method: 采用人类在环优化(HILO)方法，结合偏好驱动的多目标贝叶斯优化，提出了两种算法变体：离散版本(EUBO-LineCoSpar)和连续版本(BPE4Prost)，使用专门为偏好学习设计的先进采集函数。

Result: 在基准函数和实际应用试验中显示出高效收敛、稳健的偏好获取以及可测量的生物力学改进，证明了偏好驱动调优在用户中心假肢控制中的潜力。

Conclusion: 偏好驱动的调优方法为假肢控制器个性化提供了有效途径，能够更好地满足用户需求，实现用户中心的假肢控制。

Abstract: Tuning active prostheses for people with amputation is time-consuming and relies on metrics that may not fully reflect user needs. We introduce a human-in-the-loop optimization (HILO) approach that leverages direct user preferences to personalize a standard four-parameter prosthesis controller efficiently. Our method employs preference-based Multiobjective Bayesian Optimization that uses a state-or-the-art acquisition function especially designed for preference learning, and includes two algorithmic variants: a discrete version (\textit{EUBO-LineCoSpar}), and a continuous version (\textit{BPE4Prost}). Simulation results on benchmark functions and real-application trials demonstrate efficient convergence, robust preference elicitation, and measurable biomechanical improvements, illustrating the potential of preference-driven tuning for user-centered prosthesis control.

</details>


### [18] [Considering Perspectives for Automated Driving Ethics: Collective Risk in Vehicular Motion Planning](https://arxiv.org/abs/2602.22940)
*Leon Tolksdorf,Arturo Tejada,Christian Birkner,Nathan van de Wouw*

Main category: cs.RO

TL;DR: 自动驾驶车辆规划应考虑所有道路使用者的风险视角，而非仅从自身视角最小化风险，以实现更道德和有效的交通行为。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆运动规划策略主要从车辆自身视角最小化风险，忽视了其他道路使用者的风险视角，这可能无法真正降低整体交通风险，甚至可能增加其他道路使用者的风险。

Method: 提出一种支持在所有道路使用者视角之间切换风险最小化策略的自动驾驶运动规划策略，采用集体风险视角来平衡所有道路使用者的风险。

Result: 研究发现不同道路使用者的风险视角确实存在差异；采用集体风险最小化策略的自动驾驶车辆能最好地降低整体交通风险，同时自身承担略高风险以惠及他人，这与人类驾驶行为一致；该策略还能通过在其他道路使用者对AV风险估计较低时采取果断行动来提高行驶效率。

Conclusion: 为实现包含自动驾驶车辆的道德交通，必须在自动驾驶决策中考虑每个道路使用者的风险视角，这种自我反思行为是实现社会可接受自动驾驶行为的自然前提。

Abstract: Recent automated vehicle (AV) motion planning strategies evolve around minimizing risk in road traffic. However, they exclusively consider risk from the AV's perspective and, as such, do not address the ethicality of its decisions for other road users. We argue that this does not reduce the risk of each road user, as risk may be different from the perspective of each road user. Indeed, minimizing the risk from the AV's perspective may not imply that the risk from the perspective of other road users is also being minimized; in fact, it may even increase. To test this hypothesis, we propose an AV motion planning strategy that supports switching risk minimization strategies between all road user perspectives. We find that the risk from the perspective of other road users can generally be considered different to the risk from the AV's perspective. Taking a collective risk perspective, i.e., balancing the risks of all road users, we observe an AV that minimizes overall traffic risk the best, while putting itself at slightly higher risk for the benefit of others, which is consistent with human driving behavior. In addition, adopting a collective risk minimization strategy can also be beneficial to the AV's travel efficiency by acting assertively when other road users maintain a low risk estimate of the AV. Yet, the AV drives conservatively when its planned actions are less predictable to other road users, i.e., associated with high risk. We argue that such behavior is a form of self-reflection and a natural prerequisite for socially acceptable AV behavior. We conclude that to facilitate ethicality in road traffic that includes AVs, the risk-perspective of each road user must be considered in the decision-making of AVs.

</details>


### [19] [Automated Robotic Needle Puncture for Percutaneous Dilatational Tracheostomy](https://arxiv.org/abs/2602.22952)
*Yuan Tang,Bruno V. Adorno,Brendan A. McGrath,Andrew Weightman*

Main category: cs.RO

TL;DR: 提出一种用于经皮扩张气管切开术的机器人辅助穿刺系统，使用电磁传感器引导和自适应约束控制器，显著提高了穿刺精度


<details>
  <summary>Details</summary>
Motivation: 当前经皮扩张气管切开术的穿刺步骤完全依赖手动操作，缺乏导航辅助，导致较大的位置和角度误差（5毫米和30度），可能引发严重并发症如大出血和后气管壁穿孔

Method: 开发了基于速度控制的机器人操纵器系统，使用两个电磁传感器（一个在针尖，一个在气管内）提供姿态数据，采用自适应约束控制器在线调整不确定的运动学参数，避免与患者身体和靶点周围组织碰撞

Result: 在人体模型上进行了400次穿刺实验，绝对中位穿刺位置误差为1.7毫米（IQR：1.9毫米），中线偏差为4.13度（IQR：4.55度），相比传统手动穿刺精度显著提高

Conclusion: 机器人辅助的经皮扩张气管切开术穿刺系统在模拟实验设置中表现出较小的偏差，并提供了无碰撞插入的形式保证，证明了该技术的可行性

Abstract: Percutaneous dilatational tracheostomy (PDT) is frequently performed on patients in intensive care units for prolonged mechanical ventilation. The needle puncture, as the most critical step of PDT, could lead to adverse consequences such as major bleeding and posterior tracheal wall perforation if performed inaccurately. Current practices of PDT puncture are all performed manually with no navigation assistance, which leads to large position and angular errors (5 mm and 30 degree). To improve the accuracy and reduce the difficulty of the PDT procedure, we propose a system that automates the needle insertion using a velocity-controlled robotic manipulator. Guided using pose data from two electromagnetic sensors, one at the needle tip and the other inside the trachea, the robotic system uses an adaptive constrained controller to adapt the uncertain kinematic parameters online and avoid collisions with the patient's body and tissues near the target. Simulations were performed to validate the controller's implementation, and then four hundred PDT punctures were performed on a mannequin to evaluate the position and angular accuracy. The absolute median puncture position error was 1.7 mm (IQR: 1.9 mm) and midline deviation was 4.13 degree (IQR: 4.55 degree), measured by the sensor inside the trachea. The small deviations from the nominal puncture in a simulated experimental setup and formal guarantees of collision-free insertions suggest the feasibility of the robotic PDT puncture.

</details>


### [20] [DigiArm: An Anthropomorphic 3D-Printed Prosthetic Hand with Enhanced Dexterity for Typing Tasks](https://arxiv.org/abs/2602.23017)
*Dean Zadok,Tom Naamani,Yuval Bar-Ratson,Elisha Barash,Oren Salzman,Alon Wolf,Alex M. Bronstein,Nili Krausz*

Main category: cs.RO

TL;DR: 提出低成本3D打印机器人假肢手，增强对电子设备（键盘、钢琴）的精细操作能力，支持手指独立按压和手腕调整功能


<details>
  <summary>Details</summary>
Motivation: 现有假肢手无法复制人手灵巧性和直观控制，商业假肢缺乏精细操作能力，无法满足键盘打字、钢琴演奏等需要精确手指动作的应用需求，需要可访问、可复制的假肢设计

Method: 设计低成本轻量级3D打印机器人假肢手，包含手指外展/内收间距调节机制、2维手腕控制（优化用于打字的尺骨/桡骨偏转）、独立手指按压控制

Result: 通过研究展示参与者能够使用该机器人假肢手实时执行键盘打字和钢琴演奏，支持不同级别的手指和手腕运动，证明比以往设计更有效地执行按键打字动作

Conclusion: 提出的设计能够增强假肢手的功能性，特别是在电子设备交互和精细手指操作方面，为假肢用户提供更好的操作能力

Abstract: Despite recent advancements, existing prosthetic limbs are unable to replicate the dexterity and intuitive control of the human hand. Current control systems for prosthetic hands are often limited to grasping, and commercial prosthetic hands lack the precision needed for dexterous manipulation or applications that require fine finger motions. Thus, there is a critical need for accessible and replicable prosthetic designs that enable individuals to interact with electronic devices and perform precise finger pressing, such as keyboard typing or piano playing, while preserving current prosthetic capabilities. This paper presents a low-cost, lightweight, 3D-printed robotic prosthetic hand, specifically engineered for enhanced dexterity with electronic devices such as a computer keyboard or piano, as well as general object manipulation. The robotic hand features a mechanism to adjust finger abduction/adduction spacing, a 2-D wrist with the inclusion of controlled ulnar/radial deviation optimized for typing, and control of independent finger pressing. We conducted a study to demonstrate how participants can use the robotic hand to perform keyboard typing and piano playing in real time, with different levels of finger and wrist motion. This supports the notion that our proposed design can allow for the execution of key typing motions more effectively than before, aiming to enhance the functionality of prosthetic hands.

</details>


### [21] [InCoM: Intent-Driven Perception and Structured Coordination for Whole-Body Mobile Manipulation](https://arxiv.org/abs/2602.23024)
*Jiahao Liu,Cui Wenbo,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: InCoM框架通过意图驱动的感知和结构化协调机制，解决了全身移动操作中控制耦合和感知注意力分配的问题，在多个场景中显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有全身移动操作方法面临两个关键挑战：1) 基座和机械臂动作的强耦合使全身控制优化复杂化；2) 在移动操作过程中，随着视角动态变化，感知注意力分配往往不佳。

Method: 提出InCoM框架：1) 推断潜在运动意图以动态重新加权多尺度感知特征，实现阶段自适应的感知注意力分配；2) 引入几何-语义结构化对齐机制增强多模态对应；3) 设计解耦协调流匹配动作解码器，显式建模协调的基座-机械臂动作生成。

Result: 在三个ManiSkill-HAB场景中，InCoM在无法访问特权感知信息的情况下，分别以28.2%、26.1%和23.6%的成功率优势超越了最先进的方法。

Conclusion: InCoM通过意图驱动的感知和结构化协调机制，有效解决了全身移动操作中的控制耦合和感知注意力分配问题，展示了强大的全身移动操作能力。

Abstract: Whole-body mobile manipulation is a fundamental capability for general-purpose robotic agents, requiring both coordinated control of the mobile base and manipulator and robust perception under dynamically changing viewpoints. However, existing approaches face two key challenges: strong coupling between base and arm actions complicates whole-body control optimization, and perceptual attention is often poorly allocated as viewpoints shift during mobile manipulation. We propose InCoM, an intent-driven perception and structured coordination framework for whole-body mobile manipulation. InCoM infers latent motion intent to dynamically reweight multi-scale perceptual features, enabling stage-adaptive allocation of perceptual attention. To support robust cross-modal perception, InCoM further incorporates a geometric-semantic structured alignment mechanism that enhances multimodal correspondence. On the control side, we design a decoupled coordinated flow matching action decoder that explicitly models coordinated base-arm action generation, alleviating optimization difficulties caused by control coupling. Without access to privileged perceptual information, InCoM outperforms state-of-the-art methods on three ManiSkill-HAB scenarios by 28.2%, 26.1%, and 23.6% in success rate, demonstrating strong effectiveness for whole-body mobile manipulation.

</details>


### [22] [An Empirical Analysis of Cooperative Perception for Occlusion Risk Mitigation](https://arxiv.org/abs/2602.23051)
*Aihong Wang,Tenghui Xie,Fuxi Wen,Jun Li*

Main category: cs.RO

TL;DR: 提出了一种新的风险评估指标RTL，用于量化遮挡导致的跟踪丢失风险，并通过V2X部署策略验证其有效性，发现非对称通信框架在低渗透率下即可显著降低风险。


<details>
  <summary>Details</summary>
Motivation: 遮挡对自动驾驶车辆构成重大挑战，传统风险指标难以捕捉随时间累积的威胁特性，需要一种更全面的风险评估方法。

Method: 提出了Risk of Tracking Loss (RTL)指标，聚合遮挡期间的瞬时风险强度；使用高保真实世界数据集进行大规模统计分析；应用该指标评估不同V2X部署策略；提出非对称通信框架。

Result: RTL能有效表征遮挡风险；完全V2X渗透理论上可消除风险，但需要75-90%的高渗透阈值；非对称通信框架在25%渗透率下表现优于传统对称模型75%渗透率，50%渗透率即达到饱和效益。

Conclusion: RTL提供了关键的风险评估指标，非对称通信框架为加速V2X部署的安全效益提供了成本有效的战略路线图。

Abstract: Occlusions present a significant challenge for connected and automated vehicles, as they can obscure critical road users from perception systems. Traditional risk metrics often fail to capture the cumulative nature of these threats over time adequately. In this paper, we propose a novel and universal risk assessment metric, the Risk of Tracking Loss (RTL), which aggregates instantaneous risk intensity throughout occluded periods. This provides a holistic risk profile that encompasses both high-intensity, short-term threats and prolonged exposure. Utilizing diverse and high-fidelity real-world datasets, a large-scale statistical analysis is conducted to characterize occlusion risk and validate the effectiveness of the proposed metric. The metric is applied to evaluate different vehicle-to-everything (V2X) deployment strategies. Our study shows that full V2X penetration theoretically eliminates this risk, the reduction is highly nonlinear; a substantial statistical benefit requires a high penetration threshold of 75-90%. To overcome this limitation, we propose a novel asymmetric communication framework that allows even non-connected vehicles to receive warnings. Experimental results demonstrate that this paradigm achieves better risk mitigation performance. We found that our approach at 25% penetration outperforms the traditional symmetric model at 75%, and benefits saturate at only 50% penetration. This work provides a crucial risk assessment metric and a cost-effective, strategic roadmap for accelerating the safety benefits of V2X deployment.

</details>


### [23] [Towards Intelligible Human-Robot Interaction: An Active Inference Approach to Occluded Pedestrian Scenarios](https://arxiv.org/abs/2602.23109)
*Kai Chen,Yuyao Huang,Guang Chen*

Main category: cs.RO

TL;DR: 提出基于主动推理的框架处理自动驾驶中遮挡行人突然出现的挑战，通过RBPF估计行人混合状态，引入条件信念重置和假设注入技术建模行人潜在意图，使用CEM增强的MPPI控制器进行规划，显著降低碰撞率并展现类人驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中遮挡行人突然出现是重大安全挑战，传统基于规则或纯数据驱动方法难以处理这种高不确定性的长尾场景。

Method: 1. 基于主动推理框架，赋予智能体类人的信念驱动机制；2. 使用Rao-Blackwellized粒子滤波器高效估计行人混合状态；3. 引入条件信念重置机制和假设注入技术，显式建模行人多个潜在意图；4. 采用交叉熵方法增强的模型预测路径积分控制器进行规划，结合CEM的高效迭代搜索和MPPI的鲁棒性。

Result: 仿真实验表明，相比反应式、基于规则和强化学习基线方法，该方法显著降低碰撞率，同时展现出可解释的类人驾驶行为，反映了智能体内部信念状态。

Conclusion: 提出的主动推理框架能有效处理自动驾驶中遮挡行人突然出现的高不确定性场景，通过类人的信念驱动机制实现更安全、可解释的驾驶行为。

Abstract: The sudden appearance of occluded pedestrians presents a critical safety challenge in autonomous driving. Conventional rule-based or purely data-driven approaches struggle with the inherent high uncertainty of these long-tail scenarios. To tackle this challenge, we propose a novel framework grounded in Active Inference, which endows the agent with a human-like, belief-driven mechanism. Our framework leverages a Rao-Blackwellized Particle Filter (RBPF) to efficiently estimate the pedestrian's hybrid state. To emulate human-like cognitive processes under uncertainty, we introduce a Conditional Belief Reset mechanism and a Hypothesis Injection technique to explicitly model beliefs about the pedestrian's multiple latent intentions. Planning is achieved via a Cross-Entropy Method (CEM) enhanced Model Predictive Path Integral (MPPI) controller, which synergizes the efficient, iterative search of CEM with the inherent robustness of MPPI. Simulation experiments demonstrate that our approach significantly reduces the collision rate compared to reactive, rule-based, and reinforcement learning (RL) baselines, while also exhibiting explainable and human-like driving behavior that reflects the agent's internal belief state.

</details>


### [24] [Grasp, Slide, Roll: Comparative Analysis of Contact Modes for Tactile-Based Shape Reconstruction](https://arxiv.org/abs/2602.23206)
*Chung Hee Kim,Shivani Kamtikar,Tye Brady,Taskin Padir,Joshua Migdal*

Main category: cs.RO

TL;DR: 该研究比较了三种触觉接触模式（抓握释放、手指滑动、手掌滚动）对物体形状重建的影响，发现手指滑动和手掌滚动模式能减少34%的物理交互次数，同时提高55%的重建精度。


<details>
  <summary>Details</summary>
Motivation: 触觉传感能让机器人通过物理交互获取物体的详细几何信息，但高效获取有用触觉数据仍具挑战性，因为物理接触耗时且需要战略性地选择接触位置以最大化信息增益同时最小化物理交互。

Method: 研究比较了三种接触交互模式：抓握释放、手指滑动（手指滑动引起）、手掌滚动。这些接触模式与信息论探索框架相结合，该框架使用形状补全模型指导后续采样位置。实验使用配备Inspire-Robots灵巧手的UR5e机器人手臂进行验证。

Result: 结果显示，手指滑动和手掌滚动模式提高了触觉传感效率，使形状重建收敛更快，需要减少34%的物理交互次数，同时提高55%的重建精度。该方法在基本物体几何形状上表现出鲁棒性能。

Conclusion: 手指滑动和手掌滚动等主动触觉接触模式能显著提高触觉传感效率，减少物理交互需求的同时提高形状重建精度，为机器人触觉感知提供了有效的策略。

Abstract: Tactile sensing allows robots to gather detailed geometric information about objects through physical interaction, complementing vision-based approaches. However, efficiently acquiring useful tactile data remains challenging due to the time-consuming nature of physical contact and the need to strategically choose contact locations that maximize information gain while minimizing physical interactions. This paper studies how different contact modes affect object shape reconstruction using a tactile-enabled dexterous gripper. We compare three contact interaction modes: grasp-releasing, sliding induced by finger-grazing, and palm-rolling. These contact modes are combined with an information-theoretic exploration framework that guides subsequent sampling locations using a shape completion model. Our results show that the improved tactile sensing efficiency of finger-grazing and palm-rolling translates into faster convergence in shape reconstruction, requiring 34% fewer physical interactions while improving reconstruction accuracy by 55%. We validate our approach using a UR5e robot arm equipped with an Inspire-Robots Dexterous Hand, showing robust performance across primitive object geometries.

</details>


### [25] [SPARR: Simulation-based Policies with Asymmetric Real-world Residuals for Assembly](https://arxiv.org/abs/2602.23253)
*Yijie Guo,Iretiayo Akinola,Lars Johannsmeier,Hugo Hadfield,Abhishek Gupta,Yashraj Narang*

Main category: cs.RO

TL;DR: SPARR方法结合仿真训练的基础策略和现实世界学习的残差策略，有效解决机器人装配中的sim-to-real差距问题，显著提升成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 机器人装配需要精确的接触式操作，现有方法存在局限性：仿真学习存在sim-to-real差距，现实世界RL需要大量人工监督且泛化能力差。

Method: 提出混合方法：仿真训练的基础策略（使用低级状态观测和密集奖励）提供初始行为先验；现实世界学习的残差策略（使用视觉观测和稀疏奖励）补偿动态差异和传感器噪声。

Result: SPARR在多种双部件装配任务中实现接近完美的成功率，相比零样本sim-to-real方法成功率提升38.4%，周期时间减少29.7%，且无需人工监督。

Conclusion: SPARR通过结合仿真和现实世界学习的优势，有效解决了机器人装配中的sim-to-real差距问题，实现了高效、自适应的装配策略。

Abstract: Robotic assembly presents a long-standing challenge due to its requirement for precise, contact-rich manipulation. While simulation-based learning has enabled the development of robust assembly policies, their performance often degrades when deployed in real-world settings due to the sim-to-real gap. Conversely, real-world reinforcement learning (RL) methods avoid the sim-to-real gap, but rely heavily on human supervision and lack generalization ability to environmental changes. In this work, we propose a hybrid approach that combines a simulation-trained base policy with a real-world residual policy to efficiently adapt to real-world variations. The base policy, trained in simulation using low-level state observations and dense rewards, provides strong priors for initial behavior. The residual policy, learned in the real world using visual observations and sparse rewards, compensates for discrepancies in dynamics and sensor noise. Extensive real-world experiments demonstrate that our method, SPARR, achieves near-perfect success rates across diverse two-part assembly tasks. Compared to the state-of-the-art zero-shot sim-to-real methods, SPARR improves success rates by 38.4% while reducing cycle time by 29.7%. Moreover, SPARR requires no human expertise, in contrast to the state-of-the-art real-world RL approaches that depend heavily on human supervision.

</details>


### [26] [Simple Models, Real Swimming: Digital Twins for Tendon-Driven Underwater Robots](https://arxiv.org/abs/2602.23283)
*Mike Y. Michelis,Nana Obayashi,Josie Hughes,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出一种基于简化无状态流体模型的肌腱驱动鱼机器人仿真环境，仅需两条真实游泳轨迹即可匹配实验行为，运行速度快于实时，适用于强化学习控制


<details>
  <summary>Details</summary>
Motivation: 模仿游泳动物的优雅运动是软体机器人领域的核心挑战，现有建模方法计算成本高，不适用于复杂控制或强化学习，需要更高效的仿真环境

Method: 在MuJoCo机器人框架中实现简化的无状态流体动力学公式，使用肌腱驱动鱼机器人模型，仅用两条真实游泳轨迹识别五个流体参数匹配实验行为

Result: 该无状态流体模型能泛化到未见过的驱动频率，性能优于经典解析模型如细长体理论，仿真速度快于实时，目标跟踪任务达到93%成功率

Conclusion: 即使简单的无状态模型，只要仔细匹配物理数据，也能作为软体水下机器人的有效数字孪生体，为水生环境中的可扩展学习和控制开辟新方向

Abstract: Mimicking the graceful motion of swimming animals remains a core challenge in soft robotics due to the complexity of fluid-structure interaction and the difficulty of controlling soft, biomimetic bodies. Existing modeling approaches are often computationally expensive and impractical for complex control or reinforcement learning needed for realistic motions to emerge in robotic systems. In this work, we present a tendon-driven fish robot modeled in an efficient underwater swimmer environment using a simplified, stateless hydrodynamics formulation implemented in the widespread robotics framework MuJoCo. With just two real-world swimming trajectories, we identify five fluid parameters that allow a matching to experimental behavior and generalize across a range of actuation frequencies. We show that this stateless fluid model can generalize to unseen actuation and outperform classical analytical models such as the elongated body theory. This simulation environment runs faster than real-time and can easily enable downstream learning algorithms such as reinforcement learning for target tracking, reaching a 93% success rate. Due to the simplicity and ease of use of the model and our open-source simulation environment, our results show that even simple, stateless models -- when carefully matched to physical data -- can serve as effective digital twins for soft underwater robots, opening up new directions for scalable learning and control in aquatic environments.

</details>
