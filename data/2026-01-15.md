<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fairness risk and its privacy-enabled solution in AI-driven robotic applications](https://arxiv.org/abs/2601.08953)
*Le Liu,Bangguo Yu,Nynke Vellinga,Ming Cao*

Main category: cs.RO

TL;DR: 该论文提出了一种针对机器人决策的效用感知公平性度量方法，并分析了公平性与用户数据隐私之间的联合关系，建立了隐私预算控制公平性指标的框架。


<details>
  <summary>Details</summary>
Motivation: 生成式AI驱动的自主决策系统存在公平性隐患，而机器人应用中缺乏既能捕捉用户效用又能处理数据随机性的可实施公平性定义。同时，法律要求下机器人系统必须保护用户隐私，需要探索隐私与公平性的关系。

Method: 提出了效用感知的机器人决策公平性度量方法，分析公平性与用户数据隐私的联合关系，推导隐私预算控制公平性指标的条件，建立统一的形式化框架，并在机器人导航任务中进行测试验证。

Result: 研究发现隐私预算可以联合用于满足公平性目标，隐私保护机制能够同时促进公平性实现，这在机器人导航任务中得到了验证。

Conclusion: 通过创造性结合隐私考量来解决公平性问题，是迈向AI伦理使用的重要一步，能够增强日常环境中部署的自主机器人的可信度。隐私预算可以协同用于实现公平性目标。

Abstract: Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments.

</details>


### [2] [Design Methodology of Hydraulically-driven Soft Robotic Gripper for a Large and Heavy Object](https://arxiv.org/abs/2601.09104)
*Ko Yamamoto,Kyosuke Ishibashi,Hiroki Ishikawa,Osamu Azami*

Main category: cs.RO

TL;DR: 本文提出了一种液压驱动软体机器人夹持器的设计方法，用于抓取10-20公斤、直径20-30厘米的大型重物。


<details>
  <summary>Details</summary>
Motivation: 现有软体夹持器多为气动驱动，压力仅数百kPa，无法产生足够力量抓取大型重物。液压驱动具有数MPa压力的潜力，能产生更大功率。

Method: 开发液压驱动软体夹持器，基于数学模型确定基本设计参数（驱动压力、弯曲角度、物体质量、抓取力关系），通过有限元分析选择适合抓取重物的材料。

Result: 实现了对20公斤物体的抓取实验，并完成了手指弯曲角度的闭环控制。

Conclusion: 液压驱动软体夹持器设计方法有效，能够成功抓取大型重物，为重型软体机器人应用提供了可行方案。

Abstract: This paper presents a design methodology of a hydraulically-driven soft robotic gripper for grasping a large and heavy object -- approximately 10 - 20 kg with 20 - 30 cm diameter. Most existing soft grippers are pneumatically actuated with several hundred kPa pressure, and cannot generate output force sufficient for such a large and heavy object. Instead of pneumatic actuation, hydraulic actuation has a potential to generate much larger power by several MPa pressure. In this study, we develop a hydraulically-driven soft gripper, in which its basic design parameters are determined based on a mathematical model that represents the relationship among the driving pressure, bending angle, object mass and grasping force. Moreover, we selected materials suitable for grasping a heavier object, based on the finite element analysis result of the detailed design. We report experimental results on a 20 kg object grasping and closed-loop control of the finger bending angle.

</details>


### [3] [CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space](https://arxiv.org/abs/2601.09163)
*Tong Wu,Shoujie Li,Junhao Gong,Changqing Guo,Xingting Li,Shilong Mu,Wenbo Ding*

Main category: cs.RO

TL;DR: CEI框架通过功能相似性度量和梯度优化实现不同机械臂和末端执行器之间的演示迁移，支持跨形态的机器人策略学习。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型在大型操作数据集上训练时，容易过拟合到特定视角、机械臂和平行夹爪，存在数据集偏差问题，限制了跨形态的泛化能力。

Method: 提出跨形态接口(CEI)框架：1)引入功能相似性概念，使用方向性Chamfer距离量化；2)通过梯度优化对齐机器人轨迹；3)为未见过的机械臂和末端执行器合成观测和动作。

Result: 在仿真中将Franka Panda的数据和策略迁移到16种不同形态，在真实世界中实现UR5+AG95与UR5+Xhand之间的双向迁移，平均迁移率达到82.4%。

Conclusion: CEI有效解决了机器人基础模型的形态过拟合问题，支持跨形态的演示迁移和策略学习，并可扩展到空间泛化和多模态运动生成。

Abstract: Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \CEI introduces the concept of \textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \CEI transfers data and policies from a Franka Panda robot to \textbf{16} different embodiments across \textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\%. Finally, we demonstrate that \CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/

</details>


### [4] [Vision-Conditioned Variational Bayesian Last Layer Dynamics Models](https://arxiv.org/abs/2601.09178)
*Paul Brunzema,Thomas Lew,Ray Zhang,Takeru Shirasawa,John Subosits,Marcus Greiff*

Main category: cs.RO

TL;DR: 提出了一种视觉条件变分贝叶斯最后一层动力学模型，利用视觉上下文预测环境变化，应用于车辆赛车控制，在积水路面条件下显著优于无视觉上下文的方法。


<details>
  <summary>Details</summary>
Motivation: 机器人系统的敏捷控制需要预测环境对系统行为的影响，但传统建模方法难以捕捉行为的突变，而自适应方法本质上是反应式的，可能来不及确保安全。特别是在快速变化条件下，实现自主框架内的主动适应仍然是一个挑战。

Method: 提出视觉条件变分贝叶斯最后一层动力学模型：首先学习名义车辆动力学，然后通过潜在特征的逐特征仿射变换进行微调，实现上下文感知的动力学预测。该模型集成到车辆赛车的最优控制器中。

Result: 在Lexus LC500赛车通过积水路面的实验中，视觉条件模型在变化条件下完成了所有12次尝试的圈数。相比之下，所有没有视觉上下文的基线方法都持续失控，证明了在高性能应用中主动动力学适应的重要性。

Conclusion: 视觉条件变分贝叶斯最后一层动力学模型能够有效预测环境变化，实现主动适应，在快速变化条件下显著提高机器人系统的控制性能和安全性。

Abstract: Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety. We propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment. The model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction. The resulting model is integrated into an optimal controller for vehicle racing. We validate our method on a Lexus LC500 racing through water puddles. With vision-conditioning, the system completed all 12 attempted laps under varying conditions. In contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications.

</details>


### [5] [Online Trajectory Optimization for Arbitrary-Shaped Mobile Robots via Polynomial Separating Hypersurfaces](https://arxiv.org/abs/2601.09231)
*Shuoye Li,Zhiyuan Song,Yulin Li,Zhihai Bi,Jun Ma*

Main category: cs.RO

TL;DR: 提出使用多项式超曲面替代线性超平面进行轨迹优化，实现任意几何形状的非凸机器人避障，无需保守的凸近似


<details>
  <summary>Details</summary>
Motivation: 现有基于分离超平面的轨迹优化方法需要凸近似机器人和障碍物，在复杂狭窄环境中过于保守，限制了实际应用

Method: 1) 推广经典分离超平面定理，证明任意两个不相交的有界闭集可用多项式超曲面分离；2) 构建非线性规划问题，联合优化机器人轨迹和分离多项式系数

Result: 方法在仿真和真实实验中实现平滑、无碰撞、敏捷的机动，在凸近似基线方法失败的环境中表现优异

Conclusion: 通过多项式超曲面分离，彻底消除了轨迹优化中凸近似的限制，实现了任意几何形状的精确碰撞避免

Abstract: An emerging class of trajectory optimization methods enforces collision avoidance by jointly optimizing the robot's configuration and a separating hyperplane. However, as linear separators only apply to convex sets, these methods require convex approximations of both the robot and obstacles, which becomes an overly conservative assumption in cluttered and narrow environments. In this work, we unequivocally remove this limitation by introducing nonlinear separating hypersurfaces parameterized by polynomial functions. We first generalize the classical separating hyperplane theorem and prove that any two disjoint bounded closed sets in Euclidean space can be separated by a polynomial hypersurface, serving as the theoretical foundation for nonlinear separation of arbitrary geometries. Building on this result, we formulate a nonlinear programming (NLP) problem that jointly optimizes the robot's trajectory and the coefficients of the separating polynomials, enabling geometry-aware collision avoidance without conservative convex simplifications. The optimization remains efficiently solvable using standard NLP solvers. Simulation and real-world experiments with nonconvex robots demonstrate that our method achieves smooth, collision-free, and agile maneuvers in environments where convex-approximation baselines fail.

</details>


### [6] [Feedback-Based Mobile Robot Navigation in 3-D Environments Using Artificial Potential Functions Technical Report](https://arxiv.org/abs/2601.09318)
*Ro'i Lang,Elon Rimon*

Main category: cs.RO

TL;DR: 该技术报告提出了在包含球形和圆柱形障碍物的3D工作空间中构建和分析多项式导航函数的方法，通过建立条件确保导航函数在目标点具有唯一非退化最小值且无局部极小值，包括在障碍物相交的情况下。


<details>
  <summary>Details</summary>
Motivation: 在3D工作空间中进行运动规划时，需要设计能够有效避开球形和圆柱形障碍物的导航函数，特别是在障碍物密集且可能相交的复杂环境中，确保路径规划能够收敛到目标点而不陷入局部极小值。

Method: 将工作空间建模为有界球形区域，使用光滑多项式隐函数编码障碍物，构建多项式导航函数，建立确保函数在目标点具有唯一非退化最小值且无局部极小值的条件，包括处理成对相交障碍物的情况，并进行梯度和Hessian分析。

Result: 理论分析表明所提出的导航函数在目标点具有唯一非退化最小值，能够避免局部极小值，即使在障碍物相交的情况下也能保持这一特性。数值模拟在障碍物丰富的3D环境中验证了理论结果的有效性。

Conclusion: 该研究成功构建了适用于3D工作空间的多项式导航函数，能够有效处理球形和圆柱形障碍物，包括相交障碍物的情况，为复杂环境中的运动规划提供了理论保证和实用工具。

Abstract: This technical report presents the construction and analysis of polynomial navigation functions for motion planning in 3-D workspaces populated by spherical and cylindrical obstacles. The workspace is modeled as a bounded spherical region, and obstacles are encoded using smooth polynomial implicit functions. We establish conditions under which the proposed navigation functions admit a unique non-degenerate minimum at the target while avoiding local minima, including in the presence of pairwise intersecting obstacles. Gradient and Hessian analyses are provided, and the theoretical results are validated through numerical simulations in obstacle rich 3-D environments.

</details>


### [7] [ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving](https://arxiv.org/abs/2601.09377)
*Xuemei Yao,Xiao Yang,Jianbin Sun,Liuwei Xie,Xuebin Shao,Xiyu Fang,Hang Su,Kewei Yang*

Main category: cs.RO

TL;DR: ReflexDiffusion：一种用于自动驾驶轨迹规划的新型推理阶段框架，通过反射调整增强扩散模型，在急转弯等高横向加速度场景中显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹规划器在长尾场景（特别是急转弯等高横向加速度情况）中存在系统性失败，主要原因是数据不平衡导致对车辆动力学、道路几何和环境约束建模不足，当车辆接近物理极限时会产生次优或不安全的轨迹预测。

Method: 提出ReflexDiffusion框架，在迭代去噪过程中引入基于梯度的调整机制：在每次标准轨迹更新后，计算条件与无条件噪声预测之间的梯度，显式放大关键条件信号（包括道路曲率和横向车辆动力学），从而强制严格遵守物理约束。

Result: 在nuPlan Test14-hard基准测试中，ReflexDiffusion在高横向加速度场景下相比最先进方法实现了14.1%的驾驶分数提升，证明推理时轨迹优化能有效补偿训练数据稀疏性。

Conclusion: 该框架的架构无关设计可直接部署到现有基于扩散的规划器中，为在挑战性驾驶条件下提高自动驾驶车辆安全性提供了实用解决方案，特别是在处理极限操控时能动态强化安全关键约束。

Abstract: Generating safe and reliable trajectories for autonomous vehicles in long-tail scenarios remains a significant challenge, particularly for high-lateral-acceleration maneuvers such as sharp turns, which represent critical safety situations. Existing trajectory planners exhibit systematic failures in these scenarios due to data imbalance. This results in insufficient modelling of vehicle dynamics, road geometry, and environmental constraints in high-risk situations, leading to suboptimal or unsafe trajectory prediction when vehicles operate near their physical limits. In this paper, we introduce ReflexDiffusion, a novel inference-stage framework that enhances diffusion-based trajectory planners through reflective adjustment. Our method introduces a gradient-based adjustment mechanism during the iterative denoising process: after each standard trajectory update, we compute the gradient between the conditional and unconditional noise predictions to explicitly amplify critical conditioning signals, including road curvature and lateral vehicle dynamics. This amplification enforces strict adherence to physical constraints, particularly improving stability during high-lateral-acceleration maneuvers where precise vehicle-road interaction is paramount. Evaluated on the nuPlan Test14-hard benchmark, ReflexDiffusion achieves a 14.1% improvement in driving score for high-lateral-acceleration scenarios over the state-of-the-art (SOTA) methods. This demonstrates that inference-time trajectory optimization can effectively compensate for training data sparsity by dynamically reinforcing safety-critical constraints near handling limits. The framework's architecture-agnostic design enables direct deployment to existing diffusion-based planners, offering a practical solution for improving autonomous vehicle safety in challenging driving conditions.

</details>


### [8] [Data Scaling for Navigation in Unknown Environments](https://arxiv.org/abs/2601.09444)
*Lauri Suomela,Naoki Takahata,Sasanka Kuruppu Arachchige,Harry Edelman,Joni-Kristian Kämäräinen*

Main category: cs.RO

TL;DR: 大规模研究表明，数据多样性比数据量对视觉导航策略的泛化能力更重要，使用来自35个国家161个地点的4,565小时众包数据训练的策略能在未见环境中实现零样本导航。


<details>
  <summary>Details</summary>
Motivation: 模仿学习导航策略在训练未见环境中的泛化能力仍然是一个重大挑战，需要研究数据量和数据多样性对真实世界端到端视觉导航泛化能力的影响。

Method: 使用来自35个国家161个地点的4,565小时众包数据集，训练点目标导航策略，在四个国家的侧边机器人上进行闭环控制性能评估，覆盖125公里自主驾驶。

Result: 大规模训练数据使策略能在未知环境中实现零样本导航，性能接近环境特定演示训练的策略。数据多样性比数据量更重要：训练集中地理位置数量翻倍可使导航误差减少约15%，而增加现有位置数据的性能收益在数据量很少时就饱和了。

Conclusion: 数据多样性是视觉导航策略泛化的关键因素，简单的回归模型在噪声众包数据中优于生成和序列架构，这为构建泛化导航系统提供了重要指导。

Abstract: Generalization of imitation-learned navigation policies to environments unseen in training remains a major challenge. We address this by conducting the first large-scale study of how data quantity and data diversity affect real-world generalization in end-to-end, map-free visual navigation. Using a curated 4,565-hour crowd-sourced dataset collected across 161 locations in 35 countries, we train policies for point goal navigation and evaluate their closed-loop control performance on sidewalk robots operating in four countries, covering 125 km of autonomous driving.
  Our results show that large-scale training data enables zero-shot navigation in unknown environments, approaching the performance of policies trained with environment-specific demonstrations. Critically, we find that data diversity is far more important than data quantity. Doubling the number of geographical locations in a training set decreases navigation errors by ~15%, while performance benefit from adding data from existing locations saturates with very little data. We also observe that, with noisy crowd-sourced data, simple regression-based models outperform generative and sequence-based architectures. We release our policies, evaluation setup and example videos on the project page.

</details>


### [9] [CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion](https://arxiv.org/abs/2601.09512)
*Ralf Römer,Yi Zhang,Angela P. Schoellig*

Main category: cs.RO

TL;DR: CLARE是一个参数高效的持续学习框架，通过轻量级模块化适配器和自动扩展机制，让视觉-语言-动作模型能够持续学习新任务而不遗忘旧知识，无需存储先前数据或任务标识符。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练视觉-语言-动作模型的微调方法不适合机器人在现实世界中的长期操作，因为机器人需要持续适应新任务和环境，同时保留已获得的知识。现有的机器人持续学习方法通常需要存储先前数据、难以处理长任务序列，或依赖任务标识符进行部署。

Method: CLARE在选定的前馈层中引入轻量级模块化适配器，通过层间特征相似性指导，在必要时自动扩展模型以适应新任务。部署时，基于自编码器的路由机制动态激活最相关的适配器，无需任务标签。

Result: 在LIBERO基准测试上的广泛实验表明，CLARE在新任务上实现了高性能，同时对早期任务没有灾难性遗忘，显著优于基于示例的方法。

Conclusion: CLARE提供了一个通用、参数高效的示例无关持续学习框架，使视觉-语言-动作模型能够在现实世界中持续适应新任务，同时保留已有知识，无需存储先前数据或任务标识符。

Abstract: To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars), struggle with long task sequences, or rely on task identifiers for deployment. To address these limitations, we propose CLARE, a general, parameter-efficient framework for exemplar-free continual learning with VLAs. CLARE introduces lightweight modular adapters into selected feedforward layers and autonomously expands the model only where necessary when learning a new task, guided by layer-wise feature similarity. During deployment, an autoencoder-based routing mechanism dynamically activates the most relevant adapters without requiring task labels. Through extensive experiments on the LIBERO benchmark, we show that CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks, significantly outperforming even exemplar-based methods. Code and data are available at https://tum-lsy.github.io/clare.

</details>


### [10] [Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations](https://arxiv.org/abs/2601.09518)
*Wei-Jin Huang,Yue-Yi Zhang,Yi-Lin Wei,Zhi-Wei Xia,Juantao Tan,Yuan-Ming Li,Zhilin Zhao,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: PAIR+D-STAR：通过物理感知交互重定向从人类-人类交互数据生成高质量人形机器人交互数据，并采用解耦时空动作推理器学习超越模仿的协同行为


<details>
  <summary>Details</summary>
Motivation: 人形机器人与人类物理交互是前沿领域，但缺乏高质量的人-人形交互数据。虽然可以利用丰富的人-人交互数据作为可扩展替代方案，但标准重定向方法会破坏关键接触点，且传统模仿学习策略仅模仿轨迹而缺乏交互理解。

Method: 提出两阶段框架：1) PAIR（物理感知交互重定向）- 以接触为中心的管道，通过保持跨形态差异的接触语义生成物理一致的人-人形交互数据；2) D-STAR（解耦时空动作推理器）- 分层策略，通过相位注意力（何时行动）和多尺度空间模块（何处行动）解耦时空推理，由扩散头融合产生超越模仿的同步全身行为。

Result: 通过广泛严谨的仿真验证，相比基线方法获得显著性能提升，展示了从人-人交互数据学习复杂全身交互的完整有效管道。

Conclusion: PAIR和D-STAR共同解决了从人-人交互数据学习人-人形交互的两个关键挑战：数据生成中的物理一致性和策略学习中的交互理解，实现了响应灵敏、同步协作的机器人行为。

Abstract: Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are fused by the diffusion head to produce synchronized whole-body behaviors beyond mimicry. By decoupling these reasoning streams, our model learns robust temporal phases without being distracted by spatial noise, leading to responsive, synchronized collaboration. We validate our framework through extensive and rigorous simulations, demonstrating significant performance gains over baseline approaches and a complete, effective pipeline for learning complex whole-body interactions from HHI data.

</details>


### [11] [Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping](https://arxiv.org/abs/2601.09578)
*Jiajun Sun,Yangyi Ou,Haoyuan Zheng,Chao yang,Yue Ma*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的语义增强3D点云地图方法，通过融合可见光和红外图像，将热信息作为语义层添加到3D地图中，用于高温目标识别和环境理解。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，自主机器人导航和环境感知对SLAM技术提出了更高要求。需要生成不仅具有准确几何结构，还能理解环境语义信息的地图，特别是在灾害评估和工业预防性维护等特定应用中。

Method: 1. 首先在像素级融合可见光和红外图像；2. 将实时LiDAR点云投影到融合图像流上；3. 在热通道中分割热源特征以即时识别高温目标；4. 将温度信息作为语义层应用到最终的3D地图中。

Result: 该方法生成了既具有准确几何结构，又包含关键环境语义理解的地图。能够即时识别高温目标，为快速灾害评估和工业预防性维护等应用提供了重要价值。

Conclusion: 通过将热信息作为语义层集成到3D点云地图中，该方法显著增强了SLAM系统的环境理解能力，为特定应用场景提供了更丰富的信息支持。

Abstract: In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.

</details>
