<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 19]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Designing Persuasive Social Robots for Health Behavior Change: A Systematic Review of Behavior Change Strategies and Evaluation Methods](https://arxiv.org/abs/2601.15309)
*Jiaxin Xu,Chao Zhang,Raymond H. Cuijpers,Wijnand A. IJsselsteijn*

Main category: cs.RO

TL;DR: 系统综述分析了39项研究，总结社交机器人在健康行为干预中使用的行为改变策略和评估方法，提出设计启发和未来研究方向


<details>
  <summary>Details</summary>
Motivation: 社交机器人越来越多地应用于健康行为改变干预，但指导其设计和评估的可操作知识仍然有限，需要系统总结现有研究和实践

Method: 通过系统数据库检索和手工检索识别相关文献，对39项研究进行分析，总结行为改变策略和评估方法

Result: 识别出四大类行为改变策略：指导策略、咨询策略、社会影响策略和说服增强策略；总结了当前评估实践的关键特征，包括研究设计、设置、持续时间和结果测量

Conclusion: 这些策略突出了社交机器人作为行为改变干预的独特优势，提供了有价值的设计启发，并提出了未来人机交互研究的几个方向

Abstract: Social robots are increasingly applied as health behavior change interventions, yet actionable knowledge to guide their design and evaluation remains limited. This systematic review synthesizes (1) the behavior change strategies used in existing HRI studies employing social robots to promote health behavior change, and (2) the evaluation methods applied to assess behavior change outcomes. Relevant literature was identified through systematic database searches and hand searches. Analysis of 39 studies revealed four overarching categories of behavior change strategies: coaching strategies, counseling strategies, social influence strategies, and persuasion-enhancing strategies. These strategies highlight the unique affordances of social robots as behavior change interventions and offer valuable design heuristics. The review also identified key characteristics of current evaluation practices, including study designs, settings, durations, and outcome measures, on the basis of which we propose several directions for future HRI research.

</details>


### [2] [Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray](https://arxiv.org/abs/2601.15349)
*Jiaqing Chang,Song Gao,Chaowei Dong,zhaobang Li,Yang Liu*

Main category: cs.RO

TL;DR: 本文设计了一种基于牛鼻鲼仿生的磁响应微型软体机器人，采用NdFeB和PDMS材料，通过三维亥姆霍兹线圈产生振荡谐波磁场驱动，在B=5 mT、f=11 Hz时达到最快游动速度5.25 mm/s（约0.5体长/秒），并能实现直线、转弯、定向等多种游动模式。


<details>
  <summary>Details</summary>
Motivation: 在狭窄、非结构化的水下环境（如环境监测和微创医疗）中，微型软体机器人因其灵活运动能力和小尺寸具有独特优势。仿生技术能显著提升其游动性能，但由于微型化限制难以内部供电，通常需要无线供电方式。

Method: 基于牛鼻鲼的游动原理，设计制造磁响应仿生微型软体机器人，采用NdFeB和PDMS材料。使用三维亥姆霍兹线圈产生振荡谐波磁场进行游动实验，探究磁场参数对机器人游动性能的影响，并通过调节线圈电流方向和频率实现不同游动模式。

Result: 实验结果显示：在B=5 mT、f=11 Hz时游动速度最快，达到5.25 mm/s（约0.5体长/秒）。通过调节线圈电流方向和频率，机器人能实现直线、转弯、定向等多种游动模式。采用逐步调节方法能有效减少响应误差对轨迹的影响。

Conclusion: 本研究展示了一种磁驱动微型软体机器人的方法，为无线驱动机器人在水下狭窄空间的应用奠定了基础。

Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.

</details>


### [3] [Learning a Unified Latent Space for Cross-Embodiment Robot Control](https://arxiv.org/abs/2601.15419)
*Yashuai Yan,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出一个可扩展的跨具身人形机器人控制框架，通过共享潜在表示统一人类和多样化人形平台的运动，支持直接部署到多种机器人上无需适配。


<details>
  <summary>Details</summary>
Motivation: 解决跨不同形态人形机器人（单臂、双臂、腿式等）的统一控制问题，实现可扩展且具身无关的机器人控制。

Method: 两阶段方法：1) 通过对比学习构建解耦的潜在空间，捕捉不同身体部位的局部运动模式，使用结合关节旋转和末端执行器定位的定制相似度度量；2) 在潜在空间中训练目标条件控制策略，使用条件变分自编码器预测潜在空间位移。

Result: 训练的策略可以直接部署到多种机器人上无需适配，支持通过轻量级机器人特定嵌入层高效添加新机器人，实验证明方法具有鲁棒性、可扩展性和具身无关性。

Conclusion: 该方法实现了跨多样化人形平台的统一控制框架，通过共享潜在表示解决了跨具身控制问题，为机器人控制提供了可扩展的解决方案。

Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.

</details>


### [4] [A Universal Large Language Model -- Drone Command and Control Interface](https://arxiv.org/abs/2601.15486)
*Javier N. Ramos-Silva,Peter J. Burke*

Main category: cs.RO

TL;DR: 提出基于模型上下文协议(MCP)的通用无人机-大语言模型接口，实现自然语言到无人机控制的转换


<details>
  <summary>Details</summary>
Motivation: 当前AI用于无人机控制面临接口标准化问题，每个应用都需要大量人工工作来连接LLM知识和无人机指令控制，需要通用解决方案

Method: 使用模型上下文协议(MCP)标准，开发基于云的Linux机器托管MCP服务器，支持Mavlink协议，实现LLM无关和无人机无关的通用接口

Result: 成功演示了真实无人机的飞行控制，并在模拟无人机中展示了与Google Maps MCP服务器集成的实时导航能力

Conclusion: 提供了一种通用、全面且易于使用的无人机控制接口，将现代AI产业与无人机技术无缝集成，实现自然语言到无人机控制的转换

Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.

</details>


### [5] [CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation](https://arxiv.org/abs/2601.15541)
*Heng Zhang,Wei-Hsing Huang,Qiyi Tong,Gokhan Solak,Puze Liu,Sheng Liu,Jan Peters,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出CompliantVLA-adaptor，通过VLM感知任务上下文来调整变阻抗控制参数，结合实时力反馈，提升VLA模型在接触丰富任务中的安全性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA系统（如RDT、Pi0、OpenVLA-oft）通常只输出位置控制，缺乏力感知适应能力，导致在涉及接触、柔顺或不确定性的物理任务中出现不安全或失败的情况。

Method: 提出CompliantVLA-adaptor，使用视觉语言模型（VLM）从图像和自然语言中解释任务上下文，自适应调整变阻抗控制（VIC）的刚度和阻尼参数，并利用实时力/力矩反馈调节这些参数以确保交互力保持在安全阈值内。

Result: 在仿真和真实硬件上的复杂接触丰富任务中，该方法优于VLA基线，提高了成功率并减少了力违规。所有任务的整体成功率从9.86%提升到17.29%。

Conclusion: CompliantVLA-adaptor为使用VLA进行安全接触丰富操作提供了一条有前景的路径，通过结合VLM的上下文感知和实时力反馈，显著提升了VLA模型在物理交互任务中的性能。

Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.

</details>


### [6] [A Mobile Magnetic Manipulation Platform for Gastrointestinal Navigation with Deep Reinforcement Learning Control](https://arxiv.org/abs/2601.15545)
*Zhifan Yan,Chang Liu,Yiyang Jiang,Wenxuan Zheng,Xinhao Chen,Axel Krieger*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度强化学习的紧凑型移动磁控平台，用于胃肠道靶向药物递送，解决了传统磁控系统工作空间有限和模型校准瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 胃肠道磁控机器人靶向给药有前景，但控制困难：固定磁系统工作空间有限，移动系统（如机械臂上的线圈）存在"模型校准瓶颈"，需要复杂、预校准的物理模型，耗时且计算成本高。

Method: 开发紧凑型低成本移动磁控平台，采用UR5协作机器人搭载四电磁铁阵列，使用基于Soft Actor-Critic的深度强化学习控制策略，通过仿真到现实的训练流程，15分钟内即可部署有效策略。

Result: 在2D轨迹控制7毫米磁性胶囊：DRL控制器在方形路径上均方根误差1.18毫米，圆形路径1.50毫米；在临床相关的30厘米×20厘米工作空间内成功跟踪；使用2D胃肠道模型验证。

Conclusion: 该工作展示了一种快速部署、无模型的控制框架，能够在较大工作空间内实现精确磁控操作，为胃肠道靶向给药提供了实用解决方案。

Abstract: Targeted drug delivery in the gastrointestinal (GI) tract using magnetic robots offers a promising alternative to systemic treatments. However, controlling these robots is a major challenge. Stationary magnetic systems have a limited workspace, while mobile systems (e.g., coils on a robotic arm) suffer from a "model-calibration bottleneck", requiring complex, pre-calibrated physical models that are time-consuming to create and computationally expensive. This paper presents a compact, low-cost mobile magnetic manipulation platform that overcomes this limitation using Deep Reinforcement Learning (DRL). Our system features a compact four-electromagnet array mounted on a UR5 collaborative robot. A Soft Actor-Critic (SAC)-based control strategy is trained through a sim-to-real pipeline, enabling effective policy deployment within 15 minutes and significantly reducing setup time. We validated the platform by controlling a 7-mm magnetic capsule along 2D trajectories. Our DRL-based controller achieved a root-mean-square error (RMSE) of 1.18~mm for a square path and 1.50~mm for a circular path. We also demonstrated successful tracking over a clinically relevant, 30 cm * 20 cm workspace. This work demonstrates a rapidly deployable, model-free control framework capable of precise magnetic manipulation in a large workspace,validated using a 2D GI phantom.

</details>


### [7] [Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor](https://arxiv.org/abs/2601.15607)
*Lenworth Thomas,Tjaden Bridges,Sarah Bergbreiter*

Main category: cs.RO

TL;DR: 本文提出了一种在小型四旋翼无人机上结合气流源追踪与化学羽流追踪的方法，使用定制的气流传感器实现流向和流速感知，改进了"Cast and Surge"算法，能够可靠地找到气流源。


<details>
  <summary>Details</summary>
Motivation: 随着环境灾害日益频繁和严重，使用羽流追踪寻找污染物或有害颗粒源变得越来越重要。小型四旋翼无人机上的羽流追踪可以让这些系统在人类周围运行并在更受限的空间飞行，但由于适合小型四旋翼的气体传感器灵敏度差、响应时间长，这具有挑战性。

Method: 开发了一种定制的气流传感器，可以在重量小于100克的小型四旋翼上感知气流大小和方向。使用该传感器实现改进版的"Cast and Surge"算法，利用流向感知来寻找和导航到气流源。

Result: 一系列表征实验验证了系统在飞行中能够检测气流并重新定向四旋翼朝向气流。多次随机起始位置和方向的试验表明，源追踪算法能够可靠地找到气流源。

Conclusion: 这项工作为未来平台奠定了基础，使气流传感器能够与其他传感器协同工作，实现更丰富的羽流追踪数据收集和源追踪能力。

Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors < 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.

</details>


### [8] [AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning](https://arxiv.org/abs/2601.15614)
*Zichen Yan,Yuchen Hou,Shenao Wang,Yichao Gao,Rui Huang,Lin Zhao*

Main category: cs.RO

TL;DR: AION是一个用于空中物体目标导航的端到端双策略强化学习框架，将探索和目标到达行为解耦为两个专门策略，在AI2-THOR和IsaacSim中表现出色。


<details>
  <summary>Details</summary>
Motivation: 虽然之前的工作主要研究2D运动下的零样本物体目标导航，但将其扩展到具有3D运动能力的空中平台仍未充分探索。空中机器人具有优越的机动性和搜索效率，但也带来了空间感知、动态控制和安全保障的新挑战。

Method: AION是一个端到端的双策略强化学习框架，将探索和目标到达行为解耦为两个专门策略，不依赖外部定位或全局地图，仅基于视觉输入。

Result: 在AI2-THOR基准测试中表现出色，并在IsaacSim中使用高保真无人机模型评估了其实时性能，在探索、导航效率和安全性方面都取得了优越的性能。

Conclusion: AION框架成功解决了空中物体目标导航的挑战，通过双策略设计实现了高效的探索和安全的目标到达，为空中机器人的自主导航提供了有效解决方案。

Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.

</details>


### [9] [D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot](https://arxiv.org/abs/2601.15707)
*Qifan Hu,Branko Celler,Weidong Mu,Steven W. Su*

Main category: cs.RO

TL;DR: 提出两阶段标定框架用于3自由度踝关节康复机器人，通过D最优准则选择4个最优姿态，相比随机选择显著提高信息矩阵行列式值两个数量级，实现高效精确标定。


<details>
  <summary>Details</summary>
Motivation: 多自由度康复机器人需要精确对齐以确保患者训练的安全性和有效性。传统标定方法效率低且精度不足，需要开发更高效的标定框架。

Method: 提出两阶段标定框架：1）基于Kronecker积的开环标定方法，将输入输出对齐转化为线性参数识别问题；2）使用D最优准则作为组合实验设计问题，通过PPO智能体从50个候选姿态中选择4个信息量最大的姿态。

Result: 仿真和真实机器人评估显示，PPO选择的姿态组合比随机选择的信息量高两个数量级以上，方差更小。仅用4个D最优姿态识别的参数向量比50个非结构化姿态具有更强的跨周期预测一致性。

Conclusion: 该框架在保持鲁棒参数估计的同时提高了标定效率，为多自由度康复机器人的高精度对齐提供了实用指导。

Abstract: Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.

</details>


### [10] [Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV](https://arxiv.org/abs/2601.15775)
*Amir Habel,Ivan Snegirev,Elizaveta Semenyakina,Miguel Altamirano Cabrera,Jeffrin Sam,Fawad Mehboob,Roohan Ahmed Khan,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: Glove2UAV是一个可穿戴IMU手套接口，通过手势控制无人机，并配备振动触觉警告系统，当飞行速度超过预设阈值时提供警报。


<details>
  <summary>Details</summary>
Motivation: 开发一个轻量级、易于部署的可穿戴接口，实现无人机直观的手势控制，同时在动态飞行中通过触觉反馈促进更安全、可预测的交互。

Method: 使用IMU手套实时流式传输惯性测量数据，采用中值异常值抑制和Madgwick方向估计算法处理手掌和手指方向，将运动估计映射到方向飞行控制原语，并集成振动触觉反馈系统。

Result: 验证了实时可行性，展示了快速手势命令执行、手势动态与平台运动的稳定耦合、核心命令集的正确操作，以及振动警告提示的及时传递。

Conclusion: Glove2UAV提供了一个有效的可穿戴接口，通过手势控制和触觉反馈实现了无人机直观、安全的交互，在模拟和真实飞行中均表现出良好性能。

Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.

</details>


### [11] [Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems](https://arxiv.org/abs/2601.15946)
*Zijie Chen,Xiaowei Liu,Yong Xu,Shenghai Yuan,Jianping Li,Lihua Xie*

Main category: cs.RO

TL;DR: 本文提出了LM-Calibr标定方法和EVA-LIO定位方法，解决了旋转驱动LiDAR系统的标定通用性和特征缺失区域定位鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要根据不同安装配置参数化外参，限制了通用性；旋转驱动LiDAR不可避免地扫描特征缺失区域，使得扫描覆盖度和定位鲁棒性难以平衡。

Method: 基于Denavit-Hartenberg约定提出无目标LiDAR-电机标定方法LM-Calibr，支持多种安装配置；提出环境自适应LiDAR-惯性里程计EVA-LIO，根据空间尺度自适应选择下采样率和地图分辨率。

Result: 大量实验证明LM-Calibr在不同场景、安装角度和初始值下具有高精度和收敛性；EVA-LIO使执行器能以最大速度运行，增强扫描完整性的同时确保定位鲁棒性。

Conclusion: 提出的LM-Calibr和EVA-LIO方法有效解决了旋转驱动LiDAR系统的标定通用性和特征缺失区域定位鲁棒性问题，代码和硬件设计已开源。

Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}

</details>


### [12] [PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour](https://arxiv.org/abs/2601.15995)
*Liang Wang,Kanzhong Yao,Yang Liu,Weikai Qin,Jun Wu,Zhe Sun,Qiuguo Zhu*

Main category: cs.RO

TL;DR: PUMA是一个端到端学习框架，将视觉感知和落脚点先验集成到单阶段训练中，使四足机器人能够像人类运动员一样感知环境特征并选择合适落脚点进行跑酷任务。


<details>
  <summary>Details</summary>
Motivation: 人类运动员能够有效感知环境特征来选择障碍物穿越的合适落脚点，但赋予腿式机器人类似的感知推理能力仍然是一个重大挑战。现有方法通常依赖遵循预计算落脚点的分层控制器，限制了机器人的实时适应性和强化学习的探索潜力。

Method: 提出PUMA端到端学习框架，将视觉感知和落脚点先验集成到单阶段训练过程中。该方法利用地形特征估计以自我为中心的极坐标落脚点先验（包括相对距离和航向），指导机器人进行主动姿态适应以完成跑酷任务。

Result: 在模拟和真实环境的各种离散复杂地形上进行的广泛实验表明，PUMA在具有挑战性的场景中表现出卓越的敏捷性和鲁棒性。

Conclusion: PUMA框架通过端到端学习成功整合了视觉感知和落脚点先验，使四足机器人能够在复杂地形中实现类似人类的跑酷能力，克服了现有分层控制方法的局限性。

Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.

</details>


### [13] [Collision-Free Humanoid Traversal in Cluttered Indoor Scenes](https://arxiv.org/abs/2601.16035)
*Han Xue,Sikai Liang,Zhikai Zhang,Zicheng Zeng,Yun Liu,Yunrui Lian,Jilong Wang,Qingtao Liu,Xuesong Shi,Li Yi*

Main category: cs.RO

TL;DR: 提出HumanoidPF表示方法，通过编码人形机器人与障碍物关系为无碰撞运动方向，显著促进基于强化学习的穿越技能学习，并开发混合场景生成方法实现可泛化的室内杂乱场景穿越能力。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在杂乱室内场景中的无碰撞穿越问题，如跨越地面障碍、蹲伏通过低矮障碍、挤过狭窄通道等。现有方法缺乏有效表示人形机器人与障碍物在避碰过程中的关系，使得直接学习这种映射变得困难。

Method: 提出Humanoid Potential Field (HumanoidPF)，将人形机器人与障碍物关系编码为无碰撞运动方向，显著促进基于强化学习的穿越技能学习。同时提出混合场景生成方法，结合真实3D室内场景裁剪和程序化合成障碍物，以生成多样化和具有挑战性的杂乱室内场景。

Result: HumanoidPF作为感知表示展现出惊人的可忽略的仿真到现实差距。成功将策略迁移到现实世界，并开发了遥操作系统，用户只需单次点击即可指挥人形机器人在杂乱室内场景中穿越。在仿真和现实世界中进行的大量实验验证了方法的有效性。

Conclusion: HumanoidPF方法有效解决了人形机器人在杂乱室内场景中的无碰撞穿越问题，通过创新的表示方法和场景生成技术，实现了可泛化的穿越技能，并成功实现了仿真到现实的迁移。

Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.

</details>


### [14] [DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning](https://arxiv.org/abs/2601.16046)
*Junha Lee,Eunha Park,Minsu Cho*

Main category: cs.RO

TL;DR: DextER通过接触驱动的具身推理生成灵巧抓取，将任务语义与物理约束连接，在DexGYS上达到67.14%成功率，比SOTA提升3.83%


<details>
  <summary>Details</summary>
Motivation: 现有语言驱动的灵巧抓取生成方法直接将观测映射到抓取参数，缺乏对物理交互的中间推理，需要理解任务语义、3D几何和复杂的手-物体交互

Method: 提出DextER框架，引入基于接触的具身推理，通过自回归生成具身接触令牌（指定手指链接在物体表面的接触位置），然后生成编码手部配置的抓取令牌

Result: 在DexGYS数据集上达到67.14%成功率，比现有最佳方法提升3.83%，意图对齐度提升96.4%，支持通过部分接触规范进行可控生成

Conclusion: 接触驱动的具身推理作为中间表示能有效连接任务语义与物理约束，为灵巧抓取生成提供细粒度控制，显著提升性能和对齐度

Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.

</details>


### [15] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis](https://arxiv.org/abs/2601.16062)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文分析了SE2(3)李群框架在导航建模中的自主误差传播特性，发现在考虑地球旋转和惯性器件偏差的高精度导航中，传统方法因科里奥利力项而难以保持自主性，并提出了一种改进的建模方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于李群的扩展卡尔曼滤波研究表明，在低精度应用（如不考虑地球旋转和惯性偏差的MEMS导航）中误差传播自主性成立，但在考虑地球旋转和惯性偏差的高精度导航状态估计中，保持自主性极其困难。需要分析SE2(3)群在高精度导航模型中的自主性问题。

Method: 首先在惯性系、地球系和世界系下对SE2(3)群高精度导航模型进行理论分析，发现传统SE2(3)群导航建模方法的局限性在于非惯性系中速度引入的科里奥利力项。基于此分析，提出了一种SE2(3)群导航模型的构建方法。

Result: 通过理论分析发现，传统SE2(3)群导航建模方法的主要限制是非惯性系中速度项产生的科里奥利力项破坏了误差传播的自主性。提出的新构建方法能够使导航模型更接近完全自主性。

Conclusion: 本文揭示了SE2(3)李群框架在高精度导航建模中自主性受限的根本原因，并提出了一种改进的建模方法，能够更好地保持误差传播的自主性，为高精度导航状态估计提供了理论支持。

Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.

</details>


### [16] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application](https://arxiv.org/abs/2601.16078)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文通过实际SINS/ODO实验和蒙特卡洛仿真验证了改进的SE2(3)群导航模型的性能，作为前一篇理论分析论文的补充


<details>
  <summary>Details</summary>
Motivation: SE2(3)李群框架在导航建模中的核心优势在于误差传播的自洽性。前一篇论文从理论上分析了惯性、地球和世界坐标系下导航模型的自洽性，本文旨在通过实际实验验证改进模型的性能

Method: 提出了一种SE2(3)群导航模型的构建方法，用于改进非惯性导航模型以实现完全自洽。通过实际SINS/ODO（捷联惯性导航系统/里程计）实验和蒙特卡洛仿真来验证模型性能

Result: 实验和仿真结果证明了改进的SE2(3)群基高精度导航模型的性能表现

Conclusion: 本文通过实际实验验证了SE2(3)群导航模型的有效性，为前一篇理论分析提供了实证支持，展示了改进模型在实际导航应用中的性能

Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.

</details>


### [17] [Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision](https://arxiv.org/abs/2601.16109)
*Yashuai Yan,Tobias Egle,Christian Ott,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出一个结合模型控制与强化学习的框架，通过残差策略补偿模型不确定性，实现双足机器人鲁棒行走


<details>
  <summary>Details</summary>
Motivation: 解决双足机器人在真实世界中因动力学建模不准确和传感器噪声导致的行走不稳定问题，提高鲁棒性和适应性

Method: 使用基于模型的控制器（DCM轨迹规划和全身控制器）作为基础策略，通过强化学习训练残差策略补偿不确定性，并利用具有真实动力学信息的模型先知策略监督训练

Result: 在多种随机化条件下表现出更好的鲁棒性和泛化能力，为双足机器人的仿真到现实迁移提供了可扩展的解决方案

Conclusion: 提出的框架有效整合了模型控制和强化学习的优势，通过残差学习和先知监督实现了对未建模效应的补偿，提升了双足机器人在不确定环境中的行走性能

Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.

</details>


### [18] [IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance](https://arxiv.org/abs/2601.16207)
*Jongwoo Park,Kanchana Ranasinghe,Jinhyeok Jang,Cristina Mata,Yoo Sung Jang,Michael S Ryoo*

Main category: cs.RO

TL;DR: IVRA是一种无需训练、轻量级的方法，通过利用VLA模型中视觉编码器已有的亲和性提示来增强空间理解，提升机器人操作的精度。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型将图像块展平为1D序列会削弱2D空间线索，而精确的机器人操作需要更好的空间几何结构理解。

Method: IVRA选择性注入视觉编码器中的亲和性信号到语言模型层中，在推理时重新对齐视觉-标记交互，保持几何结构，且无需训练或修改模型参数。

Result: 在多种VLA架构和模拟基准测试中，IVRA显著提升性能：2D VIMA上平均成功率提升4.2%，3D LIBERO上从96.3%提升到97.1%，在真实机器人任务中也表现一致改进。

Conclusion: IVRA证明了通过利用现有视觉编码器的亲和性提示，可以在不重新训练的情况下有效增强VLA模型的空间理解能力，为机器人操作提供更精确的几何感知。

Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA

</details>


### [19] [Point Bridge: 3D Representations for Cross Domain Policy Learning](https://arxiv.org/abs/2601.16212)
*Siddhant Haldar,Lars Johannsmeier,Lerrel Pinto,Abhishek Gupta,Dieter Fox,Yashraj Narang,Ajay Mandlekar*

Main category: cs.RO

TL;DR: Point Bridge框架通过点云表示实现零样本仿真到现实的策略迁移，无需视觉或物体级对齐，在合成数据上训练机器人操作策略，显著提升仿真到现实的性能。


<details>
  <summary>Details</summary>
Motivation: 机器人基础模型的发展受限于大规模真实世界操作数据集的稀缺，而仿真和合成数据虽然可扩展，但受到仿真与现实之间视觉域差距的限制。

Method: 提出Point Bridge框架：1) 使用视觉语言模型自动提取统一的、领域无关的点云表示；2) 基于Transformer的策略学习；3) 高效的推理时管道，仅使用合成数据训练真实世界操作智能体。

Result: Point Bridge在零样本仿真到现实迁移中实现高达44%的性能提升，结合少量真实演示数据后提升达66%，在单任务和多任务设置中均优于先前的视觉基仿真-现实联合训练方法。

Conclusion: Point Bridge通过点云表示有效弥合了仿真与现实的视觉域差距，为仅使用合成数据训练真实世界机器人操作策略提供了可行方案，显著提升了仿真到现实的迁移性能。

Abstract: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/

</details>
