<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 38]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [From Conflicts to Collisions: A Two-Stage Collision Scenario-Testing Approach for Autonomous Driving Systems](https://arxiv.org/abs/2602.15837)
*Siyuan Chen,Fuyuan Zhang,Hua Qi,Lei Ma,Tomoyuki Tsuchiya,Michio Hayashi,Manabu Okada*

Main category: cs.RO

TL;DR: 提出两阶段自动驾驶场景测试框架：先搜索冲突场景，再突变冲突场景引发碰撞，相比现有方法发现更多碰撞类型且效率更高


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统测试方法主要评估接近碰撞的场景，关注已接近碰撞的情况，忽略了其他危险情况。需要更全面的安全评估方法。

Method: 引入冲突作为中间搜索目标，提出两阶段场景测试框架：第一阶段搜索冲突场景，第二阶段突变这些冲突场景以引发实际碰撞

Result: 在百度Apollo上评估，单次运行揭示多达12种不同碰撞类型，相比最先进基线方法发现的多样性翻倍，同时因冲突导向突变而需要更少模拟

Conclusion: 使用冲突作为中间目标扩展了搜索范围，显著提高了自动驾驶系统安全评估的效率和效果

Abstract: Autonomous driving systems (ADS) are safety-critical and require rigorous testing before public deployment. Simulation-based scenario testing provides a safe and cost-effective alternative to extensive on-road trials, enabling efficient evaluation of ADS under diverse and high-risk conditions. However, existing approaches mainly evaluates the scenarios based on their proximity to collisions and focus on scenarios already close to collision, leaving many other hazardous situations unexplored. To bridge this, we introduce a collision-related concept of conflict as an intermediate search target and propose a two-stage scenario testing framework that first searches for conflicts and then mutates these conflict scenarios to induce actual collisions. Evaluated on Baidu Apollo, our approach reveals up to 12 distinct collision types in a single run, doubling the diversity discovered by state-of-the-art baselines while requiring fewer simulations thanks to conflict-targeted mutations. These results show that using conflicts as intermediate objectives broadens the search horizon and significantly improves the efficiency and effectiveness of ADS safety evaluation.

</details>


### [2] [A Decade of Human-Robot Interaction through Immersive Lenses: A Literature Review on Extended Reality as a Research Instrument in Social Robotics](https://arxiv.org/abs/2602.15840)
*André Helgert,Carolin Straßmann,Sabrina C. Eimler*

Main category: cs.RO

TL;DR: 该研究系统回顾了2015-2025年XR在社交机器人交互研究中的应用，发现该领域仍处于实验室模拟阶段，存在硬件软件报告不全、机器人交互被动、样本同质化等问题，提出了五阶段发展路线图。


<details>
  <summary>Details</summary>
Motivation: 尽管XR技术在人类-机器人交互研究中受到关注，但在社交机器人实证研究中的应用仍未被充分探索。研究旨在系统梳理该领域现状，识别当前局限，为建立可靠的社交XR-HRI研究方法提供基础。

Method: 对2015-2025年6527篇同行评审文章进行系统回顾，最终筛选出33篇符合严格纳入标准的研究。从四个维度分析：(1)XR和虚拟社交机器人的使用方式和场景，(2)数据收集分析方法，(3)研究人员和参与者人口统计特征，(4)挑战和未来议程。

Result: 研究发现社交XR-HRI研究仍以实验室模拟为主，硬件、软件、机器人规格常未报告；机器人多作为被动视觉刺激，现代头显的生物信号和日志功能未充分利用；研究团队和样本以技术中心、西方、年轻男性为主，人口统计报告存在空白；主要局限包括硬件延迟、样本小且同质、研究周期短浅。

Conclusion: 提出了五阶段路线图：促进方法创新、通过应用场景增强生态效度、提升机器人交互质量、促进样本多样性、建立社交XR-HRI分类体系。这些方向对XR从实验室原型发展为社交机器人研究的生态有效工具至关重要。

Abstract: Over the past decade, extended reality (XR), including virtual, augmented, and mixed reality, gained attention as a research instrument in human-robot interaction studies, but remains underexplored in empirical investigations of social robotics. To map the field, we systematically reviewed empirical studies from 2015 to 2025. Of 6,527 peer-reviewed articles, only 33 met strict inclusion criteria. We examined (1) how XR and virtual social robots are used and in which contexts, (2) data collection and analysis methods, (3) demographics of the researchers and participants, and (4) the stated challenges and future agendas. Our findings show that social XR-HRI research is still dominated by laboratory simulations, while crucial specifications like used hardware, software, and robots are often not reported. Robots typically act as passive and less interactive visual stimuli, while the rich biosignal (e.g., eye-tracking) and logging functions of modern head-mounted displays remain largely untapped. The research teams and samples are predominantly tech-centric, Western, young, and male, with frequent gaps in demographic reporting. Key limitations include hardware delays, small homogeneous samples, and short, shallow study cycles. We propose a five-phase roadmap to establish social XR-HRI as a reliable research medium, which includes fostering methodological innovation, a reinforced ecological validity by, e.g., using application contexts, the improvement of the robot's interaction quality, promoting diversity in the sample and the development of a social XR-HRI taxonomy. Advancing in these directions is essential for XR to mature from a lab prototype into an ecologically valid research instrument for social robotics.

</details>


### [3] [ReasonNavi: Human-Inspired Global Map Reasoning for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2602.15864)
*Yuzhuo Ao,Anbang Wang,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.RO

TL;DR: ReasonNavi是一个受人类启发的导航框架，通过将多模态大语言模型与确定性规划器结合，实现"先推理后行动"的范式，在零样本导航任务中超越需要大量训练的方法。


<details>
  <summary>Details</summary>
Motivation: 现有具身智能体主要依赖局部自我中心观察进行导航，这限制了全局预见性并导致探索效率低下。相比之下，人类使用地图进行规划：先全局推理，再局部行动。

Method: 将俯视地图转换为离散推理空间（房间分割和候选目标节点采样），通过多阶段查询MLLM识别与指令最一致的候选目标，然后使用确定性动作规划器将选定路径点转换为可执行轨迹，同时使用预训练的目标检测器和分割器确保目标识别鲁棒性。

Result: 在三个导航任务中，ReasonNavi始终优于需要大量训练或复杂场景建模的先前方法，提供了一个可扩展、可解释且全局基础的具身导航解决方案。

Conclusion: ReasonNavi提供了一个统一的零样本导航框架，无需MLLM微调，避免了基于RL策略的脆弱性，并能自然地随着基础模型的改进而扩展，为具身导航提供了可扩展、可解释且全局基础的解决方案。

Abstract: Embodied agents often struggle with efficient navigation because they rely primarily on partial egocentric observations, which restrict global foresight and lead to inefficient exploration. In contrast, humans plan using maps: we reason globally first, then act locally. We introduce ReasonNavi, a human-inspired framework that operationalizes this reason-then-act paradigm by coupling Multimodal Large Language Models (MLLMs) with deterministic planners. ReasonNavi converts a top-down map into a discrete reasoning space by room segmentation and candidate target nodes sampling. An MLLM is then queried in a multi-stage process to identify the candidate most consistent with the instruction (object, image, or text goal), effectively leveraging the model's semantic reasoning ability while sidestepping its weakness in continuous coordinate prediction. The selected waypoint is grounded into executable trajectories using a deterministic action planner over an online-built occupancy map, while pretrained object detectors and segmenters ensure robust recognition at the goal. This yields a unified zero-shot navigation framework that requires no MLLM fine-tuning, circumvents the brittleness of RL-based policies and scales naturally with foundation model improvements. Across three navigation tasks, ReasonNavi consistently outperforms prior methods that demand extensive training or heavy scene modeling, offering a scalable, interpretable, and globally grounded solution to embodied navigation. Project page: https://reasonnavi.github.io/

</details>


### [4] [MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models](https://arxiv.org/abs/2602.15872)
*Xunlan Zhou,Xuanlin Chen,Shaowei Zhang,Xiangkun Li,ShengHua Wan,Xiaohai Hu,Yuan Lei,Le Gan,De-chuan Zhan*

Main category: cs.RO

TL;DR: MARVL：通过多阶段视觉语言模型指导的机器人操作强化学习奖励设计方法，显著提升样本效率和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 密集奖励函数设计对机器人强化学习效率至关重要，但现有方法依赖人工工程，限制了强化学习的可扩展性和自动化。视觉语言模型（VLM）为奖励设计提供了有前景的路径，但原始VLM奖励存在任务进度不对齐、空间定位困难、任务语义理解有限等问题。

Method: MARVL通过微调VLM实现空间和语义一致性，将任务分解为多阶段子任务，并通过任务方向投影实现轨迹敏感性。该方法在Meta-World基准测试中验证了其有效性。

Result: MARVL在Meta-World基准测试中显著优于现有的VLM奖励方法，在稀疏奖励操作任务上表现出优越的样本效率和鲁棒性。

Conclusion: MARVL通过多阶段视觉语言模型指导解决了VLM奖励设计的核心问题，为机器人强化学习的自动化奖励设计提供了有效解决方案。

Abstract: Designing dense reward functions is pivotal for efficient robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering, which fundamentally limits the scalability and automation of reinforcement learning. While Vision-Language Models (VLMs) offer a promising path to reward design, naive VLM rewards often misalign with task progress, struggle with spatial grounding, and show limited understanding of task semantics. To address these issues, we propose MARVL-Multi-stAge guidance for Robotic manipulation via Vision-Language models. MARVL fine-tunes a VLM for spatial and semantic consistency and decomposes tasks into multi-stage subtasks with task direction projection for trajectory sensitivity. Empirically, MARVL significantly outperforms existing VLM-reward methods on the Meta-World benchmark, demonstrating superior sample efficiency and robustness on sparse-reward manipulation tasks.

</details>


### [5] [Test-Time Adaptation for Tactile-Vision-Language Models](https://arxiv.org/abs/2602.15873)
*Chuyang Ye,Haoxian Jing,Qinting Jiang,Yixi Lin,Qiang Li,Xing Tang,Jingyan Jiang*

Main category: cs.RO

TL;DR: 本文提出了一种针对触觉-视觉-语言（TVL）模型在测试时分布偏移下的可靠性感知自适应框架，通过估计各模态可靠性来过滤不可靠样本、自适应融合特征并指导优化


<details>
  <summary>Details</summary>
Motivation: 现实世界中的TVL模型部署面临测试时分布偏移问题，现有测试时自适应方法在单模态设置下有效，但缺乏对异步跨模态偏移下各模态可靠性的显式处理，当某些模态变得不可靠时表现脆弱

Method: 提出可靠性感知框架：1）基于预测不确定性和扰动响应估计各模态可靠性；2）使用共享可靠性信号进行：不可靠测试样本过滤、触觉/视觉/语言特征自适应融合、可靠性指导的测试时优化目标正则化

Result: 在TAG-C基准和额外TVL场景中，该方法持续优于强基线，在严重模态损坏下实现高达49.9%的准确率提升

Conclusion: 显式的模态级可靠性建模对于鲁棒的测试时自适应至关重要，所提框架能有效处理异步跨模态偏移下的TVL模型适应问题

Abstract: Tactile-vision-language (TVL) models are increasingly deployed in real-world robotic and multimodal perception tasks, where test-time distribution shifts are unavoidable. Existing test-time adaptation (TTA) methods provide filtering in unimodal settings but lack explicit treatment of modality-wise reliability under asynchronous cross-modal shifts, leaving them brittle when some modalities become unreliable. We study TTA for TVL models under such shifts and propose a reliability-aware framework that estimates per-modality reliability from prediction uncertainty and perturbation-based responses. This shared reliability signal is used to (i) filter unreliable test samples, (ii) adaptively fuse tactile, visual, and language features, and (iii) regularize test-time optimization with a reliability-guided objective. On the TAG-C benchmark and additional TVL scenarios, our approach consistently outperforms strong TTA baselines, achieving accuracy gains of up to 49.9\% under severe modality corruptions, underscoring the importance of explicit modality-wise reliability modeling for robust test-time adaptation.

</details>


### [6] [Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation](https://arxiv.org/abs/2602.15875)
*Zhenxing Xu,Brikit Lu,Weidong Bao,Zhengqiu Zhu,Junsong Zhang,Hui Yan,Wenhao Lu,Ji Wang*

Main category: cs.RO

TL;DR: Fly0框架通过解耦语义推理与几何规划，解决了视觉语言导航中语义理解与控制精度之间的权衡问题，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言导航方法面临语义理解与控制精度之间的权衡。多模态大语言模型虽然推理能力强，但作为低级控制器会导致高延迟、轨迹振荡和泛化能力差的问题，主要原因是几何基础薄弱。

Method: 提出Fly0框架，采用三阶段流水线：1) MLLM驱动模块将自然语言指令接地到2D像素坐标；2) 几何投影模块利用深度数据将目标定位到3D空间；3) 几何规划器生成无碰撞轨迹。该机制即使在视觉接触丢失时也能实现鲁棒导航。

Result: 在仿真和真实环境中的大量实验表明，Fly0优于最先进的基线方法，在非结构化环境中将成功率提高了20%以上，导航误差减少了约50%。通过消除持续推理需求，降低了计算开销并提高了系统稳定性。

Conclusion: Fly0通过解耦语义推理和几何规划，有效解决了VLN中的关键挑战，实现了更高效、更稳定的导航系统，为视觉语言导航领域提供了新的解决方案。

Abstract: Current Visual-Language Navigation (VLN) methodologies face a trade-off between semantic understanding and control precision. While Multimodal Large Language Models (MLLMs) offer superior reasoning, deploying them as low-level controllers leads to high latency, trajectory oscillations, and poor generalization due to weak geometric grounding. To address these limitations, we propose Fly0, a framework that decouples semantic reasoning from geometric planning. The proposed method operates through a three-stage pipeline: (1) an MLLM-driven module for grounding natural language instructions into 2D pixel coordinates; (2) a geometric projection module that utilizes depth data to localize targets in 3D space; and (3) a geometric planner that generates collision-free trajectories. This mechanism enables robust navigation even when visual contact is lost. By eliminating the need for continuous inference, Fly0 reduces computational overhead and improves system stability. Extensive experiments in simulation and real-world environments demonstrate that Fly0 outperforms state-of-the-art baselines, improving the Success Rate by over 20\% and reducing Navigation Error (NE) by approximately 50\% in unstructured environments. Our code is available at https://github.com/xuzhenxing1/Fly0.

</details>


### [7] [The SLAM Confidence Trap](https://arxiv.org/abs/2602.15884)
*Sebastian Sansoni,Santiago Ramón Tosetti Sanz*

Main category: cs.RO

TL;DR: 论文指出SLAM领域陷入"置信度陷阱"，过度追求基准分数而忽视不确定性估计，导致系统几何准确但概率不一致且脆弱，主张将不确定性计算作为主要成功指标。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM研究过于关注基准测试分数，忽视了概率一致性和不确定性估计的重要性，导致系统在实际应用中表现脆弱，需要范式转变来提升系统的鲁棒性和可靠性。

Method: 提出将一致、实时的不确定性计算作为SLAM系统的主要成功指标，倡导从单纯追求几何精度转向概率一致性的评估范式。

Result: 识别了SLAM领域的"置信度陷阱"问题，即系统在几何上准确但在概率上不一致，这限制了SLAM技术的实际应用和鲁棒性。

Conclusion: SLAM社区需要进行范式转变，将不确定性估计作为核心评估标准，而不仅仅是几何精度，这样才能构建更可靠、更鲁棒的SLAM系统。

Abstract: The SLAM community has fallen into a "Confidence Trap" by prioritizing benchmark scores over principled uncertainty estimation. This yields systems that are geometrically accurate but probabilitistically inconsistent and brittle. We advocate for a paradigm shift where the consistent, real-time computation of uncertainty becomes a primary metric of success.

</details>


### [8] [A novel Integrated Motion Tracking Device (IMTD) for Objective Laparoscopic Training Assessment: Development and Validation](https://arxiv.org/abs/2602.15885)
*Siwar Bouzid,Abdelbadia Chaker,Marc Arsicault,Sami Bennour,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出了一种新型紧凑型四自由度运动跟踪设备（IMTD），用于腹腔镜手术的培训与评估。该设备针对腹腔镜训练的特殊需求设计，包括围绕固定运动中心的移动以及与标准箱式训练器的无缝集成。研究验证了IMTD的跟踪精度和可靠性，并评估了其在捕捉手术器械角度和平移运动方面的能力。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术培训需要客观、实时的运动跟踪和评估工具，以缩短学习曲线并提高手术技能。现有系统往往成本高昂或集成复杂，因此需要开发一种紧凑、低成本且易于集成的运动跟踪设备，专门针对腹腔镜训练的特殊需求（如围绕固定中心的运动）进行优化。

Method: 开发了IMTD的四自由度运动学模型、机械设计、仪器配置和原型系统。将IMTD的跟踪精度和可靠性与运动捕捉系统（MoCap）进行比较，评估其捕捉手术器械角度和平移运动的能力。研究重点分析了精度、流畅性、速度和整体运动效率等关键性能参数。

Result: IMTD在跟踪手术手势方面表现出有效性，能够准确捕捉手术器械的运动。系统具有低成本、集成化设计的特点，易于在训练室中部署和实施。研究结果为该设备作为腹腔镜手术培训和性能评估工具的潜力提供了有价值的见解。

Conclusion: IMTD系统通过提供客观、实时的反馈，能够显著提高手术技能并缩短新手学生的学习曲线。该系统为未来手势评分算法和标准化培训协议的开发奠定了基础，为微创手术培训提供了一个实用且易于获取的解决方案。

Abstract: This paper presents a novel, compact four-degree-of-freedom motion-tracking device (IMTD) designed for training and evaluation in laparoscopic surgery. The device's kinematics, mechanical design, instrumentation, and prototypes are developed and presented to meet the specific requirements of laparoscopic training context, including movement around a fixed center of motion and seamless integration into standard box trainers. The system IMTD's tracking accuracy and reliability are compared to a motion capture system (MoCap), assessing its ability to capture both angular and translational motions of surgical instruments. The study then focuses on key performance parameters including precision, fluidity, speed, and overall motion efficiency. The results highlight the system's effectiveness in tracking surgical gestures, providing valuable insights into its potential as a tool for training and performance evaluation in minimally invasive surgery. Additionally, IMTD's low cost and integrated design allow for easy integration and implementation in training rooms, offering a practical and accessible solution for general use. By offering objective, real-time feedback, the system can significantly contribute to improving surgical skills and shortening the learning curve for novice students, while also providing a foundation for future development of gesture scoring algorithms and standardized training protocols.

</details>


### [9] [Optimization of an Augmented R-CUBE mechanism for Cervical Surgery](https://arxiv.org/abs/2602.15886)
*Terence Essomba,Yu-Wen Wu,Abdelbadia Chaker,Med Amine Laribi*

Main category: cs.RO

TL;DR: 提出一种用于脊柱手术钻孔的新型机械架构，基于改进的R-CUBE全平移机构，实现手术钻所需的3T2R运动


<details>
  <summary>Details</summary>
Motivation: 脊柱手术中需要在椎骨上钻孔以植入椎弓根螺钉，需要能够精确控制手术钻的机械系统

Method: 基于增强版全平移R-CUBE机构，改进连杆结构实现额外旋转运动；机构分为平移、传动和旋转三个阶段，分别推导运动学和速度模型后组合；基于真实患者钻孔轨迹优化机构以获得最佳运动性能

Result: 开发出具有3T2R运动能力的机械系统，能够满足手术钻操作需求，并通过优化实现了高性能运动特性

Conclusion: 提出的新型机械架构能够有效支持脊柱手术钻孔操作，为椎弓根螺钉植入提供了改进的机械解决方案

Abstract: In some surgical operations targeting the spine, it is required to drill cavities in the vertebrae for the insertion of pedicle screws. A new mechanical architecture is proposed for this application. It is based on an augmented version of the full translational R-CUBE mechanism, with improved linkages to implement additional rotational motion. Using this concept, a mechanism presented with a 3T2R motion that is required for the manipulation of the surgical drill. It is mainly composed three stages: one translational, one transmitting and one rotational. Their respective kinematic and velocity models are separately derived, then combined. Based on the drilling trajectories obtained from a real patient case, the mechanism is optimized for generating the highest kinematic performances.

</details>


### [10] [Learning to Drive in New Cities Without Human Demonstrations](https://arxiv.org/abs/2602.15891)
*Zilin Wang,Saeed Rahmani,Daphne Cornelisse,Bidipta Sarkar,Alexander David Goldie,Jakob Nicolaus Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: NOMAD：基于地图的自博弈强化学习方法，无需目标城市的人类演示数据，即可将自动驾驶策略适配到新城市


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在特定区域表现可靠，但部署到新城市成本高、速度慢，主要瓶颈是需要收集大量人类演示轨迹来适应新城市的不同道路几何、交通规则和交互模式

Method: 提出NOMAD方法，使用自博弈多智能体强化学习，仅基于目标城市的地图和元信息，在模拟器中构建环境，通过简单的奖励函数训练驾驶策略

Result: NOMAD显著提高了目标城市的任务成功率和轨迹真实性，证明了这是一种有效且可扩展的替代数据密集型城市迁移方法

Conclusion: 自博弈多智能体强化学习能够仅使用地图和元信息将驾驶策略适配到显著不同的目标城市，无需该城市的人类演示数据，为自动驾驶城市迁移提供了更高效的解决方案

Abstract: While autonomous vehicles have achieved reliable performance within specific operating regions, their deployment to new cities remains costly and slow. A key bottleneck is the need to collect many human demonstration trajectories when adapting driving policies to new cities that differ from those seen in training in terms of road geometry, traffic rules, and interaction patterns. In this paper, we show that self-play multi-agent reinforcement learning can adapt a driving policy to a substantially different target city using only the map and meta-information, without requiring any human demonstrations from that city. We introduce NO data Map-based self-play for Autonomous Driving (NOMAD), which enables policy adaptation in a simulator constructed based on the target-city map. Using a simple reward function, NOMAD substantially improves both task success rate and trajectory realism in target cities, demonstrating an effective and scalable alternative to data-intensive city-transfer methods. Project Page: https://nomaddrive.github.io/

</details>


### [11] [Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach](https://arxiv.org/abs/2602.15893)
*Zhiyuan Ren,Yudong Fang,Tao Zhang,Wenchi Cheng,Ben Lan*

Main category: cs.RO

TL;DR: 本文提出AsymmetricHuberEKF方法，通过引入非对称损失函数解决无人机在灾后搜救中因NLOS传播导致的非负测距偏差问题，克服传统对称鲁棒估计器的理论不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 灾后无人机搜救面临非视距传播带来的非负测距偏差挑战，传统基于对称损失函数的鲁棒估计器（如Huber或Tukey）因假设误差对称性而存在理论不匹配，导致统计-几何退化现象，使估计器停滞不前。

Method: 提出AsymmetricHuberEKF方法，通过推导的非对称损失函数显式地纳入NLOS偏差的非负物理先验，并设计协同的主动感知策略获取必要的双边信息来解决统计-几何退化问题。

Result: 在2D天底视图扫描场景中验证，相比对称基线方法，本文方法显著加速了收敛速度，为数据稀缺且几何受限的搜索操作提供了弹性构建模块。

Conclusion: 通过将物理约束（非负NLOS偏差）显式纳入估计框架，并配合主动感知策略，可以有效解决灾后搜救中的统计-几何退化问题，提高无人机定位幸存者的效率和可靠性。

Abstract: Post-disaster survivor localization using Unmanned Aerial Vehicles (UAVs) faces a fundamental physical challenge: the prevalence of Non-Line-of-Sight (NLOS) propagation in collapsed structures. Unlike standard Gaussian noise, signal reflection from debris introduces strictly non-negative ranging biases. Existing robust estimators, typically designed with symmetric loss functions (e.g., Huber or Tukey), implicitly rely on the assumption of error symmetry. Consequently, they experience a theoretical mismatch in this regime, leading to a phenomenon we formally identify as Statistical-Geometric Degeneracy (SGD)-a state where the estimator stagnates due to the coupling of persistent asymmetric bias and limited observation geometry. While emerging data-driven approaches offer alternatives, they often struggle with the scarcity of training data and the sim-to-real gap inherent in unstructured disaster zones. In this work, we propose a physically-grounded solution, the AsymmetricHuberEKF, which explicitly incorporates the non-negative physical prior of NLOS biases via a derived asymmetric loss function. Theoretically, we show that standard symmetric filters correspond to a degenerate case of our framework where the physical constraint is relaxed. Furthermore, we demonstrate that resolving SGD requires not just a robust filter, but specific bilateral information, which we achieve through a co-designed active sensing strategy. Validated in a 2D nadir-view scanning scenario, our approach significantly accelerates convergence compared to symmetric baselines, offering a resilient building block for search operations where data is scarce and geometry is constrained.

</details>


### [12] [VGGT-based online 3D semantic SLAM for indoor scene understanding and navigation](https://arxiv.org/abs/2602.15899)
*Anna Gelencsér-Horváth,Gergely Dinya,Dorka Boglárka Erős,Péter Halász,Islam Muhammad Muqsit,Kristóf Karacs*

Main category: cs.RO

TL;DR: SceneVGGT是一个结合SLAM与语义映射的时空3D场景理解框架，用于自主和辅助导航。它通过滑动窗口管道扩展到长视频流，使用相机位姿变换对齐局部子地图，在保持几何一致性的同时实现内存和速度高效映射。语义从2D实例掩码提升到3D对象，保持时间一致的身份用于变化检测，并支持辅助导航应用。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理长视频流的3D场景理解系统，结合SLAM和语义映射，为自主和辅助导航提供支持。需要解决内存效率和实时性的挑战，同时保持几何一致性和语义连贯性。

Method: 基于VGGT构建，采用滑动窗口管道处理长视频流。通过相机位姿变换对齐局部子地图，实现内存和速度高效映射。使用VGGT跟踪头将2D实例掩码语义提升到3D对象，保持时间一致的身份。作为概念验证，将对象位置投影到估计的地板平面上用于辅助导航。

Result: GPU内存使用保持在17GB以下，不受输入序列长度影响。在ScanNet++基准测试中实现了有竞争力的点云性能。系统支持交互式辅助导航并提供音频反馈。

Conclusion: SceneVGGT提供了一个稳健的语义识别系统，速度足够快以支持交互式辅助导航。它通过结合SLAM和语义映射，在保持内存效率的同时处理长视频流，为自主和辅助导航应用提供了有效的解决方案。

Abstract: We present SceneVGGT, a spatio-temporal 3D scene understanding framework that combines SLAM with semantic mapping for autonomous and assistive navigation. Built on VGGT, our method scales to long video streams via a sliding-window pipeline. We align local submaps using camera-pose transformations, enabling memory- and speed-efficient mapping while preserving geometric consistency. Semantics are lifted from 2D instance masks to 3D objects using the VGGT tracking head, maintaining temporally coherent identities for change detection. As a proof of concept, object locations are projected onto an estimated floor plane for assistive navigation. The pipeline's GPU memory usage remains under 17 GB, irrespectively of the length of the input sequence and achieves competitive point-cloud performance on the ScanNet++ benchmark. Overall, SceneVGGT ensures robust semantic identification and is fast enough to support interactive assistive navigation with audio feedback.

</details>


### [13] [Coverage Path Planning for Autonomous Sailboats in Inhomogeneous and Time-Varying Oceans: A Spatiotemporal Optimization Approach](https://arxiv.org/abs/2602.15901)
*Yang An,Zhikang Ge,Taiyu Zhang,Jean-Baptiste R. G. Souppez,Gaofei Xu,Zhengru Ren*

Main category: cs.RO

TL;DR: 提出了一种针对自主帆船在非均匀时变海洋环境中的时空覆盖路径规划框架，结合空间拓扑形态约束和时间预测规划，解决了传统方法失效的问题。


<details>
  <summary>Details</summary>
Motivation: 自主帆船适合长期海洋观测，但其性能具有各向异性且受非均匀时变风场和流场强烈影响，现有覆盖方法（如往复扫描）效果有限，在环境和机动约束下的规划研究不足。

Method: 提出时空覆盖路径规划框架：1）空间域基于拓扑的形态约束，促进紧凑连续覆盖；2）时间域基于预测的前瞻规划，预判环境演变实现有远见的决策。

Result: 在随机非均匀时变海洋环境（包括部分方向可达场景）的仿真中，该方法能生成高效可行的覆盖路径，而传统策略往往失败。

Conclusion: 这是首个专门针对自主帆船在非均匀时变海洋环境中覆盖路径规划问题的解决方案，为未来多帆船协同覆盖奠定了基础。

Abstract: Autonomous sailboats are well suited for long-duration ocean observation due to their wind-driven endurance. However, their performance is highly anisotropic and strongly influenced by inhomogeneous and time-varying wind and current fields, limiting the effectiveness of existing coverage methods such as boustrophedon sweeping. Planning under these environmental and maneuvering constraints remains underexplored. This paper presents a spatiotemporal coverage path planning framework tailored to autonomous sailboats, combining (1) topology-based morphological constraints in the spatial domain to promote compact and continuous coverage, and (2) forecast-aware look-ahead planning in the temporal domain to anticipate environmental evolution and enable foresighted decision-making. Simulations conducted under stochastic inhomogeneous and time-varying ocean environments, including scenarios with partial directional accessibility, demonstrate that the proposed method generates efficient and feasible coverage paths where traditional strategies often fail. To the best of our knowledge, this study provides the first dedicated solution to the coverage path planning problem for autonomous sailboats operating in inhomogeneous and time-varying ocean environments, establishing a foundation for future cooperative multi-sailboat coverage.

</details>


### [14] [World Action Models are Zero-shot Policies](https://arxiv.org/abs/2602.15922)
*Seonghyeon Ye,Yunhao Ge,Kaiyuan Zheng,Shenyuan Gao,Sihyun Yu,George Kurian,Suneel Indupuru,You Liang Tan,Chuning Zhu,Jiannan Xiang,Ayaan Malik,Kyungmin Lee,William Liang,Nadun Ranawaka,Jiasheng Gu,Yinzhen Xu,Guanzhi Wang,Fengyuan Hu,Avnish Narayan,Johan Bjorck,Jing Wang,Gwanghyun Kim,Dantong Niu,Ruijie Zheng,Yuqi Xie,Jimmy Wu,Qi Wang,Ryan Julian,Danfei Xu,Yilun Du,Yevgen Chebotar,Scott Reed,Jan Kautz,Yuke Zhu,Linxi "Jim" Fan,Joel Jang*

Main category: cs.RO

TL;DR: DreamZero是一个基于预训练视频扩散模型的世界动作模型，通过联合建模视频和动作学习物理动态，在机器人任务中实现了比现有视觉-语言-动作模型更好的泛化能力，并能进行实时闭环控制。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉-语言-动作模型在语义泛化方面表现良好，但在新环境中面对未见过的物理运动时泛化能力不足。需要一种能够学习物理动态并实现更好泛化的模型。

Method: 基于预训练视频扩散主干构建世界动作模型，通过联合建模视频和动作来预测未来世界状态和动作，使用视频作为世界演变的密集表示。通过模型和系统优化，使140亿参数的自回归视频扩散模型能够以7Hz频率进行实时闭环控制。

Result: 在真实机器人实验中，相比最先进的视觉-语言-动作模型，在新任务和环境中的泛化能力提高了2倍以上。能够实现跨具身转移：仅使用其他机器人或人类的视频演示，在10-20分钟数据下对未见任务的性能相对提升超过42%。仅用30分钟游戏数据就能适应新具身，同时保持零样本泛化能力。

Conclusion: DreamZero通过世界动作模型的方法，在机器人控制中实现了更好的物理动态学习和泛化能力，支持实时控制和跨具身转移，为机器人学习提供了新的有效途径。

Abstract: State-of-the-art Vision-Language-Action (VLA) models excel at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs, WAMs learn physical dynamics by predicting future world states and actions, using video as a dense representation of how the world evolves. By jointly modeling video and action, DreamZero learns diverse skills effectively from heterogeneous robot data without relying on repetitive demonstrations. This results in over 2x improvement in generalization to new tasks and environments compared to state-of-the-art VLAs in real robot experiments. Crucially, through model and system optimizations, we enable a 14B autoregressive video diffusion model to perform real-time closed-loop control at 7Hz. Finally, we demonstrate two forms of cross-embodiment transfer: video-only demonstrations from other robots or humans yield a relative improvement of over 42% on unseen task performance with just 10-20 minutes of data. More surprisingly, DreamZero enables few-shot embodiment adaptation, transferring to a new embodiment with only 30 minutes of play data while retaining zero-shot generalization.

</details>


### [15] [The human intention. A taxonomy attempt and its applications to robotics](https://arxiv.org/abs/2602.15963)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 该论文探讨机器人学中人类意图的定义问题，提出基于心理学研究的综合框架，将意图分类并应用于机器人研究，通过协作搜索和物体运输案例展示其重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人学研究致力于推断和理解人类意图，但缺乏普遍接受的定义，现有研究常将意图等同于特定任务目标。本文旨在填补这一空白，通过心理学视角探讨意图的多面性。

Method: 基于心理学和传播学研究，将意图分类为可理解的框架；将不同机器人学研究与这些意图类别对齐；通过协作搜索和物体运输用例进行深入分析。

Result: 提出了一个基于心理学的人类意图综合定义框架，展示了如何将机器人学研究与不同意图类别对应，并通过具体案例强调了考虑人类意图多样性的重要性。

Conclusion: 人类意图是多方面的，不能简化为单一任务目标。基于心理学的分类框架有助于机器人学研究从纯技术增强转向更以人为本的视角，对实现有效人机协作至关重要。

Abstract: Despite a surge in robotics research dedicated to inferring and understanding human intent, a universally accepted definition remains elusive since existing works often equate human intention with specific task-related goals. This article seeks to address this gap by examining the multifaceted nature of intention. Drawing on insights from psychology, it attempts to consolidate a definition of intention into a comprehensible framework for a broader audience. The article classifies different types of intention based on psychological and communication studies, offering guidance to researchers shifting from pure technical enhancements to a more human-centric perspective in robotics. It then demonstrates how various robotics studies can be aligned with these intention categories. Finally, through in-depth analyses of collaborative search and object transport use cases, the article underscores the significance of considering the diverse facets of human intention.

</details>


### [16] [ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI](https://arxiv.org/abs/2602.16005)
*Jose Rojas,Aristotelis Papatheodorou,Sergi Martinez,Ioannis Havoutis,Carlos Mastalli*

Main category: cs.RO

TL;DR: ODYN是一个新型的全位移原始对偶非内点二次规划求解器，能高效处理稠密和稀疏QP问题，结合全位移NCP函数和近端乘子法，无需约束线性独立，具有优异的预热启动性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决具有挑战性的稠密和稀疏二次规划问题，特别是在机器人学和AI应用中常见的病态和退化问题，需要一种鲁棒且高效的求解器，能够在无需约束线性独立性的情况下处理这些问题。

Method: ODYN结合了全位移非线性互补问题函数和近端乘子法，采用非内点方法，能够鲁棒地处理病态和退化问题，无需约束线性独立。

Result: 在Maros-Mészáros测试集上的基准测试表明，ODYN在小规模到大规模问题上都表现出最先进的收敛性能，特别是在预热启动方面表现优异，这在机器人和AI的序列和实时设置中至关重要。

Conclusion: ODYN是一个高效、鲁棒的QP求解器，特别适合机器人和AI应用，已成功应用于预测控制框架、深度学习可微优化层和接触动力学模拟等多个实际场景。

Abstract: We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).

</details>


### [17] [The Impact of Class Uncertainty Propagation in Perception-Based Motion Planning](https://arxiv.org/abs/2602.16035)
*Jibran Iqbal Shah,Andrei Ivanovic,Kelly Zhu,Masha Itkina,Rowan McAllister,Igor Gilitschenski,Florian Shkurti*

Main category: cs.RO

TL;DR: 本文分析了自动驾驶车辆中感知不确定性传播和校准对运动规划的影响，通过在nuPlan基准上比较两种具有不同不确定性传播水平的预测-规划流程，发现包含上游不确定性传播的方法在复杂闭环场景中表现出更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要处理传感器数据带来的感知不确定性，并将其纳入决策过程。虽然已有不确定性感知规划器考虑上游感知和预测不确定性，但这些规划器可能对预测不确定性校准错误敏感，而这种敏感性尚未得到充分研究。

Method: 在nuPlan规划基准上比较两种具有不同不确定性传播水平的新型预测-规划流程，通过闭环评估研究上游不确定性校准对感知基础运动规划的影响。

Result: 包含上游不确定性传播的方法在复杂闭环场景中表现出更好的泛化能力，这表明不确定性传播对提高自动驾驶系统在真实世界场景中的鲁棒性至关重要。

Conclusion: 不确定性传播在自动驾驶运动规划中具有重要价值，能够提高系统在复杂闭环场景中的泛化能力和鲁棒性，为未来不确定性感知规划器的设计和评估提供了重要见解。

Abstract: Autonomous vehicles (AVs) are being increasingly deployed in urban environments. In order to operate safely and reliably, AVs need to account for the inherent uncertainty associated with perceiving the world through sensor data and incorporate that into their decision-making process. Uncertainty-aware planners have recently been developed to account for upstream perception and prediction uncertainty. However, such planners may be sensitive to prediction uncertainty miscalibration, the magnitude of which has not yet been characterized. Towards this end, we perform a detailed analysis on the impact that perceptual uncertainty propagation and calibration has on perception-based motion planning. We do so by comparing two novel prediction-planning pipelines with varying levels of uncertainty propagation on the recently-released nuPlan planning benchmark. We study the impact of upstream uncertainty calibration using closed-loop evaluation on the nuPlan challenge scenarios. We find that the method incorporating upstream uncertainty propagation demonstrates superior generalization to complex closed-loop scenarios.

</details>


### [18] [ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios](https://arxiv.org/abs/2602.16073)
*Kevin Kai-Chun Chang,Ekin Beyazit,Alberto Sangiovanni-Vincentelli,Tichakorn Wongpiromsarn,Sanjit A. Seshia*

Main category: cs.RO

TL;DR: ScenicRules是一个用于评估自动驾驶系统在随机环境下多目标优先级规则遵循情况的基准测试框架


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶评估基准缺乏多目标优先级规则与形式化环境模型的结合，无法有效评估系统在复杂交通环境中平衡多个目标（如避撞、遵守交规、高效行驶）的能力

Method: 1) 形式化定义多样化的目标作为量化评估指标；2) 设计可解释、可适应的分层规则书框架，编码多目标及其优先级关系；3) 使用Scenic语言构建紧凑但具有代表性的场景集合，涵盖多样化驾驶环境和近事故情况

Result: 实验结果表明，形式化的目标定义和分层规则书与人类驾驶判断高度一致，该基准能有效暴露智能体在优先级目标方面的失败情况

Conclusion: ScenicRules为自动驾驶系统在随机环境下的多目标优先级规则评估提供了有效的基准测试框架，填补了现有评估方法的空白

Abstract: Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicles lack such combinations of multi-objective prioritized rules and formal environment models. In this work, we introduce ScenicRules, a benchmark for evaluating autonomous driving systems in stochastic environments under prioritized multi-objective specifications. We first formalize a diverse set of objectives to serve as quantitative evaluation metrics. Next, we design a Hierarchical Rulebook framework that encodes multiple objectives and their priority relations in an interpretable and adaptable manner. We then construct a compact yet representative collection of scenarios spanning diverse driving contexts and near-accident situations, formally modeled in the Scenic language. Experimental results show that our formalized objectives and Hierarchical Rulebooks align well with human driving judgments and that our benchmark effectively exposes agent failures with respect to the prioritized objectives. Our benchmark can be accessed at https://github.com/BerkeleyLearnVerify/ScenicRules/.

</details>


### [19] [Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization](https://arxiv.org/abs/2602.16127)
*Théo Ayral,Saifeddine Aloui,Mathieu Grossard*

Main category: cs.RO

TL;DR: 提出一种混合学习方法，结合模型控制与触觉感知，实时调整多指机械手的抓握力以防止物体滑动，实现35-40毫秒的闭环稳定控制。


<details>
  <summary>Details</summary>
Motivation: 在多指机器人抓握中，外部扰动会导致物体滑动，传统方法难以实时检测并调整抓握力。需要结合快速触觉感知和模型控制来实现鲁棒的抓握稳定。

Method: 采用多模态触觉堆栈：压电传感器检测快速滑动信号，压阻阵列定位接触点，在线构建抓握矩阵。检测到滑动时，通过二次规划在抓握零空间中更新内力，保持物体力矩同时满足执行器限制。

Result: 理论传感到指令延迟为35-40毫秒，其中压阻接触和几何更新5毫秒，二次规划求解约4毫秒。实验中滑动检测在20毫秒内完成，成功实现多指抓握在外部扰动下的闭环稳定。

Conclusion: 将高效的分析力控制与学习的触觉线索相结合，实现了鲁棒性和快速反应。实测延迟主要来自实验数据路径而非实际计算，为实现亚50毫秒闭环稳定提供了清晰路径。

Abstract: We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.

</details>


### [20] [Image Measurement Method for Automatic Insertion of Forks into Inclined Pallet](https://arxiv.org/abs/2602.16178)
*Nobuyuki Kita,Takuro Kato*

Main category: cs.RO

TL;DR: 提出使用广角相机测量托盘俯仰倾斜角度的方法，以及相机坐标系与叉车坐标系之间的标定方法，实现AGF自动叉取托盘


<details>
  <summary>Details</summary>
Motivation: 为了实现AGF自动叉取托盘，需要控制叉车叉子的高度、伸出位置和倾斜角度与托盘孔的位置和方向匹配，因此需要测量托盘的俯仰倾斜角度

Method: 使用固定在叉车背板上的广角相机采集托盘图像，提出图像测量方法测量托盘在相机坐标系中的俯仰倾斜角度，并建立相机坐标系与叉车坐标系之间的标定信息

Result: 通过比较图像测量值与手动测量值，在不同托盘俯仰角度、相对高度以及是否装载货物的条件下，误差均在安全插入叉子的允许范围内

Conclusion: 提出的图像测量方法能够准确测量托盘俯仰倾斜角度，标定方法有效，误差在安全范围内，可用于AGF自动叉取托盘的控制系统

Abstract: In order to insert a fork into a hole of a pallet by a forklift located in front of a pallet, it is necessary to control the height position, reach position, and tilt angle of the fork to match the position and orientation of the hole of the pallet. In order to make AGF (Autonomous Guided Forklift) do this automatically, we propose an image measurement method to measure the pitch inclination of the pallet in the camera coordinate system from an image obtained by using a wide-angle camera. In addition, we propose an image measurement method to easily acquire the calibration information between the camera coordinate system and the fork coordinate system necessary to apply the measurements in the camera coordinate system to the fork control. In the experiment space, a wide-angle camera was fixed at the backrest of a reach type forklift. The wide-angle images taken by placing a pallet in front of the camera were processed. As a result of evaluating the error by comparing the image measurement value with the hand measurement value when changing the pitch inclination angle of the pallet, the relative height of the pallet and the fork, and whether the pallet is loaded or not, it was confirmed that the error was within the allowable range for safely inserting the fork.

</details>


### [21] [SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks](https://arxiv.org/abs/2602.16187)
*Zirui Zang,Ahmad Amine,Nick-Marios T. Kokolakis,Truong X. Nghiem,Ugo Rosolia,Rahul Mangharam*

Main category: cs.RO

TL;DR: 提出SIT-LMPC算法，用于迭代任务中的安全信息论学习模型预测控制，结合信息论MPC、自适应惩罚方法和归一化流学习价值函数，实现高性能并行实时优化。


<details>
  <summary>Details</summary>
Motivation: 机器人在复杂不确定环境中执行迭代任务时，需要平衡鲁棒性、安全性和高性能的控制策略。现有方法在处理约束、不确定性和实时优化方面存在挑战。

Method: 基于信息论模型预测控制算法设计迭代控制框架，处理离散时间非线性随机系统的约束无限时域最优控制问题。开发自适应惩罚方法确保安全性与最优性平衡。利用先前迭代轨迹通过归一化流学习价值函数，实现比高斯先验更丰富的建模。设计GPU高度并行执行架构，支持高效实时优化。

Result: 基准仿真和硬件实验表明，SIT-LMPC能够迭代提升系统性能，同时鲁棒地满足系统约束条件。

Conclusion: SIT-LMPC算法成功解决了迭代任务中的安全控制问题，通过信息论学习、自适应安全机制和并行优化，实现了在复杂不确定环境中的高性能鲁棒控制。

Abstract: Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.

</details>


### [22] [Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics](https://arxiv.org/abs/2602.16206)
*Ahmad Amine,Kabir Puri,Viet-Anh Le,Rahul Mangharam*

Main category: cs.RO

TL;DR: 提出了一种用于非平面地形自动驾驶的非平面模型预测控制框架，通过几何感知建模学习残差高斯过程来近似复杂车辆动力学，使用递归稀疏GP实现实时适应，在自定义Isaac Sim环境中验证了在挑战性3D表面上保持高跟踪精度的能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在非平面地形（如起伏路面、斜坡等）上运行时，传统平面模型无法准确描述复杂车辆动力学，需要开发能够适应地形几何变化的控制框架。

Method: 1. 开发几何感知建模方法，学习残差高斯过程来近似非平面环境中的复杂车辆动力学；2. 采用递归稀疏高斯过程，使框架能够实时适应变化的地形几何；3. 使用模型预测路径积分控制器进行参考轨迹跟踪任务。

Result: 在自定义Isaac Sim环境中验证了框架的有效性，证明了该框架能够在挑战性的3D表面上保持高跟踪精度，实现了对非平面地形的自适应控制。

Conclusion: 提出的非平面模型预测控制框架通过几何感知建模和递归稀疏高斯过程，成功解决了自动驾驶车辆在非平面地形上的控制问题，为复杂环境下的自主导航提供了有效解决方案。

Abstract: This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.

</details>


### [23] [Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM](https://arxiv.org/abs/2602.16308)
*Markus Rueggeberg,Maximilian Ulmer,Maximilian Durner,Wout Boerdijk,Marcus Gerhard Mueller,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.RO

TL;DR: 提出基于深度学习6D姿态估计的无标记多机器人SLAM系统，解决多机器人数据关联和相对定位问题


<details>
  <summary>Details</summary>
Motivation: 多机器人SLAM中数据关联困难，传统基于标记的方法存在观测范围有限、光照敏感等问题，需要更鲁棒的相对定位方案

Method: 利用深度学习6D姿态估计技术实现无标记相对定位，集成到去中心化多机器人SLAM系统中

Result: 在行星类比环境测试中验证了系统有效性，提高了机器人团队间的相对定位精度

Conclusion: 基于深度学习的无标记姿态估计为多机器人SLAM提供了更鲁棒、范围更广的相对定位解决方案

Abstract: The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.

</details>


### [24] [Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning](https://arxiv.org/abs/2602.16353)
*Zhezhi Lei,Zhihai Bi,Wenxin Wang,Jun Ma*

Main category: cs.RO

TL;DR: 该论文提出了一种基于安全强化学习的双四足机器人协同运输方法，通过约束马尔可夫博弈建模、成本优势分解和约束分配机制，在狭窄环境中实现安全高效的协作运输。


<details>
  <summary>Details</summary>
Motivation: 多机器人协同运输在狭窄环境中面临巨大挑战，因为可行区域极其有限，难以同时保证安全性和高性能的机器人间协作。现有方法在狭窄环境下难以有效平衡安全约束与任务性能。

Method: 1. 将任务建模为完全合作的约束马尔可夫博弈，将碰撞避免作为约束条件；2. 提出成本优势分解方法，确保团队约束总和保持在阈值以下；3. 设计约束分配方法，将共享约束分配给个体机器人以最大化整体任务奖励，促进机器人间的自主任务分配。

Result: 仿真和实时实验结果表明，与现有方法相比，所提出的方法在双四足机器人协同运输任务中实现了更优的性能和更高的成功率。

Conclusion: 该研究提出的安全强化学习框架通过创新的约束处理机制，成功解决了狭窄环境中多机器人协同运输的安全与性能平衡问题，为复杂环境下的机器人协作提供了有效解决方案。

Abstract: Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.

</details>


### [25] [Articulated 3D Scene Graphs for Open-World Mobile Manipulation](https://arxiv.org/abs/2602.16356)
*Martin Büchner,Adrian Röfer,Tim Engelbracht,Tim Welschehold,Zuria Bauer,Hermann Blum,Marc Pollefeys,Abhinav Valada*

Main category: cs.RO

TL;DR: MoMa-SG框架通过RGB-D序列构建包含语义和运动学信息的3D场景图，能够估计物体铰接参数并检测包含关系，在真实环境中实现机器人对铰接物体的鲁棒操作。


<details>
  <summary>Details</summary>
Motivation: 机器人需要理解物体如何运动才能进行长期移动操作，当前系统缺乏将语义、几何和运动学结合的能力，无法预测物体运动。

Method: 提出MoMa-SG框架：1) 对RGB-D序列进行时间分割和遮挡鲁棒点跟踪；2) 将点轨迹提升到3D；3) 使用统一扭转估计公式同时估计旋转和平移关节参数；4) 关联物体与铰接模型；5) 通过父-子关系检测包含物体。

Result: 在Arti4D-Semantic数据集（62个真实RGB-D序列，600个物体交互）和两个数据集上评估，并通过四足机器人和移动机械臂在真实家庭环境中验证了语义-运动学场景图对铰接物体操作的鲁棒性。

Conclusion: MoMa-SG成功构建了语义-运动学3D场景图，填补了语义、几何和运动学之间的鸿沟，使机器人能够在日常环境中鲁棒地操作铰接物体。

Abstract: Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: https://momasg.cs.uni-freiburg.de.

</details>


### [26] [System Identification under Constraints and Disturbance: A Bayesian Estimation Approach](https://arxiv.org/abs/2602.16358)
*Sergi Martinez,Steve Tonneau,Carlos Mastalli*

Main category: cs.RO

TL;DR: 提出贝叶斯系统辨识框架，联合估计机器人状态轨迹和物理参数，通过硬约束和能量观测提高精度，实现线性时间复杂度的可扩展计算


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统辨识方法在联合估计状态轨迹和物理参数时精度不足，特别是在处理非线性摩擦效应、接触约束和动态一致性方面存在局限，需要更准确且可扩展的辨识框架

Method: 基于贝叶斯系统辨识框架，嵌入物理一致性的逆动力学、接触和闭环约束作为硬等式约束；使用能量回归器增强参数可观测性；支持惯性和驱动参数的等式和不等式先验；采用参数化等式约束Riccati递归保持带状结构，实现线性时间复杂度

Result: 在代表性机器人系统仿真和Unitree B1机器人硬件实验中，相比前向动力学和分离辨识基线方法，表现出更快的收敛速度、更低的惯性和摩擦估计误差、更好的接触一致性；在模型预测控制中部署时，在挑战性环境中的运动跟踪性能有显著提升

Conclusion: 该贝叶斯系统辨识框架能够高精度地联合估计机器人状态轨迹和物理参数，通过硬约束、能量观测和可扩展算法设计，在仿真和硬件实验中均表现出优越性能，为机器人模型预测控制提供了更准确的模型基础

Abstract: We introduce a Bayesian system identification (SysID) framework for jointly estimating robot's state trajectories and physical parameters with high accuracy. It embeds physically consistent inverse dynamics, contact and loop-closure constraints, and fully featured joint friction models as hard, stage-wise equality constraints. It relies on energy-based regressors to enhance parameter observability, supports both equality and inequality priors on inertial and actuation parameters, enforces dynamically consistent disturbance projections, and augments proprioceptive measurements with energy observations to disambiguate nonlinear friction effects. To ensure scalability, we derive a parameterized equality-constrained Riccati recursion that preserves the banded structure of the problem, achieving linear complexity in the time horizon, and develop computationally efficient derivatives. Simulation studies on representative robotic systems, together with hardware experiments on a Unitree B1 equipped with a Z1 arm, demonstrate faster convergence, lower inertial and friction estimation errors, and improved contact consistency compared to forward-dynamics and decoupled identification baselines. When deployed within model predictive control frameworks, the resulting models yield measurable improvements in tracking performance during locomotion over challenging environments.

</details>


### [27] [Docking and Persistent Operations for a Resident Underwater Vehicle](https://arxiv.org/abs/2602.16360)
*Leonard Günzel,Gabrielė Kasparavičiūtė,Ambjørn Grimsrud Waldum,Bjørn-Magnus Moslått,Abubakar Aliyu Badawi,Celil Yılmaz,Md Shamin Yeasher Yousha,Robert Staven,Martin Ludvigsen*

Main category: cs.RO

TL;DR: 开发并部署了一个基于对接站和迷你ROV的常驻水下基础设施系统，在90米深度实现了自主导航、对接和检查任务，验证了无缆长期水下监测的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前海洋观测方法受限于高成本和后勤困难，要么是稀疏的广域调查，要么是固定位置的长期测量。需要能够在不依赖持续水面支持的情况下实现持久自主运行的水下监测系统。

Method: 开发了一个常驻基础设施系统，包括对接站和迷你级ROV。ROV配备了增强的机载处理和感知能力，能够使用USBL信号自主导航，通过ArUco标记视觉定位与扩展卡尔曼滤波融合进行对接，并执行本地检查任务。

Result: 系统在90米深度展示了90%的自主对接成功率，并在四分钟内完成完整的检查任务，验证了声学和视觉导航在真实环境中的集成效果。

Conclusion: 可靠的无缆深水操作是可行的，常驻ROV系统具有实现可扩展、经济高效水下监测的潜力。

Abstract: Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.

</details>


### [28] [Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped](https://arxiv.org/abs/2602.16371)
*Saumya Karan,Neerav Maram,Suraj Borate,Madhu Vadali*

Main category: cs.RO

TL;DR: SLOT是一个肌腱驱动的软体四足机器人，使用3D打印TPU腿，仅用四个执行器研究顺应性腿部运动的物理建模与控制。


<details>
  <summary>Details</summary>
Motivation: 研究如何将连续体软腿集成到基于模型的运动控制中，开发可扩展、可重用的软体四足机器人建模与控制方法。

Method: 使用离散Cosserat杆理论建模腿部为可变形连续体；引入模块化全身建模框架，将柔顺腿部动力学表示为施加于刚性躯干的物理一致反作用力；嵌入凸模型预测控制框架，通过物理信息力-角度关系将地面反作用力映射到肌腱驱动。

Result: 控制器在不同扰动下实现渐近稳定性；在物理原型上验证爬行和行走步态，质心轨迹RMSE小于5毫米，达到高精度。

Conclusion: 该框架展示了将连续体软腿集成到基于模型运动控制的通用方法，推进了软体四足机器人可扩展和可重用的建模与控制技术。

Abstract: SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.

</details>


### [29] [RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](https://arxiv.org/abs/2602.16444)
*Yixue Zhang,Kun Wu,Zhi Gao,Zhen Zhao,Pei Ren,Zhiyuan Xu,Fei Liao,Xinhua Wang,Shichao Fan,Di Wu,Qiuxuan Feng,Meng Li,Zhengping Che,Chang Liu,Jian Tang*

Main category: cs.RO

TL;DR: RoboGene是一个自动化生成多样化、物理可行的机器人操作任务的智能框架，通过多样性采样、自我反思机制和人机协同优化，显著提升任务生成质量，优于现有基础模型，并能提高视觉语言动作模型的预训练效果。


<details>
  <summary>Details</summary>
Motivation: 通用机器人操作面临真实世界交互数据稀缺的挑战，数据收集成本高昂且现有方法难以自动生成多样化、物理可行的任务。手动方法不可扩展且偏向常见任务，而现有基础模型常产生物理不可行的指令。

Method: RoboGene框架包含三个核心组件：1) 多样性驱动采样实现广泛任务覆盖；2) 自我反思机制强制执行物理约束；3) 人机协同优化实现持续改进。框架支持单臂、双臂和移动机器人。

Result: 收集了18k轨迹数据集，引入新指标评估任务质量、可行性和多样性。RoboGene显著优于GPT-4o、Gemini 2.5 Pro等最先进基础模型。使用RoboGene预训练的VLA模型在真实世界实验中表现出更高的成功率和更好的泛化能力。

Conclusion: RoboGene能够自动化生成高质量、多样化且物理可行的机器人操作任务，解决了机器人数据收集的关键瓶颈，为通用机器人操作的发展提供了重要支持。

Abstract: The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate physically infeasible instructions. To address this, we introduce RoboGene, an agentic framework designed to automate the generation of diverse, physically plausible manipulation tasks across single-arm, dual-arm, and mobile robots. RoboGene integrates three core components: diversity-driven sampling for broad task coverage, self-reflection mechanisms to enforce physical constraints, and human-in-the-loop refinement for continuous improvement. We conduct extensive quantitative analysis and large-scale real-world experiments, collecting datasets of 18k trajectories and introducing novel metrics to assess task quality, feasibility, and diversity. Results demonstrate that RoboGene significantly outperforms state-of-the-art foundation models (e.g., GPT-4o, Gemini 2.5 Pro). Furthermore, real-world experiments show that VLA models pre-trained with RoboGene achieve higher success rates and superior generalization, underscoring the importance of high-quality task generation. Our project is available at https://robogene-boost-vla.github.io.

</details>


### [30] [Reactive Motion Generation With Particle-Based Perception in Dynamic Environments](https://arxiv.org/abs/2602.16462)
*Xiyuan Zhao,Huijun Li,Lifeng Zhu,Zhikai Wei,Xianyi Zhu,Aiguo Song*

Main category: cs.RO

TL;DR: 该论文提出了一种结合动态感知与反应式规划的机器人运动生成框架，通过张量化粒子权重更新方案显式建模障碍物动态特性，并基于此开发了障碍物感知的MPPI规划方法，在动态不确定环境中显著提升了安全性和反应能力。


<details>
  <summary>Details</summary>
Motivation: 在动态和非结构化场景中，传统的反应式运动生成通常基于静态感知和系统动力学模型，难以可靠地建模动态障碍物并在感知和控制不确定性下优化无碰撞轨迹。因此需要建立反应式规划与动态映射之间的紧密联系。

Method: 1. 提出张量化粒子权重更新方案，显式维护障碍物速度和协方差，实现具有表达性动态特性的高效基于粒子的感知；2. 基于此动态表示，提出障碍物感知的MPPI规划公式，联合传播机器人-障碍物动力学，在不确定性下预测和评估未来系统运动。

Result: 在模拟和噪声真实世界环境中的实验表明，该框架相比最先进的基于MPPI的感知-规划基线方法，在避免多个静态和动态障碍物方面持续提升性能。模型预测方法显著提高了动态环境中的安全性和反应能力。

Conclusion: 显式建模机器人-障碍物动力学能够持续提升性能，通过紧密集成动态感知与反应式规划，为动态不确定环境中的机器人运动生成提供了有效的解决方案。

Abstract: Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.

</details>


### [31] [VIGOR: Visual Goal-In-Context Inference for Unified Humanoid Fall Safety](https://arxiv.org/abs/2602.16511)
*Osher Azulay,Zhengjie Xu,Andrew Scheffer,Stella X. Yu*

Main category: cs.RO

TL;DR: 提出统一跌倒安全方法，通过特权教师-学生架构实现复杂地形下的零样本跌倒恢复，无需真实世界微调


<details>
  <summary>Details</summary>
Motivation: 人形机器人在复杂环境中操作时，跌倒恢复至关重要。现有方法将跌倒安全分解为多个独立问题，或依赖在平坦地形上训练的端到端策略，缺乏对复杂地形的泛化能力

Method: 基于两个关键见解：1) 自然人类跌倒恢复姿态具有高度约束性，可通过对齐从平坦地形迁移到复杂地形；2) 快速全身反应需要集成感知-运动表示。使用稀疏人类演示训练特权教师，然后蒸馏为仅依赖自我中心深度和本体感知的可部署学生模型

Result: 在仿真和真实Unitree G1人形机器人上展示了跨多样非平坦环境的鲁棒、零样本跌倒安全能力，无需真实世界微调

Conclusion: 提出的统一跌倒安全方法通过目标在上下文中的潜在表示学习，实现了复杂地形下的泛化跌倒恢复，为人形机器人在杂乱环境中的安全操作提供了解决方案

Abstract: Reliable fall recovery is critical for humanoids operating in cluttered environments. Unlike quadrupeds or wheeled robots, humanoids experience high-energy impacts, complex whole-body contact, and large viewpoint changes during a fall, making recovery essential for continued operation. Existing methods fragment fall safety into separate problems such as fall avoidance, impact mitigation, and stand-up recovery, or rely on end-to-end policies trained without vision through reinforcement learning or imitation learning, often on flat terrain. At a deeper level, fall safety is treated as monolithic data complexity, coupling pose, dynamics, and terrain and requiring exhaustive coverage, limiting scalability and generalization. We present a unified fall safety approach that spans all phases of fall recovery. It builds on two insights: 1) Natural human fall and recovery poses are highly constrained and transferable from flat to complex terrain through alignment, and 2) Fast whole-body reactions require integrated perceptual-motor representations. We train a privileged teacher using sparse human demonstrations on flat terrain and simulated complex terrains, and distill it into a deployable student that relies only on egocentric depth and proprioception. The student learns how to react by matching the teacher's goal-in-context latent representation, which combines the next target pose with the local terrain, rather than separately encoding what it must perceive and how it must act. Results in simulation and on a real Unitree G1 humanoid demonstrate robust, zero-shot fall safety across diverse non-flat environments without real-world fine-tuning. The project page is available at https://vigor2026.github.io/

</details>


### [32] [Decentralized and Fully Onboard: Range-Aided Cooperative Localization and Navigation on Micro Aerial Vehicles](https://arxiv.org/abs/2602.16594)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种完全去中心化的范围辅助定位和编队控制方法，使用块坐标下降进行定位，并通过因子图推理进行编队控制，无需全局定位系统或严格协调，在室内外实验中实现了分米级精度。


<details>
  <summary>Details</summary>
Motivation: 多机器人协同控制面临挑战：集中式方法扩展性差，全局定位系统可能不可用。需要一种去中心化的方法，仅使用机载里程计和机器人间距离测量来实现定位和编队控制。

Method: 1. 使用块坐标下降方法进行范围辅助定位，无需机器人间严格协调；2. 将编队控制建模为因子图推理问题，考虑状态估计不确定性；3. 完全去中心化架构，仅依赖机载传感器和机器人间距离测量。

Result: 方法在多种室内外环境中进行了实验验证，实现了分米级的定位和编队控制精度，无需特殊轨迹来维持编队，完全去中心化运行。

Conclusion: 提出的范围辅助去中心化定位和编队控制方法有效解决了多机器人协同的挑战，无需全局定位系统或集中计算，在真实环境中表现出色，为分布式机器人系统提供了实用解决方案。

Abstract: Controlling a team of robots in a coordinated manner is challenging because centralized approaches (where all computation is performed on a central machine) scale poorly, and globally referenced external localization systems may not always be available. In this work, we consider the problem of range-aided decentralized localization and formation control. In such a setting, each robot estimates its relative pose by combining data only from onboard odometry sensors and distance measurements to other robots in the team. Additionally, each robot calculates the control inputs necessary to collaboratively navigate an environment to accomplish a specific task, for example, moving in a desired formation while monitoring an area. We present a block coordinate descent approach to localization that does not require strict coordination between the robots. We present a novel formulation for formation control as inference on factor graphs that takes into account the state estimation uncertainty and can be solved efficiently. Our approach to range-aided localization and formation-based navigation is completely decentralized, does not require specialized trajectories to maintain formation, and achieves decimeter-level positioning and formation control accuracy. We demonstrate our approach through multiple real experiments involving formation flights in diverse indoor and outdoor environments.

</details>


### [33] [Sensor Query Schedule and Sensor Noise Covariances for Accuracy-constrained Trajectory Estimation](https://arxiv.org/abs/2602.16598)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种通过求解半定规划问题来估计传感器参数（测量频率/调度和噪声协方差）的方法，以实现特定的轨迹估计精度要求。


<details>
  <summary>Details</summary>
Motivation: 移动机器人轨迹估计的精度受限于传感器参数（测量频率和噪声协方差），而实际应用中由于成本和资源限制，无法无限制提高传感器性能。需要找到在给定系统特性下，实现特定估计精度所需的最小传感器参数配置。

Method: 将传感器参数估计问题建模为半定规划问题，具体包括：1）已知传感器协方差时，估计实现特定精度所需的测量频率/调度；2）已知测量频率时，估计实现特定精度所需的传感器协方差。使用现成的求解器解决这些优化问题。

Result: 通过仿真和真实实验验证，证明使用该方法计算出的传感器调度和协方差能够达到期望的轨迹估计精度。同时，该方法能够识别出在给定系统和传感器特性下无法达到某些估计精度的情况。

Conclusion: 该方法为传感器参数选择提供了系统化的优化框架，能够在成本和性能约束下确定实现特定轨迹估计精度所需的最小传感器配置，有助于在实际应用中做出合理的传感器设计决策。

Abstract: Trajectory estimation involves determining the trajectory of a mobile robot by combining prior knowledge about its dynamic model with noisy observations of its state obtained using sensors. The accuracy of such a procedure is dictated by the system model fidelity and the sensor parameters, such as the accuracy of the sensor (as represented by its noise covariance) and the rate at which it can generate observations, referred to as the sensor query schedule. Intuitively, high-rate measurements from accurate sensors lead to accurate trajectory estimation. However, cost and resource constraints limit the sensor accuracy and its measurement rate. Our work's novel contribution is the estimation of sensor schedules and sensor covariances necessary to achieve a specific estimation accuracy. Concretely, we focus on estimating: (i) the rate or schedule with which a sensor of known covariance must generate measurements to achieve specific estimation accuracy, and alternatively, (ii) the sensor covariance necessary to achieve specific estimation accuracy for a given sensor update rate. We formulate the problem of estimating these sensor parameters as semidefinite programs, which can be solved by off-the-shelf solvers. We validate our approach in simulation and real experiments by showing that the sensor schedules and the sensor covariances calculated using our proposed method achieve the desired trajectory estimation accuracy. Our method also identifies scenarios where certain estimation accuracy is unachievable with the given system and sensor characteristics.

</details>


### [34] [Towards Autonomous Robotic Kidney Ultrasound: Spatial-Efficient Volumetric Imaging via Template Guided Optimal Pivoting](https://arxiv.org/abs/2602.16641)
*Xihan Ma,Haichong Zhang*

Main category: cs.RO

TL;DR: 提出基于模板引导最优枢轴扫描的自主肾脏超声成像工作流，通过探索性成像定位肾脏后执行固定点枢轴扫描，显著减少探头移动范围，提高扫描效率。


<details>
  <summary>Details</summary>
Motivation: 传统手持超声成像存在操作者依赖性、缺乏3D定位信息、易导致工作相关肌肉骨骼疾病等问题。现有机器人超声系统缺乏确定最佳成像窗口的能力，导致扫描盲目、探头移动范围过大，产生声影和器官覆盖不全。

Method: 提出自主工作流：1) 执行探索性成像获取肾脏部分观测数据；2) 将数据配准到肾脏模板以估计器官姿态；3) 机器人执行固定点枢轴扫描，使成像平面与肾脏长轴对齐以最小化探头平移。

Result: 仿真表明60%探索比例在肾脏定位精度和扫描效率间达到最佳平衡。在体评估显示肾脏定位精度达7.36毫米和13.84度。最优枢轴方法比基线缩短探头移动范围约75毫米。

Conclusion: 验证了利用解剖模板优化探头对齐进行体积扫描的方法，实现了高效的肾脏成像，显著减少了探头移动范围，提高了扫描效率。

Abstract: Medical ultrasound (US) imaging is a frontline tool for the diagnosis of kidney diseases. However, traditional freehand imaging procedure suffers from inconsistent, operator-dependent outcomes, lack of 3D localization information, and risks of work-related musculoskeletal disorders. While robotic ultrasound (RUS) systems offer the potential for standardized, operator-independent 3D kidney data acquisition, the existing scanning methods lack the ability to determine the optimal imaging window for efficient imaging. As a result, the scan is often blindly performed with excessive probe footprint, which frequently leads to acoustic shadowing and incomplete organ coverage. Consequently, there is a critical need for a spatially efficient imaging technique that can maximize the kidney coverage through minimum probe footprint. Here, we propose an autonomous workflow to achieve efficient kidney imaging via template-guided optimal pivoting. The system first performs an explorative imaging to generate partial observations of the kidney. This data is then registered to a kidney template to estimate the organ pose. With the kidney localized, the robot executes a fixed-point pivoting sweep where the imaging plane is aligned with the kidney long axis to minimize the probe translation. The proposed method was validated in simulation and in-vivo. Simulation results indicate that a 60% exploration ratio provides optimal balance between kidney localization accuracy and scanning efficiency. In-vivo evaluation on two male subjects demonstrates a kidney localization accuracy up to 7.36 mm and 13.84 degrees. Moreover, the optimal pivoting approach shortened the probe footprint by around 75 mm when compared with the baselines. These results valid our approach of leveraging anatomical templates to align the probe optimally for volumetric sweep.

</details>


### [35] [Learning to unfold cloth: Scaling up world models to deformable object manipulation](https://arxiv.org/abs/2602.16675)
*Jack Rome,Stephen James,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出了一种基于DreamerV2强化学习架构的空中布料操作方法，通过引入表面法线输入、改进回放缓冲区和数据增强技术，增强了机器人对复杂布料物理特性的建模能力，实现了多种布料类型的零样本展开操作。


<details>
  <summary>Details</summary>
Motivation: 布料操作是机器人研究中的典型问题，在辅助护理和服务行业中有广泛应用。由于布料作为可变形物体的复杂物理特性，以及需要处理不同形状、尺寸、褶皱模式的外观变化，需要设计能够良好泛化的模型结构。

Method: 采用DreamerV2强化学习架构的变体，改进包括：1) 引入表面法线输入；2) 修改回放缓冲区；3) 改进数据增强过程。这些改进共同增强了机器人对布料复杂物理特性的世界模型建模能力。

Result: 在仿真和物理机器人系统中进行了评估，实现了多种不同类型布料的零样本空中展开操作，证明了所提架构在泛化性能方面的优势。

Conclusion: 通过改进DreamerV2架构来增强世界模型对布料复杂物理特性的建模能力，能够有效处理布料操作中的泛化问题，为可变形物体操作提供了有效的解决方案。

Abstract: Learning to manipulate cloth is both a paradigmatic problem for robotic research and a problem of immediate relevance to a variety of applications ranging from assistive care to the service industry. The complex physics of the deformable object makes this problem of cloth manipulation nontrivial. In order to create a general manipulation strategy that addresses a variety of shapes, sizes, fold and wrinkle patterns, in addition to the usual problems of appearance variations, it becomes important to carefully consider model structure and their implications for generalisation performance. In this paper, we present an approach to in-air cloth manipulation that uses a variation of a recently proposed reinforcement learning architecture, DreamerV2. Our implementation modifies this architecture to utilise surface normals input, in addition to modiying the replay buffer and data augmentation procedures. Taken together these modifications represent an enhancement to the world model used by the robot, addressing the physical complexity of the object being manipulated by the robot. We present evaluations both in simulation and in a zero-shot deployment of the trained policies in a physical robot setup, performing in-air unfolding of a variety of different cloth types, demonstrating the generalisation benefits of our proposed architecture.

</details>


### [36] [Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation](https://arxiv.org/abs/2602.16705)
*Runpei Dong,Ziyan Li,Xialin He,Saurabh Gupta*

Main category: cs.RO

TL;DR: HERO：结合大视觉模型泛化能力和模拟训练控制性能的人形机器人物体定位操作新范式，通过残差感知末端执行器跟踪策略实现精确控制


<details>
  <summary>Details</summary>
Motivation: 现有基于真实世界模仿学习的方法由于大规模训练数据收集困难而泛化能力有限，需要一种能在多样化真实环境中准确控制末端执行器并具备场景泛化理解能力的人形机器人定位操作方法

Method: 提出HERO范式，结合大视觉模型的开放词汇理解和模拟训练的强控制性能。设计残差感知末端执行器跟踪策略，整合逆运动学、学习型神经前向模型、目标调整和重规划技术

Result: 末端执行器跟踪误差降低3.2倍，系统能在办公室、咖啡店等多样化真实环境中可靠操作各种日常物体（杯子、苹果、玩具等），操作表面高度范围43cm到92cm

Conclusion: HERO范式为人形机器人训练与日常物体交互开辟了新途径，通过结合大视觉模型泛化能力和模拟训练控制性能，实现了在多样化真实环境中的精确物体定位操作

Abstract: Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.

</details>


### [37] [EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data](https://arxiv.org/abs/2602.16710)
*Ruijie Zheng,Dantong Niu,Yuqi Xie,Jing Wang,Mengda Xu,Yunfan Jiang,Fernando Castañeda,Fengyuan Hu,You Liang Tan,Letian Fu,Trevor Darrell,Furong Huang,Yuke Zhu,Danfei Xu,Linxi Fan*

Main category: cs.RO

TL;DR: EgoScale框架利用大规模人类自我中心视频数据训练VLA模型，通过两阶段迁移方法实现灵巧机器人操作，在22自由度灵巧手上平均成功率提升54%


<details>
  <summary>Details</summary>
Motivation: 人类行为是学习物理智能最具扩展性的数据源，但如何有效利用它来实现灵巧操作仍不清楚。先前工作只在受限环境中展示人类到机器人的迁移，不确定大规模人类数据是否能支持精细、高自由度的灵巧操作。

Method: 提出EgoScale框架：1）在20,854小时带动作标签的人类自我中心视频上训练视觉语言动作模型，比先前工作大20倍以上；2）发现人类数据规模与验证损失之间的对数线性缩放规律；3）提出两阶段迁移方法：大规模人类预训练 + 轻量级对齐的人类机器人中间训练。

Result: 验证损失与下游真实机器人性能强相关，证明大规模人类数据是可预测的监督源。最终策略在22自由度灵巧手上比无预训练基线平均成功率提升54%，并能有效迁移到低自由度手上，表明大规模人类运动提供了可重用、与具体实现无关的运动先验。

Conclusion: 大规模人类数据是学习灵巧操作的有效监督源，通过两阶段迁移方法可以实现强大的长时程灵巧操作和一次性任务适应，且该运动先验具有可重用性和实现无关性。

Abstract: Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.

</details>


### [38] [One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation](https://arxiv.org/abs/2602.16712)
*Zhenyu Wei,Yunchao Yao,Mingyu Ding*

Main category: cs.RO

TL;DR: 提出了一种参数化规范表示方法，统一了多种灵巧手架构，实现了跨不同手部设计的策略学习和零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 当前灵巧操作策略主要针对固定手部设计，难以泛化到具有不同运动学和结构布局的新手部形态。需要一种能够统一多种灵巧手架构的表示方法。

Method: 引入参数化规范表示，包括统一的参数空间和规范URDF格式。参数空间捕捉形态和运动学变化，规范URDF标准化动作空间。使用VAE学习结构化潜在流形，并开发基于规范表示的条件抓取策略。

Result: 通过抓取策略重放、VAE潜在编码和跨手部零样本迁移等实验验证。在未见过的3指LEAP Hand上实现了81.9%的零样本成功率，统一了结构多样化手部的表示空间和动作空间。

Conclusion: 该框架为跨手部学习提供了可扩展基础，实现了向通用灵巧操作的发展，能够有效统一不同结构手部的表示和动作空间。

Abstract: Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.

</details>
