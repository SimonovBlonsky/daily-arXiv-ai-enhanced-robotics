<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Lang2Manip: A Tool for LLM-Based Symbolic-to-Geometric Planning for Manipulation](https://arxiv.org/abs/2512.17062)
*Muhayy Ud Din,Jan Rosell,Waseem Akram,Irfan Hussain*

Main category: cs.RO

TL;DR: 提出一个统一管道，将基于LLM的符号规划器与Kautham运动规划框架连接，实现可泛化的、机器人无关的符号到几何操作


<details>
  <summary>Details</summary>
Motivation: 仿真对机器人操作系统开发至关重要，特别是任务与运动规划（TAMP）。虽然LLM能够从自然语言生成符号计划，但在仿真中执行这些计划通常需要机器人特定的工程或规划器依赖的集成

Method: 开发统一管道，将LLM符号规划器与Kautham运动规划框架连接。Kautham提供ROS兼容支持，支持多种工业机械臂，并在单一接口下提供几何、运动动力学、物理驱动和基于约束的运动规划

Result: 系统能够将语言指令转换为符号动作，并使用Kautham的任何规划器计算和执行无碰撞轨迹，无需额外编码

Conclusion: 创建了一个灵活且可扩展的语言驱动TAMP工具，能够在机器人、规划模式和操作任务之间实现泛化

Abstract: Simulation is essential for developing robotic manipulation systems, particularly for task and motion planning (TAMP), where symbolic reasoning interfaces with geometric, kinematic, and physics-based execution. Recent advances in Large Language Models (LLMs) enable robots to generate symbolic plans from natural language, yet executing these plans in simulation often requires robot-specific engineering or planner-dependent integration. In this work, we present a unified pipeline that connects an LLM-based symbolic planner with the Kautham motion planning framework to achieve generalizable, robot-agnostic symbolic-to-geometric manipulation. Kautham provides ROS-compatible support for a wide range of industrial manipulators and offers geometric, kinodynamic, physics-driven, and constraint-based motion planning under a single interface. Our system converts language instructions into symbolic actions and computes and executes collision-free trajectories using any of Kautham's planners without additional coding. The result is a flexible and scalable tool for language-driven TAMP that is generalized across robots, planning modalities, and manipulation tasks.

</details>


### [2] [Towards Senior-Robot Interaction: Reactive Robot Dog Gestures](https://arxiv.org/abs/2512.17136)
*Chunyang Meng,Eduardo B. Sandoval,Ricardo Sosa,Francisco Cruz*

Main category: cs.RO

TL;DR: 开发面向老年人的四足机器人社交伴侣系统，通过手势识别实现免遥控控制，并利用课程强化学习训练社交表达动作，验证了框架的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，老年人面临孤独问题。现有伴侣机器人功能有限，而任务导向机器人缺乏社交交互能力，限制了老年人对机器人的接受度。

Method: 1) 基于MediaPipe的手势和头部动作识别模块实现免遥控控制；2) 在Isaac Gym中使用课程强化学习训练机器人狗动作，从简单站立到三腿平衡和腿部伸展等复杂动作；3) 在Unitree机器人上验证关键社交手势（抬爪动作）。

Result: 仿真测试平均成功率超过95%；真实世界测试验证了框架的可行性和社交表达能力；同时揭示了从仿真到现实转换中的关节柔顺性、负载分布和平衡控制等挑战。

Conclusion: 该研究推进了四足机器人作为老年人社交伴侣的实用化发展，为仿真到现实的适应提供了路径，并为未来用户研究奠定了基础。

Abstract: As the global population ages, many seniors face the problem of loneliness. Companion robots offer a potential solution. However, current companion robots often lack advanced functionality, while task-oriented robots are not designed for social interaction, limiting their suitability and acceptance by seniors. Our work introduces a senior-oriented system for quadruped robots that allows for more intuitive user input and provides more socially expressive output. For user input, we implemented a MediaPipe-based module for hand gesture and head movement recognition, enabling control without a remote. For output, we designed and trained robotic dog gestures using curriculum-based reinforcement learning in Isaac Gym, progressing from simple standing to three-legged balancing and leg extensions, and more. The final tests achieved over 95\% success on average in simulation, and we validated a key social gesture (the paw-lift) on a Unitree robot. Real-world tests demonstrated the feasibility and social expressiveness of this framework, while also revealing sim-to-real challenges in joint compliance, load distribution, and balance control. These contributions advance the development of practical quadruped robots as social companions for the senior and outline pathways for sim-to-real adaptation and inform future user studies.

</details>


### [3] [Semantic Co-Speech Gesture Synthesis and Real-Time Control for Humanoid Robots](https://arxiv.org/abs/2512.17183)
*Gang Zhang*

Main category: cs.RO

TL;DR: 提出一个端到端框架，用于合成语义相关的伴随语音手势并在人形机器人上实时部署，通过LLM驱动的语义感知手势合成和模仿学习控制策略实现自然非语言交流。


<details>
  <summary>Details</summary>
Motivation: 解决机器人自然、富有表现力的非语言交流挑战，创建能够理解语义并实时执行伴随语音手势的完整系统。

Method: 1) 语义感知手势合成模块：基于大语言模型和自回归Motion-GPT模型从语音输入生成表达性参考动作；2) 高保真模仿学习控制策略MotionTracker：使机器人动态执行复杂动作并保持平衡；3) 通用运动重定向方法：弥合人类运动数据与机器人平台之间的差距。

Result: 系统能够生成语义恰当、节奏连贯的手势，并准确地在物理机器人上跟踪和执行，实现了自动、语义感知的伴随语音手势生成与实时物理部署的完整流程。

Conclusion: 这项工作代表了向通用真实世界应用迈出的重要一步，提供了在人形机器人上实现自动、语义感知的伴随语音手势生成和同步实时物理部署的完整管道。

Abstract: We present an innovative end-to-end framework for synthesizing semantically meaningful co-speech gestures and deploying them in real-time on a humanoid robot. This system addresses the challenge of creating natural, expressive non-verbal communication for robots by integrating advanced gesture generation techniques with robust physical control. Our core innovation lies in the meticulous integration of a semantics-aware gesture synthesis module, which derives expressive reference motions from speech input by leveraging a generative retrieval mechanism based on large language models (LLMs) and an autoregressive Motion-GPT model. This is coupled with a high-fidelity imitation learning control policy, the MotionTracker, which enables the Unitree G1 humanoid robot to execute these complex motions dynamically and maintain balance. To ensure feasibility, we employ a robust General Motion Retargeting (GMR) method to bridge the embodiment gap between human motion data and the robot platform. Through comprehensive evaluation, we demonstrate that our combined system produces semantically appropriate and rhythmically coherent gestures that are accurately tracked and executed by the physical robot. To our knowledge, this work represents a significant step toward general real-world use by providing a complete pipeline for automatic, semantic-aware, co-speech gesture generation and synchronized real-time physical deployment on a humanoid robot.

</details>


### [4] [Design and Research of a Self-Propelled Pipeline Robot Based on Force Analysis and Dynamic Simulation](https://arxiv.org/abs/2512.17212)
*Yan Gao,Jiliang Wang,Ming Cheng,Tianyun Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于力分析和动态仿真的自驱动管道机器人设计，重点解决垂直爬升失败和T型分支管道通过性差等核心挑战，为城市中低压燃气管道的检测应用提供了技术可行性参考。


<details>
  <summary>Details</summary>
Motivation: 传统有线检测机器人受电缆长度和重量的严重限制，大大限制了其行进范围和可达性。为了解决这些问题，需要开发能够自主移动的管道机器人。

Method: 采用轮式配置和模块化设计，首先使用SolidWorks完成3D建模，然后将模型导入ADAMS进行动态仿真，优化驱动模块和运动控制策略。构建亚克力管道实验平台验证动态性能。

Result: 通过调整身体姿态克服障碍和选择方向，机器人能够稳定穿越各种复杂管道场景，特别是在垂直爬升和T型分支管道中表现出良好的通过性。

Conclusion: 该自驱动管道机器人设计为解决传统有线机器人的局限性提供了有效方案，为城市中低压燃气管道的检测应用提供了技术可行性参考。

Abstract: In pipeline inspection, traditional tethered inspection robots are severely constrained by cable length and weight, which greatly limit their travel range and accessibility. To address these issues, this paper proposes a self-propelled pipeline robot design based on force analysis and dynamic simulation, with a specific focus on solving core challenges including vertical climbing failure and poor passability in T-branch pipes. Adopting a wheeled configuration and modular design, the robot prioritizes the core demand of body motion control. Specifically, 3D modeling of the robot was first completed using SolidWorks. Subsequently, the model was imported into ADAMS for dynamic simulation, which provided a basis for optimizing the drive module and motion control strategy.To verify the robot's dynamic performance, an experimental platform with acrylic pipes was constructed. Through adjusting its body posture to surmount obstacles and select directions, the robot has demonstrated its ability to stably traverse various complex pipeline scenarios. Notably, this work offers a technical feasibility reference for the application of pipeline robots in the inspection of medium and low-pressure urban gas pipelines.

</details>


### [5] [Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines](https://arxiv.org/abs/2512.17215)
*Yan Gao,Jiliang Wang,Minghan Wang,Xiaohua Chen,Demin Chen,Zhiyong Ren,Tian-Yun Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于扩展卡尔曼滤波的自驱动管道机器人定位方法，解决了复杂弯曲管道环境中传统定位方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有管道定位方法主要依赖管道定位仪器，但在复杂弯曲管道场景中常因电缆缠绕和设备灵活性不足而失效。传统视觉和激光建图方法在管道受限空间中易受光照条件和特征不足影响，导致建图漂移和发散问题。

Method: 设计自驱动管道机器人，采用基于扩展卡尔曼滤波的定位方法：首先通过惯性测量单元获取初始姿态角，然后使用扩展卡尔曼滤波算法提高姿态角估计精度，最后结合轮式里程计实现高精度管道定位。

Result: 在矩形循环管道中使用自驱动管道机器人进行实验，验证了所提出的航位推算算法的有效性。需要在机器人运动能力和定位精度之间取得平衡，避免滚轮过紧导致的摩擦过大影响运动控制灵活性。

Conclusion: 提出的基于扩展卡尔曼滤波的管道机器人定位方法能够有效解决复杂弯曲管道环境中的定位问题，相比传统方法受管道环境因素影响较小，实现了高精度管道定位。

Abstract: In the field of gas pipeline location, existing pipeline location methods mostly rely on pipeline location instruments. However, when faced with complex and curved pipeline scenarios, these methods often fail due to problems such as cable entanglement and insufficient equipment flexibility. To address this pain point, we designed a self-propelled pipeline robot. This robot can autonomously complete the location work of complex and curved pipelines in complex pipe networks without external dragging. In terms of pipeline mapping technology, traditional visual mapping and laser mapping methods are easily affected by lighting conditions and insufficient features in the confined space of pipelines, resulting in mapping drift and divergence problems. In contrast, the pipeline location method that integrates inertial navigation and wheel odometers is less affected by pipeline environmental factors. Based on this, this paper proposes a pipeline robot location method based on extended Kalman filtering (EKF). Firstly, the body attitude angle is initially obtained through an inertial measurement unit (IMU). Then, the extended Kalman filtering algorithm is used to improve the accuracy of attitude angle estimation. Finally, high-precision pipeline location is achieved by combining wheel odometers. During the testing phase, the roll wheels of the pipeline robot needed to fit tightly against the pipe wall to reduce slippage. However, excessive tightness would reduce the flexibility of motion control due to excessive friction. Therefore, a balance needed to be struck between the robot's motion capability and positioning accuracy. Experiments were conducted using the self-propelled pipeline robot in a rectangular loop pipeline, and the results verified the effectiveness of the proposed dead reckoning algorithm.

</details>


### [6] [A Service Robot's Guide to Interacting with Busy Customers](https://arxiv.org/abs/2512.17241)
*Suraj Nukala,Meera Sushma,Leimin Tian,Akansel Cosgun,Dana Kulic*

Main category: cs.RO

TL;DR: 研究比较了服务机器人在餐厅场景中不同沟通方式（语音、视觉显示、微动作）的效果，发现语音最能吸引注意力但意图传达不清晰，视觉显示在意图传达上最有效。


<details>
  <summary>Details</summary>
Motivation: 随着服务机器人在酒店业的广泛应用，需要了解如何与忙碌的顾客有效沟通。研究旨在探索服务机器人常用的沟通方式在吸引注意力和传达意图方面的效果。

Method: 采用两部分用户研究（N=24），使用Temi机器人模拟送餐任务。参与者通过打字游戏模拟忙碌状态。第一部分比较非语言声音提示与基线条件在单杯送餐任务中的注意力捕捉效果；第二部分评估语音、视觉显示、微动作及其多模态组合在两杯送餐任务中传达特定意图（正确选择杯子）的效果。

Result: 语音在吸引注意力方面效果显著，但在清晰传达意图方面效果较差。参与者认为视觉显示在意图清晰度方面最有效，其次是语音，微动作排名最低。

Conclusion: 研究结果为优化服务机器人沟通策略提供了见解，强调了在动态酒店环境中吸引注意力和传达意图的不同作用，对提升用户体验有重要意义。

Abstract: The growing use of service robots in hospitality highlights the need to understand how to effectively communicate with pre-occupied customers. This study investigates the efficacy of commonly used communication modalities by service robots, namely, acoustic/speech, visual display, and micromotion gestures in capturing attention and communicating intention with a user in a simulated restaurant scenario. We conducted a two-part user study (N=24) using a Temi robot to simulate delivery tasks, with participants engaged in a typing game (MonkeyType) to emulate a state of busyness. The participants' engagement in the typing game is measured by words per minute (WPM) and typing accuracy. In Part 1, we compared non-verbal acoustic cue versus baseline conditions to assess attention capture during a single-cup delivery task. In Part 2, we evaluated the effectiveness of speech, visual display, micromotion and their multimodal combination in conveying specific intentions (correct cup selection) during a two-cup delivery task. The results indicate that, while speech is highly effective in capturing attention, it is less successful in clearly communicating intention. Participants rated visual as the most effective modality for intention clarity, followed by speech, with micromotion being the lowest ranked.These findings provide insights into optimizing communication strategies for service robots, highlighting the distinct roles of attention capture and intention communication in enhancing user experience in dynamic hospitality settings.

</details>


### [7] [RecipeMasterLLM: Revisiting RoboEarth in the Era of Large Language Models](https://arxiv.org/abs/2512.17309)
*Asil Kaan Bozcuoglu,Ziyuan Liu*

Main category: cs.RO

TL;DR: RecipeMasterLLM是一个基于大型语言模型的高层规划器，能够根据用户提示自动生成符合RoboEarth标准化知识图谱的OWL动作本体，实现机器人知识获取的自动化。


<details>
  <summary>Details</summary>
Motivation: 传统RoboEarth系统中，知识主要通过工程师手工创建RDF三元组来构建OWL本体，更新过程繁琐。随着大型语言模型的发展，研究者认为可以显著自动化知识获取过程，减少人工干预。

Method: 提出RecipeMasterLLM系统，使用专门微调的LLM来理解和生成符合RoboEarth标准化知识图谱的动作描述。在检索增强生成阶段，系统向LLM提供环境知识以增强上下文理解，提高生成动作描述的准确性。

Result: 该方法能够根据用户提示自动生成OWL动作本体，实现了从手工知识工程向自动化知识获取的转变，提高了机器人知识共享和交换的效率。

Conclusion: RecipeMasterLLM展示了利用大型语言模型自动化机器人知识获取的可行性，为云机器人领域的知识共享提供了新的自动化解决方案，推动了从手工知识工程向智能知识生成的范式转变。

Abstract: RoboEarth was a pioneering initiative in cloud robotics, establishing a foundational framework for robots to share and exchange knowledge about actions, objects, and environments through a standardized knowledge graph. Initially, this knowledge was predominantly hand-crafted by engineers using RDF triples within OWL Ontologies, with updates, such as changes in an object's pose, being asserted by the robot's control and perception routines. However, with the advent and rapid development of Large Language Models (LLMs), we believe that the process of knowledge acquisition can be significantly automated. To this end, we propose RecipeMasterLLM, a high-level planner, that generates OWL action ontologies based on a standardized knowledge graph in response to user prompts. This architecture leverages a fine-tuned LLM specifically trained to understand and produce action descriptions consistent with the RoboEarth standardized knowledge graph. Moreover, during the Retrieval-Augmented Generation (RAG) phase, environmental knowledge is supplied to the LLM to enhance its contextual understanding and improve the accuracy of the generated action descriptions.

</details>


### [8] [Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation](https://arxiv.org/abs/2512.17349)
*Xijie Huang,Jinhan Li,Tianyue Wu,Xin Zhou,Zhichao Han,Fei Gao*

Main category: cs.RO

TL;DR: 提出结合3D高斯溅射与对抗域适应的框架，实现仅使用单目RGB图像的无人机在杂乱环境中零样本迁移导航


<details>
  <summary>Details</summary>
Motivation: 现代自主导航系统主要依赖激光雷达和深度相机，但能否仅使用单目RGB图像实现无人机在杂乱环境中的导航仍是一个基本问题。由于真实世界数据收集成本高昂，在仿真中学习策略是一条有希望的路径，但仿真到真实的感知差距阻碍了策略的直接部署。

Method: 提出一个框架，将3D高斯溅射（3DGS）环境的光照真实感与对抗域适应相结合。通过在高保真仿真中训练，同时显式最小化特征差异，确保策略依赖于域不变的特征线索。

Result: 实验结果表明，该方法实现了策略在物理世界中的鲁棒零样本迁移，能够在不同光照条件下的非结构化环境中实现安全和敏捷的飞行。

Conclusion: 通过结合高保真仿真和对抗域适应，证明了仅使用单目RGB图像实现无人机在杂乱环境中导航的可行性，成功克服了仿真到真实的感知差距。

Abstract: Modern autonomous navigation systems predominantly rely on lidar and depth cameras. However, a fundamental question remains: Can flying robots navigate in clutter using solely monocular RGB images? Given the prohibitive costs of real-world data collection, learning policies in simulation offers a promising path. Yet, deploying such policies directly in the physical world is hindered by the significant sim-to-real perception gap. Thus, we propose a framework that couples the photorealism of 3D Gaussian Splatting (3DGS) environments with Adversarial Domain Adaptation. By training in high-fidelity simulation while explicitly minimizing feature discrepancy, our method ensures the policy relies on domain-invariant cues. Experimental results demonstrate that our policy achieves robust zero-shot transfer to the physical world, enabling safe and agile flight in unstructured environments with varying illumination.

</details>


### [9] [TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data](https://arxiv.org/abs/2512.17370)
*Deqing Liu,Yinfeng Gao,Deheng Qian,Qichao Zhang,Xiaoqing Ye,Junyu Han,Yupeng Zheng,Xueyi Liu,Zhongpu Xia,Dawei Ding,Yifeng Pan,Dongbin Zhao*

Main category: cs.RO

TL;DR: TakeAD：基于偏好的后优化框架，利用专家接管数据微调预训练的模仿学习策略，以弥合自动驾驶中开环训练与闭环部署之间的差距


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法主要依赖模仿学习，但面临开环训练与闭环部署之间的不匹配问题，导致在闭环执行时频繁出现驾驶员接管和系统脱离。如何利用脱离场景中的专家接管数据来扩展模仿学习策略的能力是一个有价值但尚未充分探索的挑战。

Method: 提出TakeAD框架：1) 设计受真实世界自动驾驶系统人类接管机制启发的专家接管数据收集流程；2) 结合迭代数据集聚合（DAgger）进行模仿学习，以及直接偏好优化（DPO）进行偏好对齐。DAgger阶段通过直接模仿专家干预使策略具备处理脱离状态的基本能力，DPO阶段则细化策略行为以更好地在脱离场景中与专家偏好对齐。

Result: 在闭环Bench2Drive基准测试中，该方法相比纯模仿学习方法表现出有效性，综合消融实验确认了每个组件的贡献。

Conclusion: TakeAD通过迭代优化过程，使策略逐步学习脱离状态的恢复策略，有效缓解了开环差距问题，提升了自动驾驶系统的闭环性能。

Abstract: Existing end-to-end autonomous driving methods typically rely on imitation learning (IL) but face a key challenge: the misalignment between open-loop training and closed-loop deployment. This misalignment often triggers driver-initiated takeovers and system disengagements during closed-loop execution. How to leverage those expert takeover data from disengagement scenarios and effectively expand the IL policy's capability presents a valuable yet unexplored challenge. In this paper, we propose TakeAD, a novel preference-based post-optimization framework that fine-tunes the pre-trained IL policy with this disengagement data to enhance the closed-loop driving performance. First, we design an efficient expert takeover data collection pipeline inspired by human takeover mechanisms in real-world autonomous driving systems. Then, this post optimization framework integrates iterative Dataset Aggregation (DAgger) for imitation learning with Direct Preference Optimization (DPO) for preference alignment. The DAgger stage equips the policy with fundamental capabilities to handle disengagement states through direct imitation of expert interventions. Subsequently, the DPO stage refines the policy's behavior to better align with expert preferences in disengagement scenarios. Through multiple iterations, the policy progressively learns recovery strategies for disengagement states, thereby mitigating the open-loop gap. Experiments on the closed-loop Bench2Drive benchmark demonstrate our method's effectiveness compared with pure IL methods, with comprehensive ablations confirming the contribution of each component.

</details>


### [10] [Personalized Gait Patterns During Exoskeleton-Aided Training May Have Minimal Effect on User Experience. Insights from a Pilot Study](https://arxiv.org/abs/2512.17425)
*Beatrice Luciani,Katherine Lin Poggensee,Heike Vallery,Alex van den Berg,Severin David Woernle,Mostafa Mogharabi,Stefano Dalla Gasperina,Laura Marchal-Crespo*

Main category: cs.RO

TL;DR: 本文提出了一种用于支持多平面运动外骨骼的数据驱动步态个性化框架，通过回归模型生成个性化轨迹，但在实验中未发现个性化轨迹与标准模式在舒适度和自然性方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前大多数外骨骼依赖预先录制、非个性化的步态轨迹，且局限于矢状面运动，这可能限制运动的自然性和用户舒适度。需要开发支持多平面运动并考虑个体差异的个性化步态控制方法。

Method: 提出数据驱动的步态个性化框架，使用回归模型基于人体测量学、人口统计学和步行速度数据从规范数据库中生成个性化轨迹。在10名健康参与者中进行受试者内实验，比较个性化轨迹与两种标准模式（平均值模式和随机选择模式）。

Result: 未发现不同模式条件之间存在相关差异，尽管所有轨迹都通过刚性位置导数控制器高精度执行。然而，后期试验中的模式条件被评定为比第一次试验更舒适和自然，表明参与者可能适应了外骨骼行走，与强制执行的步态模式无关。

Conclusion: 研究结果强调了在设计个性化步态控制器时整合主观反馈的重要性，以及在实验过程中考虑用户适应性的必要性。个性化轨迹并未显著优于标准模式，但用户适应过程对体验有积极影响。

Abstract: Robot-aided gait rehabilitation facilitates high-intensity and repeatable therapy. However, most exoskeletons rely on pre-recorded, non-personalized gait trajectories constrained to the sagittal plane, potentially limiting movement naturalness and user comfort. We present a data-driven gait personalization framework for an exoskeleton that supports multi-planar motion, including hip abduction/adduction and pelvic translation and rotation. Personalized trajectories to individual participants were generated using regression models trained on anthropometric, demographic, and walking speed data from a normative database. In a within-subject experiment involving ten unimpaired participants, these personalized trajectories were evaluated in regard to comfort, naturalness, and overall experience and compared against two standard patterns from the same database: one averaging all the trajectories, and one randomly selected. We did not find relevant differences across pattern conditions, despite all trajectories being executed with high accuracy thanks to a stiff position-derivative controller. We found, however, that pattern conditions in later trials were rated as more comfortable and natural than those in the first trial, suggesting that participants might have adapted to walking within the exoskeleton, regardless of the enforced gait pattern. Our findings highlight the importance of integrating subjective feedback when designing personalized gait controllers and accounting for user adaptation during experimentation.

</details>


### [11] [ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination](https://arxiv.org/abs/2512.17435)
*Teng Wang,Xinxin Zhao,Wenzhe Cai,Changyin Sun*

Main category: cs.RO

TL;DR: ImagineNav++：基于视觉语言模型的想象驱动导航框架，通过想象未来观测图像来选择最佳视角，实现无需地图的视觉导航，在开放词汇对象导航基准上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的导航方法受限于文本表示，无法充分捕捉空间占用和场景几何等对导航决策至关重要的因素。本研究探索视觉语言模型是否能够仅使用机载RGB/RGB-D流实现无需地图的视觉导航，释放其在空间感知和规划方面的潜力。

Method: 提出ImagineNav++框架：1) 未来视角想象模块，通过蒸馏人类导航偏好生成具有高探索潜力的语义有意义视点；2) 使用VLM从想象视图中选择最具信息量的视角；3) 选择性注视记忆机制，通过稀疏到密集的层次化框架整合关键帧观测，构建紧凑而全面的长期空间推理记忆；4) 将目标导向导航转化为一系列可处理的点目标导航任务。

Result: 在开放词汇对象和实例导航基准上的广泛实验表明，ImagineNav++在无需地图的设置中实现了SOTA性能，甚至超越了大多数基于地图的方法，突显了场景想象和记忆在基于VLM的空间推理中的重要性。

Conclusion: ImagineNav++成功展示了VLM在无需地图视觉导航中的潜力，通过想象未来观测和选择性记忆机制实现了高效的空间推理和规划，为自主家庭辅助机器人的长期任务提供了新的解决方案。

Abstract: Visual navigation is a fundamental capability for autonomous home-assistance robots, enabling long-horizon tasks such as object search. While recent methods have leveraged Large Language Models (LLMs) to incorporate commonsense reasoning and improve exploration efficiency, their planning remains constrained by textual representations, which cannot adequately capture spatial occupancy or scene geometry--critical factors for navigation decisions. We explore whether Vision-Language Models (VLMs) can achieve mapless visual navigation using only onboard RGB/RGB-D streams, unlocking their potential for spatial perception and planning. We achieve this through an imagination-powered navigation framework, ImagineNav++, which imagines future observation images from candidate robot views and translates navigation planning into a simple best-view image selection problem for VLMs. First, a future-view imagination module distills human navigation preferences to generate semantically meaningful viewpoints with high exploration potential. These imagined views then serve as visual prompts for the VLM to identify the most informative viewpoint. To maintain spatial consistency, we develop a selective foveation memory mechanism, which hierarchically integrates keyframe observations via a sparse-to-dense framework, constructing a compact yet comprehensive memory for long-term spatial reasoning. This approach transforms goal-oriented navigation into a series of tractable point-goal navigation tasks. Extensive experiments on open-vocabulary object and instance navigation benchmarks show that ImagineNav++ achieves SOTA performance in mapless settings, even surpassing most map-based methods, highlighting the importance of scene imagination and memory in VLM-based spatial reasoning.

</details>


### [12] [Adaptive Covariance and Quaternion-Focused Hybrid Error-State EKF/UKF for Visual-Inertial Odometry](https://arxiv.org/abs/2512.17505)
*Ufuk Asil,Efendi Nasibov*

Main category: cs.RO

TL;DR: 提出一种用于无人机的混合视觉惯性里程计方法，结合误差状态扩展卡尔曼滤波和缩放无迹卡尔曼滤波，通过动态传感器置信度评估提升复杂环境下的姿态估计性能。


<details>
  <summary>Details</summary>
Motivation: 无人机在复杂环境中面临传感器可靠性变化的问题，传统视觉惯性里程计方法在环境挑战下性能下降，需要一种既能保持计算效率又能提升估计精度的方法。

Method: 采用松耦合传感器融合架构，提出混合四元数误差状态EKF/UKF架构：先用误差状态扩展卡尔曼滤波传播整个状态，再用缩放无迹卡尔曼滤波专门优化方向估计。通过图像熵、强度变化、运动模糊和推理质量等指标动态评估视觉测量可靠性，调整测量噪声协方差。

Result: 在EuRoC MAV数据集上的实验显示：在挑战性场景中位置精度平均提升49%，旋转精度比ESKF方法平均提升57%，达到与SUKF相当的精度但计算成本降低约48%。

Conclusion: 该方法在计算效率和估计精度之间取得了有效平衡，显著提升了无人机在传感器可靠性变化的复杂环境中的姿态估计性能。

Abstract: This study presents an innovative hybrid Visual-Inertial Odometry (VIO) method for Unmanned Aerial Vehicles (UAVs) that is resilient to environmental challenges and capable of dynamically assessing sensor reliability. Built upon a loosely coupled sensor fusion architecture, the system utilizes a novel hybrid Quaternion-focused Error-State EKF/UKF (Qf-ES-EKF/UKF) architecture to process inertial measurement unit (IMU) data. This architecture first propagates the entire state using an Error-State Extended Kalman Filter (ESKF) and then applies a targeted Scaled Unscented Kalman Filter (SUKF) step to refine only the orientation. This sequential process blends the accuracy of SUKF in quaternion estimation with the overall computational efficiency of ESKF. The reliability of visual measurements is assessed via a dynamic sensor confidence score based on metrics, such as image entropy, intensity variation, motion blur, and inference quality, adapting the measurement noise covariance to ensure stable pose estimation even under challenging conditions. Comprehensive experimental analyses on the EuRoC MAV dataset demonstrate key advantages: an average improvement of 49% in position accuracy in challenging scenarios, an average of 57% in rotation accuracy over ESKF-based methods, and SUKF-comparable accuracy achieved with approximately 48% lower computational cost than a full SUKF implementation. These findings demonstrate that the presented approach strikes an effective balance between computational efficiency and estimation accuracy, and significantly enhances UAV pose estimation performance in complex environments with varying sensor reliability.

</details>


### [13] [Deep Learning-based Robust Autonomous Navigation of Aerial Robots in Dense Forests](https://arxiv.org/abs/2512.17553)
*Guglielmo Del Col,Väinö Karjalainen,Teemu Hakala,Yibo Zhang,Eija Honkavaara*

Main category: cs.RO

TL;DR: 该研究提出了一种改进的深度学习导航框架，通过语义增强深度编码和神经运动基元评估，结合多个优化模块，实现了在密集森林环境中的鲁棒自主飞行。


<details>
  <summary>Details</summary>
Motivation: 在密集自然环境中进行自主空中导航面临诸多挑战，包括能见度有限、细薄不规则障碍物、GNSS信号缺失以及频繁的感知退化。现有方法在真实世界部署中存在局限性，需要改进以提升在杂乱森林环境中的飞行可靠性。

Method: 在原始sevae-ORACLE算法基础上集成了多个模块：语义增强深度编码与神经运动基元评估相结合；增加了横向控制以实现更锐利的机动；引入时间一致性机制抑制振荡规划决策；采用基于立体的视觉惯性里程计进行漂移弹性状态估计；添加实时过滤不安全动作的监督安全层；包含深度细化阶段以改善细枝表示并减少立体噪声；通过GPU优化将推理速度从4Hz提升至10Hz。

Result: 在相同环境条件和硬件约束下，与现有学习型导航方法相比，该方法显示出更高的成功率、更稳定的轨迹和更好的碰撞避免能力，特别是在高度杂乱的森林环境中。在三种北方森林环境中部署于定制四旋翼无人机上，在中度和密集杂乱环境中所有飞行均完全自主完成，在高度密集灌木丛中15次飞行成功12次。

Conclusion: 该方法在复杂自然环境中相比现有导航方法展现出更高的可靠性和安全性，证明了深度学习导航框架在密集森林环境中自主飞行的可行性。

Abstract: Autonomous aerial navigation in dense natural environments remains challenging due to limited visibility, thin and irregular obstacles, GNSS-denied operation, and frequent perceptual degradation. This work presents an improved deep learning-based navigation framework that integrates semantically enhanced depth encoding with neural motion-primitive evaluation for robust flight in cluttered forests. Several modules are incorporated on top of the original sevae-ORACLE algorithm to address limitations observed during real-world deployment, including lateral control for sharper maneuvering, a temporal consistency mechanism to suppress oscillatory planning decisions, a stereo-based visual-inertial odometry solution for drift-resilient state estimation, and a supervisory safety layer that filters unsafe actions in real time. A depth refinement stage is included to improve the representation of thin branches and reduce stereo noise, while GPU optimization increases onboard inference throughput from 4 Hz to 10 Hz.
  The proposed approach is evaluated against several existing learning-based navigation methods under identical environmental conditions and hardware constraints. It demonstrates higher success rates, more stable trajectories, and improved collision avoidance, particularly in highly cluttered forest settings. The system is deployed on a custom quadrotor in three boreal forest environments, achieving fully autonomous completion in all flights in moderate and dense clutter, and 12 out of 15 flights in highly dense underbrush. These results demonstrate improved reliability and safety over existing navigation methods in complex natural environments.

</details>


### [14] [Learning-Based Safety-Aware Task Scheduling for Efficient Human-Robot Collaboration](https://arxiv.org/abs/2512.17560)
*M. Faroni,A. Spano,A. M. Zanchettin,P. Rocco*

Main category: cs.RO

TL;DR: 提出一种安全感知方法，通过深度学习模型学习系统状态与安全减速之间的关系，优化任务选择以减少协作机器人循环时间，无需预先了解安全逻辑。


<details>
  <summary>Details</summary>
Motivation: 传统协作机器人安全措施在频繁人机交互时会增加机器人循环时间，降低效率。需要一种方法在保证安全的同时减少效率损失。

Method: 使用深度学习模型基于执行数据学习系统状态与安全诱导速度降低之间的关系，不预测人类运动而是直接建模交互对机器人速度的影响。运行时通过学习模型优化任务选择以最小化循环时间。

Result: 在拾取和包装场景实验中，该方法显著减少了循环时间。

Conclusion: 该方法能够在保证安全要求的同时有效减少协作机器人的效率损失，简化实现并增强对不同安全逻辑的泛化能力。

Abstract: Ensuring human safety in collaborative robotics can compromise efficiency because traditional safety measures increase robot cycle time when human interaction is frequent. This paper proposes a safety-aware approach to mitigate efficiency losses without assuming prior knowledge of safety logic. Using a deep-learning model, the robot learns the relationship between system state and safety-induced speed reductions based on execution data. Our framework does not explicitly predict human motions but directly models the interaction effects on robot speed, simplifying implementation and enhancing generalizability to different safety logics. At runtime, the learned model optimizes task selection to minimize cycle time while adhering to safety requirements. Experiments on a pick-and-packaging scenario demonstrated significant reductions in cycle times.

</details>


### [15] [Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation](https://arxiv.org/abs/2512.17568)
*Kangchen Lv,Mingrui Yu,Yongyi Jia,Chenyu Zhang,Xiang Li*

Main category: cs.RO

TL;DR: 提出了一种基于3D点表示的全身控制模仿学习框架，通过空间一致的表示提高策略的样本效率和空间泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统关节空间策略学习存在任务空间不对齐问题，需要学习复杂的非线性手臂运动学，难以从有限演示中泛化

Method: 使用3D空间一致的表示方法，将机器人状态和动作表示为手臂上的3D点集，在扩散策略中融入运动学先验，通过优化逆运动学求解关节角度

Result: 仿真和真实实验表明，相比现有方法，该方法在身体感知操作策略学习中具有更高的成功率和更强的空间泛化能力

Conclusion: 提出的空间一致表示和运动学先验集成方法有效解决了全身控制中的空间泛化问题，提高了策略学习效率

Abstract: Whole-body control of robotic manipulators with awareness of full-arm kinematics is crucial for many manipulation scenarios involving body collision avoidance or body-object interactions, which makes it insufficient to consider only the end-effector poses in policy learning. The typical approach for whole-arm manipulation is to learn actions in the robot's joint space. However, the unalignment between the joint space and actual task space (i.e., 3D space) increases the complexity of policy learning, as generalization in task space requires the policy to intrinsically understand the non-linear arm kinematics, which is difficult to learn from limited demonstrations. To address this issue, this letter proposes a kinematics-aware imitation learning framework with consistent task, observation, and action spaces, all represented in the same 3D space. Specifically, we represent both robot states and actions using a set of 3D points on the arm body, naturally aligned with the 3D point cloud observations. This spatially consistent representation improves the policy's sample efficiency and spatial generalizability while enabling full-body control. Built upon the diffusion policy, we further incorporate kinematics priors into the diffusion processes to guarantee the kinematic feasibility of output actions. The joint angle commands are finally calculated through an optimization-based whole-body inverse kinematics solver for execution. Simulation and real-world experimental results demonstrate higher success rates and stronger spatial generalizability of our approach compared to existing methods in body-aware manipulation policy learning.

</details>


### [16] [Optimized Scheduling and Positioning of Mobile Manipulators in Collaborative Applications](https://arxiv.org/abs/2512.17584)
*Christian Cella,Sole Ester Sonnino,Marco Faroni,Andrea Zanchettin,Paolo Rocco*

Main category: cs.RO

TL;DR: 提出基于数字模型的移动机械臂优化框架，使用粒子群算法平衡冲突的KPI指标，在协作装箱场景中提升周期时间、任务排序和适应人类存在的能力


<details>
  <summary>Details</summary>
Motivation: 移动机器人在共享工作空间中的集成日益增长，需要高效的路径规划和协调，同时考虑安全性和生产效率

Method: 提出数字模型优化框架，将完整问题视为黑盒，采用粒子群优化算法平衡冲突的关键性能指标，确定机器人基座姿态序列和任务调度

Result: 在协作装箱场景中展示了在周期时间、任务排序和适应人类存在方面的改进

Conclusion: 提出的数字模型优化框架能有效提升移动机械臂在人类-机器人协作环境中的性能表现

Abstract: The growing integration of mobile robots in shared workspaces requires efficient path planning and coordination between the agents, accounting for safety and productivity. In this work, we propose a digital model-based optimization framework for mobile manipulators in human-robot collaborative environments, in order to determine the sequence of robot base poses and the task scheduling for the robot. The complete problem is treated as black-box, and Particle Swarm Optimization (PSO) is employed to balance conflicting Key-Performance Indicators (KPIs). We demonstrate improvements in cycle time, task sequencing, and adaptation to human presence in a collaborative box-packing scenario.

</details>


### [17] [Vidarc: Embodied Video Diffusion Model for Closed-loop Control](https://arxiv.org/abs/2512.17661)
*Yao Feng,Chendong Xiang,Xinyi Mao,Hengkai Tan,Zuyue Zhang,Shuhe Huang,Kaiwen Zheng,Haitian Liu,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: Vidarc是一种基于视频扩散的机器人控制方法，通过掩码逆动力学模型和自回归生成实现快速闭环控制，在数据稀缺环境下显著提升成功率并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺环境下，机器人手臂操作面临复杂本体动力学和多样化场景的挑战。现有基于视频的方法虽然能捕捉时空交互，但通常未针对特定本体的闭环控制进行优化，存在高延迟和基础不足的问题。

Method: 提出Vidarc方法，结合自回归体现视频扩散和掩码逆动力学模型。通过动作相关掩码对视频预测进行基础化，并利用缓存自回归生成实现实时反馈，从而实现快速准确的闭环控制。

Result: 在100万跨本体片段上预训练后，Vidarc超越了现有最佳基线，在真实世界部署中成功率至少提高15%，延迟降低91%。同时展示了在未见过的机器人平台上的强大泛化和纠错能力。

Conclusion: Vidarc通过视频扩散和掩码逆动力学模型的结合，有效解决了数据稀缺环境下机器人控制的挑战，实现了快速、准确的闭环操作，并展现出良好的跨平台泛化能力。

Abstract: Robotic arm manipulation in data-scarce settings is a highly challenging task due to the complex embodiment dynamics and diverse contexts. Recent video-based approaches have shown great promise in capturing and transferring the temporal and physical interactions by pre-training on Internet-scale video data. However, such methods are often not optimized for the embodiment-specific closed-loop control, typically suffering from high latency and insufficient grounding. In this paper, we present Vidarc (Video Diffusion for Action Reasoning and Closed-loop Control), a novel autoregressive embodied video diffusion approach augmented by a masked inverse dynamics model. By grounding video predictions with action-relevant masks and incorporating real-time feedback through cached autoregressive generation, Vidarc achieves fast, accurate closed-loop control. Pre-trained on one million cross-embodiment episodes, Vidarc surpasses state-of-the-art baselines, achieving at least a 15% higher success rate in real-world deployment and a 91% reduction in latency. We also highlight its robust generalization and error correction capabilities across previously unseen robotic platforms.

</details>


### [18] [A Dual Quaternion based RRT* Path Planning Approach for Satellite Rendezvous and Docking](https://arxiv.org/abs/2512.17680)
*Ana Stankovic,Mohamed Khalil Ben-Larbi,Wolfgang H. Müller*

Main category: cs.RO

TL;DR: 提出一种基于对偶四元数的采样运动规划器，用于卫星交会对接的六自由度位姿轨迹生成，在RRT*框架中直接集成对偶四元数代数，实现SE(3)空间的自然螺旋运动插值。


<details>
  <summary>Details</summary>
Motivation: 卫星交会对接需要生成平滑、无碰撞的六自由度位姿轨迹，传统方法分别处理平移和旋转可能导致位姿不连续。对偶四元数能更自然地表示SE(3)空间中的刚体运动。

Method: 将对偶四元数代数直接集成到RRT*框架中，使用对偶四元数表示位姿，实现SE(3)空间的自然螺旋运动插值。在Python中实现该算法，并在多障碍物场景中进行演示。

Result: 与使用分离平移和四元数转向的标准RRT*相比，该方法在位姿连续性和避障能力方面表现更优。算法在代表性多障碍物场景中成功生成平滑轨迹。

Conclusion: 该方法为纯运动学方法，不考虑相对轨道动力学，生成的路径可作为后续基于优化的轨迹规划器的初步估计，后者将加入动力学约束以用于实际卫星交会对接任务。

Abstract: This paper proposes a sampling-based motion planner that employs a dual quaternion representation to generate smooth, collision-free six-degree-of-freedom pose trajectories for satellite rendezvous and docking under keep-out zone constraints. The proposed planner integrates the dual quaternion algebra directly into an RRT* framework, thereby enabling natural screw motion interpolation in SE(3). The dual quaternion-based RRT* has been implemented in Python and demonstrated on a representative multi-obstacle scenario. A comparison with a standard RRT* using separate translation and quaternion steering highlights the enhanced pose continuity and obstacle avoidance of the proposed method. The present approach is purely kinematic in nature and does not take into account relative orbital dynamics. Consequently, the resulting path provides a preliminary estimate for a subsequent optimisation-based trajectory planner, which will refine the motion with dynamic constraints for the purpose of practical satellite rendezvous and docking missions.

</details>


### [19] [Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes](https://arxiv.org/abs/2512.17846)
*Carlos Vélez García,Miguel Cazorla,Jorge Pomares*

Main category: cs.RO

TL;DR: PaD是一个离线目标条件强化学习框架，通过验证驱动轨迹合成，学习目标条件能量函数，通过梯度下降在能量景观中进行规划，在OGBench立方体操作任务中达到95%成功率。


<details>
  <summary>Details</summary>
Motivation: 解决离线目标条件强化学习中训练-测试不匹配问题，传统方法通常将建模与规划解耦，导致性能下降。PaD旨在通过统一的验证驱动规划框架，在训练和推理时使用相同计算，提高规划鲁棒性。

Method: 学习目标条件能量函数，为可行且符合目标的未来轨迹分配低能量。规划通过梯度下降在能量景观中进行细化。使用自监督后见目标重标记训练，围绕规划动态塑造能量景观。推理时在多个时间假设下细化轨迹候选，选择平衡可行性和效率的低能量计划。

Result: 在OGBench立方体操作任务中，使用窄专家演示训练时达到95%成功率，显著优于之前68%的最佳方法。使用噪声、次优数据训练进一步提高了成功率和计划效率。

Conclusion: 学习评估和细化轨迹为离线、无奖励规划提供了比直接策略学习更鲁棒的替代方案。验证驱动规划在噪声数据下表现优异，表明能量函数学习结合梯度细化是有效的规划方法。

Abstract: We present Planning as Descent (PaD), a framework for offline goal-conditioned reinforcement learning that grounds trajectory synthesis in verification. Instead of learning a policy or explicit planner, PaD learns a goal-conditioned energy function over entire latent trajectories, assigning low energy to feasible, goal-consistent futures. Planning is realized as gradient-based refinement in this energy landscape, using identical computation during training and inference to reduce train-test mismatch common in decoupled modeling pipelines.
  PaD is trained via self-supervised hindsight goal relabeling, shaping the energy landscape around the planning dynamics. At inference, multiple trajectory candidates are refined under different temporal hypotheses, and low-energy plans balancing feasibility and efficiency are selected.
  We evaluate PaD on OGBench cube manipulation tasks. When trained on narrow expert demonstrations, PaD achieves state-of-the-art 95\% success, strongly outperforming prior methods that peak at 68\%. Remarkably, training on noisy, suboptimal data further improves success and plan efficiency, highlighting the benefits of verification-driven planning. Our results suggest learning to evaluate and refine trajectories provides a robust alternative to direct policy learning for offline, reward-free planning.

</details>


### [20] [AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning](https://arxiv.org/abs/2512.17853)
*Ran Gong,Xiaohan Zhang,Jinghuan Shang,Maria Vittoria Minniti,Jigarkumar Patel,Valerio Pepe,Riedana Yan,Ahmet Gundogdu,Ivan Kapelyukh,Ali Abbas,Xiaoqiang Yan,Harsh Patel,Laura Herlant,Karl Schmeckpeper*

Main category: cs.RO

TL;DR: AnyTask是一个自动化框架，利用GPU并行仿真和基础模型生成多样化机器人操作任务和数据，通过三种智能体生成专家演示，训练的行为克隆策略在真实机器人上实现了44%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 通用机器人学习受限于数据收集的昂贵成本，仿真虽然能扩展数据收集，但相关任务（仿真任务设计、场景生成、专家演示合成、仿真到真实迁移）仍需大量人工努力。

Method: 提出AnyTask框架，结合大规模GPU并行仿真和基础模型自动设计多样化操作任务和合成机器人数据。引入三种智能体生成专家演示：1) ViPR（视觉语言模型循环并行优化的任务和运动规划智能体）；2) ViPR-Eureka（生成密集奖励和LLM引导接触采样的强化学习智能体）；3) ViPR-RL（联合稀疏奖励下高质量演示的混合规划学习方法）。

Result: 在生成数据上训练行为克隆策略，在仿真中验证并直接部署到真实机器人硬件。策略能够泛化到新物体姿态，在真实世界的拾放、抽屉打开、接触丰富的推动和长时程操作任务套件中实现了44%的平均成功率。

Conclusion: AnyTask框架通过自动化任务设计和数据生成，显著减少了机器人学习所需的人工努力，在真实机器人上展示了良好的泛化能力，为通用机器人学习提供了有前景的解决方案。

Abstract: Generalist robot learning remains constrained by data: large-scale, diverse, and high-quality interaction data are expensive to collect in the real world. While simulation has become a promising way for scaling up data collection, the related tasks, including simulation task design, task-aware scene generation, expert demonstration synthesis, and sim-to-real transfer, still demand substantial human effort. We present AnyTask, an automated framework that pairs massively parallel GPU simulation with foundation models to design diverse manipulation tasks and synthesize robot data. We introduce three AnyTask agents for generating expert demonstrations aiming to solve as many tasks as possible: 1) ViPR, a novel task and motion planning agent with VLM-in-the-loop Parallel Refinement; 2) ViPR-Eureka, a reinforcement learning agent with generated dense rewards and LLM-guided contact sampling; 3) ViPR-RL, a hybrid planning and learning approach that jointly produces high-quality demonstrations with only sparse rewards. We train behavior cloning policies on generated data, validate them in simulation, and deploy them directly on real robot hardware. The policies generalize to novel object poses, achieving 44% average success across a suite of real-world pick-and-place, drawer opening, contact-rich pushing, and long-horizon manipulation tasks. Our project website is at https://anytask.rai-inst.com .

</details>
