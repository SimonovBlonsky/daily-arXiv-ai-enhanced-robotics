<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 13]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Reinforcement learning with timed constraints for robotics motion planning](https://arxiv.org/abs/2601.00087)
*Zhaoan Wang,Junchao Li,Mahdi Mohammad,Shaoping Xiao*

Main category: cs.RO

TL;DR: 提出基于自动机的强化学习框架，用于在MDP和POMDP中合成满足MITL时序逻辑规范的控制策略，通过将MITL转换为定时LDGBA并与决策过程同步，构建适合Q学习的乘积定时模型。


<details>
  <summary>Details</summary>
Motivation: 机器人在动态不确定环境中需要满足复杂时序约束的任务规划，MITL提供了形式化表达框架，但将其与强化学习结合仍面临随机动态和部分可观测性的挑战。

Method: 将MITL公式转换为定时限确定广义Büchi自动机(Timed-LDGBA)，与底层决策过程同步构建乘积定时模型，设计简单而富有表达力的奖励结构，使用Q-learning学习策略。

Result: 在三个仿真研究中验证：5×5网格世界MDP、10×10网格世界POMDP和办公室服务机器人场景。结果表明框架能学习满足严格时间约束的策略，可扩展到更大状态空间，在部分可观测环境中保持有效。

Conclusion: 该框架为时间关键和不确定环境中的可靠机器人规划提供了有效解决方案，能够处理随机转移、扩展到大状态空间，并在部分可观测环境中保持性能。

Abstract: Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \times 5$ grid-world formulated as an MDP, a $10 \times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.

</details>


### [2] [Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126)
*Utkarsh A Mishra,David He,Yongxin Chen,Danfei Xu*

Main category: cs.RO

TL;DR: CDGS通过将搜索嵌入扩散去噪过程，解决了组合生成模型中多模态分布的模式平均问题，在机器人操作、全景图像和长视频生成中实现局部可行性和全局一致性。


<details>
  <summary>Details</summary>
Motivation: 组合生成模型在建模长时程任务分布方面具有潜力，但当局部分布为多模态时，现有组合方法会平均不兼容的模式，导致生成的计划既不可行也不连贯。

Method: CDGS将搜索直接嵌入扩散去噪过程，通过基于种群的采样探索局部模式的多样化组合，使用基于似然的过滤剪枝不可行候选，并通过迭代重采样在重叠段之间强制执行全局一致性。

Result: 在七个机器人操作任务上达到oracle性能，优于缺乏组合性或需要长时程训练数据的基线方法；方法可跨领域泛化，实现连贯的文本引导全景图像和长视频生成。

Conclusion: CDGS通过将搜索与扩散过程结合，有效解决了组合生成模型中的模式平均问题，实现了局部可行性和全局一致性的平衡，为长时程规划任务提供了有效解决方案。

Abstract: Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this \emph{mode averaging} problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/

</details>


### [3] [SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks](https://arxiv.org/abs/2601.00238)
*Julia Di,Kenneth A. W. Hoffmann,Tony G. Chen,Tian-Ao Ren,Mark R. Cutkosky*

Main category: cs.RO

TL;DR: 该论文提出了一种名为SLAP的无人机垂直树干栖息系统，通过视觉检测、软着陆控制和弹性抓取机构，实现了对较大型无人机的安全、轻柔栖息和故障恢复功能。


<details>
  <summary>Details</summary>
Motivation: 无人机在垂直表面栖息可以降低能耗、进行表面采样或稳定观测，但现有方案主要针对轻量级机械设计，缺乏系统集成，且通常需要高速、激进的着陆操作，对搭载敏感电子设备的勘测无人机存在危险。

Method: 开发了SLAP系统，包含：视觉栖息点检测器、IMU栖息故障检测器、软栖息姿态控制器、光学近距离检测系统，以及使用商用slapbands制成的带微刺的快速主动弹性抓取器。在1.2公斤商用四旋翼无人机上进行验证。

Result: 室内自主飞行实验显示，在真实橡树段上进行20次飞行测试，栖息成功率达到75%；在2次诱导故障飞行中，栖息故障恢复率达到100%。

Conclusion: SLAP系统为较大型无人机提供了一种安全、轻柔的垂直树干栖息解决方案，具备故障检测和恢复能力，提高了无人机栖息操作的可靠性和安全性。

Abstract: Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.

</details>


### [4] [Vehicle Painting Robot Path Planning Using Hierarchical Optimization](https://arxiv.org/abs/2601.00271)
*Yuya Nagai,Hiromitsu Nakamura,Narito Shinmachi,Yuta Higashizono,Satoshi Ono*

Main category: cs.RO

TL;DR: 本文提出了一种分层优化方法，用于自动化车辆喷漆过程中多机械臂的路径规划，解决了传统手动设计耗时且无法直接应用现有机器人路径规划技术的问题。


<details>
  <summary>Details</summary>
Motivation: 车辆生产工厂中，多机械臂同时为传送带上的车身喷漆，路径设计目前依赖工程师手动完成，耗时且需要自动化以减少设计时间。喷漆过程的独特约束使得传统的机器人路径规划技术（如焊接中使用的）无法直接应用。

Method: 将喷漆路径设计建模为分层优化问题：上层子问题类似于车辆路径问题（VRP），负责分配车身区域给机械臂；下层子问题进行详细的路径规划。通过设计变量表示、约束、修复算子和初始化过程，灵活处理喷漆过程的特定约束，每层可使用不同的优化算法。

Result: 在三种商用车型上的实验表明，该方法能够自动设计出满足所有喷漆约束的路径，其质量与工程师手动设计的路径相当。

Conclusion: 提出的分层优化方法成功实现了车辆喷漆路径的自动化设计，解决了传统手动设计的效率问题，同时保证了路径质量满足实际生产要求。

Abstract: In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.

</details>


### [5] [Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors](https://arxiv.org/abs/2601.00275)
*Dusan Nemec,Gal Versano,Itai Savin,Vojtech Simak,Juraj Kekelak,Itzik Klein*

Main category: cs.RO

TL;DR: WiCHINS：一种结合轮载和车体惯性传感器的纯惯性导航系统，在GNSS受限或光照不佳环境下实现精确导航，平均位置误差为行驶距离的2.4%


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号受限或光照条件不佳的实际场景中，自动驾驶车辆和轮式机器人可能只能依赖惯性传感器进行导航，但纯惯性导航会随时间漂移。需要一种能在挑战性环境中实现稳健导航的纯惯性解决方案。

Method: 提出WiCHINS系统，将轮载惯性传感器与车体惯性传感器结合。开发了一个三阶段框架，每个阶段使用专用的扩展卡尔曼滤波器，充分利用轮子和车体不同位置传感器的优势进行估计。

Result: 使用5个惯性测量单元、总记录时间228.6分钟的数据集进行评估。与4个其他惯性基线方法比较，使用两个轮子和一个车体惯性测量单元时，平均位置误差为11.4米，占平均行驶距离的2.4%。

Conclusion: WiCHINS方法能够在挑战性环境中实现稳健导航，有助于弥合纯惯性导航的性能差距，为GNSS受限或光照不佳环境下的轮式机器人导航提供了有效解决方案。

Abstract: Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.

</details>


### [6] [Replaceable Bit-based Gripper for Picking Cluttered Food Items](https://arxiv.org/abs/2601.00305)
*Prashant Kumar,Yukiyasu Domae,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出一种可更换夹爪头的夹持系统，用于处理杂乱食品的称重包装，针对不同形状的食品设计了专用夹爪头，实现了高精度的重量控制抓取。


<details>
  <summary>Details</summary>
Motivation: 食品包装行业面临快速变化的食品种类和重量需求，特别是从易抓取的单件食品到柔性、长条状、杂乱的食品。需要一种能够处理各种杂乱食品并实现精确重量控制的抓取系统。

Method: 开发了可更换夹爪头的夹持系统，配备专用食品附件（夹爪头）增强抓取能力，采用皮带更换系统可在包装操作中快速切换不同食品。特别为两种柔性食品设计了夹爪头：鲑鱼子（粘性颗粒食品）和意大利面（长条状粘性杂乱食品）。

Result: 夹持系统成功抓取了意大利面和鲑鱼子，分别实现了超过80%和95%的精确重量控制投放精度。系统还展示了在不同夹爪头之间的快速切换能力，能够处理多种食品。

Conclusion: 提出的可更换夹爪头夹持系统能够有效处理各种杂乱食品的称重包装需求，实现了高精度的重量控制抓取和快速切换能力，适用于食品包装行业的多样化需求。

Abstract: The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.

</details>


### [7] [LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration](https://arxiv.org/abs/2601.00555)
*Abu Hanif Muhammad Syarubany,Farhan Zaki Rahmani,Trio Widianto*

Main category: cs.RO

TL;DR: 提出了一种基于LLM的端到端机器人探索系统，用于室内购物任务，在Gazebo仿真和真实走廊环境中验证，通过语义地图构建和模块化运动控制实现多店铺导航和物品抓取。


<details>
  <summary>Details</summary>
Motivation: 解决室内购物场景中机器人自主探索、导航和物品检索的挑战，通过LLM实现自然语言指令理解，结合轻量级语义地图和模块化控制系统，提高任务执行的灵活性和可调试性。

Method: 系统采用端到端架构：1）增量构建轻量级语义地图，通过检测路口标识牌并存储方向-POI关系；2）使用AprilTags作为可重复定位锚点；3）LLM根据自然语言请求在每个路口生成约束离散动作；4）ROS有限状态主控制器执行决策，通过门控模块化运动原语（避障、AprilTag接近、店铺进入、抓取等）。

Result: 定性结果表明，集成系统能够从用户指令到多店铺导航和物品检索的端到端任务执行，同时通过基于文本的地图和决策历史记录保持模块化和可调试性。

Conclusion: 提出的LLM-based agentic exploration系统成功实现了室内购物任务的端到端执行，展示了自然语言指令理解、语义地图构建和模块化运动控制的结合在机器人自主探索中的有效性。

Abstract: This paper presents an end-to-end LLM-based agentic exploration system for an indoor shopping task, evaluated in both Gazebo simulation and a corresponding real-world corridor layout. The robot incrementally builds a lightweight semantic map by detecting signboards at junctions and storing direction-to-POI relations together with estimated junction poses, while AprilTags provide repeatable anchors for approach and alignment. Given a natural-language shopping request, an LLM produces a constrained discrete action at each junction (direction and whether to enter a store), and a ROS finite-state main controller executes the decision by gating modular motion primitives, including local-costmap-based obstacle avoidance, AprilTag approaching, store entry, and grasping. Qualitative results show that the integrated stack can perform end-to-end task execution from user instruction to multi-store navigation and object retrieval, while remaining modular and debuggable through its text-based map and logged decision history.

</details>


### [8] [Priority-Aware Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2601.00580)
*Kanghoon Lee,Hyeonjun Kim,Jiachen Li,Jinkyoo Park*

Main category: cs.RO

TL;DR: 本文提出优先级感知的多机器人覆盖路径规划（PA-MCPP）问题，通过两阶段框架优化优先级区域的加权延迟和总完成时间


<details>
  <summary>Details</summary>
Motivation: 传统多机器人覆盖路径规划方法假设区域重要性均匀，但在实际应用中某些区域需要优先覆盖，现有方法无法有效处理这种优先级需求

Method: 提出可扩展的两阶段框架：第一阶段使用贪心区域分配结合局部搜索和基于生成树的路径规划；第二阶段采用Steiner树引导的剩余覆盖

Result: 实验表明该方法相比标准MCPP基线显著降低了优先级加权延迟，同时保持了竞争力的总完成时间；敏感性分析显示方法能良好扩展到多机器人场景，且通过调整优先级权重可有效控制区域覆盖行为

Conclusion: 提出的PA-MCPP问题和两阶段框架有效解决了优先级区域覆盖问题，在保持总完成时间的同时显著优化了优先级区域的覆盖延迟

Abstract: Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.

</details>


### [9] [Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework](https://arxiv.org/abs/2601.00610)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 该论文提出了一种用于大型机器人的安全目标到达控制框架，通过模块化设计结合强化学习、深度学习模型和鲁棒自适应控制，确保在复杂地形下的稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人应用中需要大量探索状态-动作空间，期间行为可能不安全，这限制了其在大型复杂机器人上的应用。需要设计一个安全的目标到达控制框架来解决这一问题。

Method: 将系统分解为五个紧密耦合的功能模块：1) 实时视觉姿态估计提供准确机器人状态；2) RL运动规划器生成平滑运动指令；3) 监督深度学习模型捕获机器人复杂动力学；4) 基于模型的鲁棒自适应控制器确保轮子跟踪RL指令；5) 数学安全监控器监测机器人安全。

Result: 该框架保证了执行系统的均匀指数稳定性和整个操作的安全性。在6000公斤机器人上的不同场景实验证实了该框架的有效性。

Conclusion: 提出的模块化控制框架成功解决了大型机器人在不稳定地形上使用强化学习的安全性问题，通过结合多种技术实现了安全、稳定的目标到达控制。

Abstract: Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.

</details>


### [10] [From 2D to 3D terrain-following area coverage path planning](https://arxiv.org/abs/2601.00614)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 提出了一种三维地形跟随的区域覆盖路径规划算法，能够在保持机械工作宽度间距的同时，使路径在特定工作高度上跟随地形起伏。


<details>
  <summary>Details</summary>
Motivation: 在三维地形环境中实现高效的区域覆盖路径规划，特别是在农业等实际应用中，需要同时考虑路径间距和工作高度，而传统的二维路径规划方法无法满足这些三维地形跟随需求。

Method: 算法生成多条相邻路径，这些路径（1）在局部保持与机械工作宽度相等的间距，（2）同时在特定工作高度上跟随地形起伏。方法包括使用反距离加权方法生成均匀间距的高程数据，并进行局部搜索。

Result: 在农业环境中的真实三维数据上进行了区域覆盖路径规划实验，验证了算法的有效性。与二维等效算法相比，该算法能够处理三维地形跟随的复杂性。

Conclusion: 该三维地形跟随区域覆盖路径规划算法能够有效处理真实世界地形数据，在保持适当路径间距和工作高度的同时实现地形跟随，适用于农业等实际应用场景。

Abstract: An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.

</details>


### [11] [RoboReward: General-Purpose Vision-Language Reward Models for Robotics](https://arxiv.org/abs/2601.00675)
*Tony Lee,Andrew Wagenmaker,Karl Pertsch,Percy Liang,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: 该研究提出了RoboReward数据集和基准，用于评估视觉语言模型在机器人任务中的奖励建模能力，并训练了专门的奖励模型，在真实机器人强化学习中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 在真实机器人领域中，获取有效的奖励函数通常需要大量人工标注或脆硬的手工设计目标。虽然视觉语言模型有潜力作为自动奖励模型，但它们在真实机器人任务中的有效性尚未得到充分验证。

Method: 1) 构建RoboReward数据集和基准，基于Open X-Embodiment和RoboArena的大规模真实机器人数据；2) 提出负样本数据增强流程，通过反事实重标注和时间裁剪生成校准的负样本和接近成功样本；3) 训练4B和8B参数的视觉语言奖励模型。

Result: 评估显示现有视觉语言模型在所有任务中表现不一致，存在改进空间。训练的4B/8B参数模型在短视距机器人任务中优于更大的视觉语言模型。8B参数奖励模型在真实机器人强化学习中大幅优于Gemini Robotics-ER 1.5，并显著缩小了与人工提供奖励的差距。

Conclusion: 该研究填补了视觉语言模型在机器人奖励建模领域的空白，证明了专门训练的奖励模型在真实机器人强化学习中的有效性，为自动奖励生成提供了有前景的方向。

Abstract: A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \emph{negative examples data augmentation} pipeline that generates calibrated \emph{negatives} and \emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.

</details>


### [12] [DefVINS: Visual-Inertial Odometry for Deformable Scenes](https://arxiv.org/abs/2601.00702)
*Samuel Cerezo,Javier Civera*

Main category: cs.RO

TL;DR: DefVINS是一个视觉-惯性里程计框架，专门处理可变形场景，通过将刚性IMU锚定状态与非刚性变形图分离，提高在非刚性环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-惯性里程计(VIO)基于刚性假设，在可变形场景中容易过拟合局部非刚性运动或产生严重漂移，需要专门处理变形问题的解决方案。

Method: DefVINS框架将刚性IMU锚定状态与非刚性变形图分离表示，采用标准VIO初始化后逐步激活非刚性自由度，结合可观测性分析指导激活策略，防止在激励不足时进行病态更新。

Result: 消融研究表明，结合惯性约束和可观测性感知的变形激活策略，在非刚性环境中显著提高了系统的鲁棒性。

Conclusion: DefVINS通过明确分离刚性和非刚性运动，结合可观测性分析和条件激活策略，有效解决了可变形场景中的视觉-惯性里程计问题，提高了在非刚性环境中的性能。

Abstract: Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

</details>


### [13] [Calling for Backup: How Children Navigate Successive Robot Communication Failures](https://arxiv.org/abs/2601.00754)
*Maria Teresa Parreira,Isabel Neto,Filipa Rocha,Wendy Ju*

Main category: cs.RO

TL;DR: 研究探索儿童对机器人重复错误的反应，发现儿童与成人在调整提示、改变语气和情绪表达方面相似，但儿童表现出更多脱离行为，且错误不影响儿童对机器人的感知。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探讨成人对机器人连续错误的反应，但儿童对此类错误的反应尚未得到充分研究。本研究旨在填补这一空白，探索儿童对机器人社交错误和性能错误的反应，为设计适合儿童的人机交互系统提供依据。

Method: 研究复制了Liu等人的连续机器人失败范式，招募59名8-10岁儿童参与实验。参与者与一个连续三次无法理解其提示的机器人互动，研究人员通过视频记录和分析他们的行为反应。

Result: 研究发现儿童与成人反应既有相似也有差异：儿童像成人一样调整提示、改变语气，并在连续错误中表现出更多情绪化的非语言反应。但儿童表现出更多脱离行为，如暂时忽略机器人或主动寻求成人帮助。错误不影响儿童对机器人的感知，表明儿童对对话期望更灵活。

Conclusion: 儿童对机器人重复错误的反应具有独特性，这些发现有助于设计更有效、更适合儿童发展需求的人机交互系统，特别是需要考虑儿童更灵活的对话期望和不同的行为反应模式。

Abstract: How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.

</details>
