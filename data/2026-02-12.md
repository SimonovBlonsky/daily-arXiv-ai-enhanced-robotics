<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Adaptive Time Step Flow Matching for Autonomous Driving Motion Planning](https://arxiv.org/abs/2602.10285)
*Ananya Trivedi,Anjian Li,Mohamed Elnoor,Yusuf Umut Ciftci,Avinash Singh,Jovin D'sa,Sangjae Bae,David Isele,Taskin Padir,Faizan M. Tariq*

Main category: cs.RO

TL;DR: 提出基于条件流匹配的自动驾驶轨迹规划框架，通过轻量级方差估计器动态调整推理步数，结合凸二次规划后处理，实现实时多模态轨迹生成


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶方法中，扩散模型推理延迟高，一致性模型需要精心调校噪声调度且难以适应多模态动作分布，重新训练成本高昂，需要实时高效的轨迹规划方案

Method: 基于条件流匹配的框架，联合预测周围智能体未来运动并规划自车轨迹；训练轻量级方差估计器在线选择推理步数；引入凸二次规划作为轨迹后处理步骤

Result: 在Waymo Open Motion Dataset上训练，能执行车道变换、巡航控制、无保护左转等操作；在NVIDIA RTX 3070 GPU上保持20Hz更新率；相比Transformer、扩散模型和一致性模型基线，轨迹更平滑且更符合动态约束

Conclusion: 提出的条件流匹配框架解决了现有方法的延迟和调优问题，实现了实时高效的自动驾驶轨迹规划，适合在线部署

Abstract: Autonomous driving requires reasoning about interactions with surrounding traffic. A prevailing approach is large-scale imitation learning on expert driving datasets, aimed at generalizing across diverse real-world scenarios. For online trajectory generation, such methods must operate at real-time rates. Diffusion models require hundreds of denoising steps at inference, resulting in high latency. Consistency models mitigate this issue but rely on carefully tuned noise schedules to capture the multimodal action distributions common in autonomous driving. Adapting the schedule, typically requires expensive retraining. To address these limitations, we propose a framework based on conditional flow matching that jointly predicts future motions of surrounding agents and plans the ego trajectory in real time. We train a lightweight variance estimator that selects the number of inference steps online, removing the need for retraining to balance runtime and imitation learning performance. To further enhance ride quality, we introduce a trajectory post-processing step cast as a convex quadratic program, with negligible computational overhead. Trained on the Waymo Open Motion Dataset, the framework performs maneuvers such as lane changes, cruise control, and navigating unprotected left turns without requiring scenario-specific tuning. Our method maintains a 20 Hz update rate on an NVIDIA RTX 3070 GPU, making it suitable for online deployment. Compared to transformer, diffusion, and consistency model baselines, we achieve improved trajectory smoothness and better adherence to dynamic constraints. Experiment videos and code implementations can be found at https://flow-matching-self-driving.github.io/.

</details>


### [2] [A Human-in-the-Loop Confidence-Aware Failure Recovery Framework for Modular Robot Policies](https://arxiv.org/abs/2602.10289)
*Rohan Banerjee,Krishna Palempalli,Bohan Yang,Jiaying Fang,Alif Abdullah,Tom Silver,Sarah Dean,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: 提出了一种模块化机器人策略的人机协同故障恢复框架，通过模块级不确定性估计和人工干预成本模型来决定何时、向哪个模块寻求人类帮助，以提高恢复效率并减少用户负担。


<details>
  <summary>Details</summary>
Motivation: 机器人在非结构化人类环境中（特别是护理场景）经常发生故障，虽然人类可以帮助恢复，但过多或不恰当的查询会给人类伙伴带来不必要的认知和身体负担。

Method: 提出了模块化机器人策略的人机协同故障恢复框架：1）使用校准的模块级不确定性估计和人工干预成本模型；2）分离两个决策：模块选择器识别最可能导致故障的模块，查询算法决定是否请求人工输入或自主行动；3）评估多种模块选择策略和查询算法。

Result: 在受控合成实验中揭示了恢复效率、系统/用户变量鲁棒性和用户工作负载之间的权衡关系。在机器人辅助进食系统的实际部署中，对模拟和真实行动受限个体的研究表明，该框架提高了恢复成功率，同时减少了用户的工作负担。

Conclusion: 明确考虑机器人不确定性和人类努力可以实现更高效、以用户为中心的协作机器人故障恢复。该框架在机器人护理等需要人机协作的场景中具有重要应用价值。

Abstract: Robots operating in unstructured human environments inevitably encounter failures, especially in robot caregiving scenarios. While humans can often help robots recover, excessive or poorly targeted queries impose unnecessary cognitive and physical workload on the human partner. We present a human-in-the-loop failure-recovery framework for modular robotic policies, where a policy is composed of distinct modules such as perception, planning, and control, any of which may fail and often require different forms of human feedback. Our framework integrates calibrated estimates of module-level uncertainty with models of human intervention cost to decide which module to query and when to query the human. It separates these two decisions: a module selector identifies the module most likely responsible for failure, and a querying algorithm determines whether to solicit human input or act autonomously. We evaluate several module-selection strategies and querying algorithms in controlled synthetic experiments, revealing trade-offs between recovery efficiency, robustness to system and user variables, and user workload. Finally, we deploy the framework on a robot-assisted bite acquisition system and demonstrate, in studies involving individuals with both emulated and real mobility limitations, that it improves recovery success while reducing the workload imposed on users. Our results highlight how explicitly reasoning about both robot uncertainty and human effort can enable more efficient and user-centered failure recovery in collaborative robots. Supplementary materials and videos can be found at: http://emprise.cs.cornell.edu/modularhil

</details>


### [3] [Solving Geodesic Equations with Composite Bernstein Polynomials for Trajectory Planning](https://arxiv.org/abs/2602.10365)
*Nick Gorman,Gage MacLin,Maxwell Hammond,Venanzio Cichella*

Main category: cs.RO

TL;DR: 基于复合伯恩斯坦多项式的轨迹规划方法，用于自主系统在复杂环境中的导航，通过符号优化框架实现连续路径和精确轨迹形状控制。


<details>
  <summary>Details</summary>
Motivation: 为自主系统（地面、空中、水下、太空）在复杂环境中导航提供高效、连续的轨迹规划方法，特别适用于计算资源有限的场景，如航天器轨道机动、交会对接等任务。

Method: 使用复合伯恩斯坦多项式表示轨迹，在符号优化框架中实现连续路径规划。将障碍物编码为连续成本场而非离散边界，通过高斯表面不等式约束确保最小障碍物间距，结合测地线方程引导路径沿成本表面的高效方向，并施加边界约束固定起点终点条件。

Result: 该方法能高效生成平滑、无碰撞路径，在多障碍物场景中保持安全间距，无需大量采样或后处理。支持精确导数计算，提高优化效率，适用于二维和三维环境。

Conclusion: 基于复合伯恩斯坦多项式的轨迹规划方法为自主系统导航提供了高效、连续的解决方案，可作为独立规划器或复杂运动规划问题的初始化工具，特别适合计算资源受限的航天任务。

Abstract: This work presents a trajectory planning method based on composite Bernstein polynomials for autonomous systems navigating complex environments. The method is implemented in a symbolic optimization framework that enables continuous paths and precise control over trajectory shape. Trajectories are planned over a cost surface that encodes obstacles as continuous fields rather than discrete boundaries. Regions near obstacles are assigned higher costs, naturally encouraging the trajectory to maintain a safe distance while still allowing efficient routing through constrained spaces. The use of composite Bernstein polynomials preserves continuity while enabling fine control over local curvature to satisfy geodesic constraints. The symbolic representation supports exact derivatives, improving optimization efficiency. The method applies to both two- and three-dimensional environments and is suitable for ground, aerial, underwater, and space systems. In spacecraft trajectory planning, for example, it enables the generation of continuous, dynamically feasible trajectories with high numerical efficiency, making it well suited for orbital maneuvers, rendezvous and proximity operations, cluttered gravitational environments, and planetary exploration missions with limited onboard computational resources. Demonstrations show that the approach efficiently generates smooth, collision-free paths in scenarios with multiple obstacles, maintaining clearance without extensive sampling or post-processing. The optimization incorporates three constraint types: (1) a Gaussian surface inequality enforcing minimum obstacle clearance; (2) geodesic equations guiding the path along locally efficient directions on the cost surface; and (3) boundary constraints enforcing fixed start and end conditions. The method can serve as a standalone planner or as an initializer for more complex motion planning problems.

</details>


### [4] [LocoVLM: Grounding Vision and Language for Adapting Versatile Legged Locomotion Policies](https://arxiv.org/abs/2602.10399)
*I Made Aswin Nahrendra,Seunghyun Lee,Dongkyu Lee,Hyun Myung*

Main category: cs.RO

TL;DR: 该论文提出了一种将基础模型的高级常识推理集成到腿式机器人运动适应中的新方法，通过语言模型合成技能数据库，视觉语言模型提取环境语义，实现高达87%的指令跟随准确率。


<details>
  <summary>Details</summary>
Motivation: 当前腿式机器人运动学习主要依赖环境几何表示，限制了机器人对高级语义（如人类指令）的响应能力。需要将高级常识推理融入运动适应过程。

Method: 1. 使用预训练大语言模型合成面向腿式机器人的指令接地技能数据库；2. 使用预训练视觉语言模型提取高级环境语义并将其接地到技能数据库；3. 训练风格条件策略以生成多样化且鲁棒的运动技能；4. 实现实时技能建议，无需在线查询云端基础模型。

Result: 实现了高达87%的指令跟随准确率，首次展示了腿式机器人利用环境语义和指令的高级推理进行实时运动适应，且无需在线查询云端基础模型。

Conclusion: 该方法成功将基础模型的高级常识推理集成到腿式机器人运动适应中，突破了传统几何表示的局限，使机器人能够响应高级语义指令，为智能腿式机器人发展提供了新方向。

Abstract: Recent advances in legged locomotion learning are still dominated by the utilization of geometric representations of the environment, limiting the robot's capability to respond to higher-level semantics such as human instructions. To address this limitation, we propose a novel approach that integrates high-level commonsense reasoning from foundation models into the process of legged locomotion adaptation. Specifically, our method utilizes a pre-trained large language model to synthesize an instruction-grounded skill database tailored for legged robots. A pre-trained vision-language model is employed to extract high-level environmental semantics and ground them within the skill database, enabling real-time skill advisories for the robot. To facilitate versatile skill control, we train a style-conditioned policy capable of generating diverse and robust locomotion skills with high fidelity to specified styles. To the best of our knowledge, this is the first work to demonstrate real-time adaptation of legged locomotion using high-level reasoning from environmental semantics and instructions with instruction-following accuracy of up to 87% without the need for online query to on-the-cloud foundation models.

</details>


### [5] [Towards Long-Lived Robots: Continual Learning VLA Models via Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.10503)
*Yuan Liu,Haoran Li,Shuai Tian,Yuxing Qin,Yuhui Chen,Yupeng Zheng,Yongzhen Huang,Dongbin Zhao*

Main category: cs.RO

TL;DR: 提出LifeLong-RFT方法，通过强化微调策略解决VLA模型在下游任务适应中的灾难性遗忘问题，无需在线环境反馈和预训练奖励模型，在多任务和持续学习场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: VLA模型虽然具有强大的泛化能力，但传统的监督微调需要大量任务特定数据且容易发生灾难性遗忘，限制了其在持续学习场景中的应用。

Method: 提出LifeLong-RFT方法，结合分块级在线策略强化学习和多维过程奖励机制，包括量化动作一致性奖励、连续轨迹对齐奖励和格式合规奖励三个维度来量化中间动作块的异质贡献。

Result: 在SimplerEnv、LIBERO和真实世界任务上的实验表明，LifeLong-RFT在多任务学习中表现强劲，在LIBERO基准的持续学习中，平均成功率比SFT提高22%，仅需20%的训练数据就能适应新任务。

Conclusion: LifeLong-RFT为VLA模型提供了一个有前景的后训练范式，有效解决了灾难性遗忘问题，提升了模型在持续学习场景中的适应能力。

Abstract: Pretrained on large-scale and diverse datasets, VLA models demonstrate strong generalization and adaptability as general-purpose robotic policies. However, Supervised Fine-Tuning (SFT), which serves as the primary mechanism for adapting VLAs to downstream domains, requires substantial amounts of task-specific data and is prone to catastrophic forgetting. To address these limitations, we propose LifeLong-RFT, a simple yet effective Reinforcement Fine-Tuning (RFT) strategy for VLA models independent of online environmental feedback and pre-trained reward models. By integrating chunking-level on-policy reinforcement learning with the proposed Multi-Dimensional Process Reward (MDPR) mechanism, LifeLong-RFT quantifies the heterogeneous contributions of intermediate action chunks across three dimensions to facilitate policy optimization. Specifically, (1) the Quantized Action Consistency Reward (QACR) ensures accurate action prediction within the discrete action space; (2) the Continuous Trajectory Alignment Reward (CTAR) aligns decoded continuous action chunks with reference trajectories to ensure precise control; (3) the Format Compliance Reward (FCR) guarantees the structural validity of outputs. Comprehensive experiments across SimplerEnv, LIBERO, and real-world tasks demonstrate that LifeLong-RFT exhibits strong performance in multi-task learning. Furthermore, for continual learning on the LIBERO benchmark, our method achieves a 22% gain in average success rate over SFT, while effectively adapting to new tasks using only 20% of the training data. Overall, our method provides a promising post-training paradigm for VLAs.

</details>


### [6] [Co-jump: Cooperative Jumping with Quadrupedal Robots via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.10514)
*Shihao Dong,Yeke Chen,Zeren Luo,Jiahui Zhang,Bowen Xu,Jinghan Lin,Yimin Han,Ji Ma,Zhiyou Yu,Yudong Zhao,Peng Lu*

Main category: cs.RO

TL;DR: 两个四足机器人通过协同跳跃实现远超单机能力的跳跃高度，使用去中心化强化学习框架，无需显式通信或预设动作模式


<details>
  <summary>Details</summary>
Motivation: 单机器人受限于物理驱动能力，需要通过多机器人协作来突破这些限制，实现超越个体能力的跳跃性能

Method: 采用多智能体近端策略优化(MAPPO)框架，结合渐进式课程学习策略，处理高脉冲接触动力学，仅使用本体感知反馈实现去中心化同步

Result: 成功在仿真和物理硬件上实现多方向跳跃，最高平台高度1.5米，机器人脚端提升高度达1.1米，比单机器人0.45米跳跃高度提升144%

Conclusion: 通过无通信协作实现了超越个体能力的跳跃性能，为受限环境中的协作运动奠定了基础

Abstract: While single-agent legged locomotion has witnessed remarkable progress, individual robots remain fundamentally constrained by physical actuation limits. To transcend these boundaries, we introduce Co-jump, a cooperative task where two quadrupedal robots synchronize to execute jumps far beyond their solo capabilities. We tackle the high-impulse contact dynamics of this task under a decentralized setting, achieving synchronization without explicit communication or pre-specified motion primitives. Our framework leverages Multi-Agent Proximal Policy Optimization (MAPPO) enhanced by a progressive curriculum strategy, which effectively overcomes the sparse-reward exploration challenges inherent in mechanically coupled systems. We demonstrate robust performance in simulation and successful transfer to physical hardware, executing multi-directional jumps onto platforms up to 1.5 m in height. Specifically, one of the robots achieves a foot-end elevation of 1.1 m, which represents a 144% improvement over the 0.45 m jump height of a standalone quadrupedal robot, demonstrating superior vertical performance. Notably, this precise coordination is achieved solely through proprioceptive feedback, establishing a foundation for communication-free collaborative locomotion in constrained environments.

</details>


### [7] [ReSPEC: A Framework for Online Multispectral Sensor Reconfiguration in Dynamic Environments](https://arxiv.org/abs/2602.10547)
*Yanchen Liu,Yuang Fan,Minghui Zhao,Xiaofan Jiang*

Main category: cs.RO

TL;DR: 提出一个将感知、学习和执行统一到闭环重构循环中的框架，通过RL智能体动态调整传感器配置，在嵌入式机器人平台上实现资源感知的自适应感知


<details>
  <summary>Details</summary>
Motivation: 现有多传感器融合系统大多采用静态传感器配置，无论情境效用如何都以固定速率和保真度收集所有模态数据，这种刚性浪费带宽、计算和能量，且在光照不足或遮挡等挑战条件下无法优先处理关键传感器

Method: 引入一个统一感知、学习和执行的闭环重构框架：任务特定检测骨干提取多光谱特征并生成各模态贡献分数；RL智能体根据这些分数实时动态调整传感器配置（采样频率、分辨率、感知范围等）；信息量少的传感器被降采样或停用，关键传感器则随环境条件变化以更高保真度采样

Result: 在移动机器人上实现并评估该框架，自适应控制相比启发式基线将GPU负载降低29.3%，准确率仅下降5.3%

Conclusion: 结果突显了资源感知自适应感知在嵌入式机器人平台上的潜力，通过动态传感器配置优化资源使用同时保持感知性能

Abstract: Multi-sensor fusion is central to robust robotic perception, yet most existing systems operate under static sensor configurations, collecting all modalities at fixed rates and fidelity regardless of their situational utility. This rigidity wastes bandwidth, computation, and energy, and prevents systems from prioritizing sensors under challenging conditions such as poor lighting or occlusion. Recent advances in reinforcement learning (RL) and modality-aware fusion suggest the potential for adaptive perception, but prior efforts have largely focused on re-weighting features at inference time, ignoring the physical cost of sensor data collection. We introduce a framework that unifies sensing, learning, and actuation into a closed reconfiguration loop. A task-specific detection backbone extracts multispectral features (e.g. RGB, IR, mmWave, depth) and produces quantitative contribution scores for each modality. These scores are passed to an RL agent, which dynamically adjusts sensor configurations, including sampling frequency, resolution, sensing range, and etc., in real time. Less informative sensors are down-sampled or deactivated, while critical sensors are sampled at higher fidelity as environmental conditions evolve. We implement and evaluate this framework on a mobile rover, showing that adaptive control reduces GPU load by 29.3\% with only a 5.3\% accuracy drop compared to a heuristic baseline. These results highlight the potential of resource-aware adaptive sensing for embedded robotic platforms.

</details>


### [8] [LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer](https://arxiv.org/abs/2602.10556)
*Lihan Zha,Asher J. Hancock,Mingtong Zhang,Tenny Yin,Yixuan Huang,Dhruv Shah,Allen Z. Ren,Anirudha Majumdar*

Main category: cs.RO

TL;DR: LAP-3B：首个无需特定机器人本体微调即可实现零样本迁移的视觉-语言-动作模型，通过自然语言表示低级机器人动作，在未见过的机器人本体上达到超过50%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型（VLA）虽然经过大规模多本体预训练，但仍与训练本体紧密耦合，需要昂贵的微调才能适应新机器人本体。研究目标是开发能够零样本部署到新机器人本体上的通用策略。

Method: 提出语言-动作预训练（LAP）方法，将低级机器人动作直接用自然语言表示，使动作监督与预训练视觉-语言模型的输入输出分布对齐。该方法无需学习分词器、昂贵标注或特定本体架构设计。

Result: LAP-3B在多个未见过的机器人和操作任务上实现了超过50%的平均零样本成功率，比先前最强的VLA提升了约2倍。该方法还支持高效适应和有利的扩展性，统一了动作预测和视觉问答的共享语言-动作格式。

Conclusion: LAP方法通过自然语言表示机器人动作，首次实现了无需特定本体微调的实质性零样本迁移，为通用机器人策略的发展提供了新方向，同时展示了统一语言-动作格式的协同训练优势。

Abstract: A long-standing goal in robotics is a generalist policy that can be deployed zero-shot on new robot embodiments without per-embodiment adaptation. Despite large-scale multi-embodiment pre-training, existing Vision-Language-Action models (VLAs) remain tightly coupled to their training embodiments and typically require costly fine-tuning. We introduce Language-Action Pre-training (LAP), a simple recipe that represents low-level robot actions directly in natural language, aligning action supervision with the pre-trained vision-language model's input-output distribution. LAP requires no learned tokenizer, no costly annotation, and no embodiment-specific architectural design. Based on LAP, we present LAP-3B, which to the best of our knowledge is the first VLA to achieve substantial zero-shot transfer to previously unseen robot embodiments without any embodiment-specific fine-tuning. Across multiple novel robots and manipulation tasks, LAP-3B attains over 50% average zero-shot success, delivering roughly a 2x improvement over the strongest prior VLAs. We further show that LAP enables efficient adaptation and favorable scaling, while unifying action prediction and VQA in a shared language-action format that yields additional gains through co-training.

</details>


### [9] [Morphogenetic Assembly and Adaptive Control for Heterogeneous Modular Robots](https://arxiv.org/abs/2602.10561)
*Chongxi Meng,Da Zhao,Yifei Zhao,Minghao Zeng,Yanmin Zhou,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 提出一个用于异构模块化机器人的闭环自动化框架，涵盖从形态构建到自适应控制的全流程，包括分层规划器和GPU加速的退火方差MPPI控制器。


<details>
  <summary>Details</summary>
Motivation: 解决大规模异构模块化机器人重构中的状态空间爆炸问题，以及未知装配配置的自适应运动控制挑战，实现从模块组装到动态运动生成的完整闭环自动化。

Method: 采用移动机械臂处理异构功能模块，提出分层规划器：高层使用带类型惩罚项的双向启发式搜索生成模块处理序列，低层使用A*搜索计算最优执行轨迹。引入GPU加速的退火方差MPPI控制器，采用多阶段方差退火策略平衡全局探索和局部收敛。

Result: 大规模仿真表明：类型惩罚项对异构场景规划鲁棒性至关重要；贪婪启发式比匈牙利启发式产生更低物理执行成本的规划；退火方差MPPI在速度跟踪精度和控制频率上显著优于标准MPPI，实现50Hz实时控制。

Conclusion: 该框架成功验证了模块组装、机器人合并与分裂、动态运动生成的全周期过程，为异构模块化机器人提供了完整的闭环自动化解决方案。

Abstract: This paper presents a closed-loop automation framework for heterogeneous modular robots, covering the full pipeline from morphological construction to adaptive control. In this framework, a mobile manipulator handles heterogeneous functional modules including structural, joint, and wheeled modules to dynamically assemble diverse robot configurations and provide them with immediate locomotion capability. To address the state-space explosion in large-scale heterogeneous reconfiguration, we propose a hierarchical planner: the high-level planner uses a bidirectional heuristic search with type-penalty terms to generate module-handling sequences, while the low level planner employs A* search to compute optimal execution trajectories. This design effectively decouples discrete configuration planning from continuous motion execution. For adaptive motion generation of unknown assembled configurations, we introduce a GPU accelerated Annealing-Variance Model Predictive Path Integral (MPPI) controller. By incorporating a multi stage variance annealing strategy to balance global exploration and local convergence, the controller enables configuration-agnostic, real-time motion control. Large scale simulations show that the type-penalty term is critical for planning robustness in heterogeneous scenarios. Moreover, the greedy heuristic produces plans with lower physical execution costs than the Hungarian heuristic. The proposed annealing-variance MPPI significantly outperforms standard MPPI in both velocity tracking accuracy and control frequency, achieving real time control at 50 Hz. The framework validates the full-cycle process, including module assembly, robot merging and splitting, and dynamic motion generation.

</details>


### [10] [Flow-Enabled Generalization to Human Demonstrations in Few-Shot Imitation Learning](https://arxiv.org/abs/2602.10594)
*Runze Tang,Penny Sweetser*

Main category: cs.RO

TL;DR: SFCrP：通过场景流预测和裁剪点云条件策略，利用人类视频进行跨具身学习，减少机器人演示需求，提升泛化能力


<details>
  <summary>Details</summary>
Motivation: 模仿学习需要大量机器人演示，成本高昂。现有方法使用光流作为中间表示来利用人类视频，但存在局限性：1）光流仅关注物体或特定点，无法描述交互运动；2）仅依赖光流难以捕捉精确运动细节；3）基于场景观察的条件策略可能导致过拟合训练任务，削弱泛化能力

Method: 提出SFCrP框架，包含两个组件：1）SFCr（场景流预测模型）：从机器人和人类视频中学习，预测任意点轨迹；2）FCrP（流和裁剪点云条件策略）：遵循通用流运动，同时基于观察调整动作以实现精确任务执行

Result: 方法在各种真实世界任务设置中优于最先进的基线方法，同时在仅从人类视频观察的场景中表现出强大的空间和实例泛化能力

Conclusion: SFCrP通过场景流预测和条件策略的结合，有效解决了现有光流方法的局限性，实现了从人类视频到机器人任务的跨具身学习，显著减少了机器人演示需求并提升了泛化性能

Abstract: Imitation Learning (IL) enables robots to learn complex skills from demonstrations without explicit task modeling, but it typically requires large amounts of demonstrations, creating significant collection costs. Prior work has investigated using flow as an intermediate representation to enable the use of human videos as a substitute, thereby reducing the amount of required robot demonstrations. However, most prior work has focused on the flow, either on the object or on specific points of the robot/hand, which cannot describe the motion of interaction. Meanwhile, relying on flow to achieve generalization to scenarios observed only in human videos remains limited, as flow alone cannot capture precise motion details. Furthermore, conditioning on scene observation to produce precise actions may cause the flow-conditioned policy to overfit to training tasks and weaken the generalization indicated by the flow. To address these gaps, we propose SFCrP, which includes a Scene Flow prediction model for Cross-embodiment learning (SFCr) and a Flow and Cropped point cloud conditioned Policy (FCrP). SFCr learns from both robot and human videos and predicts any point trajectories. FCrP follows the general flow motion and adjusts the action based on observations for precision tasks. Our method outperforms SOTA baselines across various real-world task settings, while also exhibiting strong spatial and instance generalization to scenarios seen only in human videos.

</details>


### [11] [Pitch Angle Control of a Magnetically Actuated Capsule Robot with Nonlinear FEA-based MPC and EKF Multisensory Fusion](https://arxiv.org/abs/2602.10610)
*Chongxun Wang,Zikang Shen,Apoorav Rathore,Akanimoh Udombeh,Harrison Teng,Fangzhou Xia*

Main category: cs.RO

TL;DR: 本文提出了一种基于非线性模型预测控制的磁驱动胶囊机器人俯仰角控制框架，通过有限元仿真建立角度相关的磁力/力矩查找表，结合滚动接触和传感器融合，实现了在胃壁倾斜表面上的快速稳定俯仰控制。


<details>
  <summary>Details</summary>
Motivation: 现有的磁驱动胶囊机器人系统大多忽视了俯仰角的控制，而俯仰自由度对于胶囊与倾斜胃壁的接触交互至关重要，需要开发有效的俯仰控制方法以实现更精确的诊断和治疗操作。

Method: 1. 使用四线圈电磁阵列驱动胶囊机器人；2. 通过三维有限元仿真表征角度相关的磁力和力矩，并嵌入控制导向的刚体俯仰模型；3. 设计约束模型预测控制器（MPC）调节俯仰角，考虑硬件电流和变化率限制；4. 结合扩展卡尔曼滤波器（EKF）融合惯性测量和间歇视觉测量。

Result: 在柔性胃壁模拟表面上的实验表明，系统能够从水平和垂直配置实现稳健的俯仰重定向，相比开关控制，稳定时间快3-5倍且振荡减少。即使相机更新率从30Hz降至1Hz（模拟临床成像限制），通过传感器融合仍能实现稳定闭环控制。

Conclusion: 有限元信息化的MPC结合传感器融合为俯仰调节、受控对接和未来多自由度胶囊运动提供了可扩展策略，推动了磁驱动胶囊机器人在胃肠道诊疗中的应用。

Abstract: Magnetically actuated capsule robots promise minimally invasive diagnosis and therapy in the gastrointestinal (GI) tract, but existing systems largely neglect control of capsule pitch, a degree of freedom critical for contact-rich interaction with inclined gastric walls. This paper presents a nonlinear, model-based framework for magnetic pitch control of an ingestible capsule robot actuated by a four-coil electromagnetic array. Angle-dependent magnetic forces and torques acting on embedded permanent magnets are characterized using three-dimensional finite-element simulations and embedded as lookup tables in a control-oriented rigid-body pitching model with rolling contact and actuator dynamics. A constrained model predictive controller (MPC) is designed to regulate pitch while respecting hardware-imposed current and slew-rate limits. Experiments on a compliant stomach-inspired surface demonstrate robust pitch reorientation from both horizontal and upright configurations, achieving about three to five times faster settling and reduced oscillatory motion than on-off control. Furthermore, an extended Kalman filter (EKF) fusing inertial sensing with intermittent visual measurements enables stable closed-loop control when the camera update rate is reduced from 30 Hz to 1 Hz, emulating clinically realistic imaging constraints. These results establish finite-element-informed MPC with sensor fusion as a scalable strategy for pitch regulation, controlled docking, and future multi-degree-of-freedom capsule locomotion.

</details>


### [12] [Free-Flying Crew Cooperative Robots on the ISS: A Joint Review of Astrobee, CIMON, and Int-Ball Operations](https://arxiv.org/abs/2602.10686)
*Seiko Piotr Yamaguchi,Andres Mora Vargas,Till Eisenberg,Christian Rogon,Tatsuya Yamamoto,Shona Inoue,Christoph Kössl,Brian Coltin,Trey Smith,Jose V. Benavides*

Main category: cs.RO

TL;DR: 对国际空间站上三个自由飞行机器人（Astrobee、CIMON、Int-Ball）的首次联合分析，总结了从设计到在轨操作的全生命周期经验教训。


<details>
  <summary>Details</summary>
Motivation: 随着载人航天中自由飞行机器人的应用日益增多，需要总结NASA、DLR、JAXA三个不同机构开发的机器人的共同经验，为未来开发提供指导。

Method: 由三个机器人开发与运营团队成员共同撰写，对Astrobee、CIMON、Int-Ball进行详细对比分析，包括目标、设计和在轨操作等方面。

Result: 尽管机器人起源和设计理念不同，但在开发和运营过程中发现了多种趋同现象，总结出了从设计到在轨操作的全生命周期经验教训。

Conclusion: 这些经验教训可作为未来自由飞行机器人开发的设计建议，促进载人航天中机器人辅助工作的发展。

Abstract: Intra-vehicular free-flying robots are anticipated to support various work in human spaceflight while working side-by-side with astronauts. Such example of robots includes NASA's Astrobee, DLR's CIMON, and JAXA's Int-Ball, which are deployed on the International Space Station. This paper presents the first joint analyses of these robot's shared experiences, co-authored by their development and operation team members. Despite the different origins and design philosophies, the development and operations of these platforms encountered various convergences. Hence, this paper presents a detailed overview of these robots, presenting their objectives, design, and onboard operations. Hence, joint lessons learned across the lifecycle are presented, from design to on-orbit operations. These lessons learned are anticipated to serve for future development and research as design recommendations.

</details>


### [13] [3D-Printed Anisotropic Soft Magnetic Coating for Directional Rolling of a Magnetically Actuated Capsule Robot](https://arxiv.org/abs/2602.10688)
*Jin Zhou,Chongxun Wang,Zikang Shen,Fangzhou Xia*

Main category: cs.RO

TL;DR: 提出一种紧凑的3D打印软胶囊机器人，采用磁性涂层替代传统内部磁铁，保留完整内部腔体用于医疗载荷，实现稳定双向滚动和全方位转向。


<details>
  <summary>Details</summary>
Motivation: 传统磁胶囊机器人在两端嵌入笨重永磁体，减少了约10-20毫米可用腔体，限制了功能模块集成。需要一种能保留完整内部空间的设计方案。

Method: 采用3D打印软胶囊机器人，表面涂覆磁性涂层替代内部磁铁。通过编程NSSN/SNNS磁极分布提供强各向异性和可靠扭矩，实现稳定运动控制。

Result: 磁性涂层设计使胶囊机器人能够稳定双向滚动、全方位转向、爬升7.5度斜坡、跨越5毫米突起。当磁场强度达到0.3 mT时可持续滚动，对应30毫米有效驱动深度。

Conclusion: 涂层基胶囊机器人设计保留了完整内部腔体，提高了可吞咽性，为可靠临床部署奠定了基础。未来将通过材料优化和闭环反馈系统进一步提升性能。

Abstract: Capsule robots are promising tools for minimally invasive diagnostics and therapy, with applications from gastrointestinal endoscopy to targeted drug delivery and biopsy sampling. Conventional magnetic capsule robots embed bulky permanent magnets at both ends, reducing the usable cavity by about 10-20 mm and limiting integration of functional modules. We propose a compact, 3D-printed soft capsule robot with a magnetic coating that replaces internal magnets, enabling locomotion via a thin, functional shell while preserving the entire interior cavity as a continuous volume for medical payloads. The compliant silicone-magnetic composite also improves swallowability, even with a slightly larger capsule size. Magnetostatic simulations and experiments confirm that programmed NSSN/SNNS pole distributions provide strong anisotropy and reliable torque generation, enabling stable bidirectional rolling, omnidirectional steering, climbing on 7.5 degree inclines, and traversal of 5 mm protrusions. Rolling motion is sustained when the magnetic field at the capsule reaches at least 0.3 mT, corresponding to an effective actuation depth of 30 mm in our setup. Future work will optimize material composition, coating thickness, and magnetic layouts to enhance force output and durability, while next-generation robotic-arm-based field generators with closed-loop feedback will address nonlinearities and expand maneuverability. Together, these advances aim to transition coating-based capsule robots toward reliable clinical deployment and broaden their applications in minimally invasive diagnostics and therapy.

</details>


### [14] [A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner](https://arxiv.org/abs/2602.10702)
*Alejandro Mendoza Barrionuevo,Dame Seck Diop,Alejandro Casado Pérez,Daniel Gutiérrez Reina,Sergio L. Toral Marín,Samuel Yanes Luis*

Main category: cs.RO

TL;DR: GuadalPlanner：一种解耦高层决策与车辆特定控制的统一架构，支持算法在不同抽象级别和部署环境（仿真、软件在环、物理车辆）中一致评估，无需修改代码。


<details>
  <summary>Details</summary>
Motivation: 当前自主车辆信息路径规划算法的评估存在两个主要问题：1）执行流程碎片化，2）仿真与真实世界部署之间的可迁移性有限。这阻碍了算法的有效评估和实际应用。

Method: 提出统一架构，通过标准化接口（规划、感知、车辆执行）实现高层决策与车辆特定控制的解耦。基于ROS2、MAVLink、MQTT等成熟机器人技术构建GuadalPlanner开源研究工具，支持离散图基环境和可互换规划策略。

Result: 验证了该架构的有效性，包括在自主水面车辆上进行真实世界部署，执行水质监测任务并提供实时传感器反馈。实现了相同算法逻辑在完全仿真环境、软件在环配置和物理自主车辆中的一致部署。

Conclusion: GuadalPlanner提供了一个开放、可扩展的统一架构，解决了自主车辆路径规划算法评估中的碎片化和可迁移性问题，促进了算法从仿真到真实世界的无缝部署。

Abstract: The evaluation of informative path planning algorithms for autonomous vehicles is often hindered by fragmented execution pipelines and limited transferability between simulation and real-world deployment. This paper introduces a unified architecture that decouples high-level decision-making from vehicle-specific control, enabling algorithms to be evaluated consistently across different abstraction levels without modification. The proposed architecture is realized through GuadalPlanner, which defines standardized interfaces between planning, sensing, and vehicle execution. It is an open and extensible research tool that supports discrete graph-based environments and interchangeable planning strategies, and is built upon widely adopted robotics technologies, including ROS2, MAVLink, and MQTT. Its design allows the same algorithmic logic to be deployed in fully simulated environments, software-in-the-loop configurations, and physical autonomous vehicles using an identical execution pipeline. The approach is validated through a set of experiments, including real-world deployment on an autonomous surface vehicle performing water quality monitoring with real-time sensor feedback.

</details>


### [15] [Omnidirectional Dual-Arm Aerial Manipulator with Proprioceptive Contact Localization for Landing on Slanted Roofs](https://arxiv.org/abs/2602.10703)
*Martijn B. J. Brummelhuis,Nathan F. Lepora,Salua Hamaza*

Main category: cs.RO

TL;DR: 本文提出了一种新型无人机机械臂形态，通过动量观测器实现触觉感知，使无人机能够在物理交互中盲测倾斜表面角度，实现高达30.5度倾斜屋顶的鲁棒着陆。


<details>
  <summary>Details</summary>
Motivation: 城市环境中无人机需要在不同几何形状和不规则表面的屋顶上着陆，传统视觉或声学传感方法受天气条件和表面材料等外部因素影响，测量可靠性差。

Method: 设计具有全向3D工作空间和扩展范围的双手臂空中机械臂，基于动量观测器开发本体感知接触检测和定位策略，通过物理交互盲测倾斜表面角度。

Result: 飞行实验验证了该方法，在高达30.5度的倾斜表面上实现鲁棒着陆，在9个不同倾斜角度的实验中平均表面倾斜估计误差为2.87度。

Conclusion: 提出的本体感知接触检测方法能够可靠地推断倾斜表面角度，为无人机在复杂城市环境中的安全着陆提供了有效解决方案。

Abstract: Operating drones in urban environments often means they need to land on rooftops, which can have different geometries and surface irregularities. Accurately detecting roof inclination using conventional sensing methods, such as vision-based or acoustic techniques, can be unreliable, as measurement quality is strongly influenced by external factors including weather conditions and surface materials. To overcome these challenges, we propose a novel unmanned aerial manipulator morphology featuring a dual-arm aerial manipulator with an omnidirectional 3D workspace and extended reach. Building on this design, we develop a proprioceptive contact detection and contact localization strategy based on a momentum-based torque observer. This enables the UAM to infer the inclination of slanted surfaces blindly - through physical interaction - prior to touchdown. We validate the approach in flight experiments, demonstrating robust landings on surfaces with inclinations of up to 30.5 degrees and achieving an average surface inclination estimation error of 2.87 degrees over 9 experiments at different incline angles.

</details>


### [16] [Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation](https://arxiv.org/abs/2602.10717)
*Songen Gu,Yunuo Cai,Tianyu Wang,Simo Wu,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出一个用于快速预测性视频条件动作的框架，通过视频生成模型预测未来状态，结合对抗蒸馏加速生成，并利用生成视频和真实观察训练动作模型来纠正空间误差，从而支持精确的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作系统缺乏预测环境演化的能力，导致操作错误和低效率。虽然视觉语言模型能提供高级指导，但无法显式预测未来状态，而现有世界模型要么只能预测短期，要么产生空间不一致的帧。

Method: 1) 选择并适配鲁棒的视频生成模型以确保可靠的未来预测；2) 应用对抗蒸馏实现快速、少步的视频生成；3) 训练动作模型，利用生成视频和真实观察来纠正空间误差。

Result: 实验表明该方法能产生时间连贯、空间准确的视频预测，直接支持精确操作，在体现一致性、空间指称能力和任务完成度方面显著优于现有基线方法。

Conclusion: 提出的框架通过预测性视频生成有效解决了机器人操作中的环境预测问题，提高了操作的准确性和效率，为机器人操作提供了新的解决方案。

Abstract: Robotic manipulation requires anticipating how the environment evolves in response to actions, yet most existing systems lack this predictive capability, often resulting in errors and inefficiency. While Vision-Language Models (VLMs) provide high-level guidance, they cannot explicitly forecast future states, and existing world models either predict only short horizons or produce spatially inconsistent frames. To address these challenges, we propose a framework for fast and predictive video-conditioned action. Our approach first selects and adapts a robust video generation model to ensure reliable future predictions, then applies adversarial distillation for fast, few-step video generation, and finally trains an action model that leverages both generated videos and real observations to correct spatial errors. Extensive experiments show that our method produces temporally coherent, spatially accurate video predictions that directly support precise manipulation, achieving significant improvements in embodiment consistency, spatial referring ability, and task completion over existing baselines. Codes & Models will be released.

</details>


### [17] [Biomimetic Mantaray robot toward the underwater autonomous -- Experimental verification of swimming and diving by flapping motion -](https://arxiv.org/abs/2602.10904)
*Kenta Tabata,Ryosuke Oku,Jun Ito,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 开发并实验验证了一种仿生蝠鲼机器人，用于水下自主探索，采用扑翼运动推进，减少海底扰动，比传统螺旋桨更高效


<details>
  <summary>Details</summary>
Motivation: 传统螺旋桨推进会扰动海底环境，不适合需要最小干扰的水下应用场景（如水族馆、鱼苗场），需要更高效、生态友好的推进方式

Method: 设计仿蝠鲼机器人，采用伺服电机驱动的胸鳍扑翼运动，流线型控制箱减少流体阻力，基于树莓派3B的控制系统集成IMU和压力传感器进行实时监控和PD控制

Result: 水池实验显示机器人能够实现稳定的游泳和潜水运动，PD控制效果良好，适合需要最小扰动和高效机动性的应用环境

Conclusion: 仿生机器人设计在生态监测和水下探索方面具有潜力，为需要最小环境干扰的应用场景提供了有效的技术解决方案

Abstract: This study presents the development and experimental verification of a biomimetic manta ray robot for underwater autonomous exploration. Inspired by manta rays, the robot uses flapping motion for propulsion to minimize seabed disturbance and enhance efficiency compared to traditional screw propulsion. The robot features pectoral fins driven by servo motors and a streamlined control box to reduce fluid resistance. The control system, powered by a Raspberry Pi 3B, includes an IMU and pressure sensor for real-time monitoring and control. Experiments in a pool assessed the robot's swimming and diving capabilities. Results show stable swimming and diving motions with PD control. The robot is suitable for applications in environments like aquariums and fish nurseries, requiring minimal disturbance and efficient maneuverability. Our findings demonstrate the potential of bio-inspired robotic designs to improve ecological monitoring and underwater exploration.

</details>


### [18] [Safe mobility support system using crowd mapping and avoidance route planning using VLM](https://arxiv.org/abs/2602.10910)
*Sena Saito,Kenta Tabata,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 提出结合视觉语言模型和高斯过程回归的框架，生成动态人群密度地图用于机器人导航


<details>
  <summary>Details</summary>
Motivation: 解决自主移动机器人在动态环境特别是拥挤区域中安全有效导航的挑战，应对劳动力短缺和提高操作效率的需求

Method: 集成视觉语言模型和高斯过程回归，利用VLM识别抽象环境概念（如人群密度），通过GPR进行概率表示，生成动态人群密度地图（抽象地图）

Result: 在大学校园的真实世界试验中，机器人成功生成了避开静态障碍和动态人群的路径，提高了导航安全性和适应性

Conclusion: 提出的框架能够有效生成动态人群密度地图，增强机器人在拥挤动态环境中的导航能力

Abstract: Autonomous mobile robots offer promising solutions for labor shortages and increased operational efficiency. However, navigating safely and effectively in dynamic environments, particularly crowded areas, remains challenging. This paper proposes a novel framework that integrates Vision-Language Models (VLM) and Gaussian Process Regression (GPR) to generate dynamic crowd-density maps (``Abstraction Maps'') for autonomous robot navigation. Our approach utilizes VLM's capability to recognize abstract environmental concepts, such as crowd densities, and represents them probabilistically via GPR. Experimental results from real-world trials on a university campus demonstrated that robots successfully generated routes avoiding both static obstacles and dynamic crowds, enhancing navigation safety and adaptability.

</details>


### [19] [Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces](https://arxiv.org/abs/2602.10961)
*Simone Orelli,Mirko Mizzoni,Antonio Franchi*

Main category: cs.RO

TL;DR: 本文首次为受寄生力影响的浮动刚体系统提供了正式稳定性分析，填补了耦合系统稳定性理论认证的空白。


<details>
  <summary>Details</summary>
Motivation: 标准几何控制依赖力-力矩解耦假设，但在许多空中平台中，控制力矩自然诱导的寄生力会破坏这一假设。虽然已有针对此类耦合系统的实验验证策略，但缺乏严格的理论稳定性认证。

Method: 引入规范模型，构建基于李雅普诺夫函数的证明，建立悬停平衡点的局部指数稳定性。分析明确处理了结构挑战（特别是诱导的非最小相位行为），这些挑战阻碍了标准级联论证的应用。

Result: 首次为受寄生力影响的通用浮动刚体类提供了正式稳定性分析，证明了悬停平衡点的局部指数稳定性。

Conclusion: 该工作填补了耦合系统稳定性理论认证的空白，为受寄生力影响的浮动刚体系统提供了首个正式稳定性分析框架，解决了标准级联论证无法应用的结构挑战。

Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.

</details>


### [20] [RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation](https://arxiv.org/abs/2602.10980)
*Yuhao Chen,Zhihao Zhan,Xiaoxin Lin,Zijian Song,Hao Liu,Qinhan Lyu,Yubo Zu,Xiao Chen,Zhiyuan Liu,Tao Pu,Tianshui Chen,Keze Wang,Liang Lin,Guangrun Wang*

Main category: cs.RO

TL;DR: RADAR是一个用于评估视觉语言动作模型在真实世界条件下泛化能力的新基准，解决了现有评估方法在物理动态、空间推理和自主评估方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型的评估主要局限于模拟或高度受限的真实环境，存在显著的现实差距。现有基准测试存在三个系统性缺陷：1) 未能建模真实世界动态；2) 忽视空间物理智能；3) 缺乏可扩展的完全自主评估方法。

Method: 提出了RADAR基准，包含三个核心组件：1) 物理动态原则性套件；2) 专门测试空间推理和物理理解的任务；3) 基于3D指标的完全自主评估管道，无需人工监督。

Result: 应用RADAR对多个最先进的VLA模型进行审计，发现它们在物理动态下表现严重脆弱：3D IoU从0.261降至0.068（传感器噪声下）。模型的空间推理能力有限。

Conclusion: RADAR是迈向可靠和可泛化的真实世界VLA模型评估的必要基准，揭示了当前模型在真实物理环境中的严重局限性。

Abstract: VLA models have achieved remarkable progress in embodied intelligence; however, their evaluation remains largely confined to simulations or highly constrained real-world settings. This mismatch creates a substantial reality gap, where strong benchmark performance often masks poor generalization in diverse physical environments. We identify three systemic shortcomings in current benchmarking practices that hinder fair and reliable model comparison. (1) Existing benchmarks fail to model real-world dynamics, overlooking critical factors such as dynamic object configurations, robot initial states, lighting changes, and sensor noise. (2) Current protocols neglect spatial--physical intelligence, reducing evaluation to rote manipulation tasks that do not probe geometric reasoning. (3) The field lacks scalable fully autonomous evaluation, instead relying on simplistic 2D metrics that miss 3D spatial structure or on human-in-the-loop systems that are costly, biased, and unscalable. To address these limitations, we introduce RADAR (Real-world Autonomous Dynamics And Reasoning), a benchmark designed to systematically evaluate VLA generalization under realistic conditions. RADAR integrates three core components: (1) a principled suite of physical dynamics; (2) dedicated tasks that explicitly test spatial reasoning and physical understanding; and (3) a fully autonomous evaluation pipeline based on 3D metrics, eliminating the need for human supervision. We apply RADAR to audit multiple state-of-the-art VLA models and uncover severe fragility beneath their apparent competence. Performance drops precipitously under modest physical dynamics, with the expectation of 3D IoU declining from 0.261 to 0.068 under sensor noise. Moreover, models exhibit limited spatial reasoning capability. These findings position RADAR as a necessary bench toward reliable and generalizable real-world evaluation of VLA models.

</details>


### [21] [Scaling World Model for Hierarchical Manipulation Policies](https://arxiv.org/abs/2602.10983)
*Qian Long,Yueze Wang,Jiaxi Song,Junbo Zhang,Peiyan Li,Wenxuan Wang,Yuqi Wang,Haoyang Li,Shaoxuan Xie,Guocai Yao,Hanbo Zhang,Xinlong Wang,Zhongyuan Wang,Xuguang Lan,Huaping Liu,Xinghang Li*

Main category: cs.RO

TL;DR: VISTA是一个分层视觉语言动作框架，使用预训练世界模型进行视觉子任务分解，通过视觉目标图像指导低层策略，显著提升VLA模型在分布外场景的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在分布外场景中表现脆弱，特别是在真实机器人数据有限的情况下，存在泛化瓶颈问题。

Method: 提出分层VLA框架：高层使用预训练世界模型作为规划器，将操作任务分解为带目标图像的子任务序列；低层VLA策略根据文本和视觉指导生成动作序列。

Result: 在大量分布外场景中验证了视觉目标合成和分层VLA策略的有效性，相同结构的VLA在未见场景中的性能从14%提升到69%，明显优于现有基线方法。

Conclusion: 通过世界模型生成的视觉目标图像为低层策略提供了视觉和物理基础细节，使模型能够在未见对象和新场景中实现有效泛化，解决了VLA模型的泛化瓶颈问题。

Abstract: Vision-Language-Action (VLA) models are promising for generalist robot manipulation but remain brittle in out-of-distribution (OOD) settings, especially with limited real-robot data. To resolve the generalization bottleneck, we introduce a hierarchical Vision-Language-Action framework \our{} that leverages the generalization of large-scale pre-trained world model for robust and generalizable VIsual Subgoal TAsk decomposition VISTA. Our hierarchical framework \our{} consists of a world model as the high-level planner and a VLA as the low-level executor. The high-level world model first divides manipulation tasks into subtask sequences with goal images, and the low-level policy follows the textual and visual guidance to generate action sequences. Compared to raw textual goal specification, these synthesized goal images provide visually and physically grounded details for low-level policies, making it feasible to generalize across unseen objects and novel scenarios. We validate both visual goal synthesis and our hierarchical VLA policies in massive out-of-distribution scenarios, and the performance of the same-structured VLA in novel scenarios could boost from 14% to 69% with the guidance generated by the world model. Results demonstrate that our method outperforms previous baselines with a clear margin, particularly in out-of-distribution scenarios. Project page: \href{https://vista-wm.github.io/}{https://vista-wm.github.io}

</details>


### [22] [ContactGaussian-WM: Learning Physics-Grounded World Model from Videos](https://arxiv.org/abs/2602.11021)
*Meizhong Wang,Wanxin Jin,Kun Cao,Lihua Xie,Yiguang Hong*

Main category: cs.RO

TL;DR: ContactGaussian-WM：一种基于可微分物理的刚体世界模型，能从稀疏接触丰富的视频序列中学习复杂物理规律，用于机器人规划与仿真。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数据稀缺和复杂接触丰富动态运动条件下难以准确建模环境，需要开发能直接从稀疏视觉观察中学习物理规律的世界模型。

Method: 提出ContactGaussian-WM框架，包含两个核心组件：1）视觉外观和碰撞几何的统一高斯表示；2）通过闭式物理引擎进行微分以从稀疏视觉观察推断物理属性的端到端可微分学习框架。

Result: 在模拟和真实世界评估中，ContactGaussian-WM在复杂场景学习方面优于现有最先进方法，展现出强大的泛化能力，并在数据合成和实时MPC等下游应用中展示了实用价值。

Conclusion: ContactGaussian-WM为从稀疏视觉数据中学习复杂物理交互提供了有效的可微分物理基础世界模型，在机器人规划和仿真应用中具有重要价值。

Abstract: Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appearance and collision geometry, and (2) an end-to-end differentiable learning framework that differentiates through a closed-form physics engine to infer physical properties from sparse visual observations.Extensive simulations and real-world evaluations demonstrate that ContactGaussian-WM outperforms state-of-the-art methods in learning complex scenarios, exhibiting robust generalization capabilities.Furthermore, we showcase the practical utility of our framework in downstream applications, including data synthesis and real-time MPC.

</details>


### [23] [RISE: Self-Improving Robot Policy with Compositional World Model](https://arxiv.org/abs/2602.11075)
*Jiazhi Yang,Kunyang Lin,Jinwei Li,Wencong Zhang,Tianwei Lin,Longyan Wu,Zhizhong Su,Hao Zhao,Ya-Qin Zhang,Li Chen,Ping Luo,Xiangyu Yue,Hongyang Li*

Main category: cs.RO

TL;DR: RISE框架通过组合世界模型在想象空间中进行机器人强化学习，避免物理交互成本，显著提升接触丰富动态操作任务的性能


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言-动作模型在能力和数据获取方面持续扩展，但在接触丰富和动态操作任务中仍然脆弱，微小的执行偏差可能导致失败。物理世界中的在线强化学习受限于安全风险、硬件成本和环境重置问题。

Method: RISE框架包含组合世界模型：可控动力学模型预测多视角未来，进度价值模型评估想象结果产生信息优势。这些组件集成到闭环自改进管道中，在想象空间生成模拟轨迹、估计优势并更新策略，无需物理交互。

Result: 在三个挑战性真实世界任务中，RISE相比先前方法取得显著改进：动态砖块分拣性能提升超过35%，背包包装提升45%，盒子关闭提升35%。

Conclusion: RISE通过组合世界模型在想象空间进行强化学习，有效解决了物理世界机器人强化学习的安全和成本限制，在动态操作任务中实现了显著性能提升。

Abstract: Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model, and (ii) evaluates imagined outcomes with a progress value model, producing informative advantages for the policy improvement. Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts, estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.

</details>


### [24] [Digging for Data: Experiments in Rock Pile Characterization Using Only Proprioceptive Sensing in Excavation](https://arxiv.org/abs/2602.11082)
*Unal Artan,Martin Magnusson,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 提出一种仅使用轮式装载机挖掘时的本体感知数据来估计碎石堆相对粒径的新方法，通过挖掘过程中的惯性响应推断岩石破碎程度。


<details>
  <summary>Details</summary>
Motivation: 采矿和采石行业中，岩石破碎堆的特征化是基础任务。传统方法依赖外部传感器（如相机或激光雷达），但本研究探索仅使用本体感知数据来估计岩石破碎程度，避免外部传感器的限制。

Method: 采用小波分析构建与岩石破碎程度成比例的特征，通过挖掘不同粒径分布的岩石堆时收集的惯性数据，构建小波特征比率来近似两个岩石堆的平均粒径比率。

Result: 在运营采石场中使用18吨电池电动LHD机器进行了全面挖掘实验，提出的传感方法生成的相对粒径估计与基于视觉的破碎分析工具和筛分采样材料的结果进行了比较。

Conclusion: 研究表明仅使用轮式装载机挖掘时的本体感知数据就能有效估计碎石堆的相对粒径，为岩石破碎特征化提供了一种无需外部传感器的新方法。

Abstract: Characterization of fragmented rock piles is a fundamental task in the mining and quarrying industries, where rock is fragmented by blasting, transported using wheel loaders, and then sent for further processing. This field report studies a novel method for estimating the relative particle size of fragmented rock piles from only proprioceptive data collected while digging with a wheel loader. Rather than employ exteroceptive sensors (e.g., cameras or LiDAR sensors) to estimate rock particle sizes, the studied method infers rock fragmentation from an excavator's inertial response during excavation. This paper expands on research that postulated the use of wavelet analysis to construct a unique feature that is proportional to the level of rock fragmentation. We demonstrate through extensive field experiments that the ratio of wavelet features, constructed from data obtained by excavating in different rock piles with different size distributions, approximates the ratio of the mean particle size of the two rock piles. Full-scale excavation experiments were performed with a battery electric, 18-tonne capacity, load-haul-dump (LHD) machine in representative conditions in an operating quarry. The relative particle size estimates generated with the proposed sensing methodology are compared with those obtained from both a vision-based fragmentation analysis tool and from sieving of sampled materials.

</details>


### [25] [Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows](https://arxiv.org/abs/2602.11142)
*Shaswat Garg,Matin Moezzi,Brandon Da Silva*

Main category: cs.RO

TL;DR: NF-HIQL：一种基于归一化流的分层隐式Q学习框架，用表达能力强的归一化流策略替代传统高斯策略，提升数据效率和策略表达能力，在数据稀缺的长时域任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统分层目标条件强化学习（H-GCRL）在实际应用中面临数据效率低和策略表达能力有限的问题，特别是在离线或数据稀缺的场景下，这限制了其实际应用。

Method: 提出了NF-HIQL框架，在分层结构的高层和低层都使用归一化流策略替代传统的单峰高斯策略。这种设计支持可处理的似然计算、高效采样，并能建模丰富的多模态行为。

Result: 理论方面推导了RealNVP策略的KL散度边界和PAC风格的样本效率结果，证明NF-HIQL在保持稳定性的同时提升泛化能力。实验在运动、运球和多步操作等长时域任务中，NF-HIQL均优于现有目标条件和分层基线方法。

Conclusion: NF-HIQL通过归一化流架构显著提升了分层强化学习的数据效率和可扩展性，在数据受限场景下表现出更强的鲁棒性，展示了流式架构在可扩展、数据高效的分层强化学习中的潜力。

Abstract: Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced. This design enables tractable log-likelihood computation, efficient sampling, and the ability to model rich multimodal behaviors. New theoretical guarantees are derived, including explicit KL-divergence bounds for Real-valued non-volume preserving (RealNVP) policies and PAC-style sample efficiency results, showing that NF-HIQL preserves stability while improving generalization. Empirically, NF-HIQL is evaluted across diverse long-horizon tasks in locomotion, ball-dribbling, and multi-step manipulation from OGBench. NF-HIQL consistently outperforms prior goal-conditioned and hierarchical baselines, demonstrating superior robustness under limited data and highlighting the potential of flow-based architectures for scalable, data-efficient hierarchical reinforcement learning.

</details>
