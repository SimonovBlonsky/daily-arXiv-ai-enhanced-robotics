<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 27]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Dynamic Modeling, Parameter Identification and Numerical Analysis of Flexible Cables in Flexibly Connected Dual-AUV Systems](https://arxiv.org/abs/2602.06087)
*Kuo Chen,Minghao Dou,Qianqi Liu,Yang An,Kai Ren,Zeming WU,Yu Tian,Jie Sun,Xinping Wang,Zhier Chen,Jiancheng Yu*

Main category: cs.RO

TL;DR: 该研究提出了柔性连接双AUV系统的动态建模框架和参数辨识方法，通过集总质量法建立模型，结合实验数据辨识材料和水动力系数，揭示了柔性缆绳在复杂边界条件下的非线性动态特性。


<details>
  <summary>Details</summary>
Motivation: 柔性连接的双AUV系统表现出高度非线性行为，直接测量材料相关参数和水动力系数存在困难，需要建立准确的动态模型来描述系统在不同工况下的响应。

Method: 基于集总质量法建立建模框架，整合轴向弹性、弯曲刚度、附加质量和水动力；提出结合物理模型与实验数据的参数辨识方法，通过多配置张力实验反演等效杨氏模量和水动力系数。

Result: 辨识的模型在各种工况下保持预测一致性；数值分析表明柔性缆绳动态特性具有显著非线性，受材料特性和AUV运动条件影响，产生松弛和拉紧两种典型响应状态。

Conclusion: 揭示了柔性缆绳在复杂边界条件下的动力学特性，为类似系统的设计、优化和控制研究提供了理论基础。

Abstract: This research presents a dynamic modeling framework and parameter identification methods for describing the highly nonlinear behaviors of flexibly connected dual-AUV systems. The modeling framework is established based on the lumped mass method, integrating axial elasticity, bending stiffness, added mass and hydrodynamic forces, thereby accurately capturing the time-varying response of the forces and cable configurations. To address the difficulty of directly measuring material-related and hydrodynamic coefficients, this research proposes a parameter identification method that combines the physical model with experimental data. High-precision inversion of the equivalent Youngs modulus and hydrodynamic coefficients is performed through tension experiments under multiple configurations, effectively demonstrating that the identified model maintains predictive consistency in various operational conditions. Further numerical analysis indicates that the dynamic properties of flexible cable exhibit significant nonlinear characteristics, which are highly dependent on material property variations and AUV motion conditions. This nonlinear dynamic behavior results in two typical response states, slack and taut, which are jointly determined by boundary conditions and hydrodynamic effects, significantly affecting the cable configuration and endpoint loads. In this research, the dynamics of flexible cables under complex boundary conditions is revealed, providing a theoretical foundation for the design, optimization and further control research of similar systems.

</details>


### [2] [Transformer-Based Reinforcement Learning for Autonomous Orbital Collision Avoidance in Partially Observable Environments](https://arxiv.org/abs/2602.06088)
*Thomas Georges,Adam Abdin*

Main category: cs.RO

TL;DR: 本文提出了一个基于Transformer的强化学习框架，用于自主轨道防撞，专门处理空间操作中的部分可观测性和不完善监测问题。


<details>
  <summary>Details</summary>
Motivation: 空间操作中存在部分可观测性和不完善监测的问题，传统方法难以有效处理这些不确定性，需要开发能够更可靠地在不完善监测环境下运行的防撞系统。

Method: 结合可配置的遭遇模拟器、距离依赖观测模型和顺序状态估计器来表示相对运动的不确定性，核心是采用基于Transformer的部分可观测马尔可夫决策过程架构，利用长程时间注意力机制更有效地解释噪声和间歇性观测。

Result: 该框架为训练防撞智能体提供了基础，使其能够在不完善监测环境下更可靠地运行，相比传统架构能更有效地解释噪声和间歇性观测。

Conclusion: 基于Transformer的POMDP架构通过长程时间注意力机制，为自主轨道防撞提供了更有效的解决方案，特别适用于处理空间操作中的部分可观测性和不完善监测问题。

Abstract: We introduce a Transformer-based Reinforcement Learning framework for autonomous orbital collision avoidance that explicitly models the effects of partial observability and imperfect monitoring in space operations. The framework combines a configurable encounter simulator, a distance-dependent observation model, and a sequential state estimator to represent uncertainty in relative motion. A central contribution of this work is the use of transformer-based Partially Observable Markov Decision Process (POMDP) architecture, which leverage long-range temporal attention to interpret noisy and intermittent observations more effectively than traditional architectures. This integration provides a foundation for training collision avoidance agents that can operate more reliably under imperfect monitoring environments.

</details>


### [3] [Active Localization of Unstable Systems with Coarse Information](https://arxiv.org/abs/2602.06191)
*Ege Yuceel,Daniel Liberzon,Sayan Mitra*

Main category: cs.RO

TL;DR: 研究在单比特粗粒度感知下不稳定系统的定位与控制问题，提出基于Voronoi分区的主动定位算法，保证初始状态指数收缩


<details>
  <summary>Details</summary>
Motivation: 研究在极简反馈（单比特感知）下不稳定系统的定位与控制，探索这种最小化反馈带来的基本限制，为机器人定位提供理论见解

Method: 开发主动定位算法，结合基于集合的估计器和从Voronoi分区导出的控制策略，确保智能体保持在信息丰富的区域

Result: 在推导的条件下，提出的方法保证初始状态不确定性的指数收缩，数值实验进一步支持了结果

Conclusion: 该研究为机器人定位提供理论见解，其中感知通常限于关键帧、分割或基于线特征等粗粒度抽象

Abstract: We study localization and control for unstable systems under coarse, single-bit sensing. Motivated by understanding the fundamental limitations imposed by such minimal feedback, we identify sufficient conditions under which the initial state can be recovered despite instability and extremely sparse measurements. Building on these conditions, we develop an active localization algorithm that integrates a set-based estimator with a control strategy derived from Voronoi partitions, which provably estimates the initial state while ensuring the agent remains in informative regions. Under the derived conditions, the proposed approach guarantees exponential contraction of the initial-state uncertainty, and the result is further supported by numerical experiments. These findings can offer theoretical insight into localization in robotics, where sensing is often limited to coarse abstractions such as keyframes, segmentations, or line-based features.

</details>


### [4] [Bioinspired Kirigami Capsule Robot for Minimally Invasive Gastrointestinal Biopsy](https://arxiv.org/abs/2602.06207)
*Ruizhou Zhao,Yichen Chu,Shuwei Zhao,Wenchao Yue,Raymond Shing-Yan Tang,Hongliang Ren*

Main category: cs.RO

TL;DR: Kiri-Capsule是一种受折纸启发的胶囊机器人，通过可展开的PI薄膜瓣实现微创、可重复的组织采集，填补了无线胶囊内窥镜无法进行活检的空白。


<details>
  <summary>Details</summary>
Motivation: 无线胶囊内窥镜(WCE)虽然革新了胃肠道诊断，但缺乏活检能力限制了其诊断价值，因为组织学分析仍是确认疾病的黄金标准。传统活检方法具有侵入性、范围有限且有穿孔或黏膜损伤风险，而现有的液体或微生物采样胶囊无法提供用于病理分析的结构化组织。

Method: 开发了Kiri-Capsule，一种受折纸启发的胶囊机器人，集成了由紧凑双凸轮机构驱动的可展开PI薄膜瓣。折纸表面在移动时保持平坦，但在凸轮驱动拉伸时转变为尖锐突起，实现可控穿透和旋转刮取，标本保留在内部扇形腔中。

Result: 台架测试显示PI薄膜的杨氏模量约为20 MPa，稳定展开角度约34°（15%应变）。离体猪组织研究表明穿透深度较浅（中位数约0.61 mm，范围0.46-0.66 mm），活检产量与标准钳相当（胃平均约10.9 mg，肠道平均约18.9 mg），且作用力在胃肠道活检安全范围内。

Conclusion: Kiri-Capsule填补了被动成像和功能性活检之间的空白，提供了一种可吞咽、深度可控且适合组织学分析的解决方案，将胶囊诊断推向安全有效的临床应用。

Abstract: Wireless capsule endoscopy (WCE) has transformed gastrointestinal (GI) diagnostics by enabling noninvasive visualization of the digestive tract, yet its diagnostic yield remains constrained by the absence of biopsy capability, as histological analysis is still the gold standard for confirming disease. Conventional biopsy using forceps, needles, or rotating blades is invasive, limited in reach, and carries risks of perforation or mucosal trauma, while fluid- or microbiota-sampling capsules cannot provide structured tissue for pathology, leaving a critical gap in swallowable biopsy solutions. Here we present the Kiri-Capsule, a kirigami-inspired capsule robot that integrates deployable PI-film flaps actuated by a compact dual-cam mechanism to achieve minimally invasive and repeatable tissue collection. The kirigami surface remains flat during locomotion but transforms into sharp protrusions upon cam-driven stretching, enabling controlled penetration followed by rotary scraping, with specimens retained in internal fan-shaped cavities. Bench tests confirmed that PI films exhibit a Young's modulus of approximately 20 MPa and stable deployment angles (about 34$^\circ$ at 15% strain), while ex vivo porcine studies demonstrated shallow penetration depths (median $\sim$0.61 mm, range 0.46--0.66 mm) and biopsy yields comparable to standard forceps (mean $\sim$10.9 mg for stomach and $\sim$18.9 mg for intestine), with forces within safe ranges reported for GI biopsy. These findings demonstrate that the Kiri-Capsule bridges passive imaging and functional biopsy, providing a swallowable, depth-controlled, and histology-ready solution that advances capsule-based diagnostics toward safe and effective clinical application.

</details>


### [5] [MORPH Wheel: A Passive Variable-Radius Wheel Embedding Mechanical Behavior Logic for Input-Responsive Transformation](https://arxiv.org/abs/2602.06265)
*JaeHyung Jang,JuYeong Seo,Dae-Young Lee,Jee-Hwan Ryu*

Main category: cs.RO

TL;DR: MORPH轮是一种完全被动的可变半径轮，通过机械结构实现扭矩响应式半径调整，无需电子元件，在80-45mm范围内自适应变化。


<details>
  <summary>Details</summary>
Motivation: 传统可变传动系统依赖执行器、传感器和主动控制，而MORPH轮旨在通过纯机械结构实现被动自适应，为不可预测或控制受限环境中的机器人移动系统提供新的被动可变传动范式。

Method: 设计集成了扭矩响应耦合器和弹簧加载连接支柱，通过几何结构和柔性结构实现被动适应。开发了全面的分析模型来描述机械行为逻辑，建立模式切换的阈值条件。

Result: 实验验证显示测量的扭矩-半径和力-位移特性与理论预测高度一致。机器人级演示验证了MORPH轮能在不同负载、坡度和非结构化地形下被动调整半径提供最优传动比。

Conclusion: MORPH轮展示了机械编程结构的概念，将智能、上下文相关行为直接嵌入物理设计中，为机器人移动系统的被动可变传动和机械智能提供了新范式。

Abstract: This paper introduces the Mechacnially prOgrammed Radius-adjustable PHysical (MORPH) wheel, a fully passive variable-radius wheel that embeds mechanical behavior logic for torque-responsive transformation. Unlike conventional variable transmission systems relying on actuators, sensors, and active control, the MORPH wheel achieves passive adaptation solely through its geometry and compliant structure. The design integrates a torque-response coupler and spring-loaded connecting struts to mechanically adjust the wheel radius between 80 mm and 45 mm in response to input torque, without any electrical components. The MORPH wheel provides three unique capabilities rarely achieved simultaneously in previous passive designs: (1) bidirectional operation with unlimited rotation through a symmetric coupler; (2) high torque capacity exceeding 10 N with rigid power transmission in drive mode; and (3) precise and repeatable transmission ratio control governed by deterministic kinematics. A comprehensive analytical model was developed to describe the wheel's mechanical behavior logic, establishing threshold conditions for mode switching between direct drive and radius transformation. Experimental validation confirmed that the measured torque-radius and force-displacement characteristics closely follow theoretical predictions across wheel weights of 1.8-2.8kg. Robot-level demonstrations on varying loads (0-25kg), slopes, and unstructured terrains further verified that the MORPH wheel passively adjusts its radius to provide optimal transmission ratio. The MORPH wheel exemplifies a mechanically programmed structure, embedding intelligent, context-dependent behavior directly into its physical design. This approach offers a new paradigm for passive variable transmission and mechanical intelligence in robotic mobility systems operating in unpredictable or control-limited environments.

</details>


### [6] [Robots That Generate Planarity Through Geometry](https://arxiv.org/abs/2602.06294)
*Jakub F. Kowalewski,Abdulaziz O. Alrashed,Jacob Alpert,Rishi Ponnapalli,Lucas R. Meza,Jeffrey Ian Lipton*

Main category: cs.RO

TL;DR: 利用球体到平面的几何反演原理，开发出仅依赖连杆长度和连接性就能实现平面运动的机器人系统，无需外部测量即可获得平面性。


<details>
  <summary>Details</summary>
Motivation: 传统精密机器人运动系统（如龙门架）依赖导轨、花岗岩平台等组件的平面度，但将静态平面度转化为运动需要精确的内部对齐和公差严格的组件，形成长且误差敏感的参考链。

Method: 通过球体到平面的几何反演原理，设计出平面运动机制（FPMs），使平面运动完全从连杆长度和连接性中产生，基于自参考几何约束实现平面性，无需外部测量。

Result: 从微米到米尺度演示了FPMs，显示制造误差在最终平面度中可被衰减一个数量级；开发了基于FPM的3轴定位机器人系统，可用于窄容器内的计量表面扫描（±12mm）和3D打印。

Conclusion: 这项工作为平面运动建立了替代的几何基础，可在不同尺寸尺度实现，为计量、制造和微定位开辟了新可能性。

Abstract: Constraining motion to a flat surface is a fundamental requirement for equipment across science and engineering. Modern precision robotic motion systems, such as gantries, rely on the flatness of components, including guide rails and granite surface plates. However, translating this static flatness into motion requires precise internal alignment and tight-tolerance components that create long, error-sensitive reference chains. Here, we show that by using the geometric inversion of a sphere into a plane, we can produce robotic motion systems that derive planarity entirely from link lengths and connectivity. This allows planar motion to emerge from self-referencing geometric constraints, and without external metrology. We demonstrate these Flat-Plane Mechanisms (FPMs) from micron to meter scales and show that fabrication errors can be attenuated by an order of magnitude in the resulting flatness. Finally, we present a robotic FPM-based 3-axis positioning system that can be used for metrology surface scans ($\pm 12$-mm) and 3D printing inside narrow containers. This work establishes an alternative geometric foundation for planar motion that can be realized across size scales and opens new possibilities in metrology, fabrication, and micro-positioning.

</details>


### [7] [Internalized Morphogenesis: A Self-Organizing Model for Growth, Replication, and Regeneration via Local Token Exchange in Modular Systems](https://arxiv.org/abs/2602.06296)
*Takeshi Ishida*

Main category: cs.RO

TL;DR: 提出了一种用于自主系统的内部化形态发生模型，通过模块间局部交互实现复杂形态生成，无需外部空间计算，适用于资源受限的物理模块。


<details>
  <summary>Details</summary>
Motivation: 传统自组织模型需要在整个坐标空间进行计算，包括空区域，这对资源受限的物理模块不切实际。需要一种仅通过内部局部交互就能实现复杂形态发生的模型。

Method: 扩展"Ishida token模型"，模块间通过RD启发的离散模拟交换整数值，无需求解微分方程。利用令牌积累和老化产生的内部电势引导自主生长、收缩和复制。使用身体边界作为信息熵（令牌）的自然汇来维持动态平衡。

Result: 在六边形网格上的模拟展示了肢体样延伸、自我分裂和结构截肢后的鲁棒再生能力。复杂形态行为可以从最小化的、仅内部规则中涌现。

Conclusion: 该框架提供了一种计算高效且生物学上合理的方法来开发自修复、自适应和自主的硬件系统，表明复杂形态行为可以从内部局部规则中涌现。

Abstract: This study presents an internalized morphogenesis model for autonomous systems, such as swarm robotics and micro-nanomachines, that eliminates the need for external spatial computation. Traditional self-organizing models often require calculations across the entire coordinate space, including empty areas, which is impractical for resource-constrained physical modules. Our proposed model achieves complex morphogenesis through strictly local interactions between adjacent modules within the "body." By extending the "Ishida token model," modules exchange integer values using an RD-inspired discrete analogue without solving differential equations. The internal potential, derived from token accumulation and aging, guides autonomous growth, shrinkage, and replication. Simulations on a hexagonal grid demonstrated the emergence of limb-like extensions, self-division, and robust regeneration capabilities following structural amputation. A key feature is the use of the body boundary as a natural sink for information entropy (tokens) to maintain a dynamic equilibrium. These results indicate that sophisticated morphological behaviors can emerge from minimal, internal-only rules. This framework offers a computationally efficient and biologically plausible approach to developing self-repairing, adaptive, and autonomous hardware.

</details>


### [8] [Action Hallucination in Generative Visual-Language-Action Models](https://arxiv.org/abs/2602.06339)
*Harold Soh,Eugene Lim*

Main category: cs.RO

TL;DR: 本文分析机器人基础模型中的动作幻觉问题，探讨其如何违反物理约束并扩展到规划层面失败，揭示了生成式机器人策略的固有局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言-动作模型等机器人基础模型在策略训练和部署方面取得了显著进展，但尚不清楚它们是否真正解决了机器人学的长期挑战。本文旨在分析这些模型中存在的动作幻觉问题及其对规划可靠性的影响。

Method: 聚焦于潜在变量生成策略，分析动作幻觉产生的结构原因。研究三种主要障碍：拓扑障碍、精度障碍和时域障碍，并展示这些障碍如何导致不可避免的权衡。

Result: 研究发现动作幻觉通常源于可行机器人行为与常见模型架构之间的结构不匹配。这些结构性障碍解释了已报道的生成式机器人策略的实证失败案例。

Conclusion: 分析为生成式机器人策略的可靠性问题提供了机制性解释，并指出了在不牺牲表达能力的条件下提高可靠性和可信度的原则性方向。

Abstract: Robot Foundation Models such as Vision-Language-Action models are rapidly reshaping how robot policies are trained and deployed, replacing hand-designed planners with end-to-end generative action models. While these systems demonstrate impressive generalization, it remains unclear whether they fundamentally resolve the long-standing challenges of robotics. We address this question by analyzing action hallucinations that violate physical constraints and their extension to plan-level failures. Focusing on latent-variable generative policies, we show that hallucinations often arise from structural mismatches between feasible robot behavior and common model architectures. We study three such barriers -- topological, precision, and horizon -- and show how they impose unavoidable tradeoffs. Our analysis provides mechanistic explanations for reported empirical failures of generative robot policies and suggests principled directions for improving reliability and trustworthiness, without abandoning their expressive power.

</details>


### [9] [HiWET: Hierarchical World-Frame End-Effector Tracking for Long-Horizon Humanoid Loco-Manipulation](https://arxiv.org/abs/2602.06341)
*Zhanxiang Cao,Liyun Yan,Yang Zhang,Sirui Chen,Jianming Ma,Tianyue Zhan,Shengcheng Fu,Yufei Jia,Cewu Lu,Yue Gao*

Main category: cs.RO

TL;DR: HiWET：一种分层强化学习框架，通过解耦全局推理与动态执行，实现人形机器人在世界坐标系下的精确末端执行器跟踪与稳定运动控制。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人运动操作方法通常在机体坐标系中制定命令，无法固有地纠正由腿部运动引起的世界坐标系累积漂移，这限制了长期精确操作任务的性能。

Method: 提出HiWET分层强化学习框架：高层策略在世界坐标系中生成同时优化末端执行器精度和基座定位的子目标；低层策略在稳定性约束下执行这些命令。引入运动学流形先验（KMP），通过残差学习将操作流形嵌入动作空间，减少探索维度并避免运动学无效行为。

Result: 广泛的仿真和消融研究表明，HiWET在长期世界坐标系任务中实现了精确稳定的末端执行器跟踪。在物理人形机器人上验证了低层策略的零样本仿真到现实迁移，展示了在不同操作命令下的稳定运动。

Conclusion: 显式的世界坐标系推理与分层控制相结合，为长期人形机器人运动操作提供了有效且可扩展的解决方案。

Abstract: Humanoid loco-manipulation requires executing precise manipulation tasks while maintaining dynamic stability amid base motion and impacts. Existing approaches typically formulate commands in body-centric frames, fail to inherently correct cumulative world-frame drift induced by legged locomotion. We reformulate the problem as world-frame end-effector tracking and propose HiWET, a hierarchical reinforcement learning framework that decouples global reasoning from dynamic execution. The high-level policy generates subgoals that jointly optimize end-effector accuracy and base positioning in the world frame, while the low-level policy executes these commands under stability constraints. We introduce a Kinematic Manifold Prior (KMP) that embeds the manipulation manifold into the action space via residual learning, reducing exploration dimensionality and mitigating kinematically invalid behaviors. Extensive simulation and ablation studies demonstrate that HiWET achieves precise and stable end-effector tracking in long-horizon world-frame tasks. We validate zero-shot sim-to-real transfer of the low-level policy on a physical humanoid, demonstrating stable locomotion under diverse manipulation commands. These results indicate that explicit world-frame reasoning combined with hierarchical control provides an effective and scalable solution for long-horizon humanoid loco-manipulation.

</details>


### [10] [Nipping the Drift in the Bud: Retrospective Rectification for Robust Vision-Language Navigation](https://arxiv.org/abs/2602.06356)
*Gang He,Zhenyang Liu,Kepeng Xu,Li Xu,Tong Qiao,Wenxin Yu,Chang Wu,Weiying Xie*

Main category: cs.RO

TL;DR: BudVLN框架通过反事实重锚定和决策条件监督合成，解决VLN中指令-状态错位问题，在R2R-CE和RxR-CE基准上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法存在暴露偏差问题，而DAgger式方法虽然尝试纠正错误状态，但存在指令-状态错位的核心限制：从偏离轨道的状态学习恢复动作会产生与原始指令语义冲突的监督信号

Method: BudVLN是一个在线框架，通过反事实重锚定和决策条件监督合成来构建与当前状态分布匹配的监督信号。使用测地线预言机从有效历史状态合成纠正轨迹，确保语义一致性

Result: 在标准R2R-CE和RxR-CE基准测试中，BudVLN持续缓解分布偏移，在成功率和SPL指标上都达到了最先进的性能

Conclusion: BudVLN通过解决指令-状态错位问题，为VLN任务提供了一种有效的在线学习框架，能够更好地处理分布偏移并提升导航性能

Abstract: Vision-Language Navigation (VLN) requires embodied agents to interpret natural language instructions and navigate through complex continuous 3D environments. However, the dominant imitation learning paradigm suffers from exposure bias, where minor deviations during inference lead to compounding errors. While DAgger-style approaches attempt to mitigate this by correcting error states, we identify a critical limitation: Instruction-State Misalignment. Forcing an agent to learn recovery actions from off-track states often creates supervision signals that semantically conflict with the original instruction. In response to these challenges, we introduce BudVLN, an online framework that learns from on-policy rollouts by constructing supervision to match the current state distribution. BudVLN performs retrospective rectification via counterfactual re-anchoring and decision-conditioned supervision synthesis, using a geodesic oracle to synthesize corrective trajectories that originate from valid historical states, ensuring semantic consistency. Experiments on the standard R2R-CE and RxR-CE benchmarks demonstrate that BudVLN consistently mitigates distribution shift and achieves state-of-the-art performance in both Success Rate and SPL.

</details>


### [11] [Towards Adaptive Environment Generation for Training Embodied Agents](https://arxiv.org/abs/2602.06366)
*Teresa Yeo,Dulaj Weerakoon,Dulanga Weerakoon,Archan Misra*

Main category: cs.RO

TL;DR: 提出了一个闭环环境生成的概念验证系统，通过根据智能体当前能力调整难度来提升学习效率和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成训练环境时采用开环范式，不考虑智能体当前表现，导致生成的环境可能过于简单或无效，无法提供有效的学习信号

Method: 使用可控环境表示，提取超越二元成功/失败的细粒度性能反馈，并实现闭环适应机制将反馈转化为环境修改

Result: 反馈驱动方法生成更具挑战性的训练环境，针对智能体需要改进的方面，实现更高效的学习和更好的泛化能力

Conclusion: 闭环环境生成能够根据智能体能力动态调整难度，相比开环方法能更有效地促进智能体学习，提升对新环境的泛化性能

Abstract: Embodied agents struggle to generalize to new environments, even when those environments share similar underlying structures to their training settings. Most current approaches to generating these training environments follow an open-loop paradigm, without considering the agent's current performance. While procedural generation methods can produce diverse scenes, diversity without feedback from the agent is inefficient. The generated environments may be trivially easy, providing limited learning signal. To address this, we present a proof-of-concept for closed-loop environment generation that adapts difficulty to the agent's current capabilities. Our system employs a controllable environment representation, extracts fine-grained performance feedback beyond binary success or failure, and implements a closed-loop adaptation mechanism that translates this feedback into environment modifications. This feedback-driven approach generates training environments that more challenging in the ways the agent needs to improve, enabling more efficient learning and better generalization to novel settings.

</details>


### [12] [A Consistency-Improved LiDAR-Inertial Bundle Adjustment](https://arxiv.org/abs/2602.06380)
*Xinran Li,Shuaikang Zheng,Pengcheng Zheng,Xinyang Wang,Jiacheng Li,Zhitian Li,Xudong Zou*

Main category: cs.RO

TL;DR: 提出了一种改进一致性的激光雷达-惯性束调整方法，通过立体投影表示参数化平面和边缘特征，并使用MAP和FEJ保持准确的协方差估计和可观测性


<details>
  <summary>Details</summary>
Motivation: 基于特征的SLAM系统虽然取得了显著成果，但常因特征参数化和协方差估计不一致而导致估计器不一致的问题

Method: 1) 提出立体投影表示法参数化平面和边缘特征；2) 进行全面的可观测性分析；3) 实现基于MAP和FEJ的激光雷达-惯性束调整；4) 将方法应用于激光雷达-惯性里程计

Result: 该方法通过改进的参数化和一致的估计器，提高了激光雷达-惯性系统的估计一致性，保持了准确的协方差估计和系统可观测性

Conclusion: 提出的改进一致性激光雷达-惯性束调整方法通过立体投影表示和FEJ技术，有效解决了传统特征参数化带来的估计不一致问题

Abstract: Simultaneous Localization and Mapping (SLAM) using 3D LiDAR has emerged as a cornerstone for autonomous navigation in robotics. While feature-based SLAM systems have achieved impressive results by leveraging edge and planar structures, they often suffer from the inconsistent estimator associated with feature parameterization and estimated covariance. In this work, we present a consistency-improved LiDAR-inertial bundle adjustment (BA) with tailored parameterization and estimator. First, we propose a stereographic-projection representation parameterizing the planar and edge features, and conduct a comprehensive observability analysis to support its integrability with consistent estimator. Second, we implement a LiDAR-inertial BA with Maximum a Posteriori (MAP) formulation and First-Estimate Jacobians (FEJ) to preserve the accurate estimated covariance and observability properties of the system. Last, we apply our proposed BA method to a LiDAR-inertial odometry.

</details>


### [13] [Now You See That: Learning End-to-End Humanoid Locomotion from Raw Pixels](https://arxiv.org/abs/2602.06382)
*Wandong Sun,Yongbo Su,Leoric Huang,Alex Zhang,Dwyane Wei,Mu San,Daniel Tian,Ellie Cao,Finn Yan,Ethan Xie,Zongwu Xie*

Main category: cs.RO

TL;DR: 提出端到端视觉驱动人形机器人运动框架，通过高保真深度传感器模拟解决仿真到真实世界的差距，结合视觉感知行为蒸馏和多地形奖励塑造，实现跨多种地形的鲁棒运动控制。


<details>
  <summary>Details</summary>
Motivation: 视觉驱动的人形机器人运动面临两大挑战：1) 仿真到真实世界的差距导致感知噪声影响精细任务性能；2) 跨多样地形训练统一策略时存在学习目标冲突。需要同时解决感知鲁棒性和地形适应性。

Method: 1) 开发高保真深度传感器模拟，捕捉真实立体匹配伪影和校准不确定性；2) 提出视觉感知行为蒸馏方法，结合潜在空间对齐和噪声不变辅助任务；3) 引入地形特定奖励塑造，集成多批评器和多判别器学习，为不同地形类型捕获动态特性和运动先验。

Result: 在两个配备不同立体深度相机的人形机器人平台上验证，策略在多样环境中表现出鲁棒性能，能无缝处理极端挑战（如高平台和宽间隙）以及精细任务（包括双向长期楼梯穿越）。

Conclusion: 该端到端框架通过解决感知鲁棒性和地形适应性两大核心问题，实现了视觉驱动人形机器人在复杂环境中的鲁棒运动控制，为实际应用提供了有效解决方案。

Abstract: Achieving robust vision-based humanoid locomotion remains challenging due to two fundamental issues: the sim-to-real gap introduces significant perception noise that degrades performance on fine-grained tasks, and training a unified policy across diverse terrains is hindered by conflicting learning objectives. To address these challenges, we present an end-to-end framework for vision-driven humanoid locomotion. For robust sim-to-real transfer, we develop a high-fidelity depth sensor simulation that captures stereo matching artifacts and calibration uncertainties inherent in real-world sensing. We further propose a vision-aware behavior distillation approach that combines latent space alignment with noise-invariant auxiliary tasks, enabling effective knowledge transfer from privileged height maps to noisy depth observations. For versatile terrain adaptation, we introduce terrain-specific reward shaping integrated with multi-critic and multi-discriminator learning, where dedicated networks capture the distinct dynamics and motion priors of each terrain type. We validate our approach on two humanoid platforms equipped with different stereo depth cameras. The resulting policy demonstrates robust performance across diverse environments, seamlessly handling extreme challenges such as high platforms and wide gaps, as well as fine-grained tasks including bidirectional long-term staircase traversal.

</details>


### [14] [ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking](https://arxiv.org/abs/2602.06445)
*Weidong Huang,Jingwen Zhang,Jiongye Li,Shibowen Zhang,Jiayang Wu,Jiayi Wang,Hangxin Liu,Yaodong Yang,Yao Su*

Main category: cs.RO

TL;DR: ECO是一个约束强化学习框架，通过将能量相关指标从奖励函数中分离出来，重新表述为显式不等式约束，实现了人形机器人稳定、对称且节能的行走。


<details>
  <summary>Details</summary>
Motivation: 现有MPC和RL方法通常将能量相关指标嵌入多目标优化框架中，需要大量超参数调优且往往产生次优策略。为了解决这些问题，需要一种更清晰、可解释的能量成本物理表示方法。

Method: ECO提出约束RL框架，将能量消耗和参考运动作为专门约束，使用拉格朗日方法强制执行，实现稳定、对称且节能的人形机器人行走。

Result: 与MPC、标准RL奖励塑形以及四种最先进的约束RL方法相比，ECO在保持稳健行走性能的同时显著降低了能量消耗，在sim-to-sim和sim-to-real实验中验证了其有效性。

Conclusion: ECO框架在人形机器人节能运动方面取得了实质性进展，提供了一种更高效、直观的超参数调优方法，实现了稳定且节能的行走性能。

Abstract: Achieving stable and energy-efficient locomotion is essential for humanoid robots to operate continuously in real-world applications. Existing MPC and RL approaches often rely on energy-related metrics embedded within a multi-objective optimization framework, which require extensive hyperparameter tuning and often result in suboptimal policies. To address these challenges, we propose ECO (Energy-Constrained Optimization), a constrained RL framework that separates energy-related metrics from rewards, reformulating them as explicit inequality constraints. This method provides a clear and interpretable physical representation of energy costs, enabling more efficient and intuitive hyperparameter tuning for improved energy efficiency. ECO introduces dedicated constraints for energy consumption and reference motion, enforced by the Lagrangian method, to achieve stable, symmetric, and energy-efficient walking for humanoid robots. We evaluated ECO against MPC, standard RL with reward shaping, and four state-of-the-art constrained RL methods. Experiments, including sim-to-sim and sim-to-real transfers on the kid-sized humanoid robot BRUCE, demonstrate that ECO significantly reduces energy consumption compared to baselines while maintaining robust walking performance. These results highlight a substantial advancement in energy-efficient humanoid locomotion. All experimental demonstrations can be found on the project website: https://sites.google.com/view/eco-humanoid.

</details>


### [15] [MultiGraspNet: A Multitask 3D Vision Model for Multi-gripper Robotic Grasping](https://arxiv.org/abs/2602.06504)
*Stephany Ortuno-Chanelo,Paolo Rabino,Enrico Civitelli,Tatiana Tommasi,Raffaello Camoriano*

Main category: cs.RO

TL;DR: MultiGraspNet是一个多任务3D深度学习模型，能够同时预测平行夹爪和真空吸盘的可行抓取位姿，使单个机器人能够处理多种末端执行器。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法存在局限性：要么只针对单一夹爪，要么依赖需要专门学习程序的定制混合夹爪，逻辑无法跨任务迁移，限制了通用性。

Method: 提出MultiGraspNet多任务3D深度学习框架，在统一框架内同时预测平行夹爪和真空吸盘的可行抓取位姿。模型在GraspNet-1Billion和SuctionNet-1Billion数据集上训练，共享早期特征但保持夹爪特定的细化器，生成抓取性掩码量化每个场景点的抓取适宜性。

Result: 在相关基准测试中与单任务模型竞争力相当。真实世界实验中，在单臂多夹爪机器人设置上，真空任务比基线多抓取16%的已知物体和32%的新物体，平行夹爪任务也获得有竞争力的结果。

Conclusion: MultiGraspNet通过统一框架有效利用不同抓取模式的互补信息，增强了杂乱场景中的鲁棒性和适应性，为多夹爪机器人系统提供了实用的解决方案。

Abstract: Vision-based models for robotic grasping automate critical, repetitive, and draining industrial tasks. Existing approaches are typically limited in two ways: they either target a single gripper and are potentially applied on costly dual-arm setups, or rely on custom hybrid grippers that require ad-hoc learning procedures with logic that cannot be transferred across tasks, restricting their general applicability. In this work, we present MultiGraspNet, a novel multitask 3D deep learning method that predicts feasible poses simultaneously for parallel and vacuum grippers within a unified framework, enabling a single robot to handle multiple end effectors. The model is trained on the richly annotated GraspNet-1Billion and SuctionNet-1Billion datasets, which have been aligned for the purpose, and generates graspability masks quantifying the suitability of each scene point for successful grasps. By sharing early-stage features while maintaining gripper-specific refiners, MultiGraspNet effectively leverages complementary information across grasping modalities, enhancing robustness and adaptability in cluttered scenes. We characterize MultiGraspNet's performance with an extensive experimental analysis, demonstrating its competitiveness with single-task models on relevant benchmarks. We run real-world experiments on a single-arm multi-gripper robotic setup showing that our approach outperforms the vacuum baseline, grasping 16% percent more seen objects and 32% more of the novel ones, while obtaining competitive results for the parallel task.

</details>


### [16] [World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy](https://arxiv.org/abs/2602.06508)
*Xiaokang Liu,Zechen Bai,Hai Ci,Kevin Yuchen Ma,Mike Zheng Shou*

Main category: cs.RO

TL;DR: World-VLA-Loop是一个闭环框架，通过联合优化世界模型和视觉-语言-动作策略，解决视频扩散世界模型动作跟随精度不足的问题，实现虚拟环境中的强化学习后训练。


<details>
  <summary>Details</summary>
Motivation: 当前基于视频扩散变换器的机器人世界模型虽然能预测逼真的视觉结果，但动作跟随精度较差，限制了其在机器人学习中的应用。

Method: 提出状态感知视频世界模型作为高保真交互模拟器，联合预测未来观察和奖励信号；引入SANS数据集包含接近成功的轨迹以改善动作-结果对齐；建立闭环框架，将VLA策略的失败轨迹反馈给世界模型进行迭代优化。

Result: 在模拟和真实世界任务中的评估表明，该框架显著提升了VLA性能，仅需最少的物理交互，建立了世界建模与策略学习之间的互利关系。

Conclusion: World-VLA-Loop框架通过世界模型和VLA策略的协同进化，为通用机器人建立了世界建模与策略学习之间的良性循环，实现了高效的虚拟环境训练。

Abstract: Recent progress in robotic world models has leveraged video diffusion transformers to predict future observations conditioned on historical states and actions. While these models can simulate realistic visual outcomes, they often exhibit poor action-following precision, hindering their utility for downstream robotic learning. In this work, we introduce World-VLA-Loop, a closed-loop framework for the joint refinement of world models and Vision-Language-Action (VLA) policies. We propose a state-aware video world model that functions as a high-fidelity interactive simulator by jointly predicting future observations and reward signals. To enhance reliability, we introduce the SANS dataset, which incorporates near-success trajectories to improve action-outcome alignment within the world model. This framework enables a closed-loop for reinforcement learning (RL) post-training of VLA policies entirely within a virtual environment. Crucially, our approach facilitates a co-evolving cycle: failure rollouts generated by the VLA policy are iteratively fed back to refine the world model precision, which in turn enhances subsequent RL optimization. Evaluations across simulation and real-world tasks demonstrate that our framework significantly boosts VLA performance with minimal physical interaction, establishing a mutually beneficial relationship between world modeling and policy learning for general-purpose robotics. Project page: https://showlab.github.io/World-VLA-Loop/.

</details>


### [17] [Beyond the Majority: Long-tail Imitation Learning for Robotic Manipulation](https://arxiv.org/abs/2602.06512)
*Junhong Zhu,Ji Zhang,Jingkuan Song,Lianli Gao,Heng Tao Shen*

Main category: cs.RO

TL;DR: 该论文针对机器人模仿学习中普遍存在的长尾分布问题，分析了传统长尾学习策略的局限性，并提出了一种无需外部演示的知识迁移方法APA来提升尾任务性能。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略通过模仿学习掌握多样化操作技能具有巨大潜力，但训练数据的长尾分布严重制约了其性能。数据丰富的头部任务占据了大部分训练样本，而大量数据稀缺的尾任务导致策略在这些任务上泛化能力差，这是当前机器人模仿学习面临的核心挑战。

Method: 论文首先分析了传统长尾学习策略（如重采样）在机器人策略学习中的局限性。研究发现数据稀缺直接损害了策略的空间推理能力。为此，作者提出了Approaching-Phase Augmentation (APA)方法，该方法通过从数据丰富的头部任务向数据稀缺的尾任务转移知识，无需外部演示即可增强尾任务的性能。

Result: 在模拟和真实世界操作任务上的大量实验表明，APA方法能有效提升策略在尾任务上的性能。该方法成功解决了长尾分布带来的挑战，验证了知识迁移策略的有效性。

Conclusion: 该研究系统分析了机器人模仿学习中的长尾分布问题，揭示了传统长尾学习策略失效的根本原因，并提出了一种简单有效的APA方法，通过知识迁移显著提升了策略在数据稀缺尾任务上的性能，为解决机器人学习中的长尾挑战提供了新思路。

Abstract: While generalist robot policies hold significant promise for learning diverse manipulation skills through imitation, their performance is often hindered by the long-tail distribution of training demonstrations. Policies learned on such data, which is heavily skewed towards a few data-rich head tasks, frequently exhibit poor generalization when confronted with the vast number of data-scarce tail tasks. In this work, we conduct a comprehensive analysis of the pervasive long-tail challenge inherent in policy learning. Our analysis begins by demonstrating the inefficacy of conventional long-tail learning strategies (e.g., re-sampling) for improving the policy's performance on tail tasks. We then uncover the underlying mechanism for this failure, revealing that data scarcity on tail tasks directly impairs the policy's spatial reasoning capability. To overcome this, we introduce Approaching-Phase Augmentation (APA), a simple yet effective scheme that transfers knowledge from data-rich head tasks to data-scarce tail tasks without requiring external demonstrations. Extensive experiments in both simulation and real-world manipulation tasks demonstrate the effectiveness of APA. Our code and demos are publicly available at: https://mldxy.github.io/Project-VLA-long-tail/.

</details>


### [18] [Primary Experimental Feedback on a Co-manipulated Robotic System for Assisted Cervical Surgery](https://arxiv.org/abs/2602.06541)
*Seifeddine Sellemi,Abdelbadia Chaker,Tanguy Vendeuvre,Terence Essomba,Med Amine Laribi*

Main category: cs.RO

TL;DR: 研究评估了协作机器人系统在颈椎手术钻孔任务中的性能，通过测量14次钻孔操作中工具相对于预定轨迹的偏差，量化了系统的位置和方向精度。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术在改善手术人体工程学、精度和工作流程效率方面具有潜力，特别是在颈椎手术等复杂手术中。本研究旨在评估协作机器人系统在钻孔任务中的准确性，为系统集成到临床实践提供关键数据。

Method: 8名经验丰富的颈椎外科医生使用机器人辅助设置进行了14次钻孔操作。研究量化了钻孔工具相对于预定轨迹的位置和方向偏差，重点关注实验设置和误差评估方法。

Result: 研究提供了机器人系统在钻孔任务中位置和方向偏差的量化数据，分析了系统的可靠性和对临床结果的影响。虽然机器人辅助的主要功能是增强外科医生舒适度和程序指导，但精度评估对系统有效集成至关重要。

Conclusion: 该研究为机器人辅助颈椎手术的持续发展提供了重要反馈，突出了其优势和改进领域，有助于实现更安全、更高效的手术工作流程。

Abstract: Robotic-assisted surgery has emerged as a promising approach to improve surgical ergonomics, precision, and workflow efficiency, particularly in complex procedures such as cervical spine surgery. In this study, we evaluate the performance of a collaborative robotic system designed to assist surgeons in drilling tasks by assessing its accuracy in executing predefined trajectories. A total of 14 drillings were performed by eight experienced cervical surgeons, utilizing a robotic-assisted setup aimed at ensuring stability and alignment. The primary objective of this study is to quantify the deviations in the position and orientation of the drilling tool relative to the planned trajectory, providing insights into the system's reliability and potential impact on clinical outcomes. While the primary function of robotic assistance in surgery is to enhance surgeon comfort and procedural guidance rather than solely optimizing precision, understanding the system's accuracy remains crucial for its effective integration into surgical practices part of this primary experimental feedback, the study offers an in-depth analysis of the co-manipulated robotic system's performance, focusing on the experimental setup and error evaluation methods. The findings of this study will contribute to the ongoing development of robotic-assisted cervical surgery, highlighting both its advantages and areas for improvement in achieving safer and more efficient surgical workflows

</details>


### [19] [Think Proprioceptively: Embodied Visual Reasoning for VLA Manipulation](https://arxiv.org/abs/2602.06575)
*Fangyuan Wang,Peng Zhou,Jiaming Qi,Shipeng Lyu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: ThinkProprio是一种新的视觉-语言-动作模型，通过将本体感觉转换为文本标记并与任务指令早期融合，让机器人状态参与视觉推理和标记选择，减少冗余视觉标记，提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常将本体感觉作为后期条件信号注入，这限制了机器人状态对指令理解和视觉标记注意力分布的影响。需要一种方法让机器人状态更早、更深入地参与推理过程。

Method: 将本体感觉转换为VLM嵌入空间中的文本标记序列，并与任务指令在输入层进行早期融合。这种方法允许机器人状态参与后续的视觉推理和标记选择，偏向于动作关键证据，同时抑制冗余视觉标记。

Result: 在CALVIN、LIBERO和真实世界操作任务中，ThinkProprio匹配或超越了强基线方法，同时将端到端推理延迟降低了50%以上。文本标记化比学习投影器更有效，保留约15%的视觉标记即可达到完整标记集的性能。

Conclusion: 通过将本体感觉转换为文本标记并与指令早期融合，ThinkProprio实现了更有效的状态感知推理，显著提高了VLA模型的效率和性能，为机器人控制提供了更高效的解决方案。

Abstract: Vision-language-action (VLA) models typically inject proprioception only as a late conditioning signal, which prevents robot state from shaping instruction understanding and from influencing which visual tokens are attended throughout the policy. We introduce ThinkProprio, which converts proprioception into a sequence of text tokens in the VLM embedding space and fuses them with the task instruction at the input. This early fusion lets embodied state participate in subsequent visual reasoning and token selection, biasing computation toward action-critical evidence while suppressing redundant visual tokens. In a systematic ablation over proprioception encoding, state entry point, and action-head conditioning, we find that text tokenization is more effective than learned projectors, and that retaining roughly 15% of visual tokens can match the performance of using the full token set. Across CALVIN, LIBERO, and real-world manipulation, ThinkProprio matches or improves over strong baselines while reducing end-to-end inference latency over 50%.

</details>


### [20] [Force Generative Imitation Learning: Bridging Position Trajectory and Force Commands through Control Technique](https://arxiv.org/abs/2602.06620)
*Hiroshi Sato,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 提出了一种力生成模型，用于从给定的位置轨迹估计力指令，并引入反馈控制机制来处理未见过的位置轨迹，最终实现了在真实机器人书写任务中的泛化能力提升。


<details>
  <summary>Details</summary>
Motivation: 在接触丰富的任务中，位置轨迹容易获取，但合适的力指令通常未知。虽然可以使用预训练的基础模型（如VLA模型）生成力指令，但力控制高度依赖于机器人特定硬件，这使得此类模型的应用具有挑战性。

Method: 提出力生成模型从位置轨迹估计力指令，引入反馈控制机制处理未见轨迹，发现带记忆的模型会导致反馈控制不收敛，因此采用无记忆模型实现稳定反馈控制。

Result: 实验表明，无记忆的力生成模型结合反馈控制能够有效生成力指令，即使对于未见过的位置轨迹也能工作，提高了真实世界机器人书写任务的泛化能力。

Conclusion: 通过采用无记忆的力生成模型和反馈控制机制，成功解决了从位置轨迹生成力指令的泛化问题，为接触丰富的机器人任务提供了有效的解决方案。

Abstract: In contact-rich tasks, while position trajectories are often easy to obtain, appropriate force commands are typically unknown. Although it is conceivable to generate force commands using a pretrained foundation model such as Vision-Language-Action (VLA) models, force control is highly dependent on the specific hardware of the robot, which makes the application of such models challenging. To bridge this gap, we propose a force generative model that estimates force commands from given position trajectories. However, when dealing with unseen position trajectories, the model struggles to generate accurate force commands. To address this, we introduce a feedback control mechanism. Our experiments reveal that feedback control does not converge when the force generative model has memory. We therefore adopt a model without memory, enabling stable feedback control. This approach allows the system to generate force commands effectively, even for unseen position trajectories, improving generalization for real-world robot writing tasks.

</details>


### [21] [Humanoid Manipulation Interface: Humanoid Whole-Body Manipulation from Robot-Free Demonstrations](https://arxiv.org/abs/2602.06643)
*Ruiqian Nai,Boyuan Zheng,Junming Zhao,Haodong Zhu,Sicong Dai,Zunhao Chen,Yihang Hu,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: HuMI框架通过便携硬件采集人体全身运动数据，驱动分层学习管道，实现人形机器人多样化全身操控任务，数据采集效率比遥操作提高3倍，在未见环境中达到70%成功率。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人全身操控方法主要依赖遥操作或视觉模拟到现实的强化学习，存在硬件物流复杂和奖励工程困难的问题，导致自主技能有限且通常局限于受控环境。

Method: 提出Humanoid Manipulation Interface (HuMI)框架：1) 使用便携硬件采集丰富的全身运动数据；2) 构建分层学习管道，将人体运动转化为灵巧可行的人形机器人技能。

Result: 在五个全身任务（跪姿、蹲姿、投掷、行走和双手操作）上进行广泛实验，HuMI的数据采集效率比遥操作提高3倍，在未见环境中达到70%的成功率。

Conclusion: HuMI提供了一个便携高效的框架，能够学习多样化的全身操控任务，克服了传统方法的局限性，为人形机器人在各种环境中的自主操作提供了可行方案。

Abstract: Current approaches for humanoid whole-body manipulation, primarily relying on teleoperation or visual sim-to-real reinforcement learning, are hindered by hardware logistics and complex reward engineering. Consequently, demonstrated autonomous skills remain limited and are typically restricted to controlled environments. In this paper, we present the Humanoid Manipulation Interface (HuMI), a portable and efficient framework for learning diverse whole-body manipulation tasks across various environments. HuMI enables robot-free data collection by capturing rich whole-body motion using portable hardware. This data drives a hierarchical learning pipeline that translates human motions into dexterous and feasible humanoid skills. Extensive experiments across five whole-body tasks--including kneeling, squatting, tossing, walking, and bimanual manipulation--demonstrate that HuMI achieves a 3x increase in data collection efficiency compared to teleoperation and attains a 70% success rate in unseen environments.

</details>


### [22] [RAPID: Reconfigurable, Adaptive Platform for Iterative Design](https://arxiv.org/abs/2602.06653)
*Zi Yin,Fanhong Li,Shurui Zheng,Jia Liu*

Main category: cs.RO

TL;DR: RAPID是一个全栈可重构机器人平台，通过模块化硬件架构和软件堆栈，将多模态配置设置时间减少两个数量级，支持传感器热插拔和策略持续执行。


<details>
  <summary>Details</summary>
Motivation: 机器人操作策略开发是迭代和假设驱动的过程，但即使微小的末端执行器更改通常也需要机械重新装配和系统重新集成，这显著减慢了迭代速度。研究人员需要一种能够减少这种摩擦的平台。

Method: RAPID采用免工具模块化硬件架构，统一手持数据收集和机器人部署，配合软件堆栈通过USB事件驱动的物理掩码实时感知硬件配置。该架构支持快速重新配置和系统化多模态消融研究。

Result: 系统中心实验显示，与传统工作流程相比，RAPID将多模态配置的设置时间减少了两个数量级，并在运行时传感器热拔插事件下保持策略执行。平台支持传感器热插拔时的自动配置和优雅降级。

Conclusion: RAPID通过模块化硬件和软件堆栈显著加速了机器人操作策略的迭代开发，使研究人员能够快速探索不同的夹持器和传感配置，而无需重复的系统启动过程。硬件设计、驱动程序和软件堆栈已开源。

Abstract: Developing robotic manipulation policies is iterative and hypothesis-driven: researchers test tactile sensing, gripper geometries, and sensor placements through real-world data collection and training. Yet even minor end-effector changes often require mechanical refitting and system re-integration, slowing iteration. We present RAPID, a full-stack reconfigurable platform designed to reduce this friction. RAPID is built around a tool-free, modular hardware architecture that unifies handheld data collection and robot deployment, and a matching software stack that maintains real-time awareness of the underlying hardware configuration through a driver-level Physical Mask derived from USB events. This modular hardware architecture reduces reconfiguration to seconds and makes systematic multi-modal ablation studies practical, allowing researchers to sweep diverse gripper and sensing configurations without repeated system bring-up. The Physical Mask exposes modality presence as an explicit runtime signal, enabling auto-configuration and graceful degradation under sensor hot-plug events, so policies can continue executing when sensors are physically added or removed. System-centric experiments show that RAPID reduces the setup time for multi-modal configurations by two orders of magnitude compared to traditional workflows and preserves policy execution under runtime sensor hot-unplug events. The hardware designs, drivers, and software stack are open-sourced at https://rapid-kit.github.io/ .

</details>


### [23] [Constraint Manifold Exploration for Efficient Continuous Coverage Estimation](https://arxiv.org/abs/2602.06749)
*Robert Wilbrandt,Rüdiger Dillmann*

Main category: cs.RO

TL;DR: 提出一种基于采样的连续覆盖估计方法，用于分析工业机器人对复杂工件表面完全覆盖的可行性


<details>
  <summary>Details</summary>
Motivation: 在研磨、打磨、喷涂或检测等工业应用中，机器人需要完全覆盖工件表面并保持工具垂直于表面。虽然已有生成轨迹的方法，但缺乏分析完全表面覆盖可行性的充分方法

Method: 提出基于采样的连续覆盖估计方法，在构型空间中探索可达表面区域。定义扩展的环境构型空间来表示工具位置和方向约束，使用基于连续性的方法，采用两种不同的采样策略进行探索

Result: 通过对不同运动学和环境的全面评估，分析了方法的运行时间和效率。验证了能够准确高效地计算复杂表面在复杂环境中的表面覆盖率

Conclusion: 该方法能够准确高效地分析工业机器人对复杂工件表面完全覆盖的可行性，为自动化制造过程中的轨迹规划提供了重要的可行性分析工具

Abstract: Many automated manufacturing processes rely on industrial robot arms to move process-specific tools along workpiece surfaces. In applications like grinding, sanding, spray painting, or inspection, they need to cover a workpiece fully while keeping their tools perpendicular to its surface. While there are approaches to generate trajectories for these applications, there are no sufficient methods for analyzing the feasibility of full surface coverage. This work proposes a sampling-based approach for continuous coverage estimation that explores reachable surface regions in the configuration space. We define an extended ambient configuration space that allows for the representation of tool position and orientation constraints. A continuation-based approach is used to explore it using two different sampling strategies. A thorough evaluation across different kinematics and environments analyzes their runtime and efficiency. This validates our ability to accurately and efficiently calculate surface coverage for complex surfaces in complicated environments.

</details>


### [24] [A 26-Gram Butterfly-Inspired Robot Achieving Autonomous Tailless Flight](https://arxiv.org/abs/2602.06811)
*Weibin Gu,Chenrui Feng,Lian Liu,Chen Yang,Xingchi Jiao,Yuhe Ding,Xiaofei Shi,Chao Gao,Alessandro Rizzo,Guyue Zhou*

Main category: cs.RO

TL;DR: AirPulse是一款26克蝴蝶仿生扑翼微型飞行器，首次实现无尾双翼、无辅助控制面的全机载闭环飞行，通过扑翼调制控制姿态稳定。


<details>
  <summary>Details</summary>
Motivation: 探索无尾双翼扑翼微型飞行器的飞行控制难题，这类配置因复杂的流固耦合和翼体耦合而研究较少，但具有生物仿生优势和实际应用潜力。

Method: 设计蝴蝶仿生结构（低展弦比、碳纤维增强柔性翼、低频大幅扑动），建立扑翼调制参数与力-力矩生成的定量映射，开发STAR发生器实现平滑可参数化的扑动不对称控制，结合姿态控制器实现稳定飞行。

Result: 成功实现稳定爬升和转弯机动飞行，通过角度偏移或扑动时序调制控制姿态，这是文献报道中最轻的无尾双翼蝴蝶仿生扑翼飞行器的首次机载控制飞行。

Conclusion: 该工作为轻量化、防碰撞的扑翼微型飞行器建立了基础平台，将生物启发与实际空中机器人技术结合，适用于受限空间检查和生态监测等传统无人机难以进入的场景，同时为解码真实蝴蝶飞行原理提供了物理模型。

Abstract: Flapping-wing micro air vehicles (FWMAVs) have demonstrated remarkable bio-inspired agility, yet tailless two-winged configurations remain largely unexplored due to their complex fluid-structure and wing-body coupling. Here we present \textit{AirPulse}, a 26-gram butterfly-inspired FWMAV that achieves fully onboard, closed-loop, untethered flight without auxiliary control surfaces. The AirPulse robot replicates key biomechanical traits of butterfly flight, including low wing aspect ratio, compliant carbon-fiber-reinforced wings, and low-frequency, high-amplitude flapping that induces cyclic variations in the center of gravity and moment of inertia, producing characteristic body undulation. We establish a quantitative mapping between flapping modulation parameters and force-torque generation, and introduce the Stroke Timing Asymmetry Rhythm (STAR) generator, enabling smooth, stable, and linearly parameterized wingstroke asymmetry for flapping control. Integrating these with an attitude controller, the AirPulse robot maintains pitch and yaw stability despite strong oscillatory dynamics. Free-flight experiments demonstrate stable climbing and turning maneuvers via either angle offset or stroke timing modulation, marking the first onboard controlled flight of the lightest two-winged, tailless butterfly-inspired FWMAV reported in peer-reviewed literature. This work corroborates a foundational platform for lightweight, collision-proof FWMAVs, bridging biological inspiration with practical aerial robotics. Their non-invasive maneuverability is ideally suited for real-world applications, such as confined-space inspection and ecological monitoring, inaccessible to traditional drones, while their biomechanical fidelity provides a physical model to decode the principles underlying the erratic yet efficient flight of real butterflies.

</details>


### [25] [SURE: Safe Uncertainty-Aware Robot-Environment Interaction using Trajectory Optimization](https://arxiv.org/abs/2602.06864)
*Zhuocheng Zhang,Haizhou Zhao,Xudong Sun,Aaron M. Johnson,Majid Khadiv*

Main category: cs.RO

TL;DR: SURE：一种考虑接触时间不确定性的鲁棒轨迹优化框架，通过分支轨迹设计提高机器人接触任务的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 机器人接触交互任务中的轨迹优化面临挑战，传统方法假设确定性接触事件，限制了在实际环境中的鲁棒性和适应性

Method: 提出SURE框架，通过允许多条轨迹从可能的预碰撞状态分支，并在后续重新汇合到共享轨迹，在统一优化框架中实现鲁棒性和计算效率

Result: 在不确定墙壁位置的倒立摆平衡任务中，启用分支切换时成功率平均提高21.6%；在机械臂接鸡蛋实验中，成功率提高40%

Conclusion: SURE框架相比传统名义公式显著增强了机器人接触任务的鲁棒性，能够有效处理接触时间不确定性

Abstract: Robotic tasks involving contact interactions pose significant challenges for trajectory optimization due to discontinuous dynamics. Conventional formulations typically assume deterministic contact events, which limit robustness and adaptability in real-world settings. In this work, we propose SURE, a robust trajectory optimization framework that explicitly accounts for contact timing uncertainty. By allowing multiple trajectories to branch from possible pre-impact states and later rejoin a shared trajectory, SURE achieves both robustness and computational efficiency within a unified optimization framework. We evaluate SURE on two representative tasks with unknown impact times. In a cart-pole balancing task involving uncertain wall location, SURE achieves an average improvement of 21.6% in success rate when branch switching is enabled during control. In an egg-catching experiment using a robotic manipulator, SURE improves the success rate by 40%. These results demonstrate that SURE substantially enhances robustness compared to conventional nominal formulations.

</details>


### [26] [Consensus-based optimization (CBO): Towards Global Optimality in Robotics](https://arxiv.org/abs/2602.06868)
*Xudong Sun,Armand Jordana,Massimo Fornasier,Jalal Etesami,Majid Khadiv*

Main category: cs.RO

TL;DR: 该论文将共识优化（CBO）引入机器人学，用于解决轨迹优化问题，相比现有局部优化方法（如MPPI、CEM、CMA-ES），CBO能在温和假设下保证收敛到全局最优解。


<details>
  <summary>Details</summary>
Motivation: 现有机器人轨迹优化的零阶优化方法（如MPPI、CEM、CMA-ES）本质上是局部的，依赖于梯度估计，缺乏全局收敛保证。需要一种能保证全局最优的优化方法来解决机器人学中的挑战性轨迹优化问题。

Method: 引入共识优化（CBO）到机器人学领域，该方法基于粒子群优化思想，通过粒子间的共识形成机制实现全局优化。论文提供了理论分析，并通过三个具有挑战性的轨迹优化场景验证方法：1）简单系统的长时域问题；2）高度欠驱动系统的动态平衡问题；3）仅有终端成本的高维问题。

Result: 在所有三个挑战性场景中，CBO相比现有方法都能获得更低的成本。理论分析表明CBO在温和假设下能保证收敛到全局最优解，为机器人轨迹优化提供了新的全局优化框架。

Conclusion: CBO为机器人学中的全局轨迹优化提供了一个有前景的新框架，能够有效解决现有局部优化方法难以处理的挑战性问题，在保证全局收敛性的同时展现出良好的可扩展性。

Abstract: Zero-order optimization has recently received significant attention for designing optimal trajectories and policies for robotic systems. However, most existing methods (e.g., MPPI, CEM, and CMA-ES) are local in nature, as they rely on gradient estimation. In this paper, we introduce consensus-based optimization (CBO) to robotics, which is guaranteed to converge to a global optimum under mild assumptions. We provide theoretical analysis and illustrative examples that give intuition into the fundamental differences between CBO and existing methods. To demonstrate the scalability of CBO for robotics problems, we consider three challenging trajectory optimization scenarios: (1) a long-horizon problem for a simple system, (2) a dynamic balance problem for a highly underactuated system, and (3) a high-dimensional problem with only a terminal cost. Our results show that CBO is able to achieve lower costs with respect to existing methods on all three challenging settings. This opens a new framework to study global trajectory optimization in robotics.

</details>


### [27] [Strategizing at Speed: A Learned Model Predictive Game for Multi-Agent Drone Racing](https://arxiv.org/abs/2602.06925)
*Andrei-Carlo Papuc,Lasse Peters,Sihao Sun,Laura Ferranti,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: 该研究比较了无人机竞速中的两种规划范式：考虑交互但计算慢的MPG和快速但不考虑交互的MPC，发现MPG在中等速度下更优但在高速下因延迟而失效，为此提出了LMPG方法通过摊销计算来减少延迟，在仿真和硬件实验中均优于两种基线方法。


<details>
  <summary>Details</summary>
Motivation: 无人机竞速需要同时处理高速运动规划和多智能体战略决策，既要达到性能极限又要预测和应对竞争对手的行动。核心研究问题是：智能体在采取行动前应该进行多深层次的战略规划？这涉及到计算时间与战略深度的权衡。

Method: 研究比较了两种规划范式：模型预测博弈（MPG）和轮廓模型预测控制（MPC）。MPG寻找交互感知策略但计算时间长，MPC快速计算但不考虑交互。为克服MPG的延迟问题，提出了学习型模型预测博弈（LMPG），通过摊销模型预测博弈来减少延迟。在仿真和硬件实验中进行了头对头竞速基准测试。

Result: 实验表明：MPG在中等速度下优于MPC，但在更高速度下由于延迟而失去优势。LMPG方法在仿真和硬件实验中均优于MPG和MPC两种基线方法，成功解决了延迟问题。

Conclusion: 研究表明在无人机竞速中，战略规划的深度需要与计算延迟相平衡。LMPG通过摊销计算有效解决了这一权衡问题，在保持交互感知能力的同时减少了延迟，为高速多智能体竞速提供了有效的解决方案。

Abstract: Autonomous drone racing pushes the boundaries of high-speed motion planning and multi-agent strategic decision-making. Success in this domain requires drones not only to navigate at their limits but also to anticipate and counteract competitors' actions. In this paper, we study a fundamental question that arises in this domain: how deeply should an agent strategize before taking an action? To this end, we compare two planning paradigms: the Model Predictive Game (MPG), which finds interaction-aware strategies at the expense of longer computation times, and contouring Model Predictive Control (MPC), which computes strategies rapidly but does not reason about interactions. We perform extensive experiments to study this trade-off, revealing that MPG outperforms MPC at moderate velocities but loses its advantage at higher speeds due to latency. To address this shortcoming, we propose a Learned Model Predictive Game (LMPG) approach that amortizes model predictive gameplay to reduce latency. In both simulation and hardware experiments, we benchmark our approach against MPG and MPC in head-to-head races, finding that LMPG outperforms both baselines.

</details>
